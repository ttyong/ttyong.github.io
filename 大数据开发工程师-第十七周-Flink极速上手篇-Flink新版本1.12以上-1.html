<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<script src="https://cdn.jsdelivr.net/gh/wallleap/cdn/js/piao.js"></script>
<head>
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">
<meta name="baidu-site-verification" content="s8Pe1TBqyy">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-big-counter.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/animal_bear_panda_32px_4023_easyicon.net.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/animal_bear_panda_16px_4023_easyicon.net.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="tianyong">





  <link rel="alternate" href="/atom.xml" title="TianYong's Blog" type="application/atom+xml">






<meta name="description" content="Flink新版本1.12以上-1Flink新版本新特性介绍1234567891011121314151617181920212223242526272829303132333435下面针对Flink最近几个版本的更新的重要新特性进行汇总，帮助大家快速了解一下每个版本的差异。1：Flink 1.12版本重要新特性在DataStreamAPI 中支持批处理(批流一体化)。DataSetAPI被标">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据开发工程师-Flink新版本1.12以上-1">
<meta property="og:url" content="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-1.html">
<meta property="og:site_name" content="TianYong&#39;s Blog">
<meta property="og:description" content="Flink新版本1.12以上-1Flink新版本新特性介绍1234567891011121314151617181920212223242526272829303132333435下面针对Flink最近几个版本的更新的重要新特性进行汇总，帮助大家快速了解一下每个版本的差异。1：Flink 1.12版本重要新特性在DataStreamAPI 中支持批处理(批流一体化)。DataSetAPI被标">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311504599.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311510294.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311511091.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311511275.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311525852.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311529454.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311530588.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311530210.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311536495.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311539652.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311553801.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311554256.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311557837.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311558118.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311559880.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311600510.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311600921.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311600611.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311637004.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311642457.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011745279.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011818673.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011823622.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011827274.png">
<meta property="og:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011848126.png">
<meta property="article:published_time" content="2023-04-20T08:46:48.000Z">
<meta property="article:modified_time" content="2023-06-02T08:22:04.622Z">
<meta property="article:author" content="TTYONG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311504599.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://tianyong.fun/大数据开发工程师-第十七周-Flink极速上手篇-Flink新版本1.12以上-1.html">





  <title>大数据开发工程师-Flink新版本1.12以上-1 | TianYong's Blog</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>


<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">TianYong's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">比你优秀的人都努力，有什么理由不努力！</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>
            
            站点地图
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TTYONG">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TianYong's Blog">
    </span>

    
      <header class="post-header">
	  
	  



        
        
          <h2 class="post-title" itemprop="name headline">大数据开发工程师-Flink新版本1.12以上-1</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-04-20T16:46:48+08:00">
                2023-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/" itemprop="url" rel="index">
                    <span itemprop="name">大数据开发工程师</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  22k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  91
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <hr>
<script type="text/javascript" src="/js/src/bai.js"></script>

<h1 id="Flink新版本1-12以上-1"><a href="#Flink新版本1-12以上-1" class="headerlink" title="Flink新版本1.12以上-1"></a>Flink新版本1.12以上-1</h1><h2 id="Flink新版本新特性介绍"><a href="#Flink新版本新特性介绍" class="headerlink" title="Flink新版本新特性介绍"></a>Flink新版本新特性介绍</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">下面针对Flink最近几个版本的更新的重要新特性进行汇总，帮助大家快速了解一下每个版本的差异。</span><br><span class="line">1：Flink 1.12版本重要新特性</span><br><span class="line"></span><br><span class="line">在DataStreamAPI 中支持批处理(批流一体化)。</span><br><span class="line">DataSetAPI被标记为过时。</span><br><span class="line">针对离线计算需求，建议使用Table API和SQL，或者使用DataStreamAPI 中的批处理模式。</span><br><span class="line">增加新的DataSinkAPI。</span><br><span class="line">扩展了KafkaSQL Connector，可以支持Upsert模式。</span><br><span class="line">…</span><br><span class="line">2：Flink 1.13版本重要新特性</span><br><span class="line"></span><br><span class="line">正式弃用旧的Flink Planner。</span><br><span class="line">相关SQL日期函数的修正，解决了时区的问题。</span><br><span class="line">例如：增加了 timestamp_ltz类型。</span><br><span class="line">正式弃用 Mesos 支持。</span><br><span class="line">提升Hive SQL的兼容性。</span><br><span class="line">增强DataStream API 和 Table API 的交互。</span><br><span class="line">Flink SQL Client 的改进。</span><br><span class="line">…</span><br><span class="line">3：Flink 1.14版本重要新特性</span><br><span class="line"></span><br><span class="line">移除旧的Flink Planner，将Blink Planner作为默认实现。</span><br><span class="line">批流一体化功能的完善。</span><br><span class="line">Checkpoint机制的改进。</span><br><span class="line">性能优化与效率提升。</span><br><span class="line">Table API &amp; SQL的功能完善与升级。</span><br><span class="line">…</span><br><span class="line">4：Flink 1.15版本重要新特性</span><br><span class="line"></span><br><span class="line">批流一体化功能的进一步完善。</span><br><span class="line">针对KafkaConnector模块提供了KafkaSource和KafkaSink。</span><br><span class="line">后续会移除FlinkKafkaConsumer和FlinkKafkaProducer。</span><br><span class="line">Flink SQL中添加了对JSON相关函数的支持。</span><br><span class="line">对 Flink 的运维操作进行了简化。</span><br><span class="line">…</span><br></pre></td></tr></table></figure>

<h2 id="快速上手使用Flink1-15"><a href="#快速上手使用Flink1-15" class="headerlink" title="快速上手使用Flink1.15"></a>快速上手使用Flink1.15</h2><h3 id="开发Flink-1-15代码"><a href="#开发Flink-1-15代码" class="headerlink" title="开发Flink 1.15代码"></a>开发Flink 1.15代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">首先创建一个新的maven项目：db_flink15</span><br><span class="line">修改基础环境：</span><br><span class="line">引入scala2.12，选择本地安装的java1.8、修改编译级别为8</span><br><span class="line">在src&#x2F;main中添加scala目录</span><br><span class="line">在src&#x2F;main&#x2F;scala中创建package：com.imooc.scala</span><br><span class="line"></span><br><span class="line">引入flink相关依赖，注释掉依赖中的&lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br></pre></td></tr></table></figure>

<h4 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-streaming-scala_2.12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.15.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;&#x2F;scope&gt; --&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-clients&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.15.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;&#x2F;scope&gt; --&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- log4j的依赖 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;&#x2F;scope&gt; --&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;&#x2F;scope&gt; --&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在项目的resource目录下添加log4j.properties文件，文件内容如下：</span><br><span class="line">log4j.rootLogger&#x3D;warn,stdout</span><br><span class="line"></span><br><span class="line">log4j.appender.stdout &#x3D; org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.stdout.Target &#x3D; System.out</span><br><span class="line">log4j.appender.stdout.layout&#x3D;org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern&#x3D;%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%t] [%c] [%p] - %m%n</span><br></pre></td></tr></table></figure>

<h4 id="WordCountScala"><a href="#WordCountScala" class="headerlink" title="WordCountScala"></a>WordCountScala</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">package com.imooc.scala</span><br><span class="line"></span><br><span class="line">import org.apache.flink.api.common.RuntimeExecutionMode</span><br><span class="line">import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span><br><span class="line">import org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows</span><br><span class="line">import org.apache.flink.streaming.api.windowing.time.Time</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 单词计数案例</span><br><span class="line"> * 注意：基于最新Flink批流一体化的API开发</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">object WordCountScala &#123;</span><br><span class="line">  def main(args: Array[String]): Unit &#x3D; &#123;</span><br><span class="line">    &#x2F;&#x2F;获取执行环境</span><br><span class="line">    val env &#x3D; StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">    &#x2F;&#x2F;指定处理模式，默认支持流处理模式，也支持批处理模式。</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * STREAMING：流处理模式，默认。</span><br><span class="line">     * BATCH：批处理模式。</span><br><span class="line">     * AUTOMATIC：让系统根据数据源是否有界来自动判断是使用STREAMING还是BATCH。</span><br><span class="line">     *</span><br><span class="line">     * 建议在客户端中使用flink run提交任务的时候通过-Dexecution.runtime-mode&#x3D;BATCH指定</span><br><span class="line">     *&#x2F;</span><br><span class="line">    env.setRuntimeMode(RuntimeExecutionMode.AUTOMATIC)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;指定DataSource</span><br><span class="line">    val text &#x3D; env.socketTextStream(&quot;bigdata04&quot;, 9001)&#x2F;&#x2F;当处理模式指定为AUTOMATIC时，会按照流处理模式执行</span><br><span class="line">    &#x2F;&#x2F;val text &#x3D; env.readTextFile(&quot;D:\\data\\hello.txt&quot;)&#x2F;&#x2F;当处理模式指定为AUTOMATIC时，会按照批处理模式执行</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;指定具体的业务逻辑</span><br><span class="line">    import org.apache.flink.api.scala._</span><br><span class="line">    val wordCount &#x3D; text.flatMap(_.split(&quot; &quot;))</span><br><span class="line">      .map((_,1))</span><br><span class="line">      .keyBy(_._1)</span><br><span class="line">      &#x2F;&#x2F;针对时间窗口，目前官方建议使用window，主要是为了让用户指定窗口触发是使用处理时间 or 事件时间</span><br><span class="line">      .window(TumblingProcessingTimeWindows.of(Time.seconds(2)))</span><br><span class="line">      .sum(1)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;指定DataSink</span><br><span class="line">    wordCount.print().setParallelism(1)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;执行程序</span><br><span class="line">    env.execute(&quot;WordCountScala&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="在已有的大数据集群中集成Flink-1-15环境"><a href="#在已有的大数据集群中集成Flink-1-15环境" class="headerlink" title="在已有的大数据集群中集成Flink 1.15环境"></a>在已有的大数据集群中集成Flink 1.15环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1：下载Flink1.15版本的安装包，上传到bigdata04机器的&#x2F;data&#x2F;soft目录中。</span><br><span class="line">2：解压</span><br><span class="line">3：在·&#x2F;etc&#x2F;profile·中配置·HADOOP_CLASSPATH·环境变量</span><br><span class="line">如果之前在安装·Flink1.11·版本环境的时候配置过了，则忽略此步骤。</span><br><span class="line">[root@bigdata04 soft]# vi &#x2F;etc&#x2F;profile</span><br><span class="line">...</span><br><span class="line">export HADOOP_CLASSPATH&#x3D;&#96;$&#123;HADOOP_HOME&#125;&#x2F;bin&#x2F;hadoop classpath&#96;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">4：使用Flink中yarn-session的方式验证一下此Flink客户端是否正常</span><br><span class="line">[root@bigdata04 flink-1.15.0]# bin&#x2F;yarn-session.sh -jm 1024m -tm 1024m -d</span><br><span class="line"></span><br><span class="line">提交之后到YARN上验证一下</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311504599.png" alt="image-20230531150430359"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">任务的web界面上显示的是Flink1.15版本，说明是没有问题的。</span><br><span class="line">5：最后停止这个yarn-session</span><br></pre></td></tr></table></figure>

<h3 id="向YARN中同时提交Flink-1-11-和1-15版本的代码"><a href="#向YARN中同时提交Flink-1-11-和1-15版本的代码" class="headerlink" title="向YARN中同时提交Flink 1.11 和1.15版本的代码"></a>向YARN中同时提交Flink 1.11 和1.15版本的代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">为了便于在YARN中同时提交Flink 1.11和1.15版本的代码，我们可以参考之前在讲spark3.x版本扩展内容时候的思路，对flink1.15版本中需要用到的脚本名称进行修改，增加版本名称后缀，便于分辨和使用。</span><br><span class="line">提交代码时常用的是yarn-session.sh和flink这两个脚本，修改这两个脚本的名称</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ~]# cd &#x2F;data&#x2F;soft&#x2F;flink-1.15.0&#x2F;bin</span><br><span class="line">[root@bigdata04 bin]# mv yarn-session.sh yarn-session-1-15.sh</span><br><span class="line">[root@bigdata04 bin]# mv flink flink1-15</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">然后为了便于在任何目录中使用这些脚本，需要在&#x2F;etc&#x2F;profile中配置环境变量</span><br><span class="line"></span><br><span class="line">注意：针对之前的Flink 1.11.1版本对应的环境变量是这样的</span><br><span class="line">[root@bigdata04 bin]# vi &#x2F;etc&#x2F;profile</span><br><span class="line">...</span><br><span class="line">export FLINK_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;flink-1.11.1</span><br><span class="line">export PATH&#x3D;.:$JAVA_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$FLINK_HOME&#x2F;bin:&#x2F;data&#x2F;so</span><br><span class="line">ft&#x2F;flink-1.15.0&#x2F;bin:$SPARK_HOME&#x2F;bin:$HIVE_HOME&#x2F;bin:&#x2F;data&#x2F;soft&#x2F;spark-3.</span><br><span class="line">2.1-bin-hadoop3.2&#x2F;bin:$PATH</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">现在还需要针对Flink 1.15.0版本配置对应的环境变量，可以直接在PATH中指定即可</span><br><span class="line">[root@bigdata04 bin]# vi &#x2F;etc&#x2F;profile</span><br><span class="line">...</span><br><span class="line">export PATH&#x3D;.:$JAVA_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$FLINK_HOME&#x2F;bin:&#x2F;data&#x2F;so</span><br><span class="line">ft&#x2F;flink-1.15.0&#x2F;bin:$SPARK_HOME&#x2F;bin:$HIVE_HOME&#x2F;bin:&#x2F;data&#x2F;soft&#x2F;spark-3.</span><br><span class="line">2.1-bin-hadoop3.2&#x2F;bin:$PATH</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 bin]# source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">接下来验证这两个版本中yarn-session的使用是否正常</span><br><span class="line">1：使用flink1.11.1版本启动一个yarn-session</span><br><span class="line">[root@bigdata04 ~]# yarn-session.sh -jm 1024m -tm 1024m -d</span><br><span class="line"></span><br><span class="line">在启动窗口可以看到如下日志</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:&#x2F;data&#x2F;soft&#x2F;flink-1.11.1&#x2F;lib&#x2F;log4j-slf4j-impl-2.12.1.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:&#x2F;data&#x2F;soft&#x2F;hadoop-3.2.0&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;slf4j-log4j12-1.7.25.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这里面可以看到确实使用的是1.11.1版本。</span><br><span class="line"></span><br><span class="line">启动之后查看对应的任务页面，发现显示的是1.11.1版本</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311510294.png" alt="image-20230531151053162"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看jobmanager中的信息也可以验证是使用的1.11.1版本</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311511091.png" alt="image-20230531151114768"></p>
<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311511275.png" alt="image-20230531151148156"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">停止此任务</span><br></pre></td></tr></table></figure>

<h4 id="Flink1-15-0版本的代码"><a href="#Flink1-15-0版本的代码" class="headerlink" title="Flink1.15.0版本的代码"></a>Flink1.15.0版本的代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2：使用flink1.15.0版本启动一个yarn-session</span><br><span class="line"></span><br><span class="line">在启动窗口可以看到如下日志</span><br><span class="line">(按照上述步骤验证)</span><br><span class="line"></span><br><span class="line">停止此任务</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">3：配置Flink 1.15的historyserver</span><br><span class="line">目前任务停止后无法查看任务界面，需要配置并开启flink的historyserver</span><br><span class="line">之前针对flink 1.11.1版本我们已经配置过historyserver了，在这里先把他的historyserver服务启动起来。</span><br><span class="line">[root@bigdata04 flink-1.11.1]# bin&#x2F;historyserver.sh start</span><br><span class="line"></span><br><span class="line">注意：针对Flink的每个版本都需要启动一个对应的historyserver服务，如果一个客户端节点上部署了多个flink的版本，则需要启动多个historyserver服务。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">可以选择在一个节点上启动多个Flink版本的historyserver服务，也可以选择把多个historyserver服务放到多个不同的节点上。</span><br><span class="line">如果是在一个节点上启动多个historyserver服务，则需要修改historyserver服务的端口，每个historyserver服务使用一个独立的端口。</span><br><span class="line"></span><br><span class="line">在这里需要修改flink 1.15版本的相关配置</span><br><span class="line">修改flink 1.15中conf目录下的flink-conf.yaml配置文件，内容如下：</span><br><span class="line">[root@bigdata04 conf]# vi flink-conf.yaml </span><br><span class="line">...</span><br><span class="line">jobmanager.archive.fs.dir: hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;completed-jobs-1-15&#x2F;</span><br><span class="line">historyserver.web.address: bigdata04</span><br><span class="line">historyserver.web.port: 8083</span><br><span class="line">historyserver.archive.fs.dir: hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;completed-jobs-1-15&#x2F;</span><br><span class="line">historyserver.archive.fs.refresh-interval: 10000</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注意：在这里针对flink1.15版本使用的historyserver端口是8083，flink1.11.1使用的是8082。</span><br><span class="line"></span><br><span class="line">还有就是flink1.15版本使用的hdfs路径也改了一下，使用的是completed-jobs-1-15，不要和flink1.11.1版本使用相同的路径，否则后期会出现错乱。</span><br><span class="line"></span><br><span class="line">再启动flink1.15中的historyserver服务</span><br><span class="line">[root@bigdata04 flink-1.15.0]# bin&#x2F;historyserver.sh start</span><br><span class="line">[INFO] 1 instance(s) of historyserver are already running on bigdata04.</span><br><span class="line">Starting historyserver daemon on host bigdata04.</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">在启动的时候会提示在这个节点上已经成功启动了一个historyserver，不要紧， 通过jps验证一下这个是否启动成功。</span><br><span class="line">[root@bigdata04 flink-1.15.0]# jps</span><br><span class="line">2289 HistoryServer</span><br><span class="line">3650 HistoryServer</span><br><span class="line"></span><br><span class="line">发现有两个HistoryServer，具体哪个是Flink1.15启动的，可以使用jps -ml查看</span><br><span class="line">[root@bigdata04 flink-1.15.0]# jps -ml</span><br><span class="line">2289 org.apache.flink.runtime.webmonitor.history.HistoryServer --configDir &#x2F;data&#x2F;soft&#x2F;flink-1.11.1&#x2F;conf</span><br><span class="line">3650 org.apache.flink.runtime.webmonitor.history.HistoryServer --configDir &#x2F;data&#x2F;soft&#x2F;flink-1.15.0&#x2F;conf</span><br><span class="line">4067 sun.tools.jps.Jps -ml</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">还需要启动Hadoop集群的historyserver服务。</span><br><span class="line">在bigdata01上执行。</span><br><span class="line">[root@bigdata01 hadoop-3.2.0]# bin&#x2F;mapred --daemon start historyserver</span><br><span class="line"></span><br><span class="line">在bigdata02上执行。</span><br><span class="line">[root@bigdata02 hadoop-3.2.0]# bin&#x2F;mapred --daemon start historyserver</span><br><span class="line"></span><br><span class="line">在bigdata03上执行。</span><br><span class="line">[root@bigdata03 hadoop-3.2.0]# bin&#x2F;mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">4：向YARN集群中正式提交Flink1.15.0版本的代码</span><br><span class="line">基于前面刚开发的代码进行打包，打包之前需要在pom.xml中先添加编译和打包的配置</span><br><span class="line"></span><br><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;!-- 编译插件 --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;3.6.0&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;source&gt;1.8&lt;&#x2F;source&gt;</span><br><span class="line">                &lt;target&gt;1.8&lt;&#x2F;target&gt;</span><br><span class="line">                &lt;encoding&gt;UTF-8&lt;&#x2F;encoding&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        &lt;!-- scala编译插件 --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;net.alchim31.maven&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;scala-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;3.1.6&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;scalaCompatVersion&gt;2.12&lt;&#x2F;scalaCompatVersion&gt;</span><br><span class="line">                &lt;scalaVersion&gt;2.12.11&lt;&#x2F;scalaVersion&gt;</span><br><span class="line">                &lt;encoding&gt;UTF-8&lt;&#x2F;encoding&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">            &lt;executions&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;id&gt;compile-scala&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;phase&gt;compile&lt;&#x2F;phase&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;add-source&lt;&#x2F;goal&gt;</span><br><span class="line">                        &lt;goal&gt;compile&lt;&#x2F;goal&gt;</span><br><span class="line">                    &lt;&#x2F;goals&gt;</span><br><span class="line">                &lt;&#x2F;execution&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;id&gt;test-compile-scala&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;phase&gt;test-compile&lt;&#x2F;phase&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;add-source&lt;&#x2F;goal&gt;</span><br><span class="line">                        &lt;goal&gt;testCompile&lt;&#x2F;goal&gt;</span><br><span class="line">                    &lt;&#x2F;goals&gt;</span><br><span class="line">                &lt;&#x2F;execution&gt;</span><br><span class="line">            &lt;&#x2F;executions&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        &lt;!-- 打jar包插件(会包含所有依赖) --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-assembly-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.6&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;descriptorRefs&gt;</span><br><span class="line">                    &lt;descriptorRef&gt;jar-with-dependencies&lt;&#x2F;descriptorRef&gt;</span><br><span class="line">                &lt;&#x2F;descriptorRefs&gt;</span><br><span class="line">                &lt;archive&gt;</span><br><span class="line">                    &lt;manifest&gt;</span><br><span class="line">                        &lt;!-- 可以设置jar包的入口类(可选) --&gt;</span><br><span class="line">                        &lt;mainClass&gt;&lt;&#x2F;mainClass&gt;</span><br><span class="line">                    &lt;&#x2F;manifest&gt;</span><br><span class="line">                &lt;&#x2F;archive&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">            &lt;executions&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;id&gt;make-assembly&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;phase&gt;package&lt;&#x2F;phase&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;single&lt;&#x2F;goal&gt;</span><br><span class="line">                    &lt;&#x2F;goals&gt;</span><br><span class="line">                &lt;&#x2F;execution&gt;</span><br><span class="line">            &lt;&#x2F;executions&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">    &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">修改已有依赖的scope配置，全部设置为provided</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-streaming-scala_2.12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.15.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-clients&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.15.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;!-- log4j的依赖 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">执行打包操作</span><br><span class="line"></span><br><span class="line">启动socket服务</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line"></span><br><span class="line">将jar包上传到flink1.15目录下，然后使用flink run命令提交任务</span><br><span class="line">[root@bigdata04 flink-1.15.0]# flink1-15 run -m yarn-cluster  -c com.imooc.scala.WordCountScala -yjm 1024 -ytm 1024 db_flink15-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">a b</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311525852.png" alt="image-20230531152500101"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">停止后任务后再去查看任务界面发现也是可以的。</span><br><span class="line"></span><br><span class="line">注意：任务停止后需要稍微等一会才可以在这里刷新出来任务列表。</span><br></pre></td></tr></table></figure>

<h4 id="Flink1-11-1版本的代码"><a href="#Flink1-11-1版本的代码" class="headerlink" title="Flink1.11.1版本的代码"></a>Flink1.11.1版本的代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">5：向YARN集群中正式提交Flink1.11.1版本的代码</span><br><span class="line"></span><br><span class="line">接下来验证一下Flink1.11.1版本的代码是否正常。</span><br><span class="line">基于之前开发的代码重新打包，上传到bigdata04中的flink1.11.1目录中</span><br><span class="line"></span><br><span class="line">注意：需要将里面的依赖的scope暂时都设置为provided。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">启动socket服务</span><br><span class="line"></span><br><span class="line">提交任务</span><br><span class="line">[root@bigdata04 flink-1.11.1]# flink run -m yarn-cluster  -c com.imooc.scala.stream.SocketWindowWordCountScala -yjm 1024 -ytm 1024 db_flink-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br><span class="line"></span><br><span class="line">模拟生成数据</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311529454.png" alt="image-20230531152920001"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">停止后任务后再去查看任务界面发现也是可以的。</span><br><span class="line"></span><br><span class="line">注意：任务停止后需要稍微等一会才可以在这里刷新出来任务列表。</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311530588.png" alt="image-20230531153010268"></p>
<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311530210.png" alt="image-20230531153022755"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">到这为止，bigdata04客户端节点中可以同时支持提交flink1.11和1.15版本的代码。</span><br></pre></td></tr></table></figure>

<h2 id="Flink-1-15之State-状态-的容错与一致性"><a href="#Flink-1-15之State-状态-的容错与一致性" class="headerlink" title="Flink 1.15之State(状态)的容错与一致性"></a>Flink 1.15之State(状态)的容错与一致性</h2><h3 id="什么是State-状态"><a href="#什么是State-状态" class="headerlink" title="什么是State(状态)"></a>什么是State(状态)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">State中文翻译为状态。</span><br><span class="line"></span><br><span class="line">在Flink流计算中的某些业务场景下，状态是非常重要的。</span><br><span class="line">那下面我们首先来分析一下到底什么是状态。</span><br><span class="line"></span><br><span class="line">比较官方一点的定义是这样的：当前流计算任务执行过程中需要用到之前的数据，那么之前的数据就可以称之为状态。</span><br><span class="line"></span><br><span class="line">所以说针对流计算任务中的状态其实可以理解为历史流数据。</span><br><span class="line"></span><br><span class="line">举个生活中的例子：我们每个人的大脑中存储的昨天、前天的信息也可以认为是状态。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">状态在代码层面的体现其实就是一种存储数据的数据结构。类似于Java中的list、map之类的数据结构。</span><br><span class="line"></span><br><span class="line">它的出现主要是为了解决流(实时)计算中的两大问题：</span><br><span class="line">第一个问题：解决流计算中需要使用历史流数据的问题</span><br><span class="line">例如一些流计算的去重场景，当然也可以借助于外部存储系统来实现去重。</span><br><span class="line">状态的引入可以实现不依赖外部存储系统来存储中间数据，最终实现去重操作。</span><br><span class="line"></span><br><span class="line">第二个问题：解决流计算中数据一致性的问题(单纯使用状态是解决不了的，需要结合Checkpoint机制一起实现)</span><br><span class="line">例如金融数据的流计算场景，对结果的准确度要求比较高，需要保证任务故障重启后结果数据依然是准确的，不能出现重复或者丢失数据的情况。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">下面来通过两个图加深一下理解</span><br><span class="line"></span><br><span class="line">第一个图</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311536495.png" alt="image-20230531153628847"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">这个图里面显示了Flink实现流计算去重的业务流程，source组件接入实时数据流，中间在具体的算子中对实时数据进行去重，这里借助于State实现去重，也就是将source传输过来的数据存储到State中，只保留不重复的数据，最后通过Sink组件将需要的结果数据写出去。</span><br><span class="line"></span><br><span class="line">刚才我们说了，这里其实也可以通过外部存储系统来实现去重</span><br><span class="line">例如：我们可以通过redis实现数据去重的效果，这样其实也是可以的，但是有点大材小用了，引入外部存储系统会增加Flink任务的复杂度，使用State这个轻量级解决方案是比较合适的。</span><br><span class="line"></span><br><span class="line">大家可能还有一个疑问，针对这里实现的去重功能，我在Flink中直接new一个基于内存的set集合来存储历史接收到的数据，是不是也可以实现数据去重的效果？</span><br><span class="line">是可以的，这样也可以实现数据去重的效果，但是如果任务发生了异常，重启之后基于内存的set集合中的数据就没了，这样会导致任务重启后数据无法恢复到之前的样子。</span><br><span class="line"></span><br><span class="line">state中存储的数据默认也是存放在内存中的，不过state借助于checkpoint机制可以将内存中的数据持久化到HDFS中，这样可以实现任务重启后State数据的恢复。</span><br><span class="line"></span><br><span class="line">接下来来看一下第二个图</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311539652.png" alt="image-20230531153924351"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">这个图里面显示了Flink在对金融数据实现实时累加求和时的业务场景，source组件对接的是kafka中的数据，中间通过算子实现数据累加求和，将聚合后的结果数据存储到State中，最终通过sink组件将聚合后的结果写出去。</span><br><span class="line">为了保证数据累加求和计算任务失败重启后数据的准确性，除了需要在State中维护每次累加求和的中间结果，还需要维护消费者对应的offset偏移量信息。</span><br><span class="line"></span><br><span class="line">在这个图里面</span><br><span class="line">当Source组件消费到第1条数据1的时候，此时offset偏移量会等于1，后面的算子接收到第1条数据1的时候会进行累加求和，产生的结果还是1。此时Source组件会在State中写入offset&#x3D;1，同时算子也会在State中写入累加后的结果1。假设这个时候触发了checkpoint操作，那么就会把State中存储的数据持久化到HDFS中，便于后期使用。</span><br><span class="line"></span><br><span class="line">当Source组件消费到第2条数据3的时候，此时offset偏移量会等于2，后面的算子接收到第2条数据3的时候会和上次的结果累加求和，所以产生的结果是1+3&#x3D;4。此时Source组件会在State中写入offset&#x3D;2，同时算子也会在State中写入累加后的结果4。假设这个时候也触发了checkpoint操作，也会把State中存储的数据持久化到HDFS中。</span><br><span class="line"></span><br><span class="line">当Source组件消费到第3条数据5的时候，此时offset偏移量会等于3，后面的算子接收到第3条数据5的时候会和上次的结果累加求和，所以产生的结果是4+5&#x3D;9。此时Source组件会在State中写入offset&#x3D;3，同时算子也会在State中写入累加后的结果9。假设这个时候也触发了checkpoint操作，也会把State中存储的数据持久化到HDFS中。</span><br><span class="line"></span><br><span class="line">后面再来新数据的话也是按照这个流程去执行。</span><br><span class="line"></span><br><span class="line">如果Flink任务将第4条数据消费出来了，并且发送到后面的算子中进行计算，但是在计算的时候却由于网络异常出现了问题，导致任务异常停止，当网络恢复正常后，我们重启任务，此时可以基于上一次checkpoint持久化的数据恢复任务中的State。这样就可以将消费者的offset重置为3，算子中累加的结果重置为9，接下来继续正常消费第4条数据进行计算，这样就可以保证数据的准确性了。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：如果我们使用的是Java中的map、list之类数据结构来存储offset偏移量和算子的中间结果，checkpoint的时候无法将这些数据持久化到HDFS中，只有State中的数据才可以，这是Flink框架默认实现的机制，并不是所有的数据都可以被checkpoint持久化的，正因为如此，我们才需要使用State。</span><br></pre></td></tr></table></figure>

<h3 id="离线计算是否需要State-状态-？"><a href="#离线计算是否需要State-状态-？" class="headerlink" title="离线计算是否需要State(状态)？"></a>离线计算是否需要State(状态)？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">在离线计算的时候我们没有提到过状态，但是在实时计算中却经常提到状态，这是为什么？</span><br><span class="line"></span><br><span class="line">状态主要是为了保存历史数据，并且保证结果数据的一致性。</span><br><span class="line"></span><br><span class="line">针对离线计算，所有历史数据都已经到了，不需要单独保存，如果在离线计算中任务失败了，重跑一遍程序就可以了，基本上没有影响。所以可以认为离线计算是不需要维护状态的。</span><br><span class="line"></span><br><span class="line">但是针对实时计算，数据是源源不断产生的，实时计算任务是7x24小时执行的，如果实时计算任务失败了，想要恢复数据，总不能从头再重新计算一遍把，这样肯定是不现实的。就算数据源是Kafka，支持重跑数据，但是这个任务可能已经运行了很多天了，重新把之前的数据再计算一遍也需要消耗很长时间，这样在数据时效层面上来说也是不合理的，因为这个数据恢复时间太长了。</span><br><span class="line">如果数据源是基于socket的，任务失败的时候还会导致数据丢失。</span><br><span class="line"></span><br><span class="line">所以说实时计算任务失败之后可能会导致源数据、以及中间结果数据丢失，这个时候想要在一定时效内保证数据的准确性就需要借助于状态实现了。</span><br></pre></td></tr></table></figure>

<h3 id="State相关概念整体概览"><a href="#State相关概念整体概览" class="headerlink" title="State相关概念整体概览"></a>State相关概念整体概览</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">State涉及的相关概念比较多，所以在这里我们首先从全局层面分析一下这些概念，这样可以构建一个全局观，便于后面的深入理解。</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311553801.png" alt="image-20230531155313232"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">首先看图里面蓝色的方框，主要包括JobManager和TaskManager。</span><br><span class="line">JobManager对应的是Flink集群的主节点，TaskManager对应的是Flink集群的从节点。</span><br><span class="line"></span><br><span class="line">假设我们向Flink集群中提交了一个流计算任务，这个任务中包含了Source、Map、和Sink这三块。</span><br><span class="line">其中Source是负责从Kafka中消费数据的，为了保证任务重启后的数据准确性，Source组件会把消费到的Offset偏移量数据保存到State中。</span><br><span class="line">Map算子会把计算的中间结果也保存到State中，Sink也会把某些数据保存到State中，这样可以便于后期的数据恢复，保证数据的准确性。</span><br><span class="line"></span><br><span class="line">默认情况下，Source、Map、和Sink写入到State中的数据会存储在TaskManager节点中的JVM堆内存中。</span><br><span class="line">当然官方也可以支持将这些State数据存储到Rocksdb这个内嵌数据库中，Rocksdb数据库中的数据会存储在对应节点的本地磁盘文件中。</span><br><span class="line"></span><br><span class="line">当满足一定时机的情况下，Flink任务会触发checkpoint操作，当执行checkpoint操作的时候，会将默认存储在TaskManager节点JVM堆内存中的State数据保存到另外一个地方，这个地方可以是JobManager的JVM堆内存中，也可以是分布式文件系统中(例如HDFS)。</span><br><span class="line"></span><br><span class="line">初始的State数据的存储位置是由State Backend这个功能控制的。</span><br><span class="line">checkpoint时State数据的存储位置是由checkpoint storage这个功能控制的。</span><br><span class="line"></span><br><span class="line">这就是涉及到状态的Flink任务的整体执行流程以及checkpoint时的流程，在这大家先有一个初步的了解，这里面的细节内容后面我们会进一步详细分析。</span><br></pre></td></tr></table></figure>

<h3 id="State-状态-的类型"><a href="#State-状态-的类型" class="headerlink" title="State(状态)的类型"></a>State(状态)的类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">前面我们对状态有了基本的了解，其实状态对应的就是数据，这些数据会涉及到存储和恢复。</span><br><span class="line">任务正常运行的时候会向状态中写入数据，在任务重启时会涉及到状态的恢复。</span><br><span class="line"></span><br><span class="line">Flink从管理层面对这些状态进行了划分，大致划分出两种类型的状态：</span><br><span class="line">一种是Raw State，中文翻译为原生状态</span><br><span class="line">另外一种是Managed State，中文翻译为托管状态。</span><br></pre></td></tr></table></figure>

<h3 id="Raw-State-VS-Managed-State"><a href="#Raw-State-VS-Managed-State" class="headerlink" title="Raw State VS Managed State"></a>Raw State VS Managed State</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这两种类型的状态有什么区别吗？</span><br><span class="line">下面我们来详细分析一下，看这个表格：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311554256.png" alt="image-20230531155439184"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">在这里会从3个角度进行分析：</span><br><span class="line">1：从管理方式这个角度上进行分析</span><br><span class="line">原生状态是需要开发者自己管理的，需要自己实现数据的序列化。</span><br><span class="line"></span><br><span class="line">而托管状态是由Flink Runtime进行托管管理的，Flink已经实现好了存储和恢复这些功能，不需要我们自己实现序列化。</span><br><span class="line">从这里可以看出来，原生状态需要自己实现相关的功能，使用起来比较复杂。而托管状态已经被封装好了，使用起来比较方便。</span><br><span class="line"></span><br><span class="line">2：从数据结构这个角度上进行分析</span><br><span class="line">原生状态只支持字节数组类型，而托管状态则支持多种数据结构，例如：MapState、ListState、ValueState等。</span><br><span class="line">从这里可以看出来原生状态支持的是最基础的数据类型，比较灵活。而托管状态主要支持常见的数据类型。不过托管状态中支持的那些常见的数据类型在工作中其实已经足够使用了。</span><br><span class="line"></span><br><span class="line">3：从使用场景这个角度上进行分析</span><br><span class="line">原生状态主要在自定义Operator时使用，Operator是DataSource、Transform、以及DataSink这三块的统称。而托管状态在所有数据流场景中都是可以使用的，也就是说托管状态的应用场景是包含了原生状态的应用场景。</span><br><span class="line"></span><br><span class="line">这就是原生状态和托管状态的区别。</span><br><span class="line">在实际工作中，基本上只会用到托管状态，而不会用到原生状态。</span><br><span class="line"></span><br><span class="line">所以后面我们主要分析托管状态的使用。</span><br></pre></td></tr></table></figure>

<h4 id="托管状态-Managed-State-的类型"><a href="#托管状态-Managed-State-的类型" class="headerlink" title="托管状态(Managed State)的类型"></a>托管状态(Managed State)的类型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">针对托管状态，从作用域层面进行划分，还可以再细分为两种类型：</span><br><span class="line">一种是keyed State，还有一种是Operator State。</span><br><span class="line"></span><br><span class="line">这两种类型的State中支持的数据结构是不一样的，来看一下这个表格</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311557837.png" alt="image-20230531155737405"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keyed State可以支持ValueState、ListState、ReducingState、AggregatingState、MapState这5种数据结构，这些数据结构也可以称为原语，原语是一个官方名词，不太好理解，我还是喜欢将它称为是数据结构。</span><br><span class="line">从名字上可以看出来，ListState其实就相当于是一个List列表了，MapState相当于是一个Map集合，具体这些数据类型的使用后面我们再具体分析，在这里先有个基本认识就可以了。</span><br><span class="line"></span><br><span class="line">Operator State可以支持ListState、UnionListState和BroadcastState这3种数据结构。</span><br></pre></td></tr></table></figure>

<h5 id="Keyed-State-VS-Operator-State"><a href="#Keyed-State-VS-Operator-State" class="headerlink" title="Keyed State VS Operator State"></a>Keyed State VS Operator State</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Keyed State和Operator State除了在支持的数据结构层面有区别，还有一些其他的区别，看这个表格：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311558118.png" alt="image-20230531155849233"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">在这里会从4个角度进行分析：</span><br><span class="line">1：从State使用场景这个角度上进行分析</span><br><span class="line">针对Keyed State，它只能应用在基于KeyedStream的数据流中，在Flink中，普通的数据流是DataStream，在DataStream后面调用keyBy算子之后，返回的就是KeyedStream数据流，那也就是说Keyed State只能应用在做过keyBy之后的数据流里面。</span><br><span class="line"></span><br><span class="line">而Operator State可以应用在所有数据流中，包括keyedStream。</span><br><span class="line"></span><br><span class="line">2：从State分配方式这个角度上进行分析</span><br><span class="line">针对Keyed State，因为是基于key进行分组的数据流，相同key的数据会进入到同一个子任务中被处理，此时每个相同的Key共享一个State实例。</span><br><span class="line"></span><br><span class="line">针对Operator State，需要兼容所有类型的数据流，所以此时算子的同一个子任务共享一个State实例，和key无关。</span><br><span class="line"></span><br><span class="line">3：从State创建方式这个角度上进行分析</span><br><span class="line">针对Keyed State，需要借助于getRuntimeContext这个对象来创建。</span><br><span class="line">针对Operator State，需要借助于context这个对象来创建。</span><br><span class="line"></span><br><span class="line">4：从State扩缩容模式这个角度上进行分析</span><br><span class="line">什么是扩缩容模式？</span><br><span class="line">通俗一点来说，其实就是在任务故障后恢复的时候，算子的并行度发生了变化，可能增加了并行度，或者减少了并行度。</span><br><span class="line">针对无状态的算子，扩缩容很容易，没有什么影响。</span><br><span class="line">但是针对有状态的算子，并行度发生改变之后，状态在恢复的时候会涉及到重新分组，需要将状态数据分配到和之前数量不相等的算子任务中。</span><br><span class="line"></span><br><span class="line">针对Keyed State，它会以KeyGroup为单位重新分配状态数据，KeyGroup其实就是包含了多个key的一个分组。</span><br><span class="line">针对Operator State，它会均匀分配状态数据，或者是广播分配，具体要看你使用的是哪种数据类型了。</span><br></pre></td></tr></table></figure>

<h6 id="Keyed-State类型的状态的扩缩容模式"><a href="#Keyed-State类型的状态的扩缩容模式" class="headerlink" title="Keyed State类型的状态的扩缩容模式"></a>Keyed State类型的状态的扩缩容模式</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">针对扩缩容模式，下面有几个图，我们来看一下，详细分析一下</span><br><span class="line"></span><br><span class="line">首先是针对Keyed State类型的状态的扩缩容模式</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311559880.png" alt="image-20230531155938701"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">图中左边的task1和task2表示是keyBy后面连接的某个算子的2个并行实例，表示这个算子的并行度为2。</span><br><span class="line">中间的 task1 、task2和task3表示任务重启后，将keyBy后面那个算子的并行度改为了3。</span><br><span class="line">右边的task1表示是任务又一次重启后，将keyBy后面那个算子的并行度又改为了1。</span><br><span class="line">这个图里面显示的是Flink任务中的同一个算子，在任务重启后，算子并行度发生变化时状态的分配情况。</span><br><span class="line"></span><br><span class="line">基于Keyed State类型状态的算子在扩缩容时会根据新的算子并行度数量对状态重新分配，不过为了降低状态数据在不同任务之间的迁移成本，Flink对这些状态做了分组，会按照所有状态的key进行分组，划分成多个keyGroup，每个keyGroup内部包含一部分key的状态，以keyGroup为单位重新分配状态数据。</span><br><span class="line"></span><br><span class="line">在这个图里面最开始算子的并行度为2，会产生2个task，task1和task2。其中task1里面的k1和k3这两个key的状态被划分到了一个keyGroup，k5和k7这两个key的状态被划分到了一个keyGroup，k9和k11这两个key的状态被划分到了一个keyGroup。</span><br><span class="line">Task2里面也是类似这样的效果，也划分出了一些keyGroup。</span><br><span class="line"></span><br><span class="line">此时当这个任务异常结束，重新启动的时候，我们对这个算子的并行度进行了调整，改成了3，相当于增加了并行度。此时这个算子在运行时会产生3个task，分别是这里面的task1 、task2和task3。</span><br><span class="line">这个时候在对状态数据进行恢复的时候就需要将之前2个task产生的状态数据恢复到最新的3个task中，如图所示，这些状态数据会按照keyGroup为单位分配到这3个task中。</span><br><span class="line"></span><br><span class="line">当任务重启运行了一段时间之后，由于某些异常情况导致任务又停止了，重启再启动的时候，我们将算子的并行度改为了1，相当于减少了并行度。此时这个算子在运行时只会产生1个task。</span><br><span class="line">这个时候在对状态数据进行恢复的时候就需要将之前3个task产生的状态数据恢复到这1个task中，如图所示，这些状态数据会按照keyGroup为单位分配到这1个task中。</span><br><span class="line"></span><br><span class="line">这就是Keyed State类型的状态在任务重启并行度发生了变化时状态的分配方式。</span><br></pre></td></tr></table></figure>

<h6 id="Operator-State类型的状态的扩缩容模式"><a href="#Operator-State类型的状态的扩缩容模式" class="headerlink" title="Operator State类型的状态的扩缩容模式"></a>Operator State类型的状态的扩缩容模式</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看一下Operator State类型的状态的扩缩容模式，</span><br><span class="line">在这里需要针对Operator State中的不同数据结构进行单独分析：</span><br><span class="line"></span><br><span class="line">首先是Operator State中的ListState，看这个图：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311600510.png" alt="image-20230531160009335"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如果算子中使用了Operator State类型中的ListState这种状态，那么算子在扩缩容时会对ListState中的数据重新分配。</span><br><span class="line">大致流程是这样的：这个算子的所有并行运行的task中的ListState数据会被统一收集起来，然后均匀分配给更多的task或者更少的task。</span><br><span class="line"></span><br><span class="line">最开始这些ListState中的状态数据在2个task中维护。</span><br><span class="line">后面任务重启，并行度变成3以后，会将之前的状态数据分配给这3个task。</span><br><span class="line">当后面任务重启，并行度变成1以后，会将之前的状态数据都分配这1个task。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接下来是针对Operator State中的UnionListState，看这个图：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311600921.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">UnionListState底层其实就是ListState，唯一的区别就是在扩缩容时状态数据的分配策略不一样。</span><br><span class="line">UnionListState会在扩缩容时把里面的所有状态数据全部广播发送给新任务。</span><br><span class="line">最开始这些状态数据在2个task中维护。</span><br><span class="line">后面任务重启，并行度变成3以后，之前task1和task2维护的状态数据都会分配给这3个task。</span><br><span class="line">当后面任务重启，并行度变成1以后，前面3个task都会将自己维护的数据分配给这1个task。</span><br><span class="line">所以针对UnionListState这种方式，任务重启恢复状态数据的时候，每个子任务都会收到所有的数据，但是这个子任务可以根据一定的策略选择操作部分状态数据。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最后一个是Operator State中的BroadcastState，看这个图：</span><br></pre></td></tr></table></figure>



<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311600611.png" alt="image-20230531160052830"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BroadcastState在扩缩容时会把状态广播发送给所有的新任务。</span><br><span class="line">那这种方式和UnionListState有什么区别？</span><br><span class="line">针对UnionListState这种方式，假设算子A的并行度为2，那么会产生2个task，这2个task中维护的状态数据是不一样的，当任务重启之后，如果并行度发生了变化，那么算子A的每个子任务都可以接收到之前2个task中维护的状态数据。</span><br><span class="line"></span><br><span class="line">针对BroadcastState这种方式，假设算子A的并行度为2，那么这2个task中的数据是完全一样的，当任务重启之后，如果并行度增加了，只需要基于某一个task中的状态数据复制到新的task中即可。如果任务重启后并行度减少了，只需要简单的去掉多余的task即可。</span><br></pre></td></tr></table></figure>

<h5 id="Keyed-State详解"><a href="#Keyed-State详解" class="headerlink" title="Keyed State详解"></a>Keyed State详解</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">首先看一下针对Keyed State的解释</span><br><span class="line">Keyed State是基于KeyedStream上的状态，在普通数据流后面调用keyBy之后可以获取到一个KeyedStream数据流。</span><br><span class="line">此时状态是和特定的key绑定的。</span><br><span class="line"></span><br><span class="line">针对KeyedStream上的每个Key，Flink都会维护一个状态实例。</span><br><span class="line"></span><br><span class="line">看一下下面这个图，加深一下理解</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311637004.png" alt="image-20230531163721767"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">图中左边的Source表示是数据源，这个组件的并行度为2，所以Source产生了2个task。</span><br><span class="line">右边的Stateful表示是有状态的算子，这个算子的并行度也是2，所以也产生了2个task。</span><br><span class="line"></span><br><span class="line">假如数据源按照ID这个列作为Key进行了keyBy分组，形成了一个KeyedStream数据流，其中ID的值为A\B\C\D这种英文字母。</span><br><span class="line">此时这个数据流中所有ID为A的key共享一个状态，可以访问和更新这个状态，以此类推，每个Key对应一个自己的状态。</span><br><span class="line"></span><br><span class="line">在这个图里面Stateful 1这个task实例维护了A\B\Y这些key的状态数据。Stateful 2这个task实例维护了D\E\Z这些key的状态数据。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意了：无论是Keyed State还是Operator State，Flink的状态都是基于本地的，也就是说每个算子子任务维护着这个子任务对应的状态存储，子任务之间的状态不支持互相访问。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在这个图里面，Stateful 1和Stateful 2这两个子任务虽然都属于同一个算子，但是他们是2个独立的子任务，所以这2个子任务之间的状态数据也是不支持互相访问的。</span><br></pre></td></tr></table></figure>

<h5 id="Keyed-State中支持的数据结构"><a href="#Keyed-State中支持的数据结构" class="headerlink" title="Keyed State中支持的数据结构"></a>Keyed State中支持的数据结构</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来具体分析一下Keyed State中支持的常见数据结构，也可以称之为状态的原语。</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305311642457.png" alt="image-20230531164250345"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ValueState:存储类型为T的单值状态，T是一个泛型。这个状态与对应的key绑定，是最简单的状态了。它里面可以存储任意类型的值，这个值也可以是一个复杂数据结构。它可以通过update方法更新状态的值，通过value()方法获取状态值。</span><br><span class="line"></span><br><span class="line">ListState:表示是一个列表状态，列表里面存储多个类型为T的元素。可以通过add方法往列表中添加数据；也可以通过get()方法返回一个Iterable列表来遍历状态数据。</span><br><span class="line"></span><br><span class="line">ReducingState:存储一个聚合后类型为T的单值状态，这种状态通过用户传入的reduceFunction，每次调用add方法添加值的时候，会调用reduceFunction，最后合并到一个单一的状态值，有点类似于ValueState，都是存储单个数值的。</span><br><span class="line"></span><br><span class="line">AggregatingState&lt;IN , OUT&gt;：存储一个聚合后类型为OUT的单值状态，它和ReducingState的区别是ReducingState在聚合时接收的数据类型和最终产生的聚合结果数据类型是一致的。但是AggregatingState在聚合时接收的数据类型和最终产生的聚合结果数据类型可以不一样，AggregatingState里面使用了两个泛型，IN代表聚合时传入的数据类型，OUT表示最终产生的结果数据类型。</span><br><span class="line"></span><br><span class="line">MapState&lt;UK, UV&gt;:可以存储key-value类型的多个元素，key和value可以是任何类型。用户可以通过put或putAll方法添加元素。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在这需要注意一点：我们前面分析的这些State对象，只是用于和状态进行交互(例如：更新、删除、清空、查询等操作)，真正的状态值，有可能是存储在内存中，也可能是rocksdb对应的本地磁盘中，相当于我们只是持有了状态的句柄。</span><br><span class="line"></span><br><span class="line">类似于我们在Java中new了一个对象a1，这个a1只是一个引用，真正的对象是存储在JVM堆内存中的，a1只是持有了这个对象在堆内存中的内存地址值。</span><br><span class="line"></span><br><span class="line">在实际工作中，其实最常用的State就是keyed State，keyed State中最常用的其实主要是ValueState、ListState和MapState这3个。</span><br><span class="line"></span><br><span class="line">其它State很少用，包括后面我们要讲到的Operator State。</span><br></pre></td></tr></table></figure>

<h5 id="Keyed-State的使用案例"><a href="#Keyed-State的使用案例" class="headerlink" title="Keyed State的使用案例"></a>Keyed State的使用案例</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">前面我们针对Keyed State的原理有了一定的了解，下面我们来真正实操一下，掌握Keyed State在工作中的实际应用：</span><br></pre></td></tr></table></figure>

<h6 id="温度告警-ValueState"><a href="#温度告警-ValueState" class="headerlink" title="温度告警-ValueState"></a>温度告警-ValueState</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">首先看第一个案例：温度告警</span><br><span class="line">大致需求是这样的，某机房内的多个设备会实时上报温度信息，在Flink任务内部需要对设备最近两次的温度进行对比，如果温差超过了20度，则需要发送告警信息，说明设备出问题了。</span><br><span class="line"></span><br><span class="line">在这里我们可以把设备的唯一标识ID字段作为keyby分组的key，这样的话在Flink内部就只需要维护设备的温度即可，温度值是一个数字，数字属于一个普通的单值，所以可以考虑使用ValueState。</span><br><span class="line"></span><br><span class="line">下面开始开发代码，</span><br><span class="line">创建package：com.imooc.scala.state</span><br><span class="line">创建object：KeyedState_AlarmDemo</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.<span class="type">RuntimeExecutionMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.&#123;<span class="type">MapFunction</span>, <span class="type">RichFlatMapFunction</span>, <span class="type">RichMapFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 温度告警：ValueState</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KeyedState_AlarmDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(<span class="type">RuntimeExecutionMode</span>.<span class="type">AUTOMATIC</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据格式为 设备ID,温度</span></span><br><span class="line">    <span class="keyword">val</span> text = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    text.map(line=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> tup = line.split(<span class="string">","</span>)</span><br><span class="line">      (tup(<span class="number">0</span>),tup(<span class="number">1</span>).toInt)</span><br><span class="line">    &#125;).keyBy(_._1)</span><br><span class="line">      .flatMap(<span class="keyword">new</span> <span class="type">RichFlatMapFunction</span>[(<span class="type">String</span>,<span class="type">Int</span>),<span class="type">String</span>] &#123;</span><br><span class="line">        <span class="comment">//声明一个ValueState类型的状态变量，存储设备上一次收到的温度数据</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">var</span> lastDataState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 任务初始化的时候这个方法执行一次</span></span><br><span class="line"><span class="comment">         * @param parameters</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="comment">//注册状态</span></span><br><span class="line">          <span class="keyword">val</span> valueStateDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](</span><br><span class="line">            <span class="string">"lastDataState"</span>,<span class="comment">//指定状态名称</span></span><br><span class="line">            classOf[<span class="type">Int</span>]<span class="comment">//指定状态中存储的数据类型</span></span><br><span class="line">          )</span><br><span class="line">          lastDataState = getRuntimeContext.getState(valueStateDesc)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>), out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="comment">//初始化</span></span><br><span class="line">          <span class="keyword">if</span>(lastDataState.value() == <span class="literal">null</span>)&#123;</span><br><span class="line">            lastDataState.update(value._2)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//获取上次温度</span></span><br><span class="line">          <span class="keyword">val</span> tmpLastData = lastDataState.value()</span><br><span class="line">          <span class="comment">//如果某个设备的最近两次温差超过20度，则告警</span></span><br><span class="line">          <span class="keyword">if</span>(<span class="type">Math</span>.abs(value._2 - tmpLastData) &gt;= <span class="number">20</span>)&#123;</span><br><span class="line">            out.collect(value._1+<span class="string">"_温度异常"</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//更新状态</span></span><br><span class="line">          lastDataState.update(value._2)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;).print()</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"KeyedState_AlarmDemo"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在这段代码中，确实没有设置状态存储位置或状态后端。默认情况下，Flink会使用内存作为状态后端，将状态存储在TaskManager的JVM堆上。如果要使用其他状态后端，例如RocksDB，需要在Flink配置文件中进行配置或在代码中显式设置。这段代码可能只是一个简单的示例，用于演示如何使用&#96;ValueState&#96;。</span><br><span class="line"></span><br><span class="line">无论您使用哪种状态后端（RocksDB或文件系统），都需要启用checkpoint才能在发生故障时恢复状态。状态后端负责管理运行时状态的存储和访问，而checkpoint则负责将状态数据定期保存到持久化存储中，以便在发生故障时可以从最近的checkpoint恢复状态。因此，如果您希望您的应用程序能够在发生故障时恢复状态，那么建议启用checkpoint。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">s1,50</span><br><span class="line">s2,10</span><br><span class="line">s3,10</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一直到这，程序还是打印不出任何数据，说明没有触发温度异常的逻辑。</span><br><span class="line">因为这里会针对每个key维护一个状态，现在输入的3个key都是不一样的，所以没有触发。</span><br><span class="line"></span><br><span class="line">只有再输入一个s1的值，才可能会触发</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">s1,10</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">此时程序触发打印操作了</span><br><span class="line"></span><br><span class="line">s1_温度异常</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">为了加深大家的理解，我在代码里面增加一些调试代码，打印一些中间数据，便于我们观察分析：</span><br><span class="line">1：首先将任务的并行度调整一下，默认我的windows是8核的，所以并行度为8，为了看起来清晰，我就在代码层面将任务的并行度设置为8。</span><br><span class="line">2：在flatmap中增加一些打印操作，将当前的线程id、初始的状态值，以及上次的状态值打印一下。</span><br><span class="line"></span><br><span class="line">修改后的代码如下：</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.<span class="type">RuntimeExecutionMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.&#123;<span class="type">MapFunction</span>, <span class="type">RichFlatMapFunction</span>, <span class="type">RichMapFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 温度告警：ValueState</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KeyedState_AlarmDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(<span class="type">RuntimeExecutionMode</span>.<span class="type">AUTOMATIC</span>)</span><br><span class="line">    <span class="comment">//设置任务全局并行度为8</span></span><br><span class="line">    env.setParallelism(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据格式为 设备ID,温度</span></span><br><span class="line">    <span class="keyword">val</span> text = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    text.map(line=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> tup = line.split(<span class="string">","</span>)</span><br><span class="line">      (tup(<span class="number">0</span>),tup(<span class="number">1</span>).toInt)</span><br><span class="line">    &#125;).keyBy(_._1)</span><br><span class="line">      .flatMap(<span class="keyword">new</span> <span class="type">RichFlatMapFunction</span>[(<span class="type">String</span>,<span class="type">Int</span>),<span class="type">String</span>] &#123;</span><br><span class="line">        <span class="comment">//声明一个ValueState类型的状态变量，存储设备上一次收到的温度数据</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">var</span> lastDataState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 任务初始化的时候这个方法执行一次</span></span><br><span class="line"><span class="comment">         * @param parameters</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="comment">//注册状态</span></span><br><span class="line">          <span class="keyword">val</span> valueStateDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](</span><br><span class="line">            <span class="string">"lastDataState"</span>,<span class="comment">//指定状态名称</span></span><br><span class="line">            classOf[<span class="type">Int</span>]<span class="comment">//指定状态中存储的数据类型</span></span><br><span class="line">          )</span><br><span class="line">          lastDataState = getRuntimeContext.getState(valueStateDesc)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>), out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">          println(<span class="string">"线程ID："</span>+<span class="type">Thread</span>.currentThread().getId+<span class="string">",接收到数据："</span>+value)</span><br><span class="line"><span class="comment">//打印当前的线程ID和接收到的数据</span></span><br><span class="line">          <span class="comment">//初始化</span></span><br><span class="line">          <span class="keyword">if</span>(lastDataState.value() == <span class="literal">null</span>)&#123;</span><br><span class="line">            lastDataState.update(value._2)</span><br><span class="line">            println(<span class="string">"lastDataState is null"</span>)<span class="comment">//打印初始的状态为null</span></span><br><span class="line">          &#125;</span><br><span class="line">          println(<span class="string">"lastDataState is "</span>+ lastDataState.value())<span class="comment">//打印上次的状态值</span></span><br><span class="line">          <span class="comment">//获取上次温度</span></span><br><span class="line">          <span class="keyword">val</span> tmpLastData = lastDataState.value()</span><br><span class="line">          <span class="comment">//如果某个设备的最近两次温差超过20度，则告警</span></span><br><span class="line">          <span class="keyword">if</span>(<span class="type">Math</span>.abs(value._2 - tmpLastData) &gt;= <span class="number">20</span>)&#123;</span><br><span class="line">            out.collect(value._1+<span class="string">"_温度异常"</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//更新状态</span></span><br><span class="line">          lastDataState.update(value._2)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;).print()</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"KeyedState_AlarmDemo"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">重启开启socket</span><br><span class="line"></span><br><span class="line">运行代码。</span><br><span class="line">在socket中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">s1,50</span><br><span class="line"></span><br><span class="line">控制台打印的数据如下：</span><br><span class="line">线程ID：91,接收到数据：(s1,50)</span><br><span class="line">lastDataState is null</span><br><span class="line">lastDataState is 50</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">flatmap算子的并行度为8，同时会有8个线程处理，通过keyBy对数据流分组之后，相同规则的数据会进入到同一个线程中。</span><br><span class="line">这里就说明s1,50这条数据被线程ID为91的线程处理了，s1这个key是第一次过来，对应的状态为null，所以这里打印出来了null，当状态为null时，程序会把当前的数据赋值给状态，所以下面打印的上次状态值就是50了。</span><br><span class="line"></span><br><span class="line">在之前的socket中再模拟产生一条数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">s2,10</span><br><span class="line"></span><br><span class="line">控制台打印的数据如下：</span><br><span class="line">线程ID：84,接收到数据：(s2,10)</span><br><span class="line">lastDataState is null</span><br><span class="line">lastDataState is 10</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">此时说明这条数据被线程ID为84的线程处理了，s2这个key也是第一次过来的，所以初始也为null，后面给他赋值之后是10。</span><br><span class="line"></span><br><span class="line">在之前的socket中再模拟产生一条数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">s3,10</span><br><span class="line"></span><br><span class="line">控制台打印的数据如下：</span><br><span class="line">线程ID：91,接收到数据：(s3,10)</span><br><span class="line">lastDataState is null</span><br><span class="line">lastDataState is 10</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">此时显示的线程ID也是91，说明s3这条数据和s1那条数据都是由同一个线程处理的，但是注意此时s3对应的状态默认依然是null，因为s3也是第一次过来，虽然ts3和s1都是由同一个线程处理的，但是状态是和key绑定的，所以s3对应的状态依然是null。</span><br><span class="line">所以前面咱们说过，KeyedSate是和key绑定的，针对KeyedStream上的每个Key，Flink都会维护一个状态实例。</span><br><span class="line"></span><br><span class="line">如果我们把ValueState换成一个普通的int变量，就不是这样的效果了，当s3这条数据过来的时候就可以获取到之前s1存储的数据50了，因为普通的变量在同一个线程里面是共享的。</span><br></pre></td></tr></table></figure>

<h6 id="直播间数据统计-MapState"><a href="#直播间数据统计-MapState" class="headerlink" title="直播间数据统计-MapState"></a>直播间数据统计-MapState</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看第二个案例：直播间数据统计</span><br><span class="line">大致需求是这样的，需要统计平台中每个主播在直播间内收到的礼物信息、点赞、关注等指标，以直播间为单位进行统计。</span><br><span class="line"></span><br><span class="line">由于用户每次开播都会生成一个新的直播间vid，并且我们需要基于这个直播间vid统计它里面的数据指标，这些数据指标包含多个维度，例如：礼物对应的数量、点赞对应的数据量、关注对应的数量，这种数据就适合使用MapState进行存储了，每一个直播间的数据指标存储到一个MapState中。</span><br><span class="line"></span><br><span class="line">下面开始开发代码，</span><br><span class="line">创建object：KeyedState_VideoDataDemo</span><br><span class="line"></span><br><span class="line">由于数据格式是JSON格式的，所以引入fastjson依赖</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.68&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!--&lt;scope&gt;provided&lt;&#x2F;scope&gt;--&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.<span class="type">JSON</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.<span class="type">RuntimeExecutionMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">MapState</span>, <span class="type">MapStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 直播间数据统计-MapState</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KeyedState_VideoDataDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(<span class="type">RuntimeExecutionMode</span>.<span class="type">AUTOMATIC</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据格式</span></span><br><span class="line">    <span class="comment">//送礼数据：&#123;"type":"gift","uid":"1001","vid":"29901","value":100&#125;</span></span><br><span class="line">    <span class="comment">//关注数据：&#123;"type":"follow","uid":"1001","vid":"29901"&#125;</span></span><br><span class="line">    <span class="comment">//点赞数据：&#123;"type":"like","uid":"1001","vid":"29901"&#125;</span></span><br><span class="line">    <span class="keyword">val</span> text = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    text.map(line=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> videoJsonData = <span class="type">JSON</span>.parseObject(line)</span><br><span class="line">      <span class="keyword">val</span> vid = videoJsonData.getString(<span class="string">"vid"</span>)</span><br><span class="line">      <span class="keyword">val</span> videoType = videoJsonData.getString(<span class="string">"type"</span>)</span><br><span class="line">      <span class="comment">//也可以使用if语句实现</span></span><br><span class="line">      videoType <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">"gift"</span> =&gt; &#123;</span><br><span class="line">          <span class="keyword">val</span> value = videoJsonData.getIntValue(<span class="string">"value"</span>)</span><br><span class="line">          (vid,videoType,value)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">case</span> _ =&gt; (vid,videoType,<span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;).keyBy(_._1)<span class="comment">//注意：后面也可以使用flatmap算子，在这里换一种形式，使用低级API process</span></span><br><span class="line">      .process(<span class="keyword">new</span> <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>,(<span class="type">String</span>,<span class="type">String</span>,<span class="type">Int</span>),(<span class="type">String</span>,<span class="type">String</span>,<span class="type">Int</span>)] &#123;</span><br><span class="line">        <span class="comment">//声明一个MapState类型的状态变量，存储用户的直播间数据指标</span></span><br><span class="line">        <span class="comment">//MapState中key的值为gift\follow\like，value的值为累加后的结果</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">var</span> videoDataState: <span class="type">MapState</span>[<span class="type">String</span>,<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="comment">//注册状态</span></span><br><span class="line">          <span class="keyword">val</span> mapStateDesc = <span class="keyword">new</span> <span class="type">MapStateDescriptor</span>[<span class="type">String</span>,<span class="type">Int</span>](</span><br><span class="line">            <span class="string">"videoDataState"</span>,<span class="comment">//指定状态名称</span></span><br><span class="line">            classOf[<span class="type">String</span>],<span class="comment">//指定key的类型</span></span><br><span class="line">            classOf[<span class="type">Int</span>]<span class="comment">//指定value的类型</span></span><br><span class="line">          )</span><br><span class="line">          videoDataState = getRuntimeContext.getMapState(mapStateDesc)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(value: (<span class="type">String</span>, <span class="type">String</span>, <span class="type">Int</span>),</span><br><span class="line">                                    ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">String</span>, <span class="type">Int</span>)]#<span class="type">Context</span>,</span><br><span class="line">                                    out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Int</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">          <span class="keyword">val</span> videoType = value._2</span><br><span class="line">          <span class="keyword">var</span> num = value._3</span><br><span class="line">          <span class="comment">//判断状态中是否有这个数据</span></span><br><span class="line">          <span class="keyword">if</span>(videoDataState.contains(videoType))&#123;</span><br><span class="line">            num += videoDataState.get(videoType)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//更新状态</span></span><br><span class="line">          videoDataState.put(videoType,num)</span><br><span class="line">          out.collect((value._1,videoType,num))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;).print()</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"KeyedState_VideoDataDemo"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">在Flink程序中，要使用Keyed State，必须先对数据流进行keyBy操作。keyBy操作会将数据流分区，使得具有相同键的数据被发送到同一个算子实例进行处理。</span><br><span class="line"></span><br><span class="line">在keyBy之后，可以使用flatMap或process函数来访问和操作Keyed State。这两种函数都可以访问Keyed State，但它们之间有一些区别。</span><br><span class="line"></span><br><span class="line">&#96;flatMap&#96;函数允许您对输入数据进行一对多的转换。它接收一个输入元素，并可以生成零个、一个或多个输出元素。它通常用于对数据流进行扁平化处理。</span><br><span class="line"></span><br><span class="line">process函数提供了更多的控制能力。它允许您访问时间戳、watermark和其他元数据，并且可以注册定时器来执行基于时间的操作。它通常用于更复杂的事件驱动应用程序。</span><br><span class="line"></span><br><span class="line">因此，在选择使用flatMap还是process函数时，需要根据您的应用程序需求来决定。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">除了&#96;flatMap&#96;和&#96;process&#96;函数之外，还可以使用&#96;reduce&#96;和&#96;aggregate&#96;函数来访问和操作Keyed State。</span><br><span class="line"></span><br><span class="line">&#96;reduce&#96;函数允许您对数据流中的元素进行归约操作，以计算每个键的累积结果。它需要一个ReduceFunction，该函数指定如何将两个输入元素合并为一个输出元素。</span><br><span class="line"></span><br><span class="line">&#96;aggregate&#96;函数与&#96;reduce&#96;函数类似，但提供了更多的灵活性。它需要一个AggregateFunction，该函数由三个方法组成：&#96;createAccumulator&#96;、&#96;add&#96;和&#96;getResult&#96;。这些方法分别用于创建累加器、将输入元素添加到累加器中并计算累积结果。</span><br><span class="line"></span><br><span class="line">这些函数都可以访问Keyed State，并根据您的应用程序需求选择使用。</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">开启一个新的socket</span><br><span class="line"></span><br><span class="line">运行代码。</span><br><span class="line">在socket中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">&#123;&quot;type&quot;:&quot;gift&quot;,&quot;uid&quot;:&quot;1001&quot;,&quot;vid&quot;:&quot;29901&quot;,&quot;value&quot;:100&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;follow&quot;,&quot;uid&quot;:&quot;1001&quot;,&quot;vid&quot;:&quot;29901&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;like&quot;,&quot;uid&quot;:&quot;1001&quot;,&quot;vid&quot;:&quot;29902&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;like&quot;,&quot;uid&quot;:&quot;1001&quot;,&quot;vid&quot;:&quot;29901&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;gift&quot;,&quot;uid&quot;:&quot;1001&quot;,&quot;vid&quot;:&quot;29901&quot;,&quot;value&quot;:100&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;like&quot;,&quot;uid&quot;:&quot;1001&quot;,&quot;vid&quot;:&quot;29904&quot;&#125;</span><br><span class="line"></span><br><span class="line">控制台打印的数据如下</span><br><span class="line">7&gt; (29901,gift,100)</span><br><span class="line">7&gt; (29901,follow,1)</span><br><span class="line">6&gt; (29902,like,1)</span><br><span class="line">7&gt; (29901,like,1)</span><br><span class="line">7&gt; (29901,gift,200)</span><br><span class="line">6&gt; (29904,like,1)</span><br></pre></td></tr></table></figure>

<h6 id="订单数据补全-ListState"><a href="#订单数据补全-ListState" class="headerlink" title="订单数据补全-ListState"></a>订单数据补全-ListState</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看第三个案例：订单数据补全</span><br><span class="line">大致需求是这样的，某外卖平台需要开发一个实时订单消息推送功能，当用户下单，并且成功支付后向商家推送一条消息。</span><br><span class="line">其中下单数据是一个数据流，支付数据是另外一个数据流。</span><br><span class="line">这个时候就需要对两个数据流进行关联了，当同一个订单相关的数据都到齐之后向外推送消息。</span><br><span class="line">针对这个需求，我们计划使用ListState实现。</span><br><span class="line"></span><br><span class="line">下面开始开发代码，</span><br><span class="line">创建object：KeyedState_OrderDataDemo</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.<span class="type">JSON</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.<span class="type">RuntimeExecutionMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">RichFlatMapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ListState</span>, <span class="type">ListStateDescriptor</span>, <span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.co.<span class="type">KeyedCoProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 订单数据补全-ListState （双流Join）</span></span><br><span class="line"><span class="comment"> * 订单数据流 + 支付数据流</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KeyedState_OrderDataDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(<span class="type">RuntimeExecutionMode</span>.<span class="type">AUTOMATIC</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据格式为</span></span><br><span class="line">    <span class="comment">//订单数据流：&#123;"pid":"1001","pname":"n1"&#125;</span></span><br><span class="line">    <span class="comment">//支付数据流：&#123;"pid":"1001","pstatus":"success"&#125;</span></span><br><span class="line">    <span class="keyword">val</span> orderText = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9001</span>)</span><br><span class="line">    <span class="keyword">val</span> payText = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9002</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    <span class="comment">//解析订单数据流</span></span><br><span class="line">    <span class="keyword">val</span> orderTupleData = orderText.map(line =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> orderJsonObj = <span class="type">JSON</span>.parseObject(line)</span><br><span class="line">      <span class="keyword">val</span> pid = orderJsonObj.getString(<span class="string">"pid"</span>)</span><br><span class="line">      <span class="keyword">val</span> pname = orderJsonObj.getString(<span class="string">"pname"</span>)</span><br><span class="line">      (pid, pname)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//解析支付数据流</span></span><br><span class="line">    <span class="keyword">val</span> payTupleData = payText.map(line =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> payJsonObj = <span class="type">JSON</span>.parseObject(line)</span><br><span class="line">      <span class="keyword">val</span> pid = payJsonObj.getString(<span class="string">"pid"</span>)</span><br><span class="line">      <span class="keyword">val</span> pstatus = payJsonObj.getString(<span class="string">"pstatus"</span>)</span><br><span class="line">      (pid, pstatus)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//针对两个流进行分组+connect连接(也可以先对两个流分别调用keyBy，再调用connect，效果一样)</span></span><br><span class="line">    orderTupleData.connect(payTupleData)</span><br><span class="line">        .keyBy(<span class="string">"_1"</span>,<span class="string">"_1"</span>)<span class="comment">//field1表示第1个流里面的分组字段，field2表示第2个流里面的分组字段</span></span><br><span class="line">        .process(<span class="keyword">new</span> <span class="type">KeyedCoProcessFunction</span>[<span class="type">String</span>,(<span class="type">String</span>,<span class="type">String</span>),(<span class="type">String</span>,<span class="type">String</span>),(<span class="type">String</span>,<span class="type">String</span>,<span class="type">String</span>)] &#123;</span><br><span class="line">          <span class="comment">//声明两个ListState类型的状态变量，分别存储订单数据流和支付数据流</span></span><br><span class="line">          <span class="comment">/**</span></span><br><span class="line"><span class="comment">           * 注意：针对这个业务需求，pid在一个数据流中是不会重复的，其实使用ValueState也是可以的，</span></span><br><span class="line"><span class="comment">           * 因为在这里已经通过keyBy基于pid对数据分组了，所以只需要在状态中存储pname或者pstatus即可。</span></span><br><span class="line"><span class="comment">           * 但是如果pid数据在一个数据流里面会重复，那么就必须要使用ListState了，这样才能存储指定pid的多条数据</span></span><br><span class="line"><span class="comment">           */</span></span><br><span class="line">          <span class="keyword">private</span> <span class="keyword">var</span> orderDataState: <span class="type">ListState</span>[(<span class="type">String</span>,<span class="type">String</span>)] = _</span><br><span class="line">          <span class="keyword">private</span> <span class="keyword">var</span> payDataState: <span class="type">ListState</span>[(<span class="type">String</span>,<span class="type">String</span>)] = _</span><br><span class="line"></span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">            <span class="comment">//注册状态</span></span><br><span class="line">            <span class="keyword">val</span> orderListStateDesc = <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[(<span class="type">String</span>,<span class="type">String</span>)](</span><br><span class="line">              <span class="string">"orderDataState"</span>,</span><br><span class="line">              classOf[(<span class="type">String</span>, <span class="type">String</span>)]</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">val</span> payListStateDesc = <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[(<span class="type">String</span>,<span class="type">String</span>)](</span><br><span class="line">              <span class="string">"payDataState"</span>,</span><br><span class="line">              classOf[(<span class="type">String</span>, <span class="type">String</span>)]</span><br><span class="line">            )</span><br><span class="line">            orderDataState = getRuntimeContext.getListState(orderListStateDesc)</span><br><span class="line">            payDataState = getRuntimeContext.getListState(payListStateDesc)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">//处理订单数据流</span></span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement1</span></span>(orderTup: (<span class="type">String</span>, <span class="type">String</span>),</span><br><span class="line">                                       ctx: <span class="type">KeyedCoProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">String</span>), (<span class="type">String</span>, <span class="type">String</span>), (<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]#<span class="type">Context</span>,</span><br><span class="line">                                       out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">            <span class="comment">//获取当前pid对应的支付数据流，关联之后输出数据，（可能是支付数据先到）</span></span><br><span class="line">            payDataState.get().forEach(payTup=&gt;&#123;</span><br><span class="line">              out.collect((orderTup._1,orderTup._2,payTup._2))</span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="comment">//将本次接收到的订单数据添加到状态中，便于和支付数据流中的数据关联</span></span><br><span class="line">            orderDataState.add(orderTup)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//处理支付数据流</span></span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement2</span></span>(payTup: (<span class="type">String</span>, <span class="type">String</span>),</span><br><span class="line">                                       ctx: <span class="type">KeyedCoProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">String</span>), (<span class="type">String</span>, <span class="type">String</span>), (<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]#<span class="type">Context</span>,</span><br><span class="line">                                       out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">            <span class="comment">//获取当前pid对应的订单数据流，关联之后输出数据，（可能是订单数据先到）</span></span><br><span class="line">            orderDataState.get().forEach(orderTup=&gt;&#123;</span><br><span class="line">              out.collect((orderTup._1,orderTup._2,payTup._2))</span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="comment">//将本次接收到的订单数据添加到状态中，便于和订单数据流中的数据关联</span></span><br><span class="line">            payDataState.add(payTup)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;).print()</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"KeyedState_OrderDataDemo"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">开启两个新的socket</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">[root@bigdata04 ~]# nc -l 9002</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">运行代码。</span><br><span class="line"></span><br><span class="line">在socket 9001中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">&#123;&quot;pid&quot;:&quot;1001&quot;,&quot;pname&quot;:&quot;n1&quot;&#125;</span><br><span class="line"></span><br><span class="line">在socket 9002中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9002</span><br><span class="line">&#123;&quot;pid&quot;:&quot;1003&quot;,&quot;pstatus&quot;:&quot;success&quot;&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">此时两条数据不是同一个订单的，所以程序没有任何输出</span><br><span class="line"></span><br><span class="line">接下来继续在socket 9001中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">&#123;&quot;pid&quot;:&quot;1003&quot;,&quot;pname&quot;:&quot;n3&quot;&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">此时可以看到控制台输出一条数据</span><br><span class="line">5&gt; (1003,n3,success)</span><br><span class="line"></span><br><span class="line">接下来继续在socket 9002中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9002</span><br><span class="line">&#123;&quot;pid&quot;:&quot;1001&quot;,&quot;pstatus&quot;:&quot;success&quot;&#125;</span><br><span class="line"></span><br><span class="line">此时可以看到控制台输出一条数据</span><br><span class="line">4&gt; (1001,n1,success)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">这样就实现了订单数据流和支付数据流的数据关联，这就是Flink中的双流Join，双流Join还有很多中实现方式，后面我们会有一个单独的章节详细分析双流Join。</span><br><span class="line"></span><br><span class="line">注意：这个案例中两个数据流的数据会一直存储在状态中，随着时间的增长，状态会越来越多，状态如果是存储在内存中的话，内存可能就扛不住了，最终导致内存溢出。</span><br><span class="line"></span><br><span class="line">针对这个问题有两个解决方案</span><br><span class="line"></span><br><span class="line">我们自己基于业务层面从状态中清理掉不用的数据，例如两份数据join到一起之后，就删除状态中的数据，这样可以保证状态中的数据不会一直无限递增。</span><br><span class="line">状态设置一个失效机制，官方提供的有一个TTL机制，可以给状态设置一个生存时间 ，过期自动删除，这个TTL机制我们后面再具体分析。</span><br><span class="line"></span><br><span class="line">在这里我们只是演示了状态的存储，针对状态的故障恢复我们还没有演示，因为我们使用状态的很大一个原因就是考虑到状态可以实现故障后的数据恢复。等后面讲到状态一致性的时候我们再来具体演示基于状态的任务故障后，状态数据是如何恢复的。</span><br></pre></td></tr></table></figure>

<h5 id="Keyed-State的使用形式总结"><a href="#Keyed-State的使用形式总结" class="headerlink" title="Keyed State的使用形式总结"></a>Keyed State的使用形式总结</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">在程序中想要使用Keyed State，大致可以通过下面这几种形式：</span><br><span class="line"></span><br><span class="line">第一种：通过重写RichXXXFunction，在里面创建和操作状态。例如针对map算子可以使用RichMapFunction，针对flatmap算子可以使用RichFlatMapFunction等。</span><br><span class="line">在这里使用对应的RichFunction主要是因为它里面提供了getRuntimeContext这个上下文，通过getRuntimeContext可以获取Keyed State。</span><br><span class="line"></span><br><span class="line">第二种：通过process()这种低级API。</span><br><span class="line">主要是因为process中也可以获取到getRuntimeContext这个上下文。</span><br><span class="line"></span><br><span class="line">第三种：其实还通过mapWithState()、flatMapWithState()等直接带有状态的算子，这种算子里面针对Keyed State直接进行了封装，使用起来更加方便，但是它有一定的局限性。</span><br><span class="line">首先是这些带有状态的算子只能应用在keyBy算子之后</span><br><span class="line">还有就是这些带有状态的算子里面封装的其实都是ValueState这种状态，不能自己控制使用哪种状态。</span><br><span class="line"></span><br><span class="line">下面我们来演示一下这种状态的使用：</span><br><span class="line">以常用的单词计数这个需求为例</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011745279.png" alt="image-20230601174451755"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Scala有一种特殊的数据类型，叫做Option。</span><br><span class="line">Option有两种值，一种是Some，表示有值，一种是None，表示没有值</span><br><span class="line">Option通常会用于模式匹配中，用于判断某个变量是有值还是没有值，这比null来的更加简洁明了</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.<span class="type">RuntimeExecutionMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用MapWithState实现带有状态的单词计数案例</span></span><br><span class="line"><span class="comment"> * 思考问题：有状态的单词计数代码 和  无状态的单词计数代码有什么区别？</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KeyedState_MapWithStateDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(<span class="type">RuntimeExecutionMode</span>.<span class="type">AUTOMATIC</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> text = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    <span class="keyword">val</span> keyedStream = text.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">      .map((_, <span class="number">1</span>))</span><br><span class="line">      .keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * T：当前数据流中的数据类型</span></span><br><span class="line"><span class="comment">     * R：返回数据类型</span></span><br><span class="line"><span class="comment">     * S：State中存储的数据类型</span></span><br><span class="line"><span class="comment">     * [(String,Int),Int] (String,Int):R    Int:S</span></span><br><span class="line"><span class="comment">     * 注意：在这里State默认是ValueState，ValueState中可以存储多种数据类型。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    keyedStream.mapWithState[(<span class="type">String</span>,<span class="type">Int</span>),<span class="type">Int</span>]((in: (<span class="type">String</span>,<span class="type">Int</span>),count: <span class="type">Option</span>[<span class="type">Int</span>])=&gt;&#123;</span><br><span class="line">      count <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="comment">//（t1,t2）</span></span><br><span class="line">        <span class="comment">//t1: 表示这个map操作需要返回的数据</span></span><br><span class="line">        <span class="comment">//t2: 表示State中目前的数据</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(c) =&gt; ((in._1,in._2+c),<span class="type">Some</span>(in._2+c))<span class="comment">//第2及以上次数，返回累加后的数据，更新状态;c是count简写，用count也行</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt; ((in._1,in._2),<span class="type">Some</span>(in._2))<span class="comment">//第1次接收到数据，直接返回数据，初始化状态</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;).print()</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"KeyedState_MapWithStateDemo"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">分析一下mapWithState方法的底层实现</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapWithState</span></span>[<span class="type">R</span>: <span class="type">TypeInformation</span>, <span class="type">S</span>: <span class="type">TypeInformation</span>](</span><br><span class="line">      fun: (<span class="type">T</span>, <span class="type">Option</span>[<span class="type">S</span>]) =&gt; (<span class="type">R</span>, <span class="type">Option</span>[<span class="type">S</span>])): <span class="type">DataStream</span>[<span class="type">R</span>] = &#123;</span><br><span class="line">  <span class="keyword">if</span> (fun == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NullPointerException</span>(<span class="string">"Map function must not be null."</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> cleanFun = clean(fun)</span><br><span class="line">  <span class="keyword">val</span> stateTypeInfo: <span class="type">TypeInformation</span>[<span class="type">S</span>] = implicitly[<span class="type">TypeInformation</span>[<span class="type">S</span>]]</span><br><span class="line">  <span class="keyword">val</span> serializer: <span class="type">TypeSerializer</span>[<span class="type">S</span>] = stateTypeInfo.createSerializer(getExecutionConfig)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> mapper = <span class="keyword">new</span> <span class="type">RichMapFunction</span>[<span class="type">T</span>, <span class="type">R</span>] <span class="keyword">with</span> <span class="type">StatefulFunction</span>[<span class="type">T</span>, <span class="type">R</span>, <span class="type">S</span>] &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> stateSerializer: <span class="type">TypeSerializer</span>[<span class="type">S</span>] = serializer</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(in: <span class="type">T</span>): <span class="type">R</span> = &#123;</span><br><span class="line">      applyWithState(in, cleanFun)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  map(mapper)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以及它里面封装的状态：ValueState</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">StatefulFunction</span>[<span class="type">I</span>, <span class="type">O</span>, <span class="type">S</span>] <span class="keyword">extends</span> <span class="title">RichFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">val</span> stateSerializer: <span class="type">TypeSerializer</span>[<span class="type">S</span>]</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> state: <span class="type">ValueState</span>[<span class="type">S</span>] = _</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">applyWithState</span></span>(in: <span class="type">I</span>, fun: (<span class="type">I</span>, <span class="type">Option</span>[<span class="type">S</span>]) =&gt; (<span class="type">O</span>, <span class="type">Option</span>[<span class="type">S</span>])): <span class="type">O</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (o, s: <span class="type">Option</span>[<span class="type">S</span>]) = fun(in, <span class="type">Option</span>(state.value()))</span><br><span class="line">    s <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(v) =&gt; state.update(v)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; state.update(<span class="literal">null</span>.asInstanceOf[<span class="type">S</span>])</span><br><span class="line">    &#125;</span><br><span class="line">    o</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(c: <span class="type">Configuration</span>) = &#123;</span><br><span class="line">    <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">S</span>](<span class="string">"state"</span>, stateSerializer)</span><br><span class="line">    state = getRuntimeContext().getState(info)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">开启一个新的socket</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line"></span><br><span class="line">启动程序。</span><br><span class="line">在socket中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">a b </span><br><span class="line"></span><br><span class="line">控制台打印的结果如下：</span><br><span class="line">2&gt; (b,1)</span><br><span class="line">6&gt; (a,1)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">再模拟产生一条数据</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">a</span><br><span class="line"></span><br><span class="line">控制台打印的结果如下：</span><br><span class="line">6&gt; (a,2)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">从这里可以看出来，整个代码的执行流程是没有问题的。</span><br><span class="line"></span><br><span class="line">注意：这种方式了解即可，以后看到了这种写法知道是什么意思就行，个人不建议在工作中使用方式，因为这种方式不好理解，不属于通俗易懂的代码。</span><br></pre></td></tr></table></figure>

<h5 id="Operator-State-详解"><a href="#Operator-State-详解" class="headerlink" title="Operator State 详解"></a>Operator State 详解</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看一下针对Operator State的解释</span><br><span class="line">Operator State表示是和算子绑定的状态，与Key无关。所以说Operator State可以应用在任何类型的数据流上。</span><br><span class="line"></span><br><span class="line">此时算子的同一个子任务共享一个状态实例，流入这个算子子任务的数据可以访问和更新这个状态实例。</span><br><span class="line"></span><br><span class="line">看一下下面这个图，加深一下理解</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011818673.png" alt="image-20230601181849199"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">图中左边的Source表示是数据源，这个组件的并行度为2，会产生2个task。</span><br><span class="line">右边的Stateful这个有状态的算子的并行度也是2，对应也会产生2个task。</span><br><span class="line"></span><br><span class="line">此时Source-1的数据都会进入到Stateful -1这个子任务中，Stateful -1会维护一个状态实例，他接收到的A\B\Y这几个数据会存储到同一个状态实例中，A\B\Y这些数据会共享同一个状态实例。</span><br><span class="line"></span><br><span class="line">对应的Source-2的数据都会进入到Stateful -2这个子任务中，Stateful -2会维护一个状态实例，他接收到的D\E\Z这几个数据会存储到同一个状态实例中。D\E\Z这些数据会共享同一个状态实例。</span><br><span class="line"></span><br><span class="line">从这个图里面可以清晰的看出来Operator State和Keyed State之间的区别。</span><br><span class="line"></span><br><span class="line">在实际工作中Operator State的实际应用场景不如Keyed State多。Operator State经常被用在Source或Sink组件中，用来保存流入数据的偏移量或者对输出的数据做缓存，以保证Flink应用的Exactly-Once语义。</span><br><span class="line"></span><br><span class="line">其中有一个典型的应用场景是Flink从Kafka中消费数据，这个时候会用到FlinkKafkaConsumerBase这个接口，我们之前在讲Flink中的DataSource的时候讲到过，针对kafka的DataSource可以提供仅一次语句，想要提供仅一次语句，那么这个DataSource中就需要维护状态了，通过状态来维护消费偏移量信息。</span><br><span class="line"></span><br><span class="line">FlinkKafkaConsumerBase中实际上会维护消费者消费的topic名称、分区编号和offset偏移量这些信息，这些数据会使用Operator State类型的状态进行存储，类似图中显示的这样：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011823622.png" alt="image-20230601182307162"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">实际上这里面会用到Operator State中的UnionListState这种状态，其实就是一个基于List列表的状态。</span><br><span class="line"></span><br><span class="line">接下来我们来具体分析一下FlinkKafkaConsumerBase的源码，需要先引入flink-connector-kafka这个依赖。</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-connector-kafka&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.15.0&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;!--&lt;scope&gt;provided&lt;&#x2F;scope--&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在FlinkKafkaConsumerBase这个类的第201行有这么一行代码：</span><br><span class="line">private transient ListState&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt; unionOffsetStates;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">这里用到了ListState，咱们刚才说的他使用的是UnionListState，其实UnionListState的底层就是ListState，唯一的区别就是任务故障恢复时状态数据的传输方式不一样，咱们之前在讲Operator State的扩缩容模式的时候详细分析过。</span><br><span class="line"></span><br><span class="line">这个ListState中存储的是Tuple2数据结构，Tuple2中的第1列是KafkaTopicPartition。</span><br><span class="line">KafkaTopicPartition中存储的是Kafka中指定topic的名称和分区的编号。</span><br><span class="line">查看KafkaTopicPartition的源码：</span><br><span class="line">private final String topic;</span><br><span class="line">private final int partition;</span><br><span class="line"></span><br><span class="line">Tuple2中的第2列是Long类型，其实存储的就是指定Topic对应分区的消费偏移量。</span><br></pre></td></tr></table></figure>

<h6 id="Operator-State中支持的数据结构"><a href="#Operator-State中支持的数据结构" class="headerlink" title="Operator State中支持的数据结构"></a>Operator State中支持的数据结构</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来具体分析一下 Operator State中支持的常见数据结构：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011827274.png" alt="image-20230601182743126"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">由于Operator State中存储的是算子的同一个子任务中的状态数据，所以提供的都是可以存储多条数据的状态，没有提供ValueState这种状态。</span><br><span class="line"></span><br><span class="line">ListState：表示是一个列表类型的状态，存储类型为T的多个元素，T是一个泛型。</span><br><span class="line">UnionListState：底层就是ListState。</span><br><span class="line"></span><br><span class="line">ListState和UnionListState的区别在于任务故障后恢复数据时：ListState是将整个状态列表按照负载均衡算法均匀分布到各个算子子任务上，每个算子子任务得到的是整个列表的子集；而UnionListState会按照广播的方式，将整个列表发送给每个算子子任务。</span><br><span class="line"></span><br><span class="line">ListState和UnionListState的区别在源码层面也可以看到，看一下OperatorStateStore这个接口的内容：</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ListState&lt;S&gt; getListState(ListStateDescriptor&lt;S&gt; stateDescriptor) throws Exception;</span><br><span class="line">ListState&lt;S&gt; getUnionListState(ListStateDescriptor&lt;S&gt; stateDescriptor) throws Exception;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">通过这块代码可以看出来，ListState和UnionListState对应的数据结构是一样的。</span><br><span class="line"></span><br><span class="line">BroadcastState：主要存储K-V类型的多个元素，存储的数据格式和MapState一样，但是它在恢复数据的时候会广播发送数据。</span><br><span class="line">BroadcastState属于OperatorState的一种特殊类型，主要是为了实现同一个算子的多个子任务共享一个State。</span><br></pre></td></tr></table></figure>

<h5 id="Operator-State的使用案例"><a href="#Operator-State的使用案例" class="headerlink" title="Operator State的使用案例"></a>Operator State的使用案例</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">前面我们针对Operator State的原理有了一定的了解，下面我们来实操一下，掌握Operator State在工作中的应用：</span><br></pre></td></tr></table></figure>

<h6 id="ListState的使用"><a href="#ListState的使用" class="headerlink" title="ListState的使用"></a>ListState的使用</h6><h6 id="Flink中自带的有状态的Source"><a href="#Flink中自带的有状态的Source" class="headerlink" title="Flink中自带的有状态的Source"></a>Flink中自带的有状态的Source</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">首先我们来分析一个Flink内部已有的Source：FromElementsFunction</span><br><span class="line">当我们使用env.fromElements或者env.fromCollection时，底层其实会用到FromElementsFunction这个数据源。</span><br><span class="line">代码路径如下所示：</span><br><span class="line">env.fromCollection() --&gt; javaEnv.fromCollection(collection, typeInfo) --&gt; SourceFunction&lt;OUT&gt; function &#x3D; new FromElementsFunction&lt;&gt;(data) --&gt; FromElementsFunction(Iterable&lt;T&gt; elements)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在FromElementsFunction这个类中有一个ListState：checkpointedState</span><br><span class="line"></span><br><span class="line">private transient ListState&lt;Integer&gt; checkpointedState;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">checkpointedState这个状态主要在initializeState和snapshotState这两个方法里面用到了。</span><br><span class="line"></span><br><span class="line">initializeState和snapshotState这两个方法有什么作用吗？</span><br><span class="line"></span><br><span class="line">在分析这两个方法之前，我们需要再重新梳理一下状态这块的概念</span><br><span class="line"></span><br><span class="line">从本质上来说，状态属于Flink算子子任务中的一种本地数据，为了保证这份数据的可恢复性，需要借助于Checkpoint机制来将状态数据持久化输出到分布式文件系统中。</span><br><span class="line"></span><br><span class="line">状态相关的主要逻辑有2块：</span><br><span class="line">1：在Checkpoint时将算子子任务中的状态数据写入到外部存储中，这个过程可以简称为：snapshot。</span><br><span class="line">2：在任务初始化或重启时，以一定的逻辑从外部存储中读取状态数据，并且恢复为算子子任务的本地数据，这个过程可以简称为restore。</span><br><span class="line"></span><br><span class="line">针对Keyed State来说，它对这2块内容做了完善的封装，我们程序员可以开箱即用。</span><br><span class="line"></span><br><span class="line">但是对于Operator State来说，每个算子子任务管理自己的Operator State，或者说每个算子子任务上的数据流共享同一个状态实例，可以访问和修改该状态。算子子任务上的数据在程序重启、扩缩容等场景下不能保证百分百的一致性。简单来说，就是Flink应用重启后，某个数据流中的元素不一定会和上次一样，还能流入到对应的子任务上。</span><br><span class="line">因此，我们需要根据自己的业务场景来设计snapshot和restore的逻辑。为了实现这两块的业务逻辑，Flink提供了最为基础的CheckpointedFunction接口。</span><br><span class="line"></span><br><span class="line">所以在这我们可以发现其实FromElementsFunction这个类就实现了CheckpointedFunction这个接口。</span><br><span class="line"></span><br><span class="line">CheckpointedFunction这个接口中提供了两个方法：</span><br><span class="line">void snapshotState(FunctionSnapshotContext context) throws Exception;</span><br><span class="line">void initializeState(FunctionInitializationContext context) throws Exception;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">其中snapshotState对应的就是刚才我们所分析的那个snapshot过程。</span><br><span class="line">initializeState对应的就是刚才我们所分析的那个restore过程。</span><br><span class="line"></span><br><span class="line">那我们来看一下FromElementsFunction里面针对这两个过程是怎么实现的：</span><br><span class="line"></span><br><span class="line">首先看一下snapshotState这个方法：</span><br><span class="line">这个方法会在checkpoint时触发执行，将checkpointedState中的数据持久化到外部存储中。</span><br><span class="line"></span><br><span class="line">public void snapshotState(FunctionSnapshotContext context) throws Exception &#123;</span><br><span class="line">    Preconditions.checkState(</span><br><span class="line">            this.checkpointedState !&#x3D; null,</span><br><span class="line">            &quot;The &quot; + getClass().getSimpleName() + &quot; has not been properly initialized.&quot;);</span><br><span class="line">    &#x2F;&#x2F;先清空一下checkpointedState中之前保存的数据</span><br><span class="line">    this.checkpointedState.clear();</span><br><span class="line">&#x2F;&#x2F;然后把目前正在处理的数据保存到checkpointedState中</span><br><span class="line">    this.checkpointedState.add(this.numElementsEmitted);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">接下来看一下initializeState这个方法：</span><br><span class="line">这个方法会在任务第一次启动，以及后续重启时执行，主要是为了从外部存储中读取状态数据，并且把状态数据恢复成本地数据。</span><br><span class="line"></span><br><span class="line">public void initializeState(FunctionInitializationContext context) throws Exception &#123;</span><br><span class="line">    Preconditions.checkState(</span><br><span class="line">            this.checkpointedState &#x3D;&#x3D; null,</span><br><span class="line">            &quot;The &quot; + getClass().getSimpleName() + &quot; has already been initialized.&quot;);</span><br><span class="line">    &#x2F;&#x2F;注册状态</span><br><span class="line">    this.checkpointedState &#x3D;</span><br><span class="line">            context.getOperatorStateStore()</span><br><span class="line">                    .getListState(</span><br><span class="line">                            new ListStateDescriptor&lt;&gt;(</span><br><span class="line">                                    &quot;from-elements-state&quot;, IntSerializer.INSTANCE));</span><br><span class="line">   &#x2F;&#x2F;判断任务是否是重启</span><br><span class="line">    if (context.isRestored()) &#123;</span><br><span class="line">        List&lt;Integer&gt; retrievedStates &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">&#x2F;&#x2F;从外部存储中读取状态数据，存储为本地数据</span><br><span class="line">        for (Integer entry : this.checkpointedState.get()) &#123;</span><br><span class="line">            retrievedStates.add(entry);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; given that the parallelism of the function is 1, we can only have 1 state</span><br><span class="line">        Preconditions.checkArgument(</span><br><span class="line">                retrievedStates.size() &#x3D;&#x3D; 1,</span><br><span class="line">                getClass().getSimpleName() + &quot; retrieved invalid state.&quot;);</span><br><span class="line">        &#x2F;&#x2F;从本地数据中获取第一条数据赋值给numElementsToSkip </span><br><span class="line">        this.numElementsToSkip &#x3D; retrievedStates.get(0);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：在initializeState里面注册状态时，首先会根据指定的状态名称到状态的外部存储中检查一下是否存在一个和当前状态名称相同的状态，如果存在，则尝试对状态进行恢复，如果不存在，则默认初始化状态。</span><br><span class="line"></span><br><span class="line">这个是Flink中自带的有状态的Source。</span><br></pre></td></tr></table></figure>

<h6 id="自定义一个有状态的Sink"><a href="#自定义一个有状态的Sink" class="headerlink" title="自定义一个有状态的Sink"></a>自定义一个有状态的Sink</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">下面我们通过自定义一个有状态的Sink来感受一下CheckpointedFunction的具体使用：</span><br><span class="line"></span><br><span class="line">需求是这样的：</span><br><span class="line">我们想要实现一个批量输出的功能，此时可以考虑在Sink组件内部定义一个缓存，但是还要保证数据一定会输出到外部系统。这个时候就需要借助于状态实现了，通过snapshotState定期将批量缓存的数据保存到状态中，如果程序出现了故障，重启后还可以从状态中将未输出的数据读取到缓存中，继续输出到外部系统。</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.<span class="type">RuntimeExecutionMode</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.<span class="type">StreamExecutionEnvironment</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过自定义Sink实现批量输出</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">OperatorState_MyBufferSinkDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(<span class="type">RuntimeExecutionMode</span>.<span class="type">AUTOMATIC</span>)</span><br><span class="line">    <span class="comment">//设置并行度为2</span></span><br><span class="line">    env.setParallelism(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> text = env.socketTextStream(<span class="string">"bigdata04"</span>, <span class="number">9001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.flink.api.scala._</span><br><span class="line">    text.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">      .map((_, <span class="number">1</span>))</span><br><span class="line">      .addSink(<span class="keyword">new</span> <span class="type">MyBufferSink</span>())</span><br><span class="line"></span><br><span class="line">    env.execute(<span class="string">"OperatorState_MyBufferSinkDemo"</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ListState</span>, <span class="type">ListStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.&#123;<span class="type">FunctionInitializationContext</span>, <span class="type">FunctionSnapshotContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.checkpoint.<span class="type">CheckpointedFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.<span class="type">SinkFunction</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义批量输出Sink</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyBufferSink</span> <span class="keyword">extends</span> <span class="title">SinkFunction</span>[(<span class="type">String</span>,<span class="type">Int</span>)] <span class="keyword">with</span> <span class="title">CheckpointedFunction</span></span>&#123;</span><br><span class="line">  <span class="comment">//声明一个ListState类型的状态变量</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> checkpointedState: <span class="type">ListState</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = _</span><br><span class="line"></span><br><span class="line">  <span class="comment">//定义一个本地缓存</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> bufferElements = <span class="type">ListBuffer</span>[(<span class="type">String</span>, <span class="type">Int</span>)]()</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Sink的核心处理逻辑，将接收到的数据输出到外部系统</span></span><br><span class="line"><span class="comment">   * 接收到一条数据，这个方法就会执行一次</span></span><br><span class="line"><span class="comment">   * @param value</span></span><br><span class="line"><span class="comment">   * @param context</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>), context: <span class="type">SinkFunction</span>.<span class="type">Context</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//将接收到的数据保存到本地缓存中</span></span><br><span class="line">    bufferElements += value</span><br><span class="line">    <span class="comment">//当本地缓存大小到达一定阈值时，将本地缓存中的数据一次性输出到外部系统</span></span><br><span class="line">    <span class="keyword">if</span> (bufferElements.size == <span class="number">2</span>) &#123;</span><br><span class="line">      println(<span class="string">"======start======"</span>)</span><br><span class="line">      <span class="keyword">for</span> (element &lt;- bufferElements) &#123;</span><br><span class="line">        println(element)</span><br><span class="line">      &#125;</span><br><span class="line">      println(<span class="string">"======end======"</span>)</span><br><span class="line">      <span class="comment">//清空本地缓存中的数据</span></span><br><span class="line">      bufferElements.clear()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 将本地缓存中的数据保存到状态中，在执行checkpoint时，会将状态中的数据持久化到外部存储中</span></span><br><span class="line"><span class="comment">   * @param context</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">snapshotState</span></span>(context: <span class="type">FunctionSnapshotContext</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//将上次写入到状态中的数据清空</span></span><br><span class="line">    checkpointedState.clear()</span><br><span class="line">    <span class="comment">//将最新的本地缓存中的数据写入到状态中</span></span><br><span class="line">    <span class="keyword">for</span> (element &lt;- bufferElements) &#123;</span><br><span class="line">      checkpointedState.add(element)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 初始化或者恢复状态</span></span><br><span class="line"><span class="comment">   * @param context</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">initializeState</span></span>(context: <span class="type">FunctionInitializationContext</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//注册状态</span></span><br><span class="line">    <span class="keyword">val</span> descriptor = <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>[(<span class="type">String</span>, <span class="type">Int</span>)](</span><br><span class="line">      <span class="string">"buffered-elements"</span>,</span><br><span class="line">      classOf[(<span class="type">String</span>,<span class="type">Int</span>)]</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">//此时借助于context获取OperatorStateStore，进而获取ListState</span></span><br><span class="line">    checkpointedState = context.getOperatorStateStore.getListState(descriptor)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果是重启任务，需要从外部存储中读取状态数据并写入到本地缓存中</span></span><br><span class="line">    <span class="keyword">if</span>(context.isRestored) &#123;</span><br><span class="line">      checkpointedState.get().forEach(e=&gt;&#123;</span><br><span class="line">        bufferElements += e</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">开启一个新的Socket</span><br><span class="line"></span><br><span class="line">启动代码。</span><br><span class="line">在socket中模拟产生数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">此时控制台没有输出数据。</span><br><span class="line"></span><br><span class="line">再产生一条数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">b</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">此时控制台依然没有输出数据。</span><br><span class="line">为什么产生两条数据了还是没有输出？这是因为此时我们给程序设置的并行度为2。所以sink组件会产生2个子任务，这两条数据现在被划分到了两个子任务中，每个子任务只收到了1条数据，所以不满足输出数据的条件。</span><br><span class="line">如果把任务的并行度修改为1这个时候就会输出数据了。</span><br><span class="line"></span><br><span class="line">再产生一条数据：</span><br><span class="line">[root@bigdata04 ~]# nc -l 9001</span><br><span class="line">a</span><br><span class="line"></span><br><span class="line">此时发现控制台输出数据了：</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;start&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">(a,1)</span><br><span class="line">(a,1)</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;end&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这样就通过自定义Sink实现了有状态的批量输出功能。</span><br></pre></td></tr></table></figure>

<h6 id="UnionListState的使用"><a href="#UnionListState的使用" class="headerlink" title="UnionListState的使用"></a>UnionListState的使用</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">针对UnionListState的使用，在Kafka Connector中的FlinkKafkaConsumerBase里面有应用，我们来看一下对应的代码：</span><br><span class="line">前面其实我们已经简单分析了一些内容了，这个时候再来查看FlinkKafkaConsumerBase这个类，理解会更深一些：</span><br><span class="line">public abstract class FlinkKafkaConsumerBase&lt;T&gt; extends RichParallelSourceFunction&lt;T&gt;</span><br><span class="line">        implements CheckpointListener, ResultTypeQueryable&lt;T&gt;, CheckpointedFunction &#123;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在这里可以发现这个类其实也实现了CheckpointedFunction接口。</span><br><span class="line">那我们来看一下FlinkKafkaConsumerBase中对应的snapshotState和initializeState这两个方法的实现</span><br><span class="line"></span><br><span class="line">首先来看snapshotState方法：</span><br><span class="line">snapshotState方法里面的逻辑大致就是先清空之前unionOffsetStates中的数据，然后写入最新的数据。</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">final</span> void snapshotState(<span class="type">FunctionSnapshotContext</span> context) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!running) &#123;</span><br><span class="line">        <span class="type">LOG</span>.debug(<span class="string">"snapshotState() called on closed source"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">//清空之前写入的状态数据</span></span><br><span class="line">        unionOffsetStates.clear();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> <span class="type">AbstractFetcher</span>&lt;?, ?&gt; fetcher = <span class="keyword">this</span>.kafkaFetcher;</span><br><span class="line">        <span class="keyword">if</span> (fetcher == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// the fetcher has not yet been initialized, which means we need to return the</span></span><br><span class="line">            <span class="comment">// originally restored offsets or the assigned partitions</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">Map</span>.<span class="type">Entry</span>&lt;<span class="type">KafkaTopicPartition</span>, <span class="type">Long</span>&gt; subscribedPartition :</span><br><span class="line">                    subscribedPartitionsToStartOffsets.entrySet()) &#123;</span><br><span class="line"><span class="comment">//向状态中写入数据</span></span><br><span class="line">                unionOffsetStates.add(</span><br><span class="line">                        <span class="type">Tuple2</span>.of(</span><br><span class="line">                                subscribedPartition.getKey(), subscribedPartition.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (offsetCommitMode == <span class="type">OffsetCommitMode</span>.<span class="type">ON_CHECKPOINTS</span>) &#123;</span><br><span class="line">                <span class="comment">// the map cannot be asynchronously updated, because only one checkpoint call</span></span><br><span class="line">                <span class="comment">// can happen</span></span><br><span class="line">                <span class="comment">// on this function at a time: either snapshotState() or</span></span><br><span class="line">                <span class="comment">// notifyCheckpointComplete()</span></span><br><span class="line">                pendingOffsetsToCommit.put(context.getCheckpointId(), restoredState);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">HashMap</span>&lt;<span class="type">KafkaTopicPartition</span>, <span class="type">Long</span>&gt; currentOffsets = fetcher.snapshotCurrentState();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (offsetCommitMode == <span class="type">OffsetCommitMode</span>.<span class="type">ON_CHECKPOINTS</span>) &#123;</span><br><span class="line">                <span class="comment">// the map cannot be asynchronously updated, because only one checkpoint call</span></span><br><span class="line">                <span class="comment">// can happen</span></span><br><span class="line">                <span class="comment">// on this function at a time: either snapshotState() or</span></span><br><span class="line">                <span class="comment">// notifyCheckpointComplete()</span></span><br><span class="line">                pendingOffsetsToCommit.put(context.getCheckpointId(), currentOffsets);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">Map</span>.<span class="type">Entry</span>&lt;<span class="type">KafkaTopicPartition</span>, <span class="type">Long</span>&gt; kafkaTopicPartitionLongEntry :</span><br><span class="line">                    currentOffsets.entrySet()) &#123;</span><br><span class="line"><span class="comment">//向状态中写入数据</span></span><br><span class="line">                unionOffsetStates.add(</span><br><span class="line">                        <span class="type">Tuple2</span>.of(</span><br><span class="line">                                kafkaTopicPartitionLongEntry.getKey(),</span><br><span class="line">                                kafkaTopicPartitionLongEntry.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (offsetCommitMode == <span class="type">OffsetCommitMode</span>.<span class="type">ON_CHECKPOINTS</span>) &#123;</span><br><span class="line">            <span class="comment">// truncate the map of pending offsets to commit, to prevent infinite growth</span></span><br><span class="line">            <span class="keyword">while</span> (pendingOffsetsToCommit.size() &gt; <span class="type">MAX_NUM_PENDING_CHECKPOINTS</span>) &#123;</span><br><span class="line">                pendingOffsetsToCommit.remove(<span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">接下来再看一下initializeState方法</span><br><span class="line">initializeState方法里面的逻辑大致就是初始化或者获取unionOffsetStates，然后再判断任务是不是重启，是的话就把数据给本地变量。</span><br><span class="line">这里面比较特殊的就是在获取状态时使用的是getUnionListState这个方法，这个方法返回的就是UnionListState这种类型的状态了。这种状态咱们前面分析过，他的底层其实就是ListState、唯一的区别就是任务在故障恢复时状态数据的传输方式不一样。</span><br><span class="line">这里面用到了UnionListState，说明FlinkKafkaConsumer在故障恢复的时候每个子任务都可以获取到之前所有子任务中维护的状态数据，这样做的目的是为了便于重新给每个子任务分配需要消费的topic分区信息。</span><br><span class="line">此时Flink任务在重启的时候，每个FlinkKafkaConsumer子任务都可以获取到待消费的kafka中指定topic的所有分区信息和对应的消费偏移量信息，具体某一个FlinkKafkaConsumer子任务在运行的时候会按照一定的策略选择一个或者多个分区进行消费。</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">final</span> void initializeState(<span class="type">FunctionInitializationContext</span> context) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">OperatorStateStore</span> stateStore = context.getOperatorStateStore();</span><br><span class="line">    <span class="comment">//初始化或者获取unionOffsetStates，这里用到了getUnionListState</span></span><br><span class="line">    <span class="keyword">this</span>.unionOffsetStates =</span><br><span class="line">            stateStore.getUnionListState(</span><br><span class="line">                    <span class="keyword">new</span> <span class="type">ListStateDescriptor</span>&lt;&gt;(</span><br><span class="line">                            <span class="type">OFFSETS_STATE_NAME</span>,</span><br><span class="line">                            createStateSerializer(getRuntimeContext().getExecutionConfig())));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">        restoredState = <span class="keyword">new</span> <span class="type">TreeMap</span>&lt;&gt;(<span class="keyword">new</span> <span class="type">KafkaTopicPartition</span>.<span class="type">Comparator</span>());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// populate actual holder for restored state</span></span><br><span class="line"><span class="comment">//从外部存储中获取状态数据，恢复到本地变量中</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">Tuple2</span>&lt;<span class="type">KafkaTopicPartition</span>, <span class="type">Long</span>&gt; kafkaOffset : unionOffsetStates.get()) &#123;</span><br><span class="line">            restoredState.put(kafkaOffset.f0, kafkaOffset.f1);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">LOG</span>.info(</span><br><span class="line">                <span class="string">"Consumer subtask &#123;&#125; restored state: &#123;&#125;."</span>,</span><br><span class="line">                getRuntimeContext().getIndexOfThisSubtask(),</span><br><span class="line">                restoredState);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">LOG</span>.info(</span><br><span class="line">                <span class="string">"Consumer subtask &#123;&#125; has no restore state."</span>,</span><br><span class="line">                getRuntimeContext().getIndexOfThisSubtask());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这就是UnionListState的使用。</span><br></pre></td></tr></table></figure>

<h6 id="BroadcastState的使用"><a href="#BroadcastState的使用" class="headerlink" title="BroadcastState的使用"></a>BroadcastState的使用</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">针对BroadcastState的使用，一个典型的应用案例就是两个流连接的场景。</span><br><span class="line">假设其中一个数据流是 事件数据流，它属于普通的数据流，里面是一些用户行为数据。</span><br><span class="line"></span><br><span class="line">另外一个数据流是 配置数据流，它不是普通的数据流，它是广播数据流，里面是一些映射关系数据。</span><br><span class="line"></span><br><span class="line">需求是使用配置数据流中的映射关系数据去完善事件数据流中的用户行为数据。</span><br><span class="line"></span><br><span class="line">这个需求来源于某直播平台，这个直播平台会在多个国家运营，如果每一个国家都使用一套运营策略，会比较麻烦，运营成本比较高，意义也不是特别大。为了方便运营管理，所以平台内部提出了大区这个概念，可以将一些国家划分到同一个大区里面，同一个大区使用相同的运营策略。</span><br><span class="line">那么对应的就有国家和大区之间的映射关系，这个映射关系不是一成不变的，他会随着平台的发展而发生变化。</span><br><span class="line">在用户行为数据中针对用户的基础数据里面只有用户所属的国家信息，没有包含大区信息，因为国家和大区的关系是可变的，但是在做报表统计的时候，是需要以大区维度进行统计的。</span><br><span class="line">所以针对实时报表这种场景，就需要对用户行为数据中的国家信息进行实时关联转换了。</span><br><span class="line"></span><br><span class="line">为了加深理解，来看一下下面这个图：</span><br></pre></td></tr></table></figure>

<p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306011848126.png" alt="image-20230601184843285"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">这个图里面有两个实时数据流。</span><br><span class="line">上面的事件数据流里面是用户的行为数据。</span><br><span class="line">下面的配置数据流里面是国家和大区之间的最新映射关系。</span><br><span class="line">在程序中需要将配置数据流广播出去，转换为BroadcastState，然后将两份数据流连接到一起，这样在处理事件数据流中的用户行为数据的时候，可以获取到BroadcastState，基于这份状态数据对用户行为数据中的国家信息进行转换。</span><br><span class="line"></span><br><span class="line">下面我们来基于这个需求开发一下对应的代码。</span><br><span class="line"></span><br><span class="line">针对事件数据流在实际工作中基本上是来源于kafka的，在这里为了演示方便，我们来开发一个自定义的Source模拟产生数据。</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.<span class="type">SimpleDateFormat</span></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Date</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.&#123;<span class="type">RichSourceFunction</span>, <span class="type">SourceFunction</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事件数据流-自定义Source</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyStreamSource</span> <span class="keyword">extends</span> <span class="title">RichSourceFunction</span>[<span class="type">String</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> isRunning = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 初始化方法，只执行一次</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param parameters</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Source的核心方法，负责源源不断的产生数据</span></span><br><span class="line"><span class="comment">   * @param ctx</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> sdf = <span class="keyword">new</span> <span class="type">SimpleDateFormat</span>(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>)</span><br><span class="line">    <span class="keyword">while</span> (isRunning)&#123;</span><br><span class="line">      <span class="comment">//&#123;"dt":"2026-01-01 10:11:11","countryCode":"US","data":[&#123;"type":"s1","score":0.3,"level":"A"&#125;,&#123;"type":"s2","score":0.2,"level":"B"&#125;]&#125;</span></span><br><span class="line">      <span class="keyword">val</span> time = sdf.format(<span class="keyword">new</span> <span class="type">Date</span>)</span><br><span class="line">      <span class="keyword">val</span> line_prefix = <span class="string">"&#123;\"dt\":\""</span>+time+<span class="string">"\",\"countryCode\":\""</span></span><br><span class="line">      <span class="keyword">val</span> line_suffix = <span class="string">"\",\"data\":[&#123;\"type\":\"s1\",\"score\":0.3,\"level\":\"A\"&#125;,&#123;\"type\":\"s2\",\"score\":0.2,\"level\":\"B\"&#125;]&#125;"</span></span><br><span class="line">      <span class="keyword">val</span> countryCodeArr = <span class="type">Array</span>(<span class="string">"US"</span>,<span class="string">"PK"</span>,<span class="string">"KW"</span>)</span><br><span class="line">      <span class="keyword">val</span> num = <span class="type">Random</span>.nextInt(<span class="number">3</span>)</span><br><span class="line">      ctx.collect(line_prefix+countryCodeArr(num)+line_suffix)</span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">1000</span>)<span class="comment">//每隔1秒产生一条数据，控制一下数据产生速度</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 任务停止的时候执行一次</span></span><br><span class="line"><span class="comment">   * 这里主要负责控制run方法中的循环</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    isRunning = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *任务停止的时候执行一次</span></span><br><span class="line"><span class="comment">   * 这里主要负责关闭在open方法中创建的连接</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">针对配置数据流在实际工作中基本上是来源于Redis或者MySQL，在这里为了演示方便，我们来开发一个自定义的Source模拟从Redis中获取数据。</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.scala.state</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.&#123;<span class="type">RichSourceFunction</span>, <span class="type">SourceFunction</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 配置数据流-自定义Source</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRedisSource</span> <span class="keyword">extends</span> <span class="title">RichSourceFunction</span>[mutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">String</span>]]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> isRunning = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 初始化方法，只执行一次</span></span><br><span class="line"><span class="comment">   * @param parameters</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//TODO 创建Redis数据库连接</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Source的核心方法，负责源源不断的产生数据</span></span><br><span class="line"><span class="comment">   * @param ctx</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(ctx: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[mutable.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">while</span> (isRunning)&#123;</span><br><span class="line">      <span class="comment">//TODO 需要从Redis中获取这些映射关系</span></span><br><span class="line">      <span class="keyword">val</span> resMap = mutable.<span class="type">Map</span>(<span class="string">"US"</span>-&gt;<span class="string">"AREA_US"</span>,<span class="string">"PK"</span>-&gt;<span class="string">"AREA_AR"</span>,<span class="string">"KW"</span>-&gt;<span class="string">"AREA_AR"</span>)</span><br><span class="line">      ctx.collect(resMap)</span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">5000</span>)<span class="comment">//每隔5秒更新一次配置数据</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 任务停止的时候执行一次</span></span><br><span class="line"><span class="comment">   * 这里主要负责控制run方法中的循环</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    isRunning = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *任务停止的时候执行一次</span></span><br><span class="line"><span class="comment">   * 这里主要负责关闭在open方法中创建的连接</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//TODO 关闭Redis数据库连接</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">package com.imooc.scala.state</span><br><span class="line"></span><br><span class="line">import com.alibaba.fastjson.JSON</span><br><span class="line">import org.apache.flink.api.common.RuntimeExecutionMode</span><br><span class="line">import org.apache.flink.api.common.state.MapStateDescriptor</span><br><span class="line">import org.apache.flink.streaming.api.functions.co.BroadcastProcessFunction</span><br><span class="line">import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment</span><br><span class="line">import org.apache.flink.util.Collector</span><br><span class="line"></span><br><span class="line">import scala.collection.JavaConverters.mapAsJavaMap</span><br><span class="line">import scala.collection.mutable</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * BroadcastState在两个流连接中的应用（双流Join）</span><br><span class="line"> * 这个场景类似于：一个事实表（事件数据流） left join 一个维度表（配置数据流）</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">object OperatorState_BroadcastStateDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit &#x3D; &#123;</span><br><span class="line">    val env &#x3D; StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">    env.setRuntimeMode(RuntimeExecutionMode.AUTOMATIC)</span><br><span class="line"></span><br><span class="line">    import org.apache.flink.api.scala._</span><br><span class="line">    &#x2F;&#x2F;构建第1个数据流：事件数据流</span><br><span class="line">    val eventStream &#x3D; env.addSource(new MyStreamSource)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;构建第2个数据流：配置数据流</span><br><span class="line">    val confStream &#x3D; env.addSource(new MyRedisSource)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;将配置数据流广播出去，变成广播数据流，并且注册一个MapState</span><br><span class="line">    val countryAreaMapStateDescriptor &#x3D; new MapStateDescriptor[String,String](</span><br><span class="line">      &quot;countryArea&quot;,</span><br><span class="line">      classOf[String],</span><br><span class="line">      classOf[String]</span><br><span class="line">    )</span><br><span class="line">    val broadcastStream &#x3D; confStream.broadcast(countryAreaMapStateDescriptor)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;将两个流进行连接</span><br><span class="line">    val broadcastConnectStream &#x3D; eventStream.connect(broadcastStream)</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;处理连接后的流</span><br><span class="line">    broadcastConnectStream.process(new BroadcastProcessFunction[String,mutable.Map[String,String],String]&#123;</span><br><span class="line">      &#x2F;&#x2F;处理事件数据流中的数据</span><br><span class="line">      override def processElement(value: String, ctx: BroadcastProcessFunction[String, mutable.Map[String, String], String]#ReadOnlyContext, out: Collector[String]): Unit &#x3D; &#123;</span><br><span class="line">        val jsonObj &#x3D; JSON.parseObject(value)</span><br><span class="line">        val countryCode &#x3D; jsonObj.getString(&quot;countryCode&quot;)</span><br><span class="line">        &#x2F;&#x2F;取出广播状态中的数据</span><br><span class="line">        val broadcastState &#x3D; ctx.getBroadcastState(countryAreaMapStateDescriptor)</span><br><span class="line">        val area &#x3D; broadcastState.get(countryCode)</span><br><span class="line">        &#x2F;&#x2F;任务刚开始执行的时候broadcastState中的数据为空，所以获取不到数据</span><br><span class="line">        if(area!&#x3D;null)&#123;</span><br><span class="line">          jsonObj.put(&quot;countryCode&quot;,area)</span><br><span class="line">          out.collect(jsonObj.toJSONString)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      &#x2F;&#x2F;处理广播后的配置数据流中的数据</span><br><span class="line">      override def processBroadcastElement(value: mutable.Map[String, String], ctx: BroadcastProcessFunction[String, mutable.Map[String, String], String]#Context, out: Collector[String]): Unit &#x3D; &#123;</span><br><span class="line">        &#x2F;&#x2F;获取BroadcastState</span><br><span class="line">        val broadcastState &#x3D; ctx.getBroadcastState(countryAreaMapStateDescriptor)</span><br><span class="line">        &#x2F;&#x2F;清空BroadcastState中的数据</span><br><span class="line">        broadcastState.clear()</span><br><span class="line">        &#x2F;&#x2F;重新写入最新的映射关系数据</span><br><span class="line">        broadcastState.putAll(mapAsJavaMap(value))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;).print()</span><br><span class="line"></span><br><span class="line">    env.execute(&quot;OperatorState_BroadcastStateDemo&quot;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">运行程序，结果发现程序报错，查看错误日志发现提示的是scala的问题：</span><br><span class="line">Exception in thread &quot;main&quot; java.util.concurrent.ExecutionException: scala.tools.reflect.ToolBoxError: reflective compilation has failed: cannot initialize the compiler due to java.lang.NoClassDefFoundError: Could not initialize class scala.tools.nsc.Properties$</span><br><span class="line">	at org.apache.flink.shaded.guava30.com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:566)</span><br><span class="line">	at org.apache.flink.shaded.guava30.com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:527)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">经过排查发现这个问题主要是因为我们代码里面用到了mapAsJavaMap这种功能，此时需要引入scala相关的依赖包：</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;scala-reflect&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">2.12</span><span class="number">.11</span>&lt;/version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;scala-compiler&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">2.12</span><span class="number">.11</span>&lt;/version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;scala-library&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">2.12</span><span class="number">.11</span>&lt;/version&gt;</span><br><span class="line">    &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">重新运行程序，发现可以正常运行，并且输出数据：</span><br><span class="line"></span><br><span class="line">3&gt; &#123;&quot;dt&quot;:&quot;2022-05-29 18:11:07&quot;,&quot;data&quot;:[&#123;&quot;score&quot;:0.3,&quot;level&quot;:&quot;A&quot;,&quot;type&quot;:&quot;s1&quot;&#125;,&#123;&quot;score&quot;:0.2,&quot;level&quot;:&quot;B&quot;,&quot;type&quot;:&quot;s2&quot;&#125;],&quot;countryCode&quot;:&quot;AREA_US&quot;&#125;</span><br><span class="line">4&gt; &#123;&quot;dt&quot;:&quot;2022-05-29 18:11:08&quot;,&quot;data&quot;:[&#123;&quot;score&quot;:0.3,&quot;level&quot;:&quot;A&quot;,&quot;type&quot;:&quot;s1&quot;&#125;,&#123;&quot;score&quot;:0.2,&quot;level&quot;:&quot;B&quot;,&quot;type&quot;:&quot;s2&quot;&#125;],&quot;countryCode&quot;:&quot;AREA_AR&quot;&#125;</span><br><span class="line">5&gt; &#123;&quot;dt&quot;:&quot;2022-05-29 18:11:09&quot;,&quot;data&quot;:[&#123;&quot;score&quot;:0.3,&quot;level&quot;:&quot;A&quot;,&quot;type&quot;:&quot;s1&quot;&#125;,&#123;&quot;score&quot;:0.2,&quot;level&quot;:&quot;B&quot;,&quot;type&quot;:&quot;s2&quot;&#125;],&quot;countryCode&quot;:&quot;AREA_AR&quot;&#125;</span><br><span class="line">6&gt; &#123;&quot;dt&quot;:&quot;2022-05-29 18:11:10&quot;,&quot;data&quot;:[&#123;&quot;score&quot;:0.3,&quot;level&quot;:&quot;A&quot;,&quot;type&quot;:&quot;s1&quot;&#125;,&#123;&quot;score&quot;:0.2,&quot;level&quot;:&quot;B&quot;,&quot;type&quot;:&quot;s2&quot;&#125;],&quot;countryCode&quot;:&quot;AREA_AR&quot;&#125;</span><br><span class="line">7&gt; &#123;&quot;dt&quot;:&quot;2022-05-29 18:11:11&quot;,&quot;data&quot;:[&#123;&quot;score&quot;:0.3,&quot;level&quot;:&quot;A&quot;,&quot;type&quot;:&quot;s1&quot;&#125;,&#123;&quot;score&quot;:0.2,&quot;level&quot;:&quot;B&quot;,&quot;type&quot;:&quot;s2&quot;&#125;],&quot;countryCode&quot;:&quot;AREA_AR&quot;&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这就是BroadcastState的常用应用场景。</span><br><span class="line"></span><br><span class="line">注意：针对这个需求，因为没有对数据流进行keyBy分组，如果不对配置数据流进行广播，那么在处理事件数据流中的数据的时候，每一个子任务无法获取到配置数据流中的所有映射关系，所以只能通过全量广播，这样才能让事件数据流的每一个子任务都可以获取到所有的配置数据流中的数据，最终实现数据关联转换。</span><br></pre></td></tr></table></figure>

<h5 id="Operator-State的使用形式总结"><a href="#Operator-State的使用形式总结" class="headerlink" title="Operator State的使用形式总结"></a>Operator State的使用形式总结</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在程序中想要使用Operator State，主要通过实现CheckpointedFunction这个接口，然后实现接口中的initializeState和snapshotState函数。</span><br><span class="line"></span><br><span class="line">可以开发一些自定义的类去继承SourceFunction、SinkFunction或者MapFunction，同时实现CheckpointedFunction这个接口，这样也可以在里面使用状态了。</span><br><span class="line"></span><br><span class="line">注意：CheckpointedFunction这种方式，既可以操作Operator State，也可以操作Keyed State，在代码中同时操作这两种类型的State也是可以的。</span><br><span class="line"></span><br><span class="line">因为在initializeState中，通过context既可以获取KeyedState，又可以获取OperatorState。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">context.getKeyedStateStore</span><br><span class="line">context.getOperatorStateStore</span><br></pre></td></tr></table></figure>



<hr>
<blockquote>
</blockquote>

      
    </div>
    
    
    
	
	<div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-1.html">大数据开发工程师-Flink新版本1.12以上-1</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 TTYONG 的个人博客">TTYONG</a></p>
  <p><span>发布时间:</span>2023年04月20日 - 16:04</p>
  <p><span>最后更新:</span>2023年06月02日 - 16:06</p>
  <p><span>原始链接:</span><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-1.html" title="大数据开发工程师-Flink新版本1.12以上-1">http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-1.html</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-1.html" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
    });
    });  
</script>



      
	</div>



    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>多少都是爱</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat_reward.jpg" alt="TTYONG 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay_reward.jpg" alt="TTYONG 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E9%AB%98%E7%BA%A7%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF-2.html" rel="next" title="大数据开发工程师-第十七周 Flink极速上手篇-Flink高级进阶之路-2">
                <i class="fa fa-chevron-left"></i> 大数据开发工程师-第十七周 Flink极速上手篇-Flink高级进阶之路-2
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1.12%E4%BB%A5%E4%B8%8A-2.html" rel="prev" title="大数据开发工程师-第十七周 Flink新版本1.12以上-2">
                大数据开发工程师-第十七周 Flink新版本1.12以上-2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
      
        
          <ul class="sidebar-nav motion-element">
            <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
              文章目录
            </li>
            <li class="sidebar-nav-overview" data-target="site-overview">
              站点概览
            </li>
          </ul>
        
      

	<section class="site-overview sidebar-panel">
	  <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
		<img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="TTYONG">
		<p class="site-author-name" itemprop="name">TTYONG</p>
		 
			<p class="site-description motion-element" itemprop="description"></p>
		 
	  </div>
	  <nav class="site-state motion-element">

		
		  <div class="site-state-item site-state-posts">
			<a href="/archives/%7C%7C%20archive">
			  <span class="site-state-item-count">371</span>
			  <span class="site-state-item-name">日志</span>
			</a>
		  </div>
		

		
		  
		  
		  <div class="site-state-item site-state-categories">
			<a href="/categories/index.html">
			  <span class="site-state-item-count">51</span>
			  <span class="site-state-item-name">分类</span>
			</a>
		  </div>
		

		
		  
		  
		  <div class="site-state-item site-state-tags">
			<a href="/tags/index.html">
			  <span class="site-state-item-count">116</span>
			  <span class="site-state-item-name">标签</span>
			</a>
		  </div>
		

	  </nav>

	  
		<div class="feed-link motion-element">
		  <a href="/atom.xml" rel="alternate">
			<i class="fa fa-rss"></i>
			RSS
		  </a>
		</div>
	  

	  <div class="links-of-author motion-element">
		
		  
			<span class="links-of-author-item">
			  <a href="2364076207@qq.com || envelope" target="_blank" title="E-Mail">
				
				  <i class="fa fa-fw fa-globe"></i>
				
				E-Mail
			  </a>
			</span>
		  
			<span class="links-of-author-item">
			  <a href="https://wpa.qq.com/msgrd?v=3&uin=2364076207&site=qq&menu=yes || qq" target="_blank" title="QQ" rel="external nofollow noopener noreferrer">
				
				  <i class="fa fa-fw fa-globe"></i>
				
				QQ
			  </a>
			</span>
		  
			<span class="links-of-author-item">
			  <a href="https://weibo.com/p/1005051833844383/home || weixin" target="_blank" title="WeiXin" rel="external nofollow noopener noreferrer">
				
				  <i class="fa fa-fw fa-globe"></i>
				
				WeiXin
			  </a>
			</span>
		  
			<span class="links-of-author-item">
			  <a href="https://www.zhihu.com/people/he-he-ty || zhihu" target="_blank" title="ZhiHu" rel="external nofollow noopener noreferrer">
				
				  <i class="fa fa-fw fa-globe"></i>
				
				ZhiHu
			  </a>
			</span>
		  
		
	  </div>

	  
	  

	  
	  
		<div class="links-of-blogroll motion-element links-of-blogroll-block">
		  <div class="links-of-blogroll-title">
			<i class="fa  fa-fw fa-link"></i>
			友链
		  </div>
		  <ul class="links-of-blogroll-list">
			
			  <li class="links-of-blogroll-item">
				<a href="https://www.baidu.com/" target="_blank" rel="external nofollow noopener noreferrer">百度</a>
			  </li>
			
		  </ul>
		</div>
	  

	  


	</section>
	
	  
	  <!--noindex-->
		<section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
		  <div class="post-toc">

			
			  
			

			
			  <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Flink新版本1-12以上-1"><span class="nav-number">1.</span> <span class="nav-text">Flink新版本1.12以上-1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink新版本新特性介绍"><span class="nav-number">1.1.</span> <span class="nav-text">Flink新版本新特性介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#快速上手使用Flink1-15"><span class="nav-number">1.2.</span> <span class="nav-text">快速上手使用Flink1.15</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#开发Flink-1-15代码"><span class="nav-number">1.2.1.</span> <span class="nav-text">开发Flink 1.15代码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#依赖"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WordCountScala"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">WordCountScala</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在已有的大数据集群中集成Flink-1-15环境"><span class="nav-number">1.2.2.</span> <span class="nav-text">在已有的大数据集群中集成Flink 1.15环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#向YARN中同时提交Flink-1-11-和1-15版本的代码"><span class="nav-number">1.2.3.</span> <span class="nav-text">向YARN中同时提交Flink 1.11 和1.15版本的代码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink1-15-0版本的代码"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">Flink1.15.0版本的代码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Flink1-11-1版本的代码"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">Flink1.11.1版本的代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink-1-15之State-状态-的容错与一致性"><span class="nav-number">1.3.</span> <span class="nav-text">Flink 1.15之State(状态)的容错与一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是State-状态"><span class="nav-number">1.3.1.</span> <span class="nav-text">什么是State(状态)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#离线计算是否需要State-状态-？"><span class="nav-number">1.3.2.</span> <span class="nav-text">离线计算是否需要State(状态)？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#State相关概念整体概览"><span class="nav-number">1.3.3.</span> <span class="nav-text">State相关概念整体概览</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#State-状态-的类型"><span class="nav-number">1.3.4.</span> <span class="nav-text">State(状态)的类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Raw-State-VS-Managed-State"><span class="nav-number">1.3.5.</span> <span class="nav-text">Raw State VS Managed State</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#托管状态-Managed-State-的类型"><span class="nav-number">1.3.5.1.</span> <span class="nav-text">托管状态(Managed State)的类型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Keyed-State-VS-Operator-State"><span class="nav-number">1.3.5.1.1.</span> <span class="nav-text">Keyed State VS Operator State</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Keyed-State类型的状态的扩缩容模式"><span class="nav-number">1.3.5.1.1.1.</span> <span class="nav-text">Keyed State类型的状态的扩缩容模式</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Operator-State类型的状态的扩缩容模式"><span class="nav-number">1.3.5.1.1.2.</span> <span class="nav-text">Operator State类型的状态的扩缩容模式</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Keyed-State详解"><span class="nav-number">1.3.5.1.2.</span> <span class="nav-text">Keyed State详解</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Keyed-State中支持的数据结构"><span class="nav-number">1.3.5.1.3.</span> <span class="nav-text">Keyed State中支持的数据结构</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Keyed-State的使用案例"><span class="nav-number">1.3.5.1.4.</span> <span class="nav-text">Keyed State的使用案例</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#温度告警-ValueState"><span class="nav-number">1.3.5.1.4.1.</span> <span class="nav-text">温度告警-ValueState</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#直播间数据统计-MapState"><span class="nav-number">1.3.5.1.4.2.</span> <span class="nav-text">直播间数据统计-MapState</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#订单数据补全-ListState"><span class="nav-number">1.3.5.1.4.3.</span> <span class="nav-text">订单数据补全-ListState</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Keyed-State的使用形式总结"><span class="nav-number">1.3.5.1.5.</span> <span class="nav-text">Keyed State的使用形式总结</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Operator-State-详解"><span class="nav-number">1.3.5.1.6.</span> <span class="nav-text">Operator State 详解</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Operator-State中支持的数据结构"><span class="nav-number">1.3.5.1.6.1.</span> <span class="nav-text">Operator State中支持的数据结构</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Operator-State的使用案例"><span class="nav-number">1.3.5.1.7.</span> <span class="nav-text">Operator State的使用案例</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#ListState的使用"><span class="nav-number">1.3.5.1.7.1.</span> <span class="nav-text">ListState的使用</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Flink中自带的有状态的Source"><span class="nav-number">1.3.5.1.7.2.</span> <span class="nav-text">Flink中自带的有状态的Source</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#自定义一个有状态的Sink"><span class="nav-number">1.3.5.1.7.3.</span> <span class="nav-text">自定义一个有状态的Sink</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#UnionListState的使用"><span class="nav-number">1.3.5.1.7.4.</span> <span class="nav-text">UnionListState的使用</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#BroadcastState的使用"><span class="nav-number">1.3.5.1.7.5.</span> <span class="nav-text">BroadcastState的使用</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Operator-State的使用形式总结"><span class="nav-number">1.3.5.1.8.</span> <span class="nav-text">Operator State的使用形式总结</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div>
			

		  </div>
		</section>
	  <!--/noindex-->
	  
	

	

  </div>
</aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2020.3.4 &mdash; <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TTYONG</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">726.5k</span>
  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io" rel="external nofollow>Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next rel="external nofollow">NexT.Pisces</a> v5.1.4</div>



-->  


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 访问总量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
  <div id="gitalk-container"></div>
  <script src="/js/src/md5.min.js"></script>
  <script type="text/javascript">
    var gitalk = new Gitalk({
      clientID: 'd3f3299eb0cc69c8f171',
      clientSecret: '23bf8796e5dda2daf0a1b12964d89f4cc88f9ddf',
      repo: 'comments_repository',
      owner: 'ttyong',
      admin: ['ttyong'],
      id: md5(location.pathname),
      distractionFreeMode: 'false'
    })
    gitalk.render('gitalk-container')
  </script>

  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  
  

  

  

  

  <link rel="stylesheet" href="/dist/APlayer.min.css">
  <div id="aplayer"></div>
  <script type="text/javascript" src="/dist/APlayer.min.js"></script>
  <script type="text/javascript" src="/dist/music.js"></script>
  
  
  
  

  <canvas id="evanyou"></canvas>
  <style>
    #evanyou {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
  <script src="/js/src/evan-you.js"></script>




  <script src="/js/src/activate-power-mode.min.js"></script>
  <script>
    POWERMODE.colorful = true;
    POWERMODE.shake = false;
    document.body.addEventListener('input', POWERMODE);
  </script>




  <script async src="/js/cursor/fireworks.js"></script>




<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
