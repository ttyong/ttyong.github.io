<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>TianYong&#39;s Blog</title>
  
  <subtitle>比你优秀的人都努力，有什么理由不努力！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://tianyong.fun/"/>
  <updated>2022-02-18T08:59:18.998Z</updated>
  <id>http://tianyong.fun/</id>
  
  <author>
    <name>TTYONG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>写linux的shell脚本方法积累</title>
    <link href="http://tianyong.fun/%E5%86%99linux%E7%9A%84shell%E8%84%9A%E6%9C%AC%E6%96%B9%E6%B3%95%E7%A7%AF%E7%B4%AF.html"/>
    <id>http://tianyong.fun/%E5%86%99linux%E7%9A%84shell%E8%84%9A%E6%9C%AC%E6%96%B9%E6%B3%95%E7%A7%AF%E7%B4%AF.html</id>
    <published>2022-02-18T06:58:58.000Z</published>
    <updated>2022-02-18T08:59:18.998Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="写linux的shell脚本方法积累"><a href="#写linux的shell脚本方法积累" class="headerlink" title="写linux的shell脚本方法积累"></a>写linux的shell脚本方法积累</h1><h1 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"># 循环向文件中生成数据</span><br><span class="line"># 下面括号里没空格会报错</span><br><span class="line">while [ &quot;1&quot;&#x3D;&quot;1&quot; ]</span><br><span class="line">do</span><br><span class="line">        # 获取当前时间戳</span><br><span class="line">        curr_time&#x3D;&#96;date +%s&#96;</span><br><span class="line">        # 获取当前主机名</span><br><span class="line">        name&#x3D;&#96;hostname&#96;</span><br><span class="line">        echo $&#123;name&#125;_$&#123;curr_time&#125; &gt;&gt; &#x2F;data&#x2F;log&#x2F;networkLogUploadToHdfsExample&#x2F;access.l</span><br><span class="line">og</span><br><span class="line">        sleep 1</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="案例二"><a href="#案例二" class="headerlink" title="案例二"></a>案例二</h2><pre><code></code></pre><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="linux" scheme="http://tianyong.fun/categories/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第2章 极速上手Flume使用 采集网络日志上传到HDFS</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC2%E7%AB%A0-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8BFlume%E4%BD%BF%E7%94%A8-%E9%87%87%E9%9B%86%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97%E4%B8%8A%E4%BC%A0%E5%88%B0HDFS.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC2%E7%AB%A0-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8BFlume%E4%BD%BF%E7%94%A8-%E9%87%87%E9%9B%86%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97%E4%B8%8A%E4%BC%A0%E5%88%B0HDFS.html</id>
    <published>2022-02-18T04:47:46.000Z</published>
    <updated>2022-02-18T08:56:12.026Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第七周-第2章-极速上手Flume使用-采集网络日志上传到HDFS"><a href="#第七周-第2章-极速上手Flume使用-采集网络日志上传到HDFS" class="headerlink" title="第七周 第2章 极速上手Flume使用 采集网络日志上传到HDFS"></a>第七周 第2章 极速上手Flume使用 采集网络日志上传到HDFS</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">前面我们讲了两个案例的使用，接下来看一个稍微复杂一点的案例：</span><br><span class="line">需求是这样的，</span><br><span class="line">1. 将A和B两台机器实时产生的日志数据汇总到机器C中</span><br><span class="line">2. 通过机器C将数据统一上传至HDFS的指定目录中</span><br><span class="line">注意：HDFS中的目录是按天生成的，每天一个目录</span><br><span class="line">看下面这个图，来详细分析一下</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HTp8o9" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/18/HTp8o9.md.png" alt="HTp8o9.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">根据刚才的需求分析可知，我们一共需要三台机器</span><br><span class="line">这里使用bigdata02和bigdata03采集当前机器上产生的实时日志数据，统一汇总到bigdata04机器上。</span><br><span class="line">其中bigdata02和bigdata03中的source使用基于file的source，ExecSource，因为要实时读取文件中的新增数据channel在这里我们使用基于内存的channel，因为这里是采集网站的访问日志，就算丢一两条数据对整体结果影响也不大，我们只希望采集到的数据可以快读进入hdfs中，所以就选择了基于内存的channel。</span><br><span class="line">由于bigdata02和bigdata03的数据需要快速发送到bigdata04中，为了快速发送我们可以通过网络直接传输，sink建议使用avrosink，avro是一种数据序列化系统，经过它序列化的数据传输起来效率更高，并且它对应的还有一个avrosource，avrosink的数据可以直接发送给avrosource，所以他们可以无缝衔接。</span><br><span class="line">这样bigdata04的source就确定了 使用avrosource、channel还是基于内存的channel，sink就使用hdfssink，因为是要向hdfs中写数据的。</span><br><span class="line">这里面的组件，只有execsource、avrosource、avrosink我们还没有使用过，其他的组件都使用过了。</span><br><span class="line">最终需要在每台机器上启动一个agent，启动的时候需要注意先后顺序，先启动bigdata04上面的，再启动bigdata02和bigdata03上面的。</span><br></pre></td></tr></table></figure><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><h3 id="bigdata02"><a href="#bigdata02" class="headerlink" title="bigdata02"></a>bigdata02</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">略</span><br></pre></td></tr></table></figure><h3 id="bigdata03"><a href="#bigdata03" class="headerlink" title="bigdata03"></a>bigdata03</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">略</span><br></pre></td></tr></table></figure><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：bigdata02和bigdata03中配置的a1.sinks.k1.port 的值45454需要和bigdata04中配置的一致</span><br></pre></td></tr></table></figure><h3 id="bigdata02-conf"><a href="#bigdata02-conf" class="headerlink" title="bigdata02 conf"></a>bigdata02 conf</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata02 conf]# vim file-to-avro-101.conf</span><br><span class="line"></span><br><span class="line">a1.sources&#x3D;r1</span><br><span class="line">a1.channels&#x3D;c1</span><br><span class="line">a1.sinks&#x3D;k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; exec</span><br><span class="line">a1.sources.r1.command &#x3D; tail -F &#x2F;data&#x2F;log&#x2F;networkLogUploadToHdfsExample&#x2F;access.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c1.transactionCapacity &#x3D; 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line"># ip也行</span><br><span class="line">a1.sinks.k1.hostname &#x3D; bigdata04</span><br><span class="line"># 端口没用过的就行</span><br><span class="line">a1.sinks.k1.port &#x3D; 45454</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels&#x3D;c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure><h3 id="bigdata03-conf"><a href="#bigdata03-conf" class="headerlink" title="bigdata03 conf"></a>bigdata03 conf</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata03 conf]# vim file-to-avro-102.conf</span><br><span class="line"></span><br><span class="line">a1.sources&#x3D;r1</span><br><span class="line">a1.channels&#x3D;c1</span><br><span class="line">a1.sinks&#x3D;k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; exec</span><br><span class="line">a1.sources.r1.command &#x3D; tail -F &#x2F;data&#x2F;log&#x2F;networkLogUploadToHdfsExample&#x2F;access.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c1.transactionCapacity &#x3D; 100</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line"># ip也行</span><br><span class="line">a1.sinks.k1.hostname &#x3D; bigdata04</span><br><span class="line"># 端口没用过的就行</span><br><span class="line">a1.sinks.k1.port &#x3D; 45454</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels&#x3D;c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure><h3 id="bigdata04-conf"><a href="#bigdata04-conf" class="headerlink" title="bigdata04 conf"></a>bigdata04 conf</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这台机器我们已经安装过Flume了，所以直接配置Agent即可</span><br><span class="line">在指定Agent中sink配置的时候注意，我们的需求是需要按天在hdfs中创建目录，并把当天的数据上传到当天的日期目录中，这也就意味着hdfssink中的path不能写死，需要使用变量，动态获取时间，查看官方文档可知，在hdfs的目录中需要使用%Y%m%d</span><br><span class="line">在这还有一点需要注意的，因为我们这里需要抽取时间，这个时间其实是需要从数据里面抽取，咱们前面说过数据的基本单位是Event，Event是一个对象，后面我们会详细分析，在这里大家先知道它里面包含的既有我们采集到的原始的数据，还有一个header属性，这个header属性是一个key-value结构的，我们现在抽取时间就需要到event的header中抽取，但是默认情况下event的header中是没有日期的，强行抽取是会报错的，会提示抽取不到，返回空指针异常。</span><br><span class="line">java.lang.NullPointerException: Expected timestamp in the Flume event headers, but it was n</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">那如何向header中添加日期呢？ 其实官方文档中也说了，可以使用hdfs.useLocalTimeStamp或者时间拦截器，时间拦截器我们后面会讲，暂时最简单直接的方式就是使用hdfs.useLocalTimeStamp，这个属性的值默认为false，需要改为true。</span><br></pre></td></tr></table></figure><p><img src="C:%5CUsers%5CTy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220218163730584.png" alt="image-20220218163730584"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 conf]# vim avro-to-hdfs.conf </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.sources&#x3D;r1</span><br><span class="line">a1.channels&#x3D;c1</span><br><span class="line">a1.sinks&#x3D;k1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; avro</span><br><span class="line">a1.sources.r1.bind &#x3D; 0.0.0.0</span><br><span class="line">a1.sources.r1.port &#x3D; 45454</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c1.transactionCapacity &#x3D; 100</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;flume&#x2F;networkLogUploadToHdfsExaple&#x2F;%Y%m%d</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix &#x3D; access-</span><br><span class="line">a1.sinks.k1.hdfs.fileSuffix&#x3D;.log</span><br><span class="line">a1.sinks.k1.hdfs.fileType&#x3D;DataStream</span><br><span class="line">a1.sinks.k1.hdfs.writeFormat&#x3D;Text</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval&#x3D;3600</span><br><span class="line">a1.sinks.k1.hdfs.rollSize&#x3D;134217728</span><br><span class="line">a1.sinks.k1.hdfs.rollCount&#x3D;0</span><br><span class="line">#(不设置前面使用时间变量会报错)使用event header里的timestamp要麻烦些</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp&#x3D;true</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels&#x3D;c1</span><br><span class="line">a1.sinks.k1.channel&#x3D;c1</span><br></pre></td></tr></table></figure><h2 id="模拟数据源"><a href="#模拟数据源" class="headerlink" title="模拟数据源"></a>模拟数据源</h2><h3 id="bigdata02-1"><a href="#bigdata02-1" class="headerlink" title="bigdata02"></a>bigdata02</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata02 log]# vim SimulateData.sh </span><br><span class="line"></span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"># 循环向文件中生成数据</span><br><span class="line">while [ &quot;1&quot;&#x3D;&quot;1&quot; ]</span><br><span class="line">do</span><br><span class="line">        # 获取当前时间戳</span><br><span class="line">        curr_time&#x3D;&#96;date +%s&#96;</span><br><span class="line">        # 获取当前主机名</span><br><span class="line">        name&#x3D;&#96;hostname&#96;</span><br><span class="line">        echo $&#123;name&#125;_$&#123;curr_time&#125; &gt;&gt; &#x2F;data&#x2F;log&#x2F;networkLogUploadToHdfsExample&#x2F;access.log</span><br><span class="line">        sleep 1</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="bigdata03-1"><a href="#bigdata03-1" class="headerlink" title="bigdata03"></a>bigdata03</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">同上</span><br></pre></td></tr></table></figure><h2 id="启动进程"><a href="#启动进程" class="headerlink" title="启动进程"></a>启动进程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">接下来开始启动相关的服务进程</span><br><span class="line">首先启动bigdata04上的agent服务</span><br><span class="line">接下来启动bigdata-02上的agent服务和shell脚本</span><br><span class="line">最后启动bigdata-03上的agent服务和shell脚本</span><br></pre></td></tr></table></figure><h3 id="启动bigdata04"><a href="#启动bigdata04" class="headerlink" title="启动bigdata04"></a>启动bigdata04</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">略</span><br></pre></td></tr></table></figure><h3 id="启动bigdata02"><a href="#启动bigdata02" class="headerlink" title="启动bigdata02"></a>启动bigdata02</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">略</span><br></pre></td></tr></table></figure><h3 id="启动bigdata03"><a href="#启动bigdata03" class="headerlink" title="启动bigdata03"></a>启动bigdata03</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">略</span><br></pre></td></tr></table></figure><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.shell脚本</span><br><span class="line">while [ 1&#x3D;1 ] </span><br><span class="line"># 两个空格不能少</span><br><span class="line"></span><br><span class="line">2.flume配置</span><br><span class="line">注释不要写在语句的同一行后面</span><br><span class="line"></span><br><span class="line">3.启动agent时</span><br><span class="line">先启动bigdata02,bigdata03和先关bigdata04都会造成数据流失</span><br></pre></td></tr></table></figure><h2 id="结果查看"><a href="#结果查看" class="headerlink" title="结果查看"></a>结果查看</h2><p><a href="https://imgtu.com/i/HTfiPs" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/18/HTfiPs.md.png" alt="HTfiPs.md.png"></a></p><p><a href="https://imgtu.com/i/HTfGM6" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/18/HTfGM6.md.png" alt="HTfGM6.md.png"></a><br><a href="https://imgtu.com/i/HTf3xx" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/18/HTf3xx.md.png" alt="HTf3xx.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：启动之后稍等一会就可以看到数据了，我们观察数据的变化，会发现hdfs中数据增长的不是很快，它会每隔一段时间添加一批数据，实时性好像没那么高？</span><br><span class="line">这是因为avrosink中有一个配置batch-size，它的默认值是100，也就是每次发送100条数据，如果数据不够100条，则不发送。</span><br><span class="line">具体这个值设置多少合适，要看你source数据源大致每秒产生多少数据，以及你希望的延迟要达到什么程度，如果这个值设置太小的话，会造成sink频繁向外面写数据，这样也会影响性能。</span><br><span class="line">最终，依次停止bigdata02、bigdata03中的服务，最后停止bigdata04中的服务</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HTIFTU" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/18/HTIFTU.md.png" alt="HTIFTU.md.png"></a></p><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第2章 极速上手Flume使用 采集文件内容到HDFS</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC2%E7%AB%A0-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8BFlume%E4%BD%BF%E7%94%A8-%E9%87%87%E9%9B%86%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E5%88%B0HDFS.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC2%E7%AB%A0-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8BFlume%E4%BD%BF%E7%94%A8-%E9%87%87%E9%9B%86%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E5%88%B0HDFS.html</id>
    <published>2022-02-18T04:18:46.000Z</published>
    <updated>2022-02-18T07:13:44.005Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第2章-极速上手Flume使用-采集文件内容到HDFS"><a href="#第2章-极速上手Flume使用-采集文件内容到HDFS" class="headerlink" title="第2章 极速上手Flume使用 采集文件内容到HDFS"></a>第2章 极速上手Flume使用 采集文件内容到HDFS</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看一个工作中的典型案例：</span><br><span class="line">采集文件内容上传至HDFS</span><br><span class="line">需求：采集目录中已有的文件内容，存储到HDFS</span><br><span class="line">分析：source是要基于目录的，channel建议使用file，可以保证不丢数据，sink使用hdfs</span><br><span class="line">下面要做的就是配置Agent了，可以把example.conf拿过来修改一下，新的文件名为file-to-hdfs.conf</span><br><span class="line">首先是基于目录的source，咱们前面说过，Spooling Directory Source可以实现目录监控来看一下这个Spooling Directory Source</span><br></pre></td></tr></table></figure><h2 id="source"><a href="#source" class="headerlink" title="source"></a>source</h2><h3 id="Spooling-Directory-Source"><a href="#Spooling-Directory-Source" class="headerlink" title="Spooling Directory Source"></a>Spooling Directory Source</h3><p><a href="https://imgtu.com/i/HI4GDS" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/HI4GDS.md.png" alt="HI4GDS.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">channels和type肯定是必填的，还有一个是spoolDir，就是指定一个监控的目录</span><br><span class="line">看他下面的案例，里面还多指定了一个fileHeader，这个我们暂时也用不到，后面等我们讲了Event之后</span><br><span class="line">大家就知道这个fileHeader可以干什么了，先记着有这个事把。</span><br></pre></td></tr></table></figure><h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">接下来是channel了</span><br><span class="line">channel在这里使用基于文件的，可以保证数据的安全性</span><br><span class="line">如果针对采集的数据，丢个一两条对整体结果影响不大，只要求采集效率，那么这个时候完全可以使用基于内存的channel</span><br><span class="line">咱们前面的例子中使用的是基于内存的channel，下面我们到文档中找一下基于文件的channel</span><br></pre></td></tr></table></figure><h3 id="File-Channel"><a href="#File-Channel" class="headerlink" title="File Channel"></a>File Channel</h3><p><a href="https://imgtu.com/i/HI5YM6" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/HI5YM6.md.png" alt="HI5YM6.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">根据这里的例子可知，主要配置checkpointDir和dataDir，因为这两个目录默认会在用户家目录下生成，建议修改到其他地方</span><br><span class="line">checkpointDir是存放检查点目录</span><br><span class="line">data是存放数据的目录</span><br></pre></td></tr></table></figure><h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">最后是sink</span><br><span class="line">因为要向hdfs中输出数据，所以可以使用hdfssink</span><br></pre></td></tr></table></figure><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p><a href="https://imgtu.com/i/HIozKx" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/HIozKx.md.png" alt="HIozKx.md.png"></a></p><p><a href="https://imgtu.com/i/HITpqK" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/HITpqK.md.png" alt="HITpqK.md.png"></a></p><p><a href="https://imgtu.com/i/HITCVO" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/HITCVO.md.png" alt="HITCVO.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs.path是必填项，指定hdfs上的存储目录</span><br><span class="line">看这里例子中还指定了filePrefix参数，这个是一个文件前缀，会在hdfs上生成的文件前面加上这个前缀，这个属于可选项，有需求的话可以加上</span><br><span class="line">一般在这我们需要设置writeFormat和fileType这两个参数</span><br><span class="line">默认情况下writeFormat的值是Writable，建议改为Text，看后面的解释，如果后期想使用hive或者impala操作这份数据的话，必须在生成数据之前设置为Text，Text表示是普通文本数据</span><br><span class="line">fileType默认是SequenceFile，还支持DataStream 和 CompressedStream ，DataStream 不会对输出数据进行压缩，CompressedStream 会对输出数据进行压缩，在这里我们先不使用压缩格式的，所以选择DataStream</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">除了这些参数以外，还有三个也比较重要</span><br><span class="line">hdfs.rollInterval、hdfs.rollSize和hdfs.rollCount</span><br><span class="line">hdfs.rollInterval默认值是30，单位是秒，表示hdfs多长时间切分一个文件，因为这个采集程序是一直运行的，只要有新数据，就会被采集到hdfs上面，hdfs默认30秒钟切分出来一个文件，如果设置为0表示不按时间切文件</span><br><span class="line">hdfs.rollSize默认是1024，单位是字节，最终hdfs上切出来的文件大小都是1024字节，如果设置为0表示不按大小切文件</span><br><span class="line">hdfs.rollCount默认设置为10，表示每隔10条数据切出来一个文件，如果设置为0表示不按数据条数切文件</span><br><span class="line">这三个参数，如果都设置的有值，哪个条件先满足就按照哪个条件都会执行。</span><br><span class="line">在实际工作中一般会根据时间或者文件大小来切分文件，我们之前在工作中是设置的时间和文件大小相结合，时间设置的是一小时，文件大小设置的128M，这两个哪个满足执行哪个</span><br><span class="line">所以针对hdfssink的配置最终是这样的</span><br></pre></td></tr></table></figure><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line"></span><br><span class="line"># Describe&#x2F;configure the source</span><br><span class="line">a1.sources.r1.type &#x3D; spooldir</span><br><span class="line">a1.sources.r1.spoolDir &#x3D; &#x2F;data&#x2F;log&#x2F;studentDir</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type &#x3D; file</span><br><span class="line">a1.channels.c1.checkpointDir &#x3D; &#x2F;data&#x2F;soft&#x2F;apache-flume-1.9.0-bin&#x2F;data&#x2F;studentDir&#x2F;chec</span><br><span class="line">kpoint</span><br><span class="line">a1.channels.c1.dataDirs &#x3D; &#x2F;data&#x2F;soft&#x2F;apache-flume-1.9.0-bin&#x2F;data&#x2F;studentDir&#x2F;data</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type &#x3D; hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;192.168.206.129:9000&#x2F;flume&#x2F;studentDir</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix &#x3D; stu-</span><br><span class="line">a1.sinks.k1.hdfs.fileType &#x3D; DataStream</span><br><span class="line">a1.sinks.k1.hdfs.writeFormat &#x3D; Text</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval &#x3D; 3600</span><br><span class="line">a1.sinks.k1.hdfs.rollSize &#x3D; 134217728</span><br><span class="line">a1.sinks.k1.hdfs.rollCount &#x3D; 0</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure><h2 id="测试文件"><a href="#测试文件" class="headerlink" title="测试文件"></a>测试文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">下面就可以启动agent了，在启动agent之前，先初始化一下测试数据</span><br><span class="line">创建&#x2F;data&#x2F;log&#x2F;studentDir目录，然后在里面添加一个文件，class1.dat</span><br><span class="line">class1.dat中存储的是学生信息，学生姓名、年龄、性别</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ~]# mkdir -p &#x2F;data&#x2F;log&#x2F;studentDir</span><br><span class="line">[root@bigdata04 ~]# cd &#x2F;data&#x2F;log&#x2F;studentDir</span><br><span class="line">[root@bigdata04 studentDir]# more class1.dat</span><br><span class="line">jack 18 male</span><br><span class="line">jessic 20 female</span><br><span class="line">tom 17 male</span><br></pre></td></tr></table></figure><h2 id="启动Agent"><a href="#启动Agent" class="headerlink" title="启动Agent"></a>启动Agent</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">启动之前，先启动hadoop</span><br><span class="line">启动Agent，使用在前台启动的方式，方便观察现象</span><br><span class="line"></span><br><span class="line">apache-flume-1.9.0-bin]# bin&#x2F;flume-ng agent --name a1 --conf conf --conf-file conf&#x2F;file-to-hdfs.conf -Dflume.root.logger&#x3D;INFO,console</span><br></pre></td></tr></table></figure><h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2020-05-02 15:36:58,283 (conf-file-poller-0) [ERROR - org.apache.flume.node.P</span><br><span class="line">java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hadoop&#x2F;io&#x2F;SequenceFile$Compression</span><br><span class="line">at org.apache.flume.sink.hdfs.HDFSEventSink.configure(HDFSEventSink.j</span><br><span class="line">at org.apache.flume.conf.Configurables.configure(Configurables.java:4</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.io.SequenceFil</span><br><span class="line">at java.net.URLClassLoader.findClass(URLClassLoader.java:382)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)</span><br><span class="line">at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">... 12 more</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">但是发现在启动的时候报错，提示找不到SequenceFile，但是我们已经把fileType改为了DataStream，</span><br><span class="line">但是Flume默认还是会加载这个类</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.io.SequenceFile$CompressionT</span><br><span class="line">ype</span><br><span class="line">就算你把SequenceFile相关的jar包都拷贝到flume的lib目录下解决了这个问题，但是还是会遇到找不到</span><br><span class="line">找不到HDFS这种文件类型，还是缺少hdfs相关的jar包</span><br><span class="line">No FileSystem for scheme: hdfs</span><br><span class="line">当然这个问题也可以通过拷贝jar包来解决这个问题，但是这样其实太费劲了，并且后期我们有很大可能需要在这个节点上操作HDFS，所以其实最简单直接的方法就是把这个节点设置为hadoop集群的一个客户端节点，这样操作hdfs就没有任何问题了。</span><br><span class="line">咱们之前在讲Hadoop的时候讲了客户端节点的特性，其实很简单，我们直接把集群中修改好配置的hadoop目录远程拷贝到bigdata04上就可以了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 soft]# scp -rq hadoop-3.2.0 192.168.182.103:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line"></span><br><span class="line">由于bigdata01和bigdata04没有做免密码登录，也不认识它的主机名，所以就使用ip，并且输入密码了。</span><br><span class="line">拷贝完成之后到bigdata04节点上验证一下</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注意：还需要修改环境变量，配置HADOOP_HOME，否则启动Agent的时候还是会提示找不到SequenceFile</span><br><span class="line"></span><br><span class="line">[root@bigdata04 hadoop-3.2.0]# vi &#x2F;etc&#x2F;profile</span><br><span class="line">.....</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;jdk1.8</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;hadoop-3.2.0</span><br><span class="line">export PATH&#x3D;.:$JAVA_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$PATH</span><br><span class="line">[root@bigdata04 hadoop-3.2.0]# source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><h2 id="再次启动Agent"><a href="#再次启动Agent" class="headerlink" title="再次启动Agent"></a>再次启动Agent</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">此时可以看到Agent正常启动</span><br><span class="line"></span><br><span class="line">到hdfs上验证结果</span><br><span class="line">[root@bigdata01 lib]# hdfs dfs -ls &#x2F;flume&#x2F;studentDir</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   2 root supergroup         47 2022-02-18 11:46 &#x2F;flume&#x2F;studentDir&#x2F;stu-.1645155976762.tmp</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">此时发现文件已经生成了，只不过默认情况下现在的文件是 .tmp 结尾的，表示它在被使用，因为Flume只要采集到数据就会向里面写，这个后缀默认是由 hdfs.inUseSuffix 参数来控制的。</span><br><span class="line">文件名上还拼接了一个当前时间戳，这个是默认文件名的格式，当达到文件切割时机的时候会给文件改名字，去掉.tmp</span><br><span class="line">这个文件现在也是可以查看的，里面的内容其实就是class1.dat文件中的内容</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ~]# hdfs dfs -cat hdfs:&#x2F;&#x2F;192.168.182.100:9000&#x2F;flume&#x2F;studentDi</span><br><span class="line">jack 18 male</span><br><span class="line">jessic 20 female</span><br><span class="line">tom 17 male</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">所以此时Flume就会监控linux中的&#x2F;data&#x2F;log&#x2F;studentDir目录，当发现里面有新文件的时候就会把数据采集过来。</span><br><span class="line">那Flume怎么知道哪些文件是新文件呢？它会不会重复读取同一个文件的数据呢？</span><br><span class="line">不会的，我们到&#x2F;data&#x2F;log&#x2F;studentDir目录看一下你就知道了</span><br><span class="line"></span><br><span class="line">[root@bigdata04 studentDir]# cd checkpoint&#x2F;</span><br><span class="line">[root@bigdata04 checkpoint]# ls</span><br><span class="line">checkpoint  checkpoint.meta  inflightputs  inflighttakes  in_use.lock  queueset</span><br><span class="line">[root@bigdata04 checkpoint]# pwd</span><br><span class="line">&#x2F;data&#x2F;soft&#x2F;apache-flume-1.9.0-bin&#x2F;data&#x2F;studentDir&#x2F;checkpoint</span><br><span class="line">You have new mail in &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 studentDir]# cd data&#x2F;</span><br><span class="line">[root@bigdata04 data]# ls</span><br><span class="line">in_use.lock  log-2       log-3.meta  log-5       log-6.meta</span><br><span class="line">log-1        log-2.meta  log-4       log-5.meta  log-7</span><br><span class="line">log-1.meta   log-3       log-4.meta  log-6       log-7.meta</span><br><span class="line">[root@bigdata04 data]# pwd</span><br><span class="line">&#x2F;data&#x2F;soft&#x2F;apache-flume-1.9.0-bin&#x2F;data&#x2F;studentDir&#x2F;data</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">发现里面有一个 log-1 的文件，这个文件中存储的其实就是读取到的内容，只不过在这无法直接查看。</span><br><span class="line">现在我们想看一下Flume最终生成的文件是什么样子的，难道要根据配置等待1个小时或者弄一个128M的文件过来吗，</span><br><span class="line">其实也没必要，我们可以暴力操作一下</span><br><span class="line">停止Agent就可以看到了，当Agent停止的时候就会去掉 .tmp 标志了</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">那我再重启Agent之后，会不会再给加上.tmp呢，不会了，每次停止之前都会把所有的文件解除占用状态，下次启动的时候如果有新数据，则会产生新的文件，这其实就模拟了一下自动切文件之后的效果。</span><br><span class="line">但是这个文件看起来比较别扭，连个后缀都没有，没有后缀倒不影响使用，就是看起来不好看</span><br><span class="line">在这给大家留一个作业，下一次再生成新文件的时候我希望文件名有一个后缀是.log，大家下去之后自己查看官网文档资料，修改Agent配置，添加测试数据，验证效果。</span><br><span class="line">答案：其实就是使用hdfs sink中的hdfs.fileSuffix参数</span><br></pre></td></tr></table></figure><h2 id="异常-1"><a href="#异常-1" class="headerlink" title="异常"></a>异常</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Flume v1.9.0启动报错ERROR - org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:459)</span><br><span class="line"></span><br><span class="line">Hadoop 3.3.0 中的 guava 版本和 Flume 1.9.0 中的版本不一致</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/llwy1428/article/details/112169028" target="_blank" rel="external nofollow noopener noreferrer">解决</a></p><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第3章 Flume核心复盘篇</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC3%E7%AB%A0-Flume%E6%A0%B8%E5%BF%83%E5%A4%8D%E7%9B%98%E7%AF%87.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC3%E7%AB%A0-Flume%E6%A0%B8%E5%BF%83%E5%A4%8D%E7%9B%98%E7%AF%87.html</id>
    <published>2022-02-16T14:47:50.000Z</published>
    <updated>2022-02-18T04:46:20.625Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第3章 Flume出神入化篇</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC3%E7%AB%A0-Flume%E5%87%BA%E7%A5%9E%E5%85%A5%E5%8C%96%E7%AF%87.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC3%E7%AB%A0-Flume%E5%87%BA%E7%A5%9E%E5%85%A5%E5%8C%96%E7%AF%87.html</id>
    <published>2022-02-16T14:47:37.000Z</published>
    <updated>2022-02-18T04:46:17.747Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第3章 精讲Flume高级组件</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC3%E7%AB%A0-%E7%B2%BE%E8%AE%B2Flume%E9%AB%98%E7%BA%A7%E7%BB%84%E4%BB%B6.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC3%E7%AB%A0-%E7%B2%BE%E8%AE%B2Flume%E9%AB%98%E7%BA%A7%E7%BB%84%E4%BB%B6.html</id>
    <published>2022-02-16T14:47:16.000Z</published>
    <updated>2022-02-18T04:46:14.383Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第2章 极速上手Flume使用</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC2%E7%AB%A0-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8BFlume%E4%BD%BF%E7%94%A8%20%20Flume%E7%9A%84hello%20world.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC2%E7%AB%A0-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8BFlume%E4%BD%BF%E7%94%A8%20%20Flume%E7%9A%84hello%20world.html</id>
    <published>2022-02-16T14:46:42.000Z</published>
    <updated>2022-02-18T04:46:57.098Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第七周-第2章-极速上手Flume使用"><a href="#第七周-第2章-极速上手Flume使用" class="headerlink" title="第七周 第2章 极速上手Flume使用"></a>第七周 第2章 极速上手Flume使用</h1><h2 id="Flume的Hello-World！"><a href="#Flume的Hello-World！" class="headerlink" title="Flume的Hello World！"></a>Flume的Hello World！</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">下面我们就想上手操作Flume，具体该怎么做呢？</span><br><span class="line">先来看一个入门级别的Hello World案例。</span><br><span class="line">我们前面说了，启动Flume任务其实就是启动一个Agent，Agent是由source、channel、sink组成的，这</span><br><span class="line">些组件在使用的时候只需要写几行配置就可以了</span><br><span class="line">那下面我们就看一下source、channel、sink该如何配置呢？</span><br><span class="line">接下来带着大家看一下官网</span><br><span class="line">找到左边的documentation，查看文档信息</span><br><span class="line"></span><br><span class="line">其实Flume的操作文档是非常良心的，整理的非常详细，给flume的维护者们点个赞。</span><br><span class="line">进入Flume User Guide</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H5YXR0" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5YXR0.md.png" alt="H5YXR0.md.png"></a></p><h3 id="flume配置"><a href="#flume配置" class="headerlink" title="flume配置"></a>flume配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">下面有一个Agent配置的例子：</span><br><span class="line"></span><br><span class="line"># example.conf: A single-node Flume configuration</span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line"># Describe&#x2F;configure the source</span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; localhost</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c1.transactionCapacity &#x3D; 100</span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">这个例子中首先定义了source的名字、sink的名字还有channel的名字</span><br><span class="line">下面配置source的相关参数</span><br><span class="line">下面配置了sink的相关参数</span><br><span class="line">接着配置了channel的相关参数</span><br><span class="line">最后把这三个组件连接到了一起，就是告诉source需要向哪个channel写入数据，告诉sink需要从哪个</span><br><span class="line">channel读取数据，这样source、channel、sink这三个组件就联通了。</span><br><span class="line">总结下来，配置Flume agent的主要流程是这样的</span><br><span class="line">1. 给每个组件起名字</span><br><span class="line">2. 配置每个组件的相关参数</span><br><span class="line">3. 把它们联通起来</span><br><span class="line">注意了，在Agent中配置的三大组件为什么要这样写呢？如果我是第一次使用我也不会写啊。</span><br><span class="line">三大组件的配置在文档中是有详细说明的，来看一下，在Flume Sources下面显示的都是已经内置支持的</span><br><span class="line">Source组件</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H5YOGq" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5YOGq.png" alt="H5YOGq.png"></a></p><h4 id="source"><a href="#source" class="headerlink" title="source"></a>source</h4><h5 id="NetCat-Tcp"><a href="#NetCat-Tcp" class="headerlink" title="NetCat Tcp"></a>NetCat Tcp</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">咱们刚才看的案例中使用的是source类型是netcat，其实就是NetCat TCP Source，看一下详细内容</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H5YLin" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5YLin.png" alt="H5YLin.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">这里面的粗体字体是必选的参数</span><br><span class="line">第一个参数是为了指定source需要向哪个channel写数据，这个其实是通用的参数，</span><br><span class="line">主要看下面这三个，type、bind、port</span><br><span class="line">type：类型需要指定为natcat</span><br><span class="line">bind：指定当前机器的ip，使用hostname也可以</span><br><span class="line">port：指定当前机器中一个没有被使用的端口</span><br><span class="line">指定bind和port表示开启监听模式，监听指定ip和端口中的数据，其实就是开启了一个socket的服务端，</span><br><span class="line">等待客户端连接进来写入数据</span><br><span class="line">在这里给agent起名为a1,所以netcat类型的配置如下，这里面还指定了source、channel的名字，并且把</span><br><span class="line">source和channel连接到一起了，刨除这几个配置之外就剩下了三行配置，就是刚才我们分析的那三个必</span><br><span class="line">填参数</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; 0.0.0.0</span><br><span class="line">a1.sources.r1.port &#x3D; 6666</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line"></span><br><span class="line">注意了，bind参数后面指定的ip是四个0，这个当前机器的通用ip，因为一台机器可以有多个ip，例如：</span><br><span class="line">内网ip、外网ip，如果通过bind参数指定某一个ip的话，表示就只监听通过这个ip发送过来的数据了，这</span><br><span class="line">样会有局限性，所以可以指定0.0.0.0。</span><br><span class="line">下面几个参数都是可选配置，默认可以不配置。</span><br><span class="line">接着是channel，案例中channel使用的是memory</span><br></pre></td></tr></table></figure><h4 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h4><h5 id="memory-channel"><a href="#memory-channel" class="headerlink" title="memory channel"></a>memory channel</h5><p><a href="https://imgtu.com/i/H5t5f1" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5t5f1.png" alt="H5t5f1.png"></a><br><a href="https://imgtu.com/i/H5t76K" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5t76K.md.png" alt="H5t76K.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这里面只有type是必填项，其他都是可选的</span><br></pre></td></tr></table></figure><h4 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h4><h5 id="logger-sink"><a href="#logger-sink" class="headerlink" title="logger sink"></a>logger sink</h5> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">最后看一下sink，在案例中sink使用的是logger，对应的就是Logger Sink</span><br><span class="line"></span><br><span class="line">logger sink中默认也只需要指定type即可</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H5NajK" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5NajK.png" alt="H5NajK.png"></a><br><a href="https://imgtu.com/i/H5NUc6" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/17/H5NUc6.md.png" alt="H5NUc6.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">后期我们如果想要使用其他的内置组件，直接到官网文档这里查找即可，这里面的配置有很多，没有必要去记，肯定记不住，只要知道到哪里去找就可以，工作的时候又不是闭卷考试，官网是可以随便使用的，</span><br><span class="line">所以建议大家到官网找到配置之后直接拷贝，要不然自己手写很容易出错。</span><br><span class="line">配置文件分析完了，可以把这些配置放到一个配置文件中，起名叫example.conf，把这个配置文件放到conf&#x2F; 目录下。</span><br></pre></td></tr></table></figure><h3 id="Flume配置文件"><a href="#Flume配置文件" class="headerlink" title="Flume配置文件"></a>Flume配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># example.conf: A single-node Flume configuration</span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line"># Describe&#x2F;configure the source</span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; localhost</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c1.transactionCapacity &#x3D; 100</span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1 注意：这里没有s，真他妈操蛋</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意了，这个配置文件中的a1表示是agent的名称，还有就是port指定的端口必须是未被使用的，可以先查询一下当前机器使用了哪些端口，端口的可用范围是1-65535，如果懒得去查的话，就尽量使用偏大一些的端口，这样被占用的概率就非常低了</span><br></pre></td></tr></table></figure><h3 id="启动Agent"><a href="#启动Agent" class="headerlink" title="启动Agent"></a>启动Agent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;flume-ng agent --name a1 --conf conf --conf-file example.conf -Dflume.root.logger&#x3D;INFO,console</span><br><span class="line">(经过实验，必须在apche安装目录下执行; 在bin下执行有问题)</span><br><span class="line"></span><br><span class="line">这里面使用flume-ng命令</span><br><span class="line"></span><br><span class="line">后面指定agent，表示启动一个Flume的agent代理</span><br><span class="line">--name：指定agent的名字</span><br><span class="line">--conf：指定flume配置文件的根目录</span><br><span class="line">--conf-file：指定Agent对应的配置文件(包含source、channel、sink配置的文件)</span><br><span class="line">-D：动态添加一些参数，在这里是指定了flume的日志输出级别和输出位置，INFO表示日志级别，</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注意了，其实agent的启动命令还可以这样写</span><br><span class="line">bin&#x2F;flume-ng agent -n $agent_name -c conf -f conf&#x2F;flume-conf.properties.template</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">这里面的-n属于简写，完整的写法就是–name</span><br><span class="line">-c完整写法的–conf</span><br><span class="line">-f完整写法是–conf-file</span><br><span class="line">所以以后看到这两种写法要知道他们都是正确的写法。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">启动Agent</span><br><span class="line">在这里我们使用完整的写法，看起来清晰一些</span><br><span class="line">注意了，由于配置文件里面指定了agent的名称为a1,所以在–name后面也需要指定a1，还有就是通过–conf-file指定配置文件的时候需要指定conf目录下的example.conf配置文件</span><br></pre></td></tr></table></figure> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">启动之后会看到如下信息，表示启动成功，启动成功之后，这个窗口会被一直占用，因为Agent服务一直在运行，现在属于一个前台进程</span><br><span class="line"></span><br><span class="line">2020-05-02 10:14:56,464 (lifecycleSupervisor-1-4) [INFO - org.apache.flume.so</span><br></pre></td></tr></table></figure><h4 id="开启的socket服务端"><a href="#开启的socket服务端" class="headerlink" title="开启的socket服务端"></a>开启的socket服务端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">如果看到提示的有ERROR级别的日志信息，就需要具体问题具体分析了，一般都是配置文件配置错误了。</span><br><span class="line">接下来我们需要连接到source中通过netcat开启的socket服务端</span><br><span class="line">克隆一个bigdata04的会话，因为前面启动Agent之后，窗口就被占用了</span><br><span class="line">使用telnet命令可以连接到指定socket服务，telnet后面的主机名和端口是根据example.conf配置文件中配置的</span><br><span class="line">注意：如果提示找不到telnet命令，则需要使用yum在线安装</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 ~]# yum install -y telnet</span><br><span class="line">[root@bigdata04 ~]# telnet localhost 44444</span><br><span class="line">Trying ::1...</span><br><span class="line">telnet: connect to address ::1: Connection refused</span><br><span class="line">Trying 127.0.0.1...</span><br><span class="line">Connected to localhost.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line">hello world!</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">回到Agent所在的窗口，可以看到下面多了一行日志，就是我们在telnet中输入的内容</span><br></pre></td></tr></table></figure><h4 id="修改ip"><a href="#修改ip" class="headerlink" title="修改ip"></a>修改ip</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">按 ctrl+c 断开telnet连接</span><br><span class="line">重新使用telnet连接，此时不使用localhost，使用本机的内网ip可以吗？ 192.168.182.103</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ~]# telnet 192.168.182.103 44444</span><br><span class="line">Trying 192.168.182.103...</span><br><span class="line">telnet: connect to address 192.168.182.103: Connection refused</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">所以此时Agent中source的配置在使用的时候就受限制了，在开启telnet客户端的时候就只能在本地开启了，无法在其他机器上使用，因为source中绑定的ip是localhost。</span><br><span class="line"></span><br><span class="line">如果想要支持一个网络内其它机器上也可以使用telnet链接的话就需要修改bind参数指定的值了最直接的就是指定192.168.182.103这个内网ip，其实还有一种更加通用的方式是指定0.0.0.0，此时表示会监听每一个可用的ip地址，所以在绑定ip端口时，ip通常都会使用0.0.0.0</span><br><span class="line">那在这里我们把example.conf中的localhost改为0.0.0.0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">按ctrl+c停止刚才启动的agent</span><br><span class="line"></span><br><span class="line">a1.sources.r1.bind &#x3D; 0.0.0.0</span><br><span class="line">启动Agent  </span><br><span class="line"></span><br><span class="line">在另一个会话窗口中使用telnet连接</span><br><span class="line">[root@bigdata04 ~]# telnet 192.168.182.103 44444</span><br><span class="line">Trying 192.168.182.103...</span><br><span class="line">Connected to 192.168.182.103.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line">hi</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">此时可以在其他机器上使用telnet连接也可以，在bigdata01机器上</span><br></pre></td></tr></table></figure><h3 id="Flume-Agent后台运行"><a href="#Flume-Agent后台运行" class="headerlink" title="Flume Agent后台运行"></a>Flume Agent后台运行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">但是注意了，此时Flume中Agent服务是在前台运行，这个服务实际工作中需要一直运行，所以需要放到后台运行。</span><br><span class="line">Flume自身没有提供直接把进程放到后台执行的参数，所以就需要使用咱们前面学习的nohup和&amp;了。</span><br><span class="line">此时就不需要指定-Dflume.root.logger&#x3D;INFO,console参数了，默认情况下flume的日志会记录到日志文件中。</span><br><span class="line">停掉之前的Agent，重新执行</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 apache-flume-1.9.0-bin]# nohup bin&#x2F;flume-ng agent --name a1 --conf conf --conf-file xxx &amp;</span><br><span class="line"></span><br><span class="line">启动之后，通过jps命令可以查看到一个application进程，这个就是启动的Agent</span><br><span class="line">[root@bigdata04 apache-flume-1.9.0-bin]# jps</span><br><span class="line">9619 Jps</span><br><span class="line">9581 Application</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">这样看起来不清晰，如果后期启动了多个Agent，都分不出来哪个是哪个了</span><br><span class="line">可以在jps后面加上参数 -ml，这样可以看到启动时指定的一些参数信息</span><br><span class="line">[root@bigdata04 apache-flume-1.9.0-bin]# jps -m</span><br><span class="line">9659 Jps -m</span><br><span class="line">9581 Application --name a1 --conf-file conf&#x2F;example.conf</span><br><span class="line"></span><br><span class="line">或者使用ps命令也可以</span><br><span class="line">[root@bigdata04 apache-flume-1.9.0-bin]# ps -ef|grep flume</span><br><span class="line">root 9581 1500 0 10:54 pts&#x2F;0 00:00:00 &#x2F;data&#x2F;soft&#x2F;jdk1.8&#x2F;bin&#x2F;java</span><br><span class="line">root 9672 1500 0 10:57 pts&#x2F;0 00:00:00 grep --color&#x3D;auto flume</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时需要想要停止这个Agent的话就需要使用kill命令了</span><br></pre></td></tr></table></figure><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">哪个都可以，条条道路通罗马，具体就看你个人喜好了，ps命令显示的内容更为详细。</span><br><span class="line">这个Agent中的sink组件把数据以日志的方式写出去了，所以这个数据默认就会进入到flume的日志文件中，那我们来看一下flume的日志文件在flume的logs目录中有一个flume.log</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 logs]# tail -2 flume.log</span><br><span class="line">02 May 2020 10:54:28,211 INFO [lifecycleSupervisor-1-4] (org.apache.flume.so</span><br><span class="line">02 May 2020 10:54:28,215 INFO [lifecycleSupervisor-1-4] (org.apache.flume.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">再使用telnet向里面输入一些数据</span><br><span class="line">[root@bigdata04 ~]# telnet 192.168.182.103 44444</span><br><span class="line">Trying 192.168.182.103...</span><br><span class="line">Connected to 192.168.182.103.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line">daemon</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">再回agent看</span><br><span class="line">[root@bigdata04 logs]# tail -2 flume.log</span><br><span class="line">02 May 2020 10:54:28,215 INFO [lifecycleSupervisor-1-4] (org.apache.flume.so</span><br><span class="line">02 May 2020 11:00:26,293 INFO [SinkRunner-PollingRunner-DefaultSinkProcessor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果配置文件里不是配置的logger，在这个日志文件里就看不见了</span><br></pre></td></tr></table></figure><h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Error downloading packages:</span><br><span class="line">  1:telnet-0.17-66.el7.x86_64: [Errno 256] No more mirrors to try.(ping www.baidu.com也ping不通)</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第七周 第1章 极速入门Flume</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC1%E7%AB%A0-%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8Flume.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%B8%83%E5%91%A8-%E7%AC%AC1%E7%AB%A0-%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8Flume.html</id>
    <published>2022-02-16T14:45:18.000Z</published>
    <updated>2022-02-18T04:45:58.433Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第七周-第1章-极速入门"><a href="#第七周-第1章-极速入门" class="headerlink" title="第七周 第1章 极速入门"></a>第七周 第1章 极速入门</h1><h2 id="什么是Flume"><a href="#什么是Flume" class="headerlink" title="什么是Flume"></a>什么是Flume</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">先来看一下官方解释</span><br><span class="line">Flume是一个高可用，高可靠，分布式的海量日志采集、聚合和传输的系统，能够有效的收集、聚合、移</span><br><span class="line">动大量的日志数据。</span><br><span class="line">其实通俗一点来说就是Flume是一个很靠谱，很方便、很强的日志采集工具。</span><br><span class="line">他是目前大数据领域数据采集最常用的一个框架</span><br><span class="line">为什么它这么香呢？</span><br><span class="line">主要是因为使用Flume采集数据不需要写一行代码，注意是一行代码都不需要，只需要在配置文件中随便</span><br><span class="line">写几行配置Flume就会死心塌地的给你干活了，是不是很香？</span><br><span class="line">看这个图，这个属于Flume的一个非常典型的应用场景，使用Flume采集数据，最终存储到HDFS上。</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H4pUiV" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/16/H4pUiV.png" alt="H4pUiV.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">左边的web server表示是一个web项目，web项目会产生日志数据，通过中间的Agent把日志数据采集到</span><br><span class="line">HDFS中。</span><br><span class="line">其中这个Agent就是我们使用Flume启动的一个代理，它是一个持续传输数据的服务，数据在Agent内部</span><br><span class="line">的这些组件之间传输的基本单位是Event</span><br><span class="line">从图中可以看到，Agent是由Source、Channel、Sink这三大组件组成的，这就是Flume中的三大核心组</span><br><span class="line">件，</span><br><span class="line">其中source是数据源，负责读取数据</span><br><span class="line">channel是临时存储数据的，source会把读取到的数据临时存储到channel中</span><br><span class="line">sink是负责从channel中读取数据的，最终将数据写出去，写到指定的目的地中</span><br><span class="line">后面我们会详细分析这三大组件。</span><br></pre></td></tr></table></figure><h2 id="Flume的特性"><a href="#Flume的特性" class="headerlink" title="Flume的特性"></a>Flume的特性</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 它有一个简单、灵活的基于流的数据流结构，这个其实就是刚才说的Agent内部有三大组件，数据通</span><br><span class="line">过这三大组件流动的</span><br><span class="line">2. 具有负载均衡机制和故障转移机制，这个后面我们会详细分析</span><br><span class="line">3. 一个简单可扩展的数据模型(Source、Channel、Sink)，这几个组件是可灵活组合的</span><br></pre></td></tr></table></figure><h2 id="Flume高级应用场景"><a href="#Flume高级应用场景" class="headerlink" title="Flume高级应用场景"></a>Flume高级应用场景</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">前面我们分析了Flume的典型常见应用场景，下面来看一下Flume的高级应用场景</span><br><span class="line">看这个图，这个图里面主要演示了Flume的多路输出，就是可以将采集到的一份数据输出到多个目的地</span><br><span class="line">中，不同目的地的数据对应不同的业务场景。</span><br></pre></td></tr></table></figure><h3 id="一对多的输出"><a href="#一对多的输出" class="headerlink" title="一对多的输出"></a>一对多的输出</h3><p><a href="https://imgtu.com/i/H49eOJ" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/16/H49eOJ.png" alt="H49eOJ.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">下面来详细分析一下</span><br><span class="line">这个图里面一共有两个Agent，表示我们启动了2个Flume的代理，或者可以理解为了启动了2个flume的</span><br><span class="line">进程。</span><br><span class="line">首先看左边这个agent，给他起个名字叫 foo</span><br><span class="line">这里面有一个source，source后面接了3个channel，表示source读取到的数据会重复发送给每个</span><br><span class="line">channel，每个channel中的数据都是一样的</span><br><span class="line">针对每个channel都接了一个sink，这三个sink负责读取对应channel中的数据，并且把数据输出到不同</span><br><span class="line">的目的地，</span><br><span class="line">sink1负责把数据写到hdfs中</span><br><span class="line">sink2负责把数据写到一个Java消息服务数据队列中</span><br><span class="line">sink3负责把数据写给另一个Agent</span><br><span class="line">注意了，Flume中多个Agent之间是可以连通的，只需要让前面Agent的sink组件把数据写到下一</span><br><span class="line">个Agent的source组件中即可。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">所以sink3就把数据输出到了Agent bar中</span><br><span class="line">在Agent bar中同样有三个组件，source组件其实就获取到了sink3发送过来的数据，然后把数据临时存</span><br><span class="line">储到自己的channel4中，最终再通过sink组件把数据写到其他地方。</span><br><span class="line">这就是这个场景的应用，把采集到的一份数据重复输出到不同的目的地中</span><br></pre></td></tr></table></figure><h3 id="flume的汇聚功能"><a href="#flume的汇聚功能" class="headerlink" title="flume的汇聚功能"></a>flume的汇聚功能</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">接着再看下面这张图，这张图主要表示了flume的汇聚功能，就是多个Agent采集到的数据统一汇聚到一</span><br><span class="line">个Agent</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H4ifAA" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/16/H4ifAA.png" alt="H4ifAA.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">下面来详细分析一下，</span><br><span class="line">这个图里面一共启动了四个agent，左边的三个agent都是负责采集对应web服务器中的日志数据，数据</span><br><span class="line">采集过来之后统一发送给agent4，最后agent4进行统一汇总，最终写入hdfs。</span><br><span class="line">这种架构的好处是后期如果要修改最终数据的输出目的地，只需要修改agent4中的sink即可，不需要修</span><br><span class="line">改agent1、2、3。</span><br><span class="line">但是这种架构也有弊端，</span><br><span class="line">1. 如果有很多个agent同时向agent4写数据，那么agent4会出现性能瓶颈，导致数据处理过慢</span><br><span class="line">2. 这种架构还存在单点故障问题，如果agent4挂了，那么所有的数据都断了。</span><br><span class="line">不过这些问题可以通过flume中的负载均衡和故障转移机制解决，后面我们会详细分析</span><br></pre></td></tr></table></figure><h2 id="Flume的三大核心组件"><a href="#Flume的三大核心组件" class="headerlink" title="Flume的三大核心组件"></a>Flume的三大核心组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Flume的三大核心组件：</span><br><span class="line">Source：数据源</span><br><span class="line">Channel：临时存储数据的管道</span><br><span class="line">Sink：目的地</span><br><span class="line">接下来具体看一下这三大核心组件都是干什么的</span><br></pre></td></tr></table></figure><h3 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Source：数据源：通过source组件可以指定让Flume读取哪里的数据，然后将数据传递给后面的</span><br><span class="line">channel</span><br><span class="line">Flume内置支持读取很多种数据源，基于文件、基于目录、基于TCP\UDP端口、基于HTTP、Kafka的</span><br><span class="line">等等、当然了，如果这里面没有你喜欢的，他也是支持自定义的</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">在这我们挑几个常用的看一下：</span><br><span class="line">Exec Source：实现文件监控，可以实时监控文件中的新增内容，类似于linux中的tail -f 效果。</span><br><span class="line">在这需要注意 tail -F 和 tail -f 的区别</span><br><span class="line">tail -F</span><br><span class="line">等同于–follow&#x3D;name --retry，根据文件名进行追踪，并保持重试，即该文件被删除或改名后，如果</span><br><span class="line">再次创建相同的文件名，会继续追踪</span><br><span class="line">tail -f</span><br><span class="line">等同于–follow&#x3D;descriptor，根据文件描述符进行追踪，当文件改名或被删除，追踪停止</span><br><span class="line">在实际工作中我们的日志数据一般都会通过log4j记录，log4j产生的日志文件名称是固定的，每天定</span><br><span class="line">时给文件重命名</span><br><span class="line">假设默认log4j会向access.log文件中写日志，每当凌晨0点的时候，log4j都会对文件进行重命名，在</span><br><span class="line">access后面添加昨天的日期，然后再创建新的access.log记录当天的新增日志数据。</span><br><span class="line">这个时候如果想要一直监控access.log文件中的新增日志数据的话，就需要使用tail -F</span><br></pre></td></tr></table></figure><h4 id="Exec-Source"><a href="#Exec-Source" class="headerlink" title="Exec Source"></a>Exec Source</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">NetCat TCP&#x2F;UDP Source： 采集指定端口(tcp、udp)的数据，可以读取流经端口的每一行数据</span><br><span class="line">Spooling Directory Source：采集文件夹里新增的文件</span><br><span class="line">Kafka Source：从Kafka消息队列中采集数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意了，前面我们分析的这几个source组件，其中execsource 和 kafkasource在实际工作中是最</span><br><span class="line">常见的，可以满足大部分的数据采集需求。</span><br></pre></td></tr></table></figure><h4 id="NetCat-TCP-UDP-Source"><a href="#NetCat-TCP-UDP-Source" class="headerlink" title="NetCat TCP/UDP Source"></a>NetCat TCP/UDP Source</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">采集指定端口(tcp、udp)的数据，可以读取流经端口的每一行数据</span><br></pre></td></tr></table></figure><h4 id="Spooling-Directory-Source"><a href="#Spooling-Directory-Source" class="headerlink" title="Spooling Directory Source"></a>Spooling Directory Source</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">采集文件夹里新增的文件</span><br></pre></td></tr></table></figure><h4 id="Kafka-Source"><a href="#Kafka-Source" class="headerlink" title="Kafka Source"></a>Kafka Source</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">从Kafka消息队列中采集数据</span><br></pre></td></tr></table></figure><h3 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Channel：接受Source发出的数据，可以把channel理解为一个临时存储数据的管道</span><br><span class="line">Channel的类型有很多：内存、文件，内存+文件、JDBC等</span><br><span class="line"></span><br><span class="line">接下来我们来分析一下</span><br></pre></td></tr></table></figure><h4 id="Memory-Channel"><a href="#Memory-Channel" class="headerlink" title="Memory Channel"></a>Memory Channel</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Memory Channel：使用内存作为数据的存储</span><br><span class="line">优点是效率高，因为就不涉及磁盘IO</span><br><span class="line">缺点有两个</span><br><span class="line">1：可能会丢数据，如果Flume的agent挂了，那么channel中的数据就丢失了。</span><br><span class="line">2：内存是有限的，会存在内存不够用的情况</span><br></pre></td></tr></table></figure><h4 id="File-Channel"><a href="#File-Channel" class="headerlink" title="File Channel"></a>File Channel</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">File Channel：使用文件来作为数据的存储</span><br><span class="line">优点是数据不会丢失</span><br><span class="line">缺点是效率相对内存来说会有点慢，但是这个慢并没有我们想象中的那么慢，</span><br><span class="line">所以这个也是比较常用的一种channel。</span><br></pre></td></tr></table></figure><h4 id="Spillable-Memory-Channel"><a href="#Spillable-Memory-Channel" class="headerlink" title="Spillable Memory Channel"></a>Spillable Memory Channel</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Spillable Memory Channel：使用内存和文件作为数据存储，即先把数据存到内存中，如果内存中</span><br><span class="line">数据达到阈值再flush到文件中</span><br><span class="line">优点：解决了内存不够用的问题。</span><br><span class="line">缺点：还是存在数据丢失的风险</span><br></pre></td></tr></table></figure><h3 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sink：从Channel中读取数据并存储到指定目的地</span><br><span class="line">Sink的表现形式有很多：打印到控制台、HDFS、Kafka等，</span><br><span class="line">注意：Channel中的数据直到进入目的地才会被删除，当Sink写入目的地失败后，可以自动重写，</span><br><span class="line">不会造成数据丢失，这块是有一个事务保证的。</span><br></pre></td></tr></table></figure><h4 id="常用的sink组件有"><a href="#常用的sink组件有" class="headerlink" title="常用的sink组件有"></a>常用的sink组件有</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Logger Sink：将数据作为日志处理，可以选择打印到控制台或者写到文件中，这个主要在测试的时</span><br><span class="line">候使用</span><br><span class="line">HDFS Sink：将数据传输到HDFS中，这个是比较常见的，主要针对离线计算的场景</span><br><span class="line">Kafka Sink：将数据发送到kafka消息队列中，这个也是比较常见的，主要针对实时计算场景，数据</span><br><span class="line">不落盘，实时传输，最后使用实时计算框架直接处理。</span><br></pre></td></tr></table></figure><h2 id="Flume安装部署"><a href="#Flume安装部署" class="headerlink" title="Flume安装部署"></a>Flume安装部署</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><h3 id="Flume安装部署-1"><a href="#Flume安装部署-1" class="headerlink" title="Flume安装部署"></a>Flume安装部署</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">想要使用Flume采集数据，那肯定要先安装Flume</span><br><span class="line">在这里我重新克隆了一台Linux机器，主机名设置为bigdata04，ip设置为192.168.206.132</span><br><span class="line">屏蔽防火墙，安装jdk并配置环境变量，因为Flume是java开发，所以需要依赖jdk环境</span><br><span class="line"></span><br><span class="line">直接克隆的bigdata01虚拟机的当前状态：ip和hostname需要改，防火墙和java环境已经配置好了，ip映射需要添加</span><br><span class="line">这些工作已经提前做好了，继续往下面分析</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">安装包下载好以后上传到linux机器的&#x2F;data&#x2F;soft目录下，并且解压</span><br><span class="line"></span><br><span class="line">修改盘flume的env环境变量配置文件</span><br><span class="line">在flume的conf目录下，修改flume-env.sh.template的名字，去掉后缀template</span><br><span class="line"></span><br><span class="line">这样就好了，Flume的安装是不是很简单，这个时候我们不需要启动任何进程，只有在配置好采集任务之</span><br><span class="line">后才需要启动Flume。</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>java使用技巧积累</title>
    <link href="http://tianyong.fun/java%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E7%A7%AF%E7%B4%AF.html"/>
    <id>http://tianyong.fun/java%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E7%A7%AF%E7%B4%AF.html</id>
    <published>2022-02-14T13:59:41.000Z</published>
    <updated>2022-02-15T15:04:26.832Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="java使用技巧积累"><a href="#java使用技巧积累" class="headerlink" title="java使用技巧积累"></a>java使用技巧积累</h1><h2 id="休眠固定时间"><a href="#休眠固定时间" class="headerlink" title="休眠固定时间"></a>休眠固定时间</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Thread.sleep((<span class="number">1</span>));</span><br></pre></td></tr></table></figure><h2 id="java生成文件"><a href="#java生成文件" class="headerlink" title="java生成文件"></a>java生成文件</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">generate_141M</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String fileName = <span class="string">"D:\\s_name_141.dat"</span>;</span><br><span class="line">        System.out.println(<span class="string">"start: 开始生成141M文件-&gt;"</span> + fileName);</span><br><span class="line">        BufferedWriter bfw = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(fileName));</span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (num &lt; <span class="number">8221592</span>) &#123;</span><br><span class="line">            bfw.write(<span class="string">"zhangsan beijing"</span>);</span><br><span class="line">            bfw.newLine();</span><br><span class="line">            num++;</span><br><span class="line">            <span class="keyword">if</span> (num % <span class="number">10000</span> == <span class="number">0</span>) &#123;</span><br><span class="line">                bfw.flush();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="字符串变整数"><a href="#字符串变整数" class="headerlink" title="字符串变整数"></a>字符串变整数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer.parseInt(&quot;2&quot;)</span><br><span class="line">生成long型的Long.parseLong(&quot;2&quot;)</span><br></pre></td></tr></table></figure><h2 id="制表符"><a href="#制表符" class="headerlink" title="制表符"></a>制表符</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;t</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="java" scheme="http://tianyong.fun/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>java写文件和读文件</title>
    <link href="http://tianyong.fun/java%E5%86%99%E6%96%87%E4%BB%B6%E5%92%8C%E8%AF%BB%E6%96%87%E4%BB%B6.html"/>
    <id>http://tianyong.fun/java%E5%86%99%E6%96%87%E4%BB%B6%E5%92%8C%E8%AF%BB%E6%96%87%E4%BB%B6.html</id>
    <published>2022-02-14T13:02:15.000Z</published>
    <updated>2022-02-14T13:03:11.573Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="java写文件和读文件"><a href="#java写文件和读文件" class="headerlink" title="java写文件和读文件"></a>java写文件和读文件</h1><p><a href="https://www.cnblogs.com/rinack/p/14173936.html" target="_blank" rel="external nofollow noopener noreferrer">url</a></p><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="java" scheme="http://tianyong.fun/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第六周 第五章 Hadoop核心复盘</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%BA%94%E7%AB%A0-Hadoop%E6%A0%B8%E5%BF%83%E5%A4%8D%E7%9B%98.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%BA%94%E7%AB%A0-Hadoop%E6%A0%B8%E5%BF%83%E5%A4%8D%E7%9B%98.html</id>
    <published>2022-02-13T06:06:56.000Z</published>
    <updated>2022-02-13T06:08:47.697Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第六周 第四章 Hadoop官方文档使用指北</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0-Hadoop%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0-Hadoop%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97.html</id>
    <published>2022-02-13T06:06:36.000Z</published>
    <updated>2022-02-16T09:08:59.547Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第六周-第四章-Hadoop官方文档使用指北"><a href="#第六周-第四章-Hadoop官方文档使用指北" class="headerlink" title="第六周 第四章 Hadoop官方文档使用指北"></a>第六周 第四章 Hadoop官方文档使用指北</h1><h2 id="Hadoop官方文档使用指北"><a href="#Hadoop官方文档使用指北" class="headerlink" title="Hadoop官方文档使用指北"></a>Hadoop官方文档使用指北</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">前面我们把Hadoop中的HDFS、MapReduce、YARN中比较常用和重要的功能基本都学习完了，但是在</span><br><span class="line">后续工作中可能会遇到一些特殊的场景需要用到特殊的知识点，这个时候就需要考验大家的自学能力了，</span><br><span class="line">以及后期你再遇到一些新的技术框架，想要从0开始学习的时候</span><br><span class="line">这个时候该如何下手呢？</span><br><span class="line">官方文档是最直接最靠谱的途径</span><br><span class="line">下面我们就以Hadoop官网为例来分析一下：</span><br><span class="line">其实咱们前面学习的很多知识点在官网中都有说明</span><br><span class="line">一般网站上都有这么几个链接，</span><br><span class="line">下载：下载安装包</span><br><span class="line">快速开始：快速安装部署，运行起来</span><br><span class="line">文档：最完整、最权威的技术文档</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">想要学习框架中的一些知识点，需要点击文档链接进去，但是目前hadoop官网的这个文档链接是有问题的，毕竟是免费开源的，大家就忍了吧</span><br><span class="line">从这里进不去，但是可以从快速开始链接进去，最终结果是一样的。</span><br><span class="line">进来之后默认是集群安装部署的内容，因为快速开始是为了帮助大家快速把这个框架安装部署运行起来，这块内容属于文档中的一部分。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">我们看文档左边的菜单，往下面拉，这里面有HDFS、MapReduce、YARN的内容</span><br><span class="line">所以说以后如果想要查找一些不常用的技术点的时候就可以到这里来查看了。</span><br><span class="line"></span><br><span class="line">大致的步骤就这样了，剩下的就是需要具体看里面的细节内容了。</span><br><span class="line">针对其他技术框架也是一样的，都是这样的思路，大家一定要学会看官方文档，这才是你学习能力的最直接体现。</span><br><span class="line">刚开始可能看起来比较懵，见得多了就熟悉了，看的多了就习惯了，这一步必须要踏出去！</span><br><span class="line">后面我们学习的每个框架我都会带着大家去看一下官网的，时间长了大家就可以掌握 如何通过官网去学习了</span><br><span class="line">学习知识是重要的，但是学习如何去学习是更重要的！</span><br></pre></td></tr></table></figure><h2 id="Hadoop在CDH和HDP中的使用"><a href="#Hadoop在CDH和HDP中的使用" class="headerlink" title="Hadoop在CDH和HDP中的使用"></a>Hadoop在CDH和HDP中的使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">咱们前面学习了官方的Apache Hadoop版本，我们前面也说了，在实际工作中其实会使用CDH或者HDP，那下面我们就看一下在CDH和HDP中如何操作Hadoop。</span><br><span class="line">注意了，在这里我不打算讲CDH和HDP的安装部署，意义不大，咱们是开发人员，主要侧重于代码开发，安装部署的工作是运维人员的，咱们不能抢饭碗啊，什么都让你做了，别人不就得喝西北风啊，这样太不地道了，对吧。</span><br><span class="line">不过我们在这里要演示，肯定先安装部署了，在这里给大家分享一个好东西，不要告诉别人哦，这里面的东西目前到官网都下载不到了，没有下载链接了，幸亏我之前留的有后手，提前下载了一份。</span><br><span class="line"></span><br><span class="line">cloudera-quickstart-vm-5.13.0-0-vmware.zip</span><br><span class="line">HDP_3.0.1_vmware_181205.ova</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这两个文件可以通过vmware打开，里面已经安装好了CDH和HDP，可以在一台机器上启动，模拟正常的集群环境，这都是在官网上下载的，可以直接使用，非常简单，我们在这主要是为了演示一下如何在CDH和HDP中操作Hadoop，其实说实话，他们在操作的时候没有什么区别，和我们操作原生版本的Hadoop一样，但是呢如果不带着大家去亲身感受一把，大家心里面总是感觉有点虚。</span><br><span class="line">注意了，这里面的cloudera-quickstart-vm-5.13.0-0-vmware.zip这个文件目前官网已经没有下载链接了</span><br><span class="line">HDP_3.0.1_vmware_181205.ova目前是有的。</span><br></pre></td></tr></table></figure><h3 id="下面我们就来先演示一下CDH"><a href="#下面我们就来先演示一下CDH" class="headerlink" title="下面我们就来先演示一下CDH"></a>下面我们就来先演示一下CDH</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">先解压，再使用vmware直接打开即可，选择本地的镜像文件，在这里最好选择centos6.7的iso镜像文件，因为这个操作系统的版本就是centos6.7。</span><br><span class="line">CentOS-6.7-x86_64-minimal.iso</span><br><span class="line"></span><br><span class="line">注意了，这个虚拟机默认会使用4G内存，1个CPU，64G的磁盘，内存至少要4个G，太少的话有可能启动不了，在这我把资源调大一些，内存给他分8个G，CPU分2个，这样这个虚拟机运行会快一些，当然了，如果你本地的资源不多的话就使用默认的也可以。</span><br><span class="line"></span><br><span class="line">接着启动这个虚拟机即可。</span><br><span class="line">在启动之前，先把本地启动的那几台虚拟机关闭掉，要不然启动太多机器容易卡。</span><br><span class="line">启动的过程稍微有点慢，不要着急。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">虚拟机启动后，CDH中大数据的所有组件都是启动状态，可以在root账号下通过jsp命令查看已启动的服务</span><br><span class="line">root账号的密码是 cloudera</span><br><span class="line">通过su命令切换到root用户，然后输入root用户的密码即可。</span><br><span class="line"></span><br><span class="line">这里面除了有Hadoop的相关进程，还有其他大数据框架的进程</span><br><span class="line">注意了，CDH和HDP是一个平台，里面可以安装很多大数据组件，Hadoop只是它里面的一个软件而已。就类似于安卓的谷歌市场，苹果的appstore一样。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">我们尝试操作一下hdfs</span><br><span class="line">在这需要注意一下，我们使用HDFS的全路径尝试一下</span><br><span class="line">结果发现执行报错，这是因为CDH中启动的Hadoop集群，namenode的端口号是8020，不是9000，这一点需要注意一下</span><br><span class="line">在这里同样可以访问HDFS的web界面和YARN的web界面</span><br><span class="line">在这里访问HDFS的web界面我们需要使用 50070 端口，因为这里面的hadoop集群的版本是2.6的，在 hadoop2.x 中hdfs的web界面端口是 50070</span><br><span class="line">可以通过hadoop version命令查看版本号</span><br><span class="line">[root@quickstart Desktop]# hdfs dfs -ls &#x2F;</span><br><span class="line">Found 6 items</span><br><span class="line">drwxrwxrwx - hdfs supergroup 0 2017-10-23 10:29 &#x2F;benchmarks</span><br><span class="line">drwxr-xr-x - hbase supergroup 0 2020-04-28 01:06 &#x2F;hbase</span><br><span class="line">drwxr-xr-x - solr solr 0 2017-10-23 10:32 &#x2F;solr</span><br><span class="line">drwxrwxrwt - hdfs supergroup 0 2020-04-28 01:06 &#x2F;tmp</span><br><span class="line">drwxr-xr-x - hdfs supergroup 0 2017-10-23 10:31 &#x2F;user</span><br><span class="line">drwxr-xr-x - hdfs supergroup 0 2017-10-23 10:31 &#x2F;var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">在这需要注意一下，我们使用HDFS的全路径尝试一下</span><br><span class="line">[root@quickstart Desktop]# hdfs dfs -ls hdfs:&#x2F;&#x2F;127.0.0.1:9000&#x2F;</span><br><span class="line">20&#x2F;04&#x2F;28 01:13:57 WARN ipc.Client: Failed to connect to server: quickstart.cl</span><br><span class="line">java.net.ConnectException: Connection refused</span><br><span class="line"></span><br><span class="line">结果发现执行报错，这是因为CDH中启动的Hadoop集群，namenode的端口号是8020，不是9000，这一点需要注意一下</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在这里同样可以访问HDFS的web界面和YARN的web界面</span><br><span class="line">在这里访问HDFS的web界面我们需要使用 50070(不是9870) 端口，因为这里面的hadoop集群的版本是2.6的，在 hadoop2.x 中hdfs的web界面端口是 50070</span><br><span class="line">127.0.0.1:50070</span><br><span class="line"></span><br><span class="line">可以通过hadoop version命令查看版本号</span><br><span class="line"></span><br><span class="line">YARN的web界面</span><br><span class="line">127.0.0.1:8088</span><br></pre></td></tr></table></figure><h2 id="接下来看一下HDP"><a href="#接下来看一下HDP" class="headerlink" title="接下来看一下HDP"></a>接下来看一下HDP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在vmware中打开HDP_3.0.1_vmware_181205.ova，会弹出如下界面</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在这里面修改一下新虚拟机的存储路径</span><br><span class="line">指定到这里，和之前安装的虚拟机放到同一个目录下</span><br><span class="line">D:\Program Files (x86)\Virtual Machines\HDP_3.0.1_vmware_181205</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第六周 第三章 YARN实战</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-YARN%E5%AE%9E%E6%88%98.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-YARN%E5%AE%9E%E6%88%98.html</id>
    <published>2022-02-13T06:05:55.000Z</published>
    <updated>2022-02-15T14:33:24.546Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第六周-第三章-YARN实战"><a href="#第六周-第三章-YARN实战" class="headerlink" title="第六周 第三章 YARN实战"></a>第六周 第三章 YARN实战</h1><h2 id="HADOOP之YARN详解"><a href="#HADOOP之YARN详解" class="headerlink" title="HADOOP之YARN详解"></a>HADOOP之YARN详解</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">前面我们学习了Hadoop中的MapReduce，我们知道MapReduce任务是需要在YARN中执行的，那下面</span><br><span class="line">我们就来学习一下Hadoop中的YARN</span><br></pre></td></tr></table></figure><h3 id="YARN的由来"><a href="#YARN的由来" class="headerlink" title="YARN的由来"></a>YARN的由来</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">从Hadoop2开始，官方把资源管理单独剥离出来，主要是为了考虑后期作为一个公共的资源管理平台，</span><br><span class="line">任何满足规则的计算引擎都可以在它上面执行。</span><br><span class="line">所以YARN可以实现HADOOP集群的资源共享，不仅仅可以跑MapRedcue，还可以跑Spark、Flink。</span><br></pre></td></tr></table></figure><h3 id="YARN架构分析"><a href="#YARN架构分析" class="headerlink" title="YARN架构分析"></a>YARN架构分析</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">咱们之前部署Hadoop集群的时候也对YARN的架构有了基本的了解</span><br><span class="line">YARN主要负责集群资源的管理和调度 ，支持主从架构，主节点最多可以有2个，从节点可以有多个</span><br><span class="line">其中：ResourceManager：是主节点，主要负责集群资源的分配和管理</span><br><span class="line">NodeManager：是从节点，主要负责当前机器资源管理</span><br></pre></td></tr></table></figure><h3 id="YARN资源管理模型"><a href="#YARN资源管理模型" class="headerlink" title="YARN资源管理模型"></a>YARN资源管理模型</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">YARN主要管理内存和CPU这两种资源类型</span><br><span class="line">  当NodeManager节点启动的时候自动向ResourceManager注册，将当前节点上的可用CPU信息和内存</span><br><span class="line">信息注册上去。</span><br><span class="line">  这样所有的nodemanager注册完成以后，resourcemanager就知道目前集群的资源总量了。</span><br><span class="line">  那我们现在来看一下我这个一主两从的集群资源是什么样子的，打开yarn的<span class="number">8088</span>界面</span><br><span class="line">    </span><br><span class="line">    注意，这里面显示的资源是集群中所有从节点的资源总和，不包括主节点的资源，</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H2ELY6" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/H2ELY6.md.png" alt="H2ELY6.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">那我们再详细看一下每一个从节点的资源信息</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H21Xsx" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/H21Xsx.md.png" alt="H21Xsx.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">但是这个数值是对不上的，我的linux机器每台只给它分配了2G的内存  通过free -m可以看到</span><br><span class="line"></span><br><span class="line">CPU只分配了1个 通过top命令可以看到</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">那为什么在这里显示是内存是8G，CPU是8个呢？</span><br><span class="line">不要着急，我们先喝杯咖啡，看一下下面这2个参数</span><br><span class="line"></span><br><span class="line">yarn.nodemanager.resource.memory-mb：单节点可分配的物理内存总量，默认是8MB*1024，即8G</span><br><span class="line">yarn.nodemanager.resource.cpu-vcores：单节点可分配的虚拟CPU个数，默认是8</span><br><span class="line">看到没有，这都是默认单节点的内存和CPU信息，就算你这个机器没有这么多资源，但是在yarndefault.xml中有这些默认资源的配置，这样当nodemanager去上报资源的时候就会读取这两个参数的值，这也就是为什么我们在前面看到了单节点都是8G内存和8个cpu，其实我们的linux机器是没有这么大资源的，那你这就是虚标啊，肯定不能这样干，你实际有多少就是多少，所以我们可以修改这些参数的值，修改的话就在yarn-site.xml中进行配置即可，改完之后就可以看到真实的信息了，在这我就先不改了，针对我们的学习环境不影响使用，修改的意义不大，你知道这回事就行了。</span><br></pre></td></tr></table></figure><h3 id="YARN中的调度器-面试中经常问"><a href="#YARN中的调度器-面试中经常问" class="headerlink" title="YARN中的调度器(面试中经常问)"></a>YARN中的调度器(面试中经常问)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来详细分析一下YARN中的调度器，这个是非常实用的东西，面试的时候也会经常问到。</span><br><span class="line">大家可以想象一个场景，我们集群的资源是有限的，在实际工作中会有很多人向集群中提交任务，那这时候资源如何分配呢？</span><br><span class="line">如果你提交了一个很占资源的任务，这一个任务就把集群中90%的资源都占用了，后面别人再提交任务，剩下的资源就不够用了，这个时候怎么办？</span><br><span class="line">让他们等你的任务执行完了再执行？还是说你把你的资源匀出来一些分给他，你少占用一些，让他也能慢慢的开始执行？</span><br><span class="line">[root@bigdata02 ~]# free -m</span><br><span class="line">total used free shared buff&#x2F;cache availab</span><br><span class="line">Mem: 1819 372 1133 9 313 12</span><br><span class="line">Swap: 2047 0 2047</span><br><span class="line">1234</span><br><span class="line">top - 11:30:35 up 1:05, 1 user, load average: 0.00, 0.08, 0.10</span><br><span class="line">Tasks: 99 total, 1 running, 98 sleeping, 0 stopped, 0 zombie</span><br><span class="line">%Cpu0 : 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">具体如何去做这个是由YARN中的调度器负责的</span><br><span class="line">YARN中支持三种调度器</span><br><span class="line"><span class="number">1</span>：FIFO Scheduler：先进先出(first in, first out)调度策略</span><br><span class="line"><span class="number">2</span>：Capacity Scheduler：FIFO Scheduler的多队列版本</span><br><span class="line"><span class="number">3</span>：FairScheduler：多队列，多用户共享资源</span><br><span class="line">    </span><br><span class="line">下面来看图分析一下这三种调度器的特性</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H2dj9f" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/H2dj9f.md.png" alt="H2dj9f.md.png"></a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FIFO Scheduler：是先进先出的，大家都是排队的，如果你的任务申请不到足够的资源，那你就等着，等前面的任务执行结束释放了资源之后你再执行。这种在有些时候是不合理的，因为我们有一些任务的优先级比较高，我们希望任务提交上去立刻就开始执行，这个就实现不了了。</span><br><span class="line">CapacityScheduler：它是FifoScheduler的多队列版本，就是我们先把集群中的整块资源划分成多份，我们可以人为的给这些资源定义使用场景，例如图里面的queue A里面运行普通的任务，queueB中运行优先级比较高的任务。这两个队列的资源是相互对立的</span><br><span class="line">但是注意一点，队列内部还是按照先进先出的规则。</span><br><span class="line">FairScheduler：支持多个队列，每个队列可以配置一定的资源，每个队列中的任务共享其所在队列的所有资源，不需要排队等待资源</span><br><span class="line">具体是这样的，假设我们向一个队列中提交了一个任务，这个任务刚开始会占用整个队列的资源，当你再提交第二个任务的时候，第一个任务会把他的资源释放出来一部分给第二个任务使用</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在实际工作中我们一般都是使用第二种， CapacityScheduler ，从hadoop2开始， CapacitySchedule r也是集群中的默认调度器了</span><br><span class="line">那下面我们到集群上看一下，点击左侧的Scheduler查看</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H2y4IJ" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/H2y4IJ.md.png" alt="H2y4IJ.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Capacity，这个是集群的调度器类型，</span><br><span class="line">下面的root是根的意思，他下面目前只有一个队列，叫default，我们之前提交的任务都会进入到这个队列中。</span><br></pre></td></tr></table></figure><h3 id="案例：YARN多资源队列配置和使用"><a href="#案例：YARN多资源队列配置和使用" class="headerlink" title="案例：YARN多资源队列配置和使用"></a>案例：YARN多资源队列配置和使用</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">下面我们来修改一下，增加多个队列</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  我们的需求是这样的，希望增加2个队列，一个是online队列，一个是offline队列</span><br><span class="line">  然后向offline队列中提交一个mapreduce任务</span><br><span class="line">  online队列里面运行实时任务，offline队列里面运行离线任务，我们现在学习的mapreduce就属于离线任务</span><br><span class="line">  实时任务我们后面会学习，等讲到了再具体分析。</span><br><span class="line"> 这两个队列其实也是我们公司中最开始分配的队列，不过随着后期集群规模的扩大和业务需求的增加，后期又增加了多个队列。</span><br><span class="line">在这里我们先增加这2个队列，后期再增加多个也是一样的。</span><br><span class="line">具体步骤如下：</span><br><span class="line">修改集群中 etc&#x2F;hadoop 目录下的 capacity-scheduler.xml 配置文件</span><br><span class="line">修改和增加以下参数，针对已有的参数，修改value中的值，针对没有的参数，则直接增加</span><br><span class="line">这里的 default 是需要保留的，增加 online,offline ，这三个队列的资源比例为 7:1:2</span><br><span class="line">具体的比例需要根据实际的业务需求来，看你们那些类型的任务比较多，对应的队列中资源比例就调高一些，我们现在暂时还没有online任务，所以我就把online队列的资源占比设置的小一些。</span><br><span class="line">先修改bigdata01上的配置</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;</span><br><span class="line">&lt;value&gt;default,online,offline&lt;/value&gt;</span><br><span class="line">&lt;description&gt;队列列表,多个队列之间使用逗号分割&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt;</span><br><span class="line">&lt;value&gt;70&lt;/value&gt;</span><br><span class="line">&lt;description&gt;default队列70%&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.online.capacity&lt;/name&gt;</span><br><span class="line">&lt;value&gt;10&lt;/value&gt;</span><br><span class="line">&lt;description&gt;online队列10%&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.offline.capacity&lt;/name&gt;</span><br><span class="line">&lt;value&gt;20&lt;/value&gt;</span><br><span class="line">&lt;description&gt;offline队列20%&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.default.maximum-capacity&lt;/name&gt;</span><br><span class="line">&lt;value&gt;70&lt;/value&gt;</span><br><span class="line">&lt;description&gt;Default队列可使用的资源上限.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.online.maximum-capacity&lt;/name&gt;</span><br><span class="line">&lt;value&gt;10&lt;/value&gt;</span><br><span class="line">&lt;description&gt;online队列可使用的资源上限.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.scheduler.capacity.root.offline.maximum-capacity&lt;/name&gt;</span><br><span class="line">&lt;value&gt;20&lt;/value&gt;</span><br><span class="line">&lt;description&gt;offline队列可使用的资源上限.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">修改好以后再同步到另外两个节点上</span><br><span class="line">scp -rq capacity-scheduler.xml bigdata02:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line">scp -rq capacity-scheduler.xml bigdata03:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line"></span><br><span class="line">然后重启集群才能生效</span><br><span class="line"></span><br><span class="line">进入yarn的web界面，查看最新的调度器队列信息</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HWPnTx" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HWPnTx.md.png" alt="HWPnTx.md.png"></a><br><a href="https://imgtu.com/i/HWPKk6" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HWPKk6.md.png" alt="HWPKk6.md.png"></a></p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意了，现在默认提交的任务还是会进入<span class="keyword">default</span>的队列，如果希望向offline队列提交任务的话，需要指定队列名称，不指定就进默认的队列</span><br><span class="line">在这里我们还需要同步微调一下代码，否则我们指定的队列信息 代码是无法识别的</span><br><span class="line">拷贝WordCountJob类，新的类名为 WordCountJobQueue</span><br><span class="line">主要在job配置中增加一行代码</span><br></pre></td></tr></table></figure><h5 id="代码的改变"><a href="#代码的改变" class="headerlink" title="代码的改变"></a>代码的改变</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在最初的wordcount案例代码基础上</span><br><span class="line">**主要改写job部分</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定Job需要的配置参数</span></span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">            <span class="comment">// (调度器)解析命令行中通过-D传递过来的参数，添加到conf中</span></span><br><span class="line">            String[] remainingArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">            <span class="comment">// 创建一个Job</span></span><br><span class="line">            Job job = Job.getInstance(conf);</span><br><span class="line">            <span class="comment">// 注意：这一行必须设置，否者在集群中执行时找不到WordCountJob这个类</span></span><br><span class="line">            job.setJarByClass(WordCountJobSkew<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定输入路径，可以是文件也可以是目录(目录里只有一个文件时可以); 注意FileInputFormat别选成hadoop1.x的了</span></span><br><span class="line">            FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(remainingArgs[<span class="number">0</span>]));</span><br><span class="line">            <span class="comment">// 指定输出路径(只能是hdfs上一个不存在的目录); 注意FileOutFormat别选成hadoop1.x的了</span></span><br><span class="line">            FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(remainingArgs[<span class="number">1</span>]));</span><br></pre></td></tr></table></figure><h3 id="打包，上传，执行"><a href="#打包，上传，执行" class="headerlink" title="打包，上传，执行"></a>打包，上传，执行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar bigdata_hadoop-1.0-SNAPSHOT-jar-with-dependencies.jar com.imooc.mc.WordCountJobQueue -Dmapreduce.job.queuename&#x3D;offline  &#x2F;test&#x2F;WordCount&#x2F;test&#x2F;test.txt &#x2F;test&#x2F;WordCount&#x2F;test&#x2F;outcomeScheduler</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HWALse" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HWALse.md.png" alt="HWALse.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如果我们去掉指定队列名称的配置(命令中，代码不用改)，此时还会使用default队列</span><br><span class="line"></span><br><span class="line">这就是YARN中调度器多资源队列的配置，在工作中我们只要掌握如何使用这些队列就可以了，具体如何配置是我们向运维同学提需求，他们去配置。</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第六周 第二章 剖析数据倾向问题与企业级解决方案</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%89%96%E6%9E%90%E6%95%B0%E6%8D%AE%E5%80%BE%E5%90%91%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%89%96%E6%9E%90%E6%95%B0%E6%8D%AE%E5%80%BE%E5%90%91%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html</id>
    <published>2022-02-13T06:05:27.000Z</published>
    <updated>2022-02-15T15:01:47.379Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第六周-第二章-剖析数据倾向问题与企业级解决方案"><a href="#第六周-第二章-剖析数据倾向问题与企业级解决方案" class="headerlink" title="第六周 第二章 剖析数据倾向问题与企业级解决方案"></a>第六周 第二章 剖析数据倾向问题与企业级解决方案</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  在实际工作中，如果我们想提高MapReduce的执行效率，最直接的方法是什么呢？</span><br><span class="line">我们知道MapReduce是分为Map阶段和Reduce阶段，其实提高执行效率就是提高这两个阶段的执行效率默认情况下Map阶段中Map任务的个数是和数据的InputSplit相关的，InputSplit的个数一般是和Block块是有关联的，所以可以认为Map任务的个数和数据的block块个数有关系，针对Map任务的个数我们一般是不需要干预的，除非是前面我们说的海量小文件，那个时候可以考虑把小文件合并成大文件。其他情况是不需要调整的，那就剩下Reduce阶段了，咱们前面说过，默认情况下reduce的个数是<span class="number">1</span>个，所以现在MapReduce任务的压力就集中在Reduce阶段了，如果说数据量比较大的时候，一个reduce任务处理起来肯定是比较慢的，所以我们可以考虑增加reduce任务的个数，这样就可以实现数据分流了，提高计算效率了。</span><br><span class="line">但是注意了，如果增加Reduce的个数，那肯定是要对数据进行分区的，分区之后，每一个分区的数据会被一个reduce任务处理。</span><br><span class="line">那如何增加分区呢？</span><br><span class="line">我们来看一下代码，进入WordCountJob中，其实我们可以通过job.setPartitionerClass 来设置分区类，不过目前我们是没有设置的，那框架中是不是有默认值啊，是有的，我们可以通过 job.getPartitionerClass 方法看到默认情况下会使用 HashPartitioner 这个分区类</span><br></pre></td></tr></table></figure><h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">那我们来看一下HashPartitioner的实现是什么样子的</span><br><span class="line"></span><br><span class="line">&#x2F;** Partition keys by their &#123;@link Object#hashCode()&#125;. *&#x2F;</span><br><span class="line">@InterfaceAudience.Public</span><br><span class="line">@InterfaceStability.Stable</span><br><span class="line">public class HashPartitioner&lt;K, V&gt; extends Partitioner&lt;K, V&gt; &#123;</span><br><span class="line">&#x2F;** Use &#123;@link Object#hashCode()&#125; to partition. *&#x2F;</span><br><span class="line">public int getPartition(K key, V value,</span><br><span class="line">int numReduceTasks) &#123;</span><br><span class="line">return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">HashPartitioner继承了Partitioner，这里面其实就一个方法， getPartition ，其实map里面每一条数据都会进入这个方法来获取他们所在的分区信息，这里的key就是k2,value就是v2</span><br><span class="line">主要看里面的实现</span><br><span class="line"></span><br><span class="line">(key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks</span><br><span class="line"></span><br><span class="line">  其实起决定性的因素就是 numReduceTasks 的值，这个值默认是1，通过 job.getNumReduceTasks() 可知。</span><br><span class="line">  所以最终任何值%1 都返回0，那也就意味着他们都在0号分区，也就只有这一个分区。</span><br><span class="line">  如果想要多个分区，很简单，只需要把 numReduceTasks 的数目调大即可(当为5时，取余后的值可能为0,1,2,3,4,也就是五个分区)，这个其实就reduce任务的数量，那也就意味着，只要redcue任务数量变大了，对应的分区数也就变多了，有多少个分区就会有多少个reduce任务，那我们就不需要单独增加分区的数量了，只需要控制好Redcue任务的数量即可。</span><br><span class="line">  增加redcue任务个数在一定场景下是可以提高效率的，但是在一些特殊场景下单纯增加reduce任务个数是无法达到质的提升的。</span><br></pre></td></tr></table></figure><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">下面我们来分析一个场景：</span><br><span class="line">  假设我们有一个文件，有1000W条数据，这里面的值主要都是数字，1,2,3,4,5,6,7,8,9,10，我们希望统计出来每个数字出现的次数</span><br><span class="line">  其实在私底下我们是知道这份数据的大致情况的，这里面这1000w条数据，值为5的数据有910w条左右，剩下的9个数字一共只有90w条，那也就意味着，这份数据中，值为5的数据比较集中，或者说值为5的数据属于倾斜的数据，在这一整份数据中，它占得比重比其他的数据多得多。</span><br><span class="line">  下面我们画图来具体分析一下：</span><br><span class="line">假设这1000W条数据的文件有3个block，会产生3个InputSplt，最终会产生3个Map任务，默认情况下只有一个reduce任务，所以所有的数据都会让这一个reduce任务处理，这样这个Reduce压力肯定很大，大量的时间都消耗在了这里</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H660gK" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/14/H660gK.png" alt="H660gK.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">那根据我们前面的分析，我们可以增加reduce任务的数量，看下面这张图，我们把reduce任务的数量调</span><br><span class="line">整到10个，这个时候就会把1000w条数据让这10 个reduce任务并行处理了，这个时候效率肯定会有一定</span><br><span class="line">的提升，但是最后我们会发现，性能提升是有限的，并没有达到质的提升，那这是为什么呢？</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H66w36" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/14/H66w36.png" alt="H66w36.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">  我们来分析一下，刚才我们说了我们这份数据中，值为5的数据有910w条，这就占了整份数据的90%了，那这90%的数据会被一个reduce任务处理，在这里假设是让reduce5处理了，reduce5这个任务执行的是比较慢的，其他reduce任务都执行结束很长时间了，它还没执行结束，因为reduce5中处理的数据量和其他reduce中处理的数据量规模相差太大了，所以最终reduce5拖了后腿。咱们mapreduce任务执行消耗的时间是一直统计到最后一个执行结束的reduce任务，所以就算其他reduce任务早都执行结束了也没有用，整个mapreduce任务是没有执行结束的。</span><br><span class="line">那针对这种情况怎么办？</span><br><span class="line">  这个时候单纯的增加reduce任务的个数已经不起多大作用了，如果启动太多可能还会适得其反。</span><br><span class="line">其实这个时候最好的办法是把这个值为5的数据尽量打散，把这个倾斜的数据分配到其他reduce任务中去计算，这样才能从根本上解决问题。</span><br><span class="line">  这就是我们要分析的一个数据倾斜的问题</span><br><span class="line">MapReduce程序执行时，Reduce节点大部分执行完毕，但是有一个或者几个Reduce节点运行很慢，导致整个程序处理时间变得很长</span><br><span class="line">  具体表现为：Ruduce阶段一直卡着不动</span><br><span class="line">根据刚才的分析，有两种方案</span><br><span class="line">1. 增加reduce任务个数，这个属于治标不治本，针对倾斜不是太严重的数据是可以解决问题的，针对倾斜严重的数据，这样是解决不了根本问题的</span><br><span class="line">2. 把倾斜的数据打散这种可以根治倾斜严重的数据。</span><br></pre></td></tr></table></figure><h2 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">现在呢我们通过理论层面分析完了，那接下来我们来具体进入一个实际案例上手操作一下</span><br><span class="line">还使用我们刚才说的那一份数据，1000w条的，其中值为5的大致有910w条左右</span><br><span class="line">其他的加起来一共90万条左右。</span><br><span class="line">这个数据文件我已经生成好了，直接上传到linux服务器上就可以，上传到&#x2F;data&#x2F;soft目录下</span><br><span class="line"></span><br><span class="line">这个文件有点大，在windows本地无法打开，在这里我们去一条数据看一下数据格式，前面是一个数</span><br><span class="line">字，后面是一行日志，这个数据是我自己造的，我们主要是使用前面的这个数字，后面的内容主要是为了</span><br><span class="line">充数的，要不然文件太小，测试不出来效果。后面我们解析数据的时候只获取前面这个数字即可，前面这</span><br><span class="line">个数字是1-10之间的数字</span><br><span class="line">接下来把这个文件上传到hdfs上</span><br><span class="line">[root@bigdata01 soft]# ll</span><br><span class="line">total 2632200</span><br><span class="line">drwxr-xr-x. 9 1001 1002 244 Apr 26 20:34 hadoop-3.2.0</span><br><span class="line">-rw-r--r--. 1 root root 345625475 Jul 19 2019 hadoop-3.2.0.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 1860100000 Apr 27 21:58 hello_10000000.dat</span><br><span class="line">drwxr-xr-x. 7 10 143 245 Dec 16 2018 jdk1.8</span><br><span class="line">-rw-r--r--. 1 root root 194042837 Apr 6 23:14 jdk-8u202-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 147616384 Apr 27 16:22 s_name_140.dat</span><br><span class="line">-rw-r--r--. 1 root root 147976384 Apr 27 16:22 s_name_141.dat</span><br><span class="line">123456789</span><br><span class="line">[root@bigdata01 soft]# tail -1 hello_10000000.dat</span><br><span class="line">10 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: FileO</span><br><span class="line"></span><br><span class="line">接下来把这个文件上传到hdfs上</span><br></pre></td></tr></table></figure><h3 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主要设置:</span><br><span class="line">1.map对k1的处理，</span><br><span class="line">2.reduce阶段模拟复杂数据处理，</span><br><span class="line">3.job.setNumReduceTasks(num);</span><br></pre></td></tr></table></figure><h4 id="自己创建的测试数据"><a href="#自己创建的测试数据" class="headerlink" title="自己创建的测试数据"></a>自己创建的测试数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">一共5000000行</span><br><span class="line">60% 5</span><br><span class="line">5% 1 2 3 4 6 7 8 9</span><br></pre></td></tr></table></figure><h4 id="map"><a href="#map" class="headerlink" title="map"></a>map</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable k1, Text v1, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="comment">// k1代表每一行数据的行首偏移量，v1代表的是每一行的数据</span></span><br><span class="line">            <span class="comment">// 需要做的是：把每一行数据的单词切割出来</span></span><br><span class="line">            <span class="comment">//logger.info("&lt;k1, v1&gt;: &lt;"+k1.get()+", "+v1.toString()+"&gt;");</span></span><br><span class="line">            <span class="comment">//System.out.println("&lt;k1, v1&gt;: &lt;"+k1.get()+", "+v1.toString()+"&gt;");</span></span><br><span class="line">            String[] words = v1.toString().split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 把切割出来的单词，封装成&lt;k2, 1&gt;</span></span><br><span class="line">            Text k2 = <span class="keyword">new</span> Text(words[<span class="number">0</span>]);</span><br><span class="line">            LongWritable v2 = <span class="keyword">new</span> LongWritable(<span class="number">1L</span>);</span><br><span class="line">            context.write(k2,v2);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//super.map(key, value, context);</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h4 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line">        <span class="comment">//Logger logger = LoggerFactory.getLogger(myReducer.class);</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 对&lt;k2, &#123;v2...&#125;&gt;的数据进行累加求和，生成&lt;k3,v3&gt;</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> k2</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> v2s</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text k2, Iterable&lt;LongWritable&gt; v2s, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(LongWritable v2:v2s)&#123;</span><br><span class="line">                <span class="comment">//logger.info("&lt;k2, v2&gt;: &lt;"+k2.toString()+", "+v2.get()+"&gt;");</span></span><br><span class="line">                <span class="comment">//System.out.println("&lt;k2, v2&gt;: &lt;"+k2.toString()+", "+v2.get()+"&gt;");</span></span><br><span class="line">                sum += v2.get();</span><br><span class="line">                <span class="comment">//模拟Reduce的复杂计算消耗的时间</span></span><br><span class="line">                <span class="keyword">if</span>(sum%<span class="number">200</span>==<span class="number">0</span>)&#123;</span><br><span class="line">                    Thread.sleep((<span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            Text k3 = k2;</span><br><span class="line">            LongWritable v3 = <span class="keyword">new</span> LongWritable(sum);</span><br><span class="line">            <span class="comment">//logger.info("&lt;k3, v3&gt;: &lt;"+k3.toString()+", "+v3.get()+"&gt;");</span></span><br><span class="line">            <span class="comment">//System.out.println("&lt;k3, v3&gt;: &lt;"+k3.toString()+", "+v3.get()+"&gt;");</span></span><br><span class="line">            context.write(k3, v3);</span><br><span class="line">            <span class="comment">// super.reduce(key, values, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="main"><a href="#main" class="headerlink" title="main"></a>main</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(args.length!=<span class="number">3</span>)&#123;</span><br><span class="line">                System.exit(<span class="number">100</span>);</span><br><span class="line">                System.out.println(<span class="string">"缺少路径参数！！！"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 指定Job需要的配置参数</span></span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">            <span class="comment">// 创建一个Job</span></span><br><span class="line">            Job job = Job.getInstance(conf);</span><br><span class="line">            <span class="comment">// 注意：这一行必须设置，否者在集群中执行时找不到WordCountJob这个类</span></span><br><span class="line">            job.setJarByClass(WordCountJobSkew<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定输入路径，可以是文件也可以是目录(目录里只有一个文件时可以); 注意FileInputFormat别选成hadoop1.x的了</span></span><br><span class="line">            FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">            <span class="comment">// 指定输出路径(只能是hdfs上一个不存在的目录); 注意FileOutFormat别选成hadoop1.x的了</span></span><br><span class="line">            FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定map相关代码</span></span><br><span class="line">            job.setMapperClass(myMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定k2类型</span></span><br><span class="line">            job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定v2类型</span></span><br><span class="line">            job.setMapOutputValueClass(LongWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//指定reduce相关代码</span></span><br><span class="line">            job.setReducerClass(myReducer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定k3类型</span></span><br><span class="line">            job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定v3类型</span></span><br><span class="line">            job.setOutputValueClass(LongWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            job.setNumReduceTasks(Integer.parseInt(args[<span class="number">2</span>]));</span><br><span class="line">            <span class="comment">// 提交job</span></span><br><span class="line">            job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="结果查看"><a href="#结果查看" class="headerlink" title="结果查看"></a>结果查看</h3><p><a href="https://imgtu.com/i/H6xkFA" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/14/H6xkFA.md.png" alt="H6xkFA.md.png"></a></p><h4 id="1个reduceTask"><a href="#1个reduceTask" class="headerlink" title="1个reduceTask"></a>1个reduceTask</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar bigdata_hadoop-1.0-SNAPSHOT-jar-with-dependencies.jar com.imooc.mc.WordCountJobSkew &#x2F;test&#x2F;shujuqingxie&#x2F;QingXieData.txt &#x2F;test&#x2F;shujuqingxie&#x2F;outcome1 1</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/H6x4kd" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/14/H6x4kd.md.png" alt="H6x4kd.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">具体分析页面打不开</span><br></pre></td></tr></table></figure><h4 id="9个reduceTask"><a href="#9个reduceTask" class="headerlink" title="9个reduceTask"></a>9个reduceTask</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar bigdata_hadoop-1.0-SNAPSHOT-jar-with-dependencies.jar com.imooc.mc.WordCountJobSkew &#x2F;test&#x2F;shujuqingxie&#x2F;QingXieData.txt &#x2F;test&#x2F;shujuqingxie&#x2F;outcome1 9</span><br></pre></td></tr></table></figure><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p><a href="https://imgtu.com/i/HczLlt" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HczLlt.md.png" alt="HczLlt.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">所以从这可以看出来，性能提升并不大</span><br><span class="line"></span><br><span class="line">具体分析Reduce任务的执行时间</span><br><span class="line">这里由于有10个reduce，所以一共有10行，在这我们截取了一部分，其中这里面有一个reduce任务消耗的时间比较长，其他reduce任务的执行时间都是4~5秒，这个reduce任务的执行时间是1分26秒，那就意味着值为5的那910w数据进入到这个reduce了，所以它执行的比较慢。</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/Hcpypn" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/14/Hcpypn.md.png" alt="Hcpypn.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map任务14个里面，kill 2个是因为“推测执行”，当map任务里某些maptask任务相比其它maptask明显慢很多时(会认为是有异常)，会自动产生新的maptask任务，两个一起执行，最后杀掉慢的 下面这是reduce阶段某个reducetask的推测执行</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HgCe78" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HgCe78.md.png" alt="HgCe78.md.png"></a></p><h3 id="把倾斜的数据打散-面试"><a href="#把倾斜的数据打散-面试" class="headerlink" title="把倾斜的数据打散(面试)"></a>把倾斜的数据打散(面试)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  那我们再把reduce任务的个数提高一下，会不会提高性能呢？不会了，刚才从1个reduce任务提高到10个reduce任务时间也就减少了三四秒钟，所以再增加reduce任务的个数就没有多大意义了。</span><br><span class="line">  那接下来就需要使用我们的绝招了，把倾斜的数据打散，在这里就是把5这个数字打散，</span><br><span class="line">怎么打散呢？其实就是给他加上一些有规律的随机数字就可以了</span><br><span class="line">  在这里我们这样处理，我把5这个数值的数据再分成10份，所以我就在这个数值5后面拼上一个0~9的随机数即可。</span><br></pre></td></tr></table></figure><h4 id="map-1"><a href="#map-1" class="headerlink" title="map"></a>map</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">只需要在map中把k2的值修改一下就可以了，这样就可以把值为<span class="number">5</span>的数据打散了。</span><br><span class="line">编译打包，提交到集群</span><br><span class="line">String[] words = v1.toString().split(<span class="string">" "</span>);</span><br><span class="line">            String key = words[<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">if</span>(<span class="string">"5"</span>.equals(key))&#123;</span><br><span class="line">                key = <span class="string">"5_"</span>+random.nextInt(<span class="number">10</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 把切割出来的单词，封装成&lt;k2, 1&gt;</span></span><br><span class="line">            Text k2 = <span class="keyword">new</span> Text(key);</span><br><span class="line">            LongWritable v2 = <span class="keyword">new</span> LongWritable(<span class="number">1L</span>);</span><br><span class="line">            context.write(k2,v2);</span><br></pre></td></tr></table></figure><h4 id="reduce-1"><a href="#reduce-1" class="headerlink" title="reduce"></a>reduce</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">没变</span><br></pre></td></tr></table></figure><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">注意，这个时候获取到的并不是最终的结果，因为我们把值为5的数据随机分成多份了，最多分成10份</span><br><span class="line"></span><br><span class="line">任务总的执行消耗时间为： Elapsed: 1mins, 39sec</span><br><span class="line">这次任务执行时间节省了1分钟多的左右，在这就属于质的提升了，相当于节省了将近一半的时间了</span><br><span class="line"></span><br><span class="line">查看一下reduce任务执行情况，在这里就没有发现特别耗时的reduce任务了，消耗的时间几乎都差不多</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HgM8TH" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HgM8TH.png" alt="HgM8TH.png"></a><br><a href="https://imgtu.com/i/HgMJkd" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HgMJkd.md.png" alt="HgMJkd.md.png"></a><br><a href="https://imgtu.com/i/HgMYtA" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HgMYtA.md.png" alt="HgMYtA.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 但是这个时候我们获取到的最终结果是一个半成品，还需要进行一次加工，其实我们前面把这个倾斜的数据打散之后相当于做了一个局部聚合，现在还需要再开发一个mapreduce任务再做一次全局聚合，其实也很简单，获取到上一个map任务的输出，在map端读取到数据之后，对数据先使用空格分割，然后对第一列的数据再使用下划线分割，分割之后总是取第一列，这样就可以把值为5的数据还原出来了，这个时候数据一共就这么十几条，怎么处理都很快了，这个代码就给大家留成作业了，我们刚才已经把详细的过程都分析过了，大家下去之后自己写一下，如果遇到了问题，可以在咱们的问答区一块讨论，或者直接找我都是可以的。</span><br><span class="line">这就是针对数据倾斜问题的处理方法，面试的时候经常问到，大家一定要能够把这个思路说明白。</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HWm7uT" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/15/HWm7uT.png" alt="HWm7uT.png"></a></p><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第六周 第一章 剖析小文件问题与企业级解决方案</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%89%96%E6%9E%90%E5%B0%8F%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%85%AD%E5%91%A8-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%89%96%E6%9E%90%E5%B0%8F%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html</id>
    <published>2022-02-13T06:04:48.000Z</published>
    <updated>2022-02-14T07:31:05.945Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第六周-第一章-剖析小文件问题与企业级解决方案"><a href="#第六周-第一章-剖析小文件问题与企业级解决方案" class="headerlink" title="第六周 第一章 剖析小文件问题与企业级解决方案"></a>第六周 第一章 剖析小文件问题与企业级解决方案</h1><h2 id="MapReduce性能优化"><a href="#MapReduce性能优化" class="headerlink" title="MapReduce性能优化"></a>MapReduce性能优化</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">现在大家已经掌握了MapReduce程序的开发步骤，注意了，针对MapReduce的案例我们并没有讲太多，主要是因为在实际工作中真正需要我们去写MapReduce代码的场景已经是凤毛麟角了，因为后面我们会学习一个大数据框架Hive，Hive支持SQL，这个Hive底层会把SQL转化为MapReduce执行，不需要我们写一行代码，所以说工作中的大部分需求我们都使用SQL去实现了，谁还苦巴巴的来写代码啊，一行SQL能抵你写的几十行代码，你还想去写MapReduce代码吗，肯定不想了。</span><br><span class="line">但是MapReduce代码的开发毕竟是基本功，所以前面我们也详细的讲解了它的开发流程。</span><br><span class="line">虽然现在MapReduce代码写的很少了，但是针对MapReduce程序的性能优化是少不了的，面试也是经常会问到的，所以下面我们就来分析一下MapReduce中典型的性能优化场景</span><br><span class="line">第一个场景是：小文件问题</span><br><span class="line">第二个场景是：数据倾斜问题</span><br></pre></td></tr></table></figure><h3 id="小文件问题"><a href="#小文件问题" class="headerlink" title="小文件问题"></a>小文件问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">先一个一个来，不要着急，我们先看小文件问题</span><br><span class="line">咱们前面分析过，Hadoop的HDFS和MapReduce都是针对大数据文件来设计的，在小文件的处理上不但效率低下，而且十分消耗内存资源</span><br><span class="line">针对HDFS而言，每一个小文件在namenode中都会占用150字节的内存空间，最终会导致集群中虽然存储了很多个文件，但是文件的体积并不大，这样就没有意义了。针对MapReduce而言，每一个小文件都是一个Block，都会产生一个InputSplit，最终每一个小文件都会产生一个map任务，这样会导致同时启动太多的Map任务，Map任务的启动是非常消耗性能的，但是启动了以后执行了很短时间就停止了，因为小文件的数据量太小了，这样就会造成任务执行消耗的时间还没有启动任务消耗的时间多，这样也会影响MapReduce执行的效率。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  针对这个问题,解决办法通常是选择一个容器，将这些小文件组织起来统一存储，HDFS提供了两种类型的容器，分别是SequenceFile 和 MapFile</span><br><span class="line">SequeceFile是Hadoop 提供的一种二进制文件，这种二进制文件直接将&lt;key, value&gt;对序列化到文件中。</span><br><span class="line">  一般对小文件可以使用这种文件合并，即将小文件的文件名作为key，文件内容作为value序列化到大文件中</span><br><span class="line">  但是这个文件有一个缺点，就是它需要一个合并文件的过程，最终合并的文件会比较大，并且合并后的文件查看起来不方便，必须通过遍历才能查看里面的每一个小文件</span><br><span class="line">  所以这个SequenceFile 其实可以理解为把很多小文件压缩成一个大的压缩包了。</span><br></pre></td></tr></table></figure><h4 id="SequenceFile"><a href="#SequenceFile" class="headerlink" title="SequenceFile"></a>SequenceFile</h4><h4 id="创建SequenceFile"><a href="#创建SequenceFile" class="headerlink" title="创建SequenceFile"></a>创建SequenceFile</h4><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">下面我们来具体看一下如何生成SequenceFile</span><br><span class="line">生成SequenceFile需要开发代码</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.imooc.mc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.io.FileUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.SequenceFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 小文件解决方案之SequenceFile</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SmallFileSeq</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>  <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        write(<span class="string">"D:\\hadoopTestData\\"</span>, <span class="string">"/seqFile"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 生成SequenceFile文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> inputDir 输入目录-windows目录</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> outputFile 输出文件-hdfs文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String inputDir, String outputFile)</span>  <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//创建一个配置对象</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定HDFS的地址</span></span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://bigdata01:9000"</span>);</span><br><span class="line">        <span class="comment">//获取操作HDFS的对象</span></span><br><span class="line">        FileSystem fileSystem = FileSystem.get(conf);</span><br><span class="line">        <span class="comment">//删除输出文件</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(outputFile),<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//构造opts数组，有三个元素</span></span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                第一个是输出路径</span></span><br><span class="line"><span class="comment">                第二个是key类型</span></span><br><span class="line"><span class="comment">                第三个是value类型</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        SequenceFile.Writer.Option[] opts = <span class="keyword">new</span> SequenceFile.Writer.Option[]&#123;</span><br><span class="line">            SequenceFile.Writer.file(<span class="keyword">new</span> Path(outputFile)),</span><br><span class="line">                SequenceFile.Writer.keyClass(Text<span class="class">.<span class="keyword">class</span>),</span></span><br><span class="line"><span class="class">                <span class="title">SequenceFile</span>.<span class="title">Writer</span>.<span class="title">valueClass</span>(<span class="title">Text</span>.<span class="title">class</span>)</span></span><br><span class="line"><span class="class">        &#125;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个writer实例</span></span><br><span class="line">        SequenceFile.Writer writer = SequenceFile.createWriter(conf, opts);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定要压缩的文件的目录</span></span><br><span class="line">        File inputDirPath = <span class="keyword">new</span> File(inputDir);</span><br><span class="line">        <span class="keyword">if</span>(inputDirPath.isDirectory())&#123;</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            File[] files = inputDirPath.listFiles();</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            <span class="keyword">for</span>(File file: files)&#123;</span><br><span class="line">                <span class="comment">//获取文件全部内容</span></span><br><span class="line">                String content = FileUtils.readFileToString(file, <span class="string">"UTF-8"</span>);</span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                String fileName = file.getName();</span><br><span class="line">                <span class="comment">//文件名作为key</span></span><br><span class="line">                Text key = <span class="keyword">new</span> Text(fileName);</span><br><span class="line">                <span class="comment">//文件内容作为value</span></span><br><span class="line">                Text value = <span class="keyword">new</span> Text(content);</span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                writer.append(key,value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        writer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">(String inputFile)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定HDFS的地址</span></span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://bigdata01:9000"</span>);</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        SequenceFile.Reader reader = <span class="keyword">new</span> SequenceFile.Reader(conf, SequenceFile.Reader.file(<span class="keyword">new</span> Path(inputFile)) );</span><br><span class="line">        Text key = <span class="keyword">new</span> Text();</span><br><span class="line">        Text value = <span class="keyword">new</span> Text();</span><br><span class="line">        <span class="keyword">while</span>(reader.next(key, value))&#123;</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            System.out.println(<span class="string">"文件名："</span>+key.toString());</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            System.out.println(<span class="string">"文件内容："</span>+value.toString()+<span class="string">" "</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        reader.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="读SquenceFile"><a href="#读SquenceFile" class="headerlink" title="读SquenceFile"></a>读SquenceFile</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">只能通过遍历的方法去读</span><br></pre></td></tr></table></figure><h5 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hadoop&#x2F;conf&#x2F;Configuration</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 前往别加载错类，搞死个人</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br></pre></td></tr></table></figure><h4 id="MapFile"><a href="#MapFile" class="headerlink" title="MapFile"></a>MapFile</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看一下MapFile</span><br><span class="line">MapFile是排序后的SequenceFile,MapFile由两部分组成，分别是index和data</span><br><span class="line">index作为文件的数据索引，主要记录了每个Record的key值，以及该Record在文件中的偏移位置。在MapFile被访问的时候,索引文件会被加载到内存，通过索引映射关系可迅速定位到指定Record所在文件位置，因此，相对SequenceFile而言，MapFile的检索效率是高效的，缺点是会消耗一部分内存来存储index数据。</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.mc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.io.FileUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.MapFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.SequenceFile;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SmallFileMap</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>  <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        write(<span class="string">"D:\\hadoopTestData\\"</span>, <span class="string">"/mapFile"</span>);</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        read(<span class="string">"/mapFile"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 生成SequenceFile文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> inputDir 输入目录-windows目录</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> outputDir 输出文件-hdfs文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String inputDir, String outputDir)</span>  <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//创建一个配置对象</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定HDFS的地址</span></span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://bigdata01:9000"</span>);</span><br><span class="line">        <span class="comment">//获取操作HDFS的对象</span></span><br><span class="line">        FileSystem fileSystem = FileSystem.get(conf);</span><br><span class="line">        <span class="comment">//删除输出文件</span></span><br><span class="line">        fileSystem.delete(<span class="keyword">new</span> Path(outputDir),<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//构造opts数组，有三个元素</span></span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                第一个是输出路径</span></span><br><span class="line"><span class="comment">                第二个是key类型</span></span><br><span class="line"><span class="comment">                第三个是value类型</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        SequenceFile.Writer.Option[] opts = <span class="keyword">new</span> SequenceFile.Writer.Option[]&#123;</span><br><span class="line">                MapFile.Writer.keyClass(Text<span class="class">.<span class="keyword">class</span>),</span></span><br><span class="line"><span class="class">                <span class="title">MapFile</span>.<span class="title">Writer</span>.<span class="title">valueClass</span>(<span class="title">Text</span>.<span class="title">class</span>)</span></span><br><span class="line"><span class="class">        &#125;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个writer实例</span></span><br><span class="line">        MapFile.Writer writer = <span class="keyword">new</span> MapFile.Writer(conf, <span class="keyword">new</span> Path(outputDir), opts);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定要压缩的文件的目录</span></span><br><span class="line">        File inputDirPath = <span class="keyword">new</span> File(inputDir);</span><br><span class="line">        <span class="keyword">if</span>(inputDirPath.isDirectory())&#123;</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            File[] files = inputDirPath.listFiles();</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            <span class="keyword">for</span>(File file: files)&#123;</span><br><span class="line">                <span class="comment">//获取文件全部内容</span></span><br><span class="line">                String content = FileUtils.readFileToString(file, <span class="string">"UTF-8"</span>);</span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                String fileName = file.getName();</span><br><span class="line">                <span class="comment">//文件名作为key</span></span><br><span class="line">                Text key = <span class="keyword">new</span> Text(fileName);</span><br><span class="line">                <span class="comment">//文件内容作为value</span></span><br><span class="line">                Text value = <span class="keyword">new</span> Text(content);</span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                writer.append(key,value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        writer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">(String inputDir)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定HDFS的地址</span></span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>,<span class="string">"hdfs://bigdata01:9000"</span>);</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        MapFile.Reader reader = <span class="keyword">new</span> MapFile.Reader(<span class="keyword">new</span> Path(inputDir), conf);</span><br><span class="line">        Text key = <span class="keyword">new</span> Text();</span><br><span class="line">        Text value = <span class="keyword">new</span> Text();</span><br><span class="line">        <span class="keyword">while</span>(reader.next(key, value))&#123;</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            System.out.println(<span class="string">"文件名："</span>+key.toString());</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            System.out.println(<span class="string">"文件内容："</span>+value.toString()+<span class="string">" "</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        reader.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="通过MapReduce读取SequenceFile"><a href="#通过MapReduce读取SequenceFile" class="headerlink" title="通过MapReduce读取SequenceFile"></a>通过MapReduce读取SequenceFile</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">下面我们来看一个案例</span><br><span class="line">我们来使用SequenceFile实现小文件的存储和计算</span><br><span class="line">小文件的存储刚才我们已经通过代码实现了，接下来我们要实现如何通过MapReduce读取SequenceFile</span><br><span class="line">咱们之前的代码默认只能读取普通文本文件，针对SequenceFile是无法读取的</span><br><span class="line">那该如何设置才能让mapreduce可以读取SequenceFile呢？</span><br><span class="line">很简单，只需要在job中设置输入数据处理类就行了，默认情况下使用的是TextInputFormat</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.mc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.sound.midi.Sequence;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 需求：读取hdfs上的hello.txt文件，计算文件中各个单词出现次数</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 原始文件内容如下：</span></span><br><span class="line"><span class="comment"> * hello you</span></span><br><span class="line"><span class="comment"> * hello me</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 最终需要的结果形式：</span></span><br><span class="line"><span class="comment"> * hello 2</span></span><br><span class="line"><span class="comment"> * me 1</span></span><br><span class="line"><span class="comment"> * you 1</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountJobSeq</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 静态内部类</span></span><br><span class="line">    <span class="comment">// map阶段</span></span><br><span class="line">    <span class="comment">// 注意：myMapper和myReducer类可以提到外面去写，这里只是为了方便学习</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line">        Logger logger = LoggerFactory.getLogger(myMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 需要实现map函数</span></span><br><span class="line"><span class="comment">         * 这个函数就是可以接受&lt;k1,v1&gt;, 产生&lt;k2,v2&gt;</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> k1</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> v1</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Text k1, Text v1, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="comment">// k1代表每一行数据的行首偏移量，v1代表的是每一行的数据</span></span><br><span class="line">            <span class="comment">// 需要做的是：把每一行数据的单词切割出来</span></span><br><span class="line">            <span class="comment">//logger.info("&lt;k1, v1&gt;: &lt;"+k1.get()+", "+v1.toString()+"&gt;");</span></span><br><span class="line">            System.out.println(<span class="string">"&lt;k1, v1&gt;: &lt;"</span>+k1.toString()+<span class="string">", "</span>+v1.toString()+<span class="string">"&gt;"</span>);</span><br><span class="line">            String[] words = v1.toString().split(<span class="string">" "</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words)&#123;</span><br><span class="line">                <span class="comment">// 把切割出来的单词，封装成&lt;k2, 1&gt;</span></span><br><span class="line">                Text k2 = <span class="keyword">new</span> Text(word);</span><br><span class="line">                LongWritable v2 = <span class="keyword">new</span> LongWritable(<span class="number">1L</span>);</span><br><span class="line">                context.write(k2,v2);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//super.map(key, value, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * reduce阶段</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line">        Logger logger = LoggerFactory.getLogger(myReducer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 对&lt;k2, &#123;v2...&#125;&gt;的数据进行累加求和，生成&lt;k3,v3&gt;</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> k2</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> v2s</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text k2, Iterable&lt;LongWritable&gt; v2s, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(LongWritable v2:v2s)&#123;</span><br><span class="line">                logger.info(<span class="string">"&lt;k2, v2&gt;: &lt;"</span>+k2.toString()+<span class="string">", "</span>+v2.get()+<span class="string">"&gt;"</span>);</span><br><span class="line">                <span class="comment">//System.out.println("&lt;k2, v2&gt;: &lt;"+k2.toString()+", "+v2.get()+"&gt;");</span></span><br><span class="line">                sum += v2.get();</span><br><span class="line">            &#125;</span><br><span class="line">            Text k3 = k2;</span><br><span class="line">            LongWritable v3 = <span class="keyword">new</span> LongWritable(sum);</span><br><span class="line">            logger.info(<span class="string">"&lt;k3, v3&gt;: &lt;"</span>+k3.toString()+<span class="string">", "</span>+v3.get()+<span class="string">"&gt;"</span>);</span><br><span class="line">            <span class="comment">//System.out.println("&lt;k3, v3&gt;: &lt;"+k3.toString()+", "+v3.get()+"&gt;");</span></span><br><span class="line">            context.write(k3, v3);</span><br><span class="line">            <span class="comment">// super.reduce(key, values, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 组装job=map+reduce</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(args.length!=<span class="number">2</span>)&#123;</span><br><span class="line">                System.exit(<span class="number">100</span>);</span><br><span class="line">                System.out.println(<span class="string">"缺少路径参数！！！"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 指定Job需要的配置参数</span></span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">            <span class="comment">// 创建一个Job</span></span><br><span class="line">            Job job = Job.getInstance(conf);</span><br><span class="line">            <span class="comment">// 注意：这一行必须设置，否者在集群中执行时找不到WordCountJob这个类</span></span><br><span class="line">            job.setJarByClass(WordCountJobForHowManyMapTask<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定输入路径，可以是文件也可以是目录(目录里只有一个文件时可以); 注意FileInputFormat别选成hadoop1.x的了</span></span><br><span class="line">            FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">            <span class="comment">// 指定输出路径(只能是hdfs上一个不存在的目录); 注意FileOutFormat别选成hadoop1.x的了</span></span><br><span class="line">            FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            job.setInputFormatClass(SequenceFileInputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定map相关代码</span></span><br><span class="line">            job.setMapperClass(myMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定k2类型</span></span><br><span class="line">            job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定v2类型</span></span><br><span class="line">            job.setMapOutputValueClass(LongWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//指定reduce相关代码</span></span><br><span class="line">            job.setReducerClass(myReducer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定k3类型</span></span><br><span class="line">            job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">            <span class="comment">// 指定v3类型</span></span><br><span class="line">            job.setOutputValueClass(LongWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 提交job</span></span><br><span class="line">            job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="异常-1"><a href="#异常-1" class="headerlink" title="异常"></a>异常</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.在hdfs上创建的seqFile和mapFile都看不见，但IDEA上read方法却正确执行</span><br><span class="line"></span><br><span class="line">conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs:&#x2F;&#x2F;bigdata01:9000&quot;) &#x2F;&#x2F; FS写成了Fs</span><br><span class="line"></span><br><span class="line">2.org.apache.hadoop.security.AccessControlException: Permission denied: user&#x3D;***</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;blog.csdn.net&#x2F;diqijiederizi&#x2F;article&#x2F;details&#x2F;82753573</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>廖雪峰java教程笔记-java数组操作</title>
    <link href="http://tianyong.fun/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0-java%E6%95%B0%E7%BB%84%E6%93%8D%E4%BD%9C.html"/>
    <id>http://tianyong.fun/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0-java%E6%95%B0%E7%BB%84%E6%93%8D%E4%BD%9C.html</id>
    <published>2022-02-10T09:48:59.000Z</published>
    <updated>2022-02-11T08:35:10.061Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="数组操作"><a href="#数组操作" class="headerlink" title="数组操作"></a>数组操作</h1><h2 id="遍历数组"><a href="#遍历数组" class="headerlink" title="遍历数组"></a>遍历数组</h2><p><em>for通过索引</em></p><p><em>for each直接得到元素</em></p><h2 id="打印数组内容"><a href="#打印数组内容" class="headerlink" title="打印数组内容"></a>打印数组内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>直接打印数组变量，得到的是数组在JVM中的引用地址：</span><br><span class="line"></span><br><span class="line">int[] ns = &#123; <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span> &#125;;</span><br><span class="line">System.out.println(ns); // 类似 [I@<span class="number">7852e922</span></span><br><span class="line">                               </span><br><span class="line"><span class="number">2.</span>这并没有什么意义，因为我们希望打印的数组的元素内容。因此，使用<span class="keyword">for</span> each循环来打印它：</span><br><span class="line">int[] ns = &#123; <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span> &#125;;</span><br><span class="line"><span class="keyword">for</span> (int n : ns) &#123;</span><br><span class="line">    System.out.print(n + <span class="string">", "</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="number">3.</span>使用<span class="keyword">for</span> each循环打印也很麻烦。幸好Java标准库提供了Arrays.toString()，可以快速打印数组内容：</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[] ns = &#123; <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span> &#125;;</span><br><span class="line">        System.out.println(Arrays.toString(ns));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">遍历数组可以使用for循环，for循环可以访问数组索引，for each循环直接迭代每个数组元素，但无法获取索引；</span><br><span class="line"></span><br><span class="line">使用Arrays.toString()可以快速获取数组内容</span><br></pre></td></tr></table></figure><h2 id="数组排序"><a href="#数组排序" class="headerlink" title="数组排序"></a>数组排序</h2><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><p><em>每次循环，将本次最大数放到后面</em></p><p><em>最多需要n-1次循环</em></p><img src="https://s1.ax1x.com/2020/03/26/8zVORH.png" alt="8zVORH.png" border="0" width="400" height="300/"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">实际上，Java的标准库已经内置了排序功能，我们只需要调用JDK提供的Arrays.sort()就可以排序</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[] ns = &#123; <span class="number">28</span>, <span class="number">12</span>, <span class="number">89</span>, <span class="number">73</span>, <span class="number">65</span>, <span class="number">18</span>, <span class="number">96</span>, <span class="number">50</span>, <span class="number">8</span>, <span class="number">36</span> &#125;;</span><br><span class="line">        Arrays.sort(ns); //降序排列</span><br><span class="line">        System.out.println(Arrays.toString(ns));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">必须注意，对数值数组排序实际上修改了数组本身</span><br><span class="line">即变量ns指向的数组内容已经被改变了</span><br><span class="line"></span><br><span class="line">如果对一个字符串数组进行排序，原来的字符串在内存中均没有任何变化，但是ns数组的每个元素指向变化了</span><br></pre></td></tr></table></figure><h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">常用的排序算法有冒泡排序、插入排序和快速排序等；</span><br><span class="line">冒泡排序使用两层for循环实现排序；</span><br><span class="line">交换两个变量的值需要借助一个临时变量。</span><br><span class="line">可以直接使用Java标准库提供的Arrays.sort()进行排序；</span><br><span class="line">对数组排序会直接修改数组本身。</span><br></pre></td></tr></table></figure><h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><h3 id="内置排序"><a href="#内置排序" class="headerlink" title="内置排序"></a>内置排序</h3><p><em>import java.util.Arrays;</em></p><p>Arrays.sort(ns);</p><p><em>当数组为数值类型，数组内容已经改变；当数组为字符串数组时，元素指向发生改变</em></p><h2 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a>多维数组</h2><h3 id="多维数组定义"><a href="#多维数组定义" class="headerlink" title="多维数组定义"></a>多维数组定义</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>[][] a =   <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>] [<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">int[] [] = &#123;&#123;&#125;,&#123;&#125;,...&#125;  # 二维数组的每个数组元素的长度并不要求相同，例如，可以这么定义</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[][] ns = &#123;</span><br><span class="line">            &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span> &#125;,</span><br><span class="line">            &#123; <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span> &#125;,</span><br><span class="line">            &#123; <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span> &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        int[] arr0 = ns[<span class="number">0</span>];</span><br><span class="line">        System.out.println(arr0.length); // <span class="number">4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">实际上arr0就获取了ns数组的第<span class="number">0</span>个元素。因为ns数组的每个元素也是一个数组，因此，arr0指向的数组就是&#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span> &#125;</span><br></pre></td></tr></table></figure><h3 id="打印多维数组"><a href="#打印多维数组" class="headerlink" title="打印多维数组"></a>打印多维数组</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>要打印一个二维数组，可以使用两层嵌套的<span class="keyword">for</span>循环：</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (int[] arr : ns) &#123;</span><br><span class="line">    <span class="keyword">for</span> (int n : arr) &#123;</span><br><span class="line">        System.out.print(n);</span><br><span class="line">        System.out.print(<span class="string">', '</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>或者使用Java标准库的Arrays.deepToString()</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[][] ns = &#123;</span><br><span class="line">            &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span> &#125;,</span><br><span class="line">            &#123; <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span> &#125;,</span><br><span class="line">            &#123; <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span> &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        System.out.println(Arrays.deepToString(ns));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="三维数组"><a href="#三维数组" class="headerlink" title="三维数组"></a>三维数组</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">三维数组就是二维数组的数组。可以这么定义一个三维数组：</span><br><span class="line"></span><br><span class="line">int[][][] ns = &#123;</span><br><span class="line">    &#123;</span><br><span class="line">        &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;,</span><br><span class="line">        &#123;<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>&#125;,</span><br><span class="line">        &#123;<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &#123;<span class="number">10</span>, <span class="number">11</span>&#125;,</span><br><span class="line">        &#123;<span class="number">12</span>, <span class="number">13</span>&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &#123;<span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>&#125;,</span><br><span class="line">        &#123;<span class="number">17</span>, <span class="number">18</span>&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">理论上，我们可以定义任意的N维数组。但在实际应用中，除了二维数组在某些时候还能用得上，更高维度的数组很少使用。</span><br></pre></td></tr></table></figure><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">二维数组就是数组的数组，三维数组就是二维数组的数组；</span><br><span class="line">多维数组的每个数组元素长度都不要求相同；</span><br><span class="line">打印多维数组可以使用Arrays.deepToString()；</span><br><span class="line">最常见的多维数组是二维数组，访问二维数组的一个元素使用array[row][col]</span><br></pre></td></tr></table></figure><h2 id="命令行参数"><a href="#命令行参数" class="headerlink" title="命令行参数"></a>命令行参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java程序的入口是main方法，它可以接受一个命令行参数，它是String数组</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">这个命令行参数由JVM接收用户输入并传给main方法：</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        <span class="keyword">for</span> (String arg : args) &#123;</span><br><span class="line">            System.out.println(arg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">我们可以利用接收到的命令行参数，根据不同的参数执行不同的代码。例如，实现一个-version参数，打印程序版本号：</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        <span class="keyword">for</span> (String arg : args) &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"-version"</span>.equals(arg)) &#123;</span><br><span class="line">                System.out.println(<span class="string">"v 1.0"</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">上面这个程序必须在命令行执行，我们先编译它：</span><br><span class="line"></span><br><span class="line">$ javac Main.java</span><br><span class="line">然后，执行的时候，给它传递一个-version参数：</span><br><span class="line"></span><br><span class="line">$ java Main -version</span><br><span class="line">v <span class="number">1.0</span></span><br><span class="line">这样，程序就可以根据传入的命令行参数，作出不同的响应</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="廖雪峰java笔记" scheme="http://tianyong.fun/categories/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>廖雪峰java教程笔记-java流程控制</title>
    <link href="http://tianyong.fun/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0-java%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6.html"/>
    <id>http://tianyong.fun/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0-java%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6.html</id>
    <published>2022-02-10T09:48:48.000Z</published>
    <updated>2022-02-11T04:50:37.277Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h1><h2 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h2><h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.out.println 换行</span><br><span class="line">System.out.<span class="keyword">print</span>  不换行</span><br></pre></td></tr></table></figure><h3 id="格式化输出"><a href="#格式化输出" class="headerlink" title="格式化输出"></a>格式化输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">printf(<span class="string">"%.3f"</span>, d)</span><br><span class="line"></span><br><span class="line">%表示占位符，连续两个%%表示%</span><br></pre></td></tr></table></figure><p><a href="https://imgchr.com/i/87yp26" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s1.ax1x.com/2020/03/23/87yp26.png" alt="87yp26.png" border="0" width="400/"></a></p><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">和输出相比，Java的输入就要复杂得多。</span><br><span class="line">我们先看一个从控制台读取一个字符串和一个整数的例子：</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Scanner scanner = new Scanner(System.<span class="keyword">in</span>); // 创建Scanner对象</span><br><span class="line">        System.out.print(<span class="string">"Input your name: "</span>); // 打印提示</span><br><span class="line">        String name = scanner.nextLine(); // 读取一行输入并获取字符串</span><br><span class="line">        System.out.print(<span class="string">"Input your age: "</span>); // 打印提示</span><br><span class="line">        int age = scanner.nextInt(); // 读取一行输入并获取整数</span><br><span class="line">        System.out.printf(<span class="string">"Hi, %s, you are %d\n"</span>, name, age); // 格式化输出</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">创建Scanner对象并传入System.in。System.out代表标准输出流，而System.in代表标准输入流。直接使用System.in读取用户输入虽然是可以的，但需要更复杂的代码，而通过Scanner就可以简化后续的代码。</span><br><span class="line"></span><br><span class="line">有了Scanner对象后，要读取用户输入的字符串，使用scanner.nextLine()，要读取用户输入的整数，使用scanner.nextInt()。Scanner会自动转换数据类型，因此不必手动转换。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+ scanner.next 读取直到空格符</span><br><span class="line">+ scanner.nextLine 读取一行</span><br><span class="line">+ scanner.nextInt</span><br><span class="line">+ scanner.nextDouble</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Java提供的输出包括：System.out.println() / print() / printf()，其中printf()可以格式化输出；</span><br><span class="line"></span><br><span class="line">Java提供Scanner对象来方便输入，读取对应的类型可以使用：scanner.nextLine() / nextInt() / nextDouble() / ...</span><br></pre></td></tr></table></figure><h2 id="if判断"><a href="#if判断" class="headerlink" title="if判断"></a>if判断</h2><p><em>只有一条语句时可以省略华括号</em></p><p><code>if()</code></p><p><code>{</code><br><code>}</code></p><p><code>else if()</code></p><p><code>{</code><br><code>}</code></p><p><code>else</code></p><p><code>{</code><br><code>}</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">前面讲过了浮点数在计算机中常常无法精确表示，并且计算可能出现误差，因此，判断浮点数相等用==判断不靠谱</span><br><span class="line">正确的方法是利用差值小于某个临界值来判断</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        double x = <span class="number">1</span> - <span class="number">9.0</span> / <span class="number">10</span>;</span><br><span class="line">        <span class="keyword">if</span> (Math.abs(x - <span class="number">0.1</span>) &lt; <span class="number">0.00001</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"x is 0.1"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"x is NOT 0.1"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">x <span class="keyword">is</span> <span class="number">0.1</span></span><br></pre></td></tr></table></figure><h3 id="判断引用类型数据是否相等"><a href="#判断引用类型数据是否相等" class="headerlink" title="判断引用类型数据是否相等"></a>判断引用类型数据是否相等</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在Java中，判断值类型的变量是否相等，可以使用==运算符。但是，判断引用类型的变量是否相等，==表示“引用是否相等”，或者说，是否指向同一个对象。例如，下面的两个String类型，它们的内容是相同的，但是，分别指向不同的对象，用==判断，结果为false：</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String s1 = <span class="string">"hello"</span>;</span><br><span class="line">        String s2 = <span class="string">"HELLO"</span>.toLowerCase();</span><br><span class="line">        System.out.println(s1);</span><br><span class="line">        System.out.println(s2);</span><br><span class="line">        <span class="keyword">if</span> (s1 == s2) &#123;</span><br><span class="line">            System.out.println(<span class="string">"s1 == s2"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"s1 != s2"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">要判断引用类型的变量内容是否相等，必须使用equals()方法：</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String s1 = <span class="string">"hello"</span>;</span><br><span class="line">        String s2 = <span class="string">"HELLO"</span>.toLowerCase();</span><br><span class="line">        System.out.println(s1);</span><br><span class="line">        System.out.println(s2);</span><br><span class="line">        <span class="keyword">if</span> (s1.equals(s2)) &#123;</span><br><span class="line">            System.out.println(<span class="string">"s1 equals s2"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"s1 not equals s2"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：执行语句s1.equals(s2)时，如果变量s1为null，会报NullPointerException</span><br><span class="line"></span><br><span class="line">要避免NullPointerException错误，可以利用短路运算符&amp;&amp;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String s1 = null;</span><br><span class="line">        <span class="keyword">if</span> (s1 != null &amp;&amp; s1.equals(<span class="string">"hello"</span>)) &#123;</span><br><span class="line">            System.out.println(<span class="string">"hello"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">还可以把一定不是null的对象<span class="string">"hello"</span>放到前面：例如：<span class="keyword">if</span> (<span class="string">"hello"</span>.equals(s)) &#123; ... &#125;。</span><br></pre></td></tr></table></figure><h2 id="switch语句"><a href="#switch语句" class="headerlink" title="switch语句"></a>switch语句</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">switch(option)</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">case <span class="number">1</span>:</span><br><span class="line">............;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">case <span class="number">2</span>:</span><br><span class="line">............;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">default：(可以没有)</span><br><span class="line"></span><br><span class="line">.....;</span><br><span class="line"></span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="新语法"><a href="#新语法" class="headerlink" title="新语法"></a>新语法</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">case没有花括号，可以合理的增减<span class="keyword">break</span>(具有 穿透性)；比较字符串时是比较内容</span><br><span class="line"></span><br><span class="line">switch新语法，可以不要break，没有穿透；case可以使用-&gt;</span><br><span class="line">注意新语法使用-&gt;，如果有多条语句，需要用&#123;&#125;括起来。不要写break语句，因为新语法只会执行匹配的语句，没有穿透效应</span><br></pre></td></tr></table></figure><img src="https://s1.ax1x.com/2020/03/23/87fFp9.png" alt="87fFp9.png" border="0" width="400/"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">使用新的switch语法，不但不需要<span class="keyword">break</span>，还可以直接返回值。把上面的代码改写如下</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String fruit = <span class="string">"apple"</span>;</span><br><span class="line">        int opt = switch (fruit) &#123;</span><br><span class="line">            case "apple" -&gt; 1;</span><br><span class="line">            case "pear", "mango" -&gt; 2;</span><br><span class="line">            default -&gt; 0;</span><br><span class="line">        &#125;; // 注意赋值语句要以;结束</span><br><span class="line">        System.out.println(<span class="string">"opt = "</span> + opt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="case语句执行的是同一组语句块"><a href="#case语句执行的是同一组语句块" class="headerlink" title="case语句执行的是同一组语句块"></a>case语句执行的是同一组语句块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">如果有几个case语句执行的是同一组语句块，可以这么写</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int option = <span class="number">2</span>;</span><br><span class="line">        switch (option) &#123;</span><br><span class="line">        case <span class="number">1</span>:</span><br><span class="line">            System.out.println(<span class="string">"Selected 1"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        case <span class="number">2</span>:</span><br><span class="line">        case <span class="number">3</span>:</span><br><span class="line">            System.out.println(<span class="string">"Selected 2, 3"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        default:</span><br><span class="line">            System.out.println(<span class="string">"Not selected"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="匹配字符串"><a href="#匹配字符串" class="headerlink" title="匹配字符串"></a>匹配字符串</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">switch语句还可以匹配字符串。字符串匹配时，是比较“内容相等”。</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String fruit = <span class="string">"apple"</span>;</span><br><span class="line">        switch (fruit) &#123;</span><br><span class="line">        case <span class="string">"apple"</span>:</span><br><span class="line">            System.out.println(<span class="string">"Selected apple"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        case <span class="string">"pear"</span>:</span><br><span class="line">            System.out.println(<span class="string">"Selected pear"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        case <span class="string">"mango"</span>:</span><br><span class="line">            System.out.println(<span class="string">"Selected mango"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        default:</span><br><span class="line">            System.out.println(<span class="string">"No fruit selected"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Selected apple</span><br></pre></td></tr></table></figure><h3 id="枚举类型"><a href="#枚举类型" class="headerlink" title="枚举类型"></a>枚举类型</h3><h3 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在switch表达式内部，我们会返回简单的值。</span><br><span class="line"></span><br><span class="line">但是，如果需要复杂的语句，我们也可以写很多语句，放到&#123;...&#125;里，然后，用<span class="keyword">yield</span>返回一个值作为switch语句的返回值</span><br></pre></td></tr></table></figure><img src="https://s1.ax1x.com/2020/03/23/87fUAS.png" alt="87fUAS.png" border="0" width="400/"><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">switch语句可以做多重选择，然后执行匹配的case语句后续代码；</span><br><span class="line">switch的计算结果必须是整型、字符串或枚举类型；</span><br><span class="line">注意千万不要漏写<span class="keyword">break</span>，建议打开fall-through警告；</span><br><span class="line">总是写上default，建议打开missing default警告；</span><br><span class="line">从Java <span class="number">14</span>开始，switch语句正式升级为表达式，不再需要<span class="keyword">break</span>，并且允许使用<span class="keyword">yield</span>返回值。</span><br></pre></td></tr></table></figure><h2 id="while"><a href="#while" class="headerlink" title="while"></a>while</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">while(xxx)&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="do…-while"><a href="#do…-while" class="headerlink" title="do….while"></a>do….while</h2><p><em>至少执行一次</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">do&#123;</span><br><span class="line">    </span><br><span class="line">&#125;<span class="keyword">while</span>(xxx);</span><br></pre></td></tr></table></figure><h2 id="for-初始条件，循环条件，更新计数器"><a href="#for-初始条件，循环条件，更新计数器" class="headerlink" title="for(初始条件，循环条件，更新计数器)"></a>for(初始条件，循环条件，更新计数器)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">除了<span class="keyword">while</span>和do <span class="keyword">while</span>循环，Java使用最广泛的是<span class="keyword">for</span>循环。</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>循环的功能非常强大，它使用计数器实现循环。<span class="keyword">for</span>循环会先初始化计数器，然后，在每次循环前检测循环条件，在每次循环后更新计数器。计数器变量通常命名为i</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (初始条件; 循环检测条件; 循环后更新计数器) &#123;</span><br><span class="line">    // 执行语句</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">使用<span class="keyword">for</span>循环时，计数器变量i要尽量定义在<span class="keyword">for</span>循环中：</span><br><span class="line"></span><br><span class="line">int[] ns = &#123; <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span> &#125;;</span><br><span class="line"><span class="keyword">for</span> (int i=<span class="number">0</span>; i&lt;ns.length; i++) &#123;</span><br><span class="line">    System.out.println(ns[i]);</span><br><span class="line">&#125;</span><br><span class="line">// 无法访问i</span><br><span class="line">int n = i; // compile error!</span><br><span class="line">如果变量i定义在<span class="keyword">for</span>循环外：</span><br><span class="line"></span><br><span class="line">int[] ns = &#123; <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span> &#125;;</span><br><span class="line">int i;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;ns.length; i++) &#123;</span><br><span class="line">    System.out.println(ns[i]);</span><br><span class="line">&#125;</span><br><span class="line">// 仍然可以使用i</span><br><span class="line">int n = i;</span><br><span class="line">那么，退出<span class="keyword">for</span>循环后，变量i仍然可以被访问，这就破坏了变量应该把访问范围缩到最小的原则</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>循环还可以缺少初始化语句、循环条件和每次循环更新语句，例如：</span><br><span class="line"></span><br><span class="line">// 不设置结束条件:</span><br><span class="line"><span class="keyword">for</span> (int i=<span class="number">0</span>; ; i++) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">// 不设置结束条件和更新语句:</span><br><span class="line"><span class="keyword">for</span> (int i=<span class="number">0</span>; ;) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">// 什么都不设置:</span><br><span class="line"><span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">通常不推荐这样写，但是，某些情况下，是可以省略<span class="keyword">for</span>循环的某些语句的</span><br></pre></td></tr></table></figure><h2 id="for-each"><a href="#for-each" class="headerlink" title="for each"></a>for each</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(变量类型  变量名: 可迭代数据类型(list,map....))</span><br><span class="line">可以直接遍历数组每个元素，计数器在<span class="keyword">for</span>循环内部</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[] ns = &#123; <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span> &#125;;</span><br><span class="line">        <span class="keyword">for</span> (int n : ns) &#123;</span><br><span class="line">            System.out.println(n);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">但是，<span class="keyword">for</span> each循环无法指定遍历顺序，也无法获取数组的索引。</span><br><span class="line"></span><br><span class="line">除了数组外，<span class="keyword">for</span> each循环能够遍历所有“可迭代”的数据类型，包括后面会介绍的List、Map等</span><br></pre></td></tr></table></figure><h2 id="break和continue"><a href="#break和continue" class="headerlink" title="break和continue"></a>break和continue</h2><p><em>break跳出所在的那层循环;continue结束当前循环，进入下一次循环</em></p><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">break</span>语句可以跳出当前循环；</span><br><span class="line"><span class="keyword">break</span>语句通常配合<span class="keyword">if</span>，在满足条件时提前结束整个循环；</span><br><span class="line"><span class="keyword">break</span>语句总是跳出最近的一层循环；</span><br><span class="line"><span class="keyword">continue</span>语句可以提前结束本次循环；</span><br><span class="line"><span class="keyword">continue</span>语句通常配合<span class="keyword">if</span>，在满足条件时提前结束本次循环</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="廖雪峰java笔记" scheme="http://tianyong.fun/categories/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>廖雪峰java教程笔记-java程序基础</title>
    <link href="http://tianyong.fun/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0-java%E7%A8%8B%E5%BA%8F%E5%9F%BA%E7%A1%80.html"/>
    <id>http://tianyong.fun/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0-java%E7%A8%8B%E5%BA%8F%E5%9F%BA%E7%A1%80.html</id>
    <published>2022-02-10T09:46:24.000Z</published>
    <updated>2022-02-11T02:57:16.070Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="java程序基础"><a href="#java程序基础" class="headerlink" title="java程序基础"></a>java程序基础</h1><h2 id="java程序基本结构"><a href="#java程序基本结构" class="headerlink" title="java程序基本结构"></a>java程序基本结构</h2><h3 id="类名规范"><a href="#类名规范" class="headerlink" title="类名规范"></a>类名规范</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">+ 首字母大写</span><br><span class="line">+ 字母开头，数字，下划线组合</span><br></pre></td></tr></table></figure><h3 id="方法名规范"><a href="#方法名规范" class="headerlink" title="方法名规范"></a>方法名规范</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">命名和class一样，但是首字母小写</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这里的方法名是main，返回值是void，表示没有任何返回值。</span><br><span class="line"></span><br><span class="line">我们注意到public除了可以修饰class外，也可以修饰方法。而关键字static是另一个修饰符，它表示静态方法，后面我们会讲解方法的类型，目前，我们只需要知道，Java入口程序规定的方法必须是静态方法，方法名必须为main，括号内的参数必须是String数组。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 注释方法</span><br><span class="line"></span><br><span class="line">~~~</span><br><span class="line">+ &#x2F;&#x2F;</span><br><span class="line">+ &#x2F;*... *&#x2F;</span><br><span class="line">+ &#x2F;**... *&#x2F;  这是一种特殊注释方法，用在类和方法的定义出，用于自动创建文档</span><br><span class="line"></span><br><span class="line">~~~</span><br><span class="line"></span><br><span class="line">~~~</span><br><span class="line">Java程序对格式没有明确的要求，多几个空格或者回车不影响程序的正确性，但是我们要养成良好的编程习惯</span><br><span class="line">*对于eclipse可以用快捷键ctrl+shift+f，快速格式化代码*</span><br><span class="line">~~~</span><br><span class="line"></span><br><span class="line">## 变量和数据类型</span><br><span class="line"></span><br><span class="line">### 变量</span><br><span class="line"></span><br><span class="line">~~~</span><br><span class="line">在Java中，变量分为两种：基本类型的变量和引用类型的变量。</span><br><span class="line">~~~</span><br><span class="line"></span><br><span class="line">~~~</span><br><span class="line">*先定义再应用*</span><br><span class="line">*可以一次性多个定义和赋值*</span><br><span class="line">*没有赋值，将自动赋默认值(基本数据类型)*</span><br><span class="line">*可以将一个基本数据类型变量赋值给另一个基本类型变量。不是指向同一个地址*</span><br><span class="line">~~~</span><br><span class="line"></span><br><span class="line">### 基本数据类型有</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;基本数据类型是CPU可以直接进行运算的类型</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+ 整型 byte,short,int,long</span><br><span class="line">+ 浮点型 float,double</span><br><span class="line">   float要加上f或F，double可以省略</span><br><span class="line">+ 字符型 char</span><br><span class="line">  用单引号</span><br><span class="line">+ 布尔型 false,true</span><br></pre></td></tr></table></figure><p><code>不同的数据类型占用的字节数不一样。我们看一下Java基本数据类型占用的字节数</code></p><p><a href="https://imgtu.com/i/HtXtqe" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/10/HtXtqe.png" alt="HtXtqe.png"></a></p><h4 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">对于整型类型，Java只定义了带符号的整型，因此，最高位的bit表示符号位（<span class="number">0</span>表示正数，<span class="number">1</span>表示负数）。各种整型能表示的最大范围如下</span><br><span class="line"></span><br><span class="line">byte：<span class="number">-128</span> ~ <span class="number">127</span></span><br><span class="line">short: <span class="number">-32768</span> ~ <span class="number">32767</span></span><br><span class="line">int: <span class="number">-2147483648</span> ~ <span class="number">2147483647</span></span><br><span class="line">long: <span class="number">-9223372036854775808</span> ~ <span class="number">9223372036854775807</span></span><br><span class="line"></span><br><span class="line">对于float类型，需要加上f后缀。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int i = <span class="number">2147483647</span>;</span><br><span class="line">        int i2 = <span class="number">-2147483648</span>;</span><br><span class="line">        int i3 = <span class="number">2</span>_000_000_000; // 加下划线更容易识别</span><br><span class="line">        int i4 = <span class="number">0xff0000</span>; // 十六进制表示的<span class="number">16711680</span></span><br><span class="line">        int i5 = <span class="number">0b1000000000</span>; // 二进制表示的<span class="number">512</span></span><br><span class="line">        long l = <span class="number">9000000000000000000L</span>; // long型的结尾需要加L</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">特别注意：同一个数的不同进制的表示是完全相同的，例如<span class="number">15</span>=<span class="number">0xf</span>＝<span class="number">0b1111</span></span><br></pre></td></tr></table></figure><h4 id="浮点型"><a href="#浮点型" class="headerlink" title="浮点型"></a>浮点型</h4><p><code>因为小数用科学计数法表示的时候，小数点是可以“浮动”的,所以称为浮点数</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">float f1 = <span class="number">3.14</span>f;</span><br><span class="line">float f2 = <span class="number">3.14e38</span>f; // 科学计数法表示的<span class="number">3.14</span>x10^<span class="number">38</span></span><br><span class="line">double d = <span class="number">1.79e308</span>;</span><br><span class="line">double d2 = <span class="number">-1.79e308</span>;</span><br><span class="line">double d3 = <span class="number">4.9e-324</span>; // 科学计数法表示的<span class="number">4.9</span>x10^<span class="number">-324</span></span><br></pre></td></tr></table></figure><h4 id="布尔类型"><a href="#布尔类型" class="headerlink" title="布尔类型"></a>布尔类型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">布尔类型boolean只有true和false两个值，布尔类型总是关系运算的计算结果</span><br><span class="line"></span><br><span class="line">Java语言对布尔类型的存储并没有做规定，因为理论上存储布尔类型只需要1 bit，但是通常JVM内部会把boolean表示为4字节整数</span><br></pre></td></tr></table></figure><h4 id="字符类型"><a href="#字符类型" class="headerlink" title="字符类型"></a>字符类型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">字符类型char表示一个字符。Java的char类型除了可表示标准的ASCII外，还可以表示一个Unicode字符：</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        char a = <span class="string">'A'</span>;</span><br><span class="line">        char zh = <span class="string">'中'</span>;</span><br><span class="line">        System.out.println(a);</span><br><span class="line">        System.out.println(zh);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意char类型使用单引号&#39;，且仅有一个字符，要和双引号&quot;的字符串类型区分开。</span><br></pre></td></tr></table></figure><h3 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h3><p><em>除了上述基本类型的变量，剩下的都是引用类型</em></p><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">引用类型最常用的就是String字符串：</span><br><span class="line"></span><br><span class="line">String s &#x3D; &quot;hello&quot;;</span><br><span class="line"></span><br><span class="line">引用类型的变量类似于C语言的指针，它内部存储一个“地址”，指向某个对象在内存的位置，后续我们介绍类的概念时会详细讨论。</span><br></pre></td></tr></table></figure><h4 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">定义变量的时候，如果加上final修饰符，这个变量就变成了常量</span><br><span class="line"></span><br><span class="line">final double PI = <span class="number">3.14</span>; // PI是一个常量</span><br><span class="line">double r = <span class="number">5.0</span>;</span><br><span class="line">double area = PI * r * r;</span><br><span class="line">PI = <span class="number">300</span>; // compile error!</span><br><span class="line"></span><br><span class="line">常量在定义时进行初始化后就不可再次赋值，再次赋值会导致编译错误。</span><br><span class="line">根据习惯，常量名通常全部大写。</span><br></pre></td></tr></table></figure><h4 id="var关键字"><a href="#var关键字" class="headerlink" title="var关键字"></a>var关键字</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">定义变量时，变量类型太长，可以用var</span><br><span class="line">StringBuilder sb = new StringBuilder();</span><br><span class="line"></span><br><span class="line">这个时候，如果想省略变量类型，可以使用var关键字:</span><br><span class="line">var sb = new StringBuilder();</span><br><span class="line">编译器会根据赋值语句自动推断出变量sb的类型是StringBuilder</span><br></pre></td></tr></table></figure><h3 id="变量的作用范围"><a href="#变量的作用范围" class="headerlink" title="变量的作用范围"></a>变量的作用范围</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">定义变量时，要遵循作用域最小化原则，尽量将变量定义在尽可能小的作用域，并且，不要重复使用变量名。</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Java提供了两种变量类型：基本类型和引用类型</span><br><span class="line">基本类型包括整型，浮点型，布尔型，字符型。</span><br><span class="line">变量可重新赋值，等号是赋值语句，不是数学意义的等号。</span><br><span class="line">常量在初始化后不可重新赋值，使用常量便于理解程序意图。</span><br></pre></td></tr></table></figure><h2 id="整数运算"><a href="#整数运算" class="headerlink" title="整数运算"></a>整数运算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">整数的数值表示不但是精确的，而且整数运算永远是精确的，即使是除法也是精确的，因为两个整数相除只能得到结果的整数部分</span><br><span class="line"></span><br><span class="line">int x = <span class="number">12345</span> / <span class="number">67</span>; // <span class="number">184</span></span><br><span class="line">求余运算使用%：</span><br><span class="line"></span><br><span class="line">int y = <span class="number">12345</span> % <span class="number">67</span>; // <span class="number">12345</span>÷<span class="number">67</span>的余数是<span class="number">17</span></span><br><span class="line">特别注意：整数的除法对于除数为<span class="number">0</span>时运行时将报错，但编译不会报错</span><br></pre></td></tr></table></figure><h3 id="溢出"><a href="#溢出" class="headerlink" title="溢出"></a>溢出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">要特别注意，整数由于存在范围限制，如果计算结果超出了范围，就会产生溢出，而溢出不会出错，却会得到一个奇怪的结果</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int x = <span class="number">2147483640</span>;</span><br><span class="line">        int y = <span class="number">15</span>;</span><br><span class="line">        int sum = x + y;</span><br><span class="line">        System.out.println(sum); // <span class="number">-2147483641</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="number">0111</span> <span class="number">1111</span> <span class="number">1111</span> <span class="number">1111</span> <span class="number">1111</span> <span class="number">1111</span> <span class="number">1111</span> <span class="number">1000</span></span><br><span class="line">+ <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span></span><br><span class="line">-----------------------------------------</span><br><span class="line">  <span class="number">1000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0111</span></span><br><span class="line">由于最高位计算结果为<span class="number">1</span>，因此，加法结果变成了一个负数</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">还有一种简写的运算符，即+=，-=，*=，/=，它们的使用方法如下：</span><br><span class="line"></span><br><span class="line">n += <span class="number">100</span>; // <span class="number">3409</span>, 相当于 n = n + <span class="number">100</span>;</span><br><span class="line">n -= <span class="number">100</span>; // <span class="number">3309</span>, 相当于 n = n - <span class="number">100</span>;</span><br></pre></td></tr></table></figure><h3 id="自增-自减"><a href="#自增-自减" class="headerlink" title="自增/自减"></a>自增/自减</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">++</span><br><span class="line"></span><br><span class="line">--</span><br><span class="line"></span><br><span class="line">*写在变量前面和后面是不同的，前面(先加减在运算)，后面(先运算再加减)*</span><br></pre></td></tr></table></figure><h3 id="移位运算符"><a href="#移位运算符" class="headerlink" title="移位运算符"></a>移位运算符</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">*数值的最高位是一个符号位*</span><br><span class="line">1.</span><br><span class="line">&gt;&gt;: 右位移</span><br><span class="line">int n &#x3D; 7;       &#x2F;&#x2F; 00000000 00000000 00000000 00000111 &#x3D; 7</span><br><span class="line">int a &#x3D; n &gt;&gt; 1;  &#x2F;&#x2F; 00000000 00000000 00000000 00000011 &#x3D; 3</span><br><span class="line">int b &#x3D; n &gt;&gt; 2;  &#x2F;&#x2F; 00000000 00000000 00000000 00000001 &#x3D; 1</span><br><span class="line">int c &#x3D; n &gt;&gt; 3;  &#x2F;&#x2F; 00000000 00000000 00000000 00000000 &#x3D; 0</span><br><span class="line">如果对一个负数进行右移，最高位的1不动，结果仍然是一个负数：</span><br><span class="line">int n &#x3D; -536870912;</span><br><span class="line">int a &#x3D; n &gt;&gt; 1;  &#x2F;&#x2F; 11110000 00000000 00000000 00000000 &#x3D; -268435456</span><br><span class="line">int b &#x3D; n &gt;&gt; 2;  &#x2F;&#x2F; 11111000 00000000 00000000 00000000 &#x3D; -134217728</span><br><span class="line">int c &#x3D; n &gt;&gt; 28; &#x2F;&#x2F; 11111111 11111111 11111111 11111110 &#x3D; -2</span><br><span class="line">int d &#x3D; n &gt;&gt; 29; &#x2F;&#x2F; 11111111 11111111 11111111 11111111 &#x3D; -1</span><br><span class="line"></span><br><span class="line">2. </span><br><span class="line">&lt;&lt;: 左位移</span><br><span class="line">int n &#x3D; 7;       &#x2F;&#x2F; 00000000 00000000 00000000 00000111 &#x3D; 7</span><br><span class="line">int a &#x3D; n &lt;&lt; 1;  &#x2F;&#x2F; 00000000 00000000 00000000 00001110 &#x3D; 14</span><br><span class="line">int b &#x3D; n &lt;&lt; 2;  &#x2F;&#x2F; 00000000 00000000 00000000 00011100 &#x3D; 28</span><br><span class="line">int c &#x3D; n &lt;&lt; 28; &#x2F;&#x2F; 01110000 00000000 00000000 00000000 &#x3D; 1879048192</span><br><span class="line">int d &#x3D; n &lt;&lt; 29; &#x2F;&#x2F; 11100000 00000000 00000000 00000000 &#x3D; -536870912</span><br><span class="line"></span><br><span class="line">*上面两种不会改变符号位*</span><br><span class="line"></span><br><span class="line">3.无符号的右移运算</span><br><span class="line">使用&gt;&gt;&gt;，它的特点是不管符号位，右移后高位总是补0，因此，对一个负数进行&gt;&gt;&gt;右移，它会变成正数，原因是最高位的1变成了0</span><br><span class="line">int n &#x3D; -536870912;</span><br><span class="line">int a &#x3D; n &gt;&gt;&gt; 1;  &#x2F;&#x2F; 01110000 00000000 00000000 00000000 &#x3D; 1879048192</span><br><span class="line">int b &#x3D; n &gt;&gt;&gt; 2;  &#x2F;&#x2F; 00111000 00000000 00000000 00000000 &#x3D; 939524096</span><br><span class="line">int c &#x3D; n &gt;&gt;&gt; 29; &#x2F;&#x2F; 00000000 00000000 00000000 00000111 &#x3D; 7</span><br><span class="line">int d &#x3D; n &gt;&gt;&gt; 31; &#x2F;&#x2F; 00000000 00000000 00000000 00000001 &#x3D; 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">对byte和short类型进行移位时，会首先转换为int再进行位移。</span><br><span class="line">仔细观察可发现，左移实际上就是不断地×2，右移实际上就是不断地÷2</span><br></pre></td></tr></table></figure><h3 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">位运算是按位进行与、或、非和异或的运算</span><br><span class="line"></span><br><span class="line">&amp;(与): 同1才为1</span><br><span class="line"></span><br><span class="line">|(或): 有1则为0</span><br><span class="line"></span><br><span class="line">~(非)： 01互换</span><br><span class="line"></span><br><span class="line">^(异或): 不同才为1</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">对两个整数进行位运算，实际上就是按位对齐，然后依次对每一位进行运算。</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int i = <span class="number">167776589</span>; // <span class="number">00001010</span> <span class="number">00000000</span> <span class="number">00010001</span> <span class="number">01001101</span></span><br><span class="line">        int n = <span class="number">167776512</span>; // <span class="number">00001010</span> <span class="number">00000000</span> <span class="number">00010001</span> <span class="number">00000000</span></span><br><span class="line">        System.out.println(i &amp; n); // <span class="number">167776512</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运算优先级"><a href="#运算优先级" class="headerlink" title="运算优先级"></a>运算优先级</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">在Java的计算表达式中，运算优先级从高到低依次是：</span><br><span class="line"></span><br><span class="line">()</span><br><span class="line">! ~ ++ --</span><br><span class="line">* / %</span><br><span class="line">+ -</span><br><span class="line">&lt;&lt; &gt;&gt; &gt;&gt;&gt;</span><br><span class="line">&amp;</span><br><span class="line">|</span><br><span class="line">+= -= *= /=</span><br><span class="line"></span><br><span class="line">记不住也没关系，只需要加括号就可以保证运算的优先级正确</span><br></pre></td></tr></table></figure><h3 id="类型自动提升-整与整"><a href="#类型自动提升-整与整" class="headerlink" title="类型自动提升(整与整)"></a>类型自动提升(整与整)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在运算过程中，如果参与运算的两个数类型不一致，那么计算结果为较大类型的整型。例如，short和int计算，结果总是int，原因是short首先自动被转型为int</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        short s = <span class="number">1234</span>;</span><br><span class="line">        int i = <span class="number">123456</span>;</span><br><span class="line">        int x = s + i; // s自动转型为int</span><br><span class="line">        short y = s + i; // 编译错误!</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="强制转换-整与整"><a href="#强制转换-整与整" class="headerlink" title="强制转换(整与整)"></a>强制转换(整与整)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">也可以将结果强制转型，即将大范围的整数转型为小范围的整数。强制转型使用(类型)，例如，将int强制转型为short：</span><br><span class="line"></span><br><span class="line">int i &#x3D; 12345;</span><br><span class="line">short s &#x3D; (short) i; &#x2F;&#x2F; 12345</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">要注意，超出范围的强制转型会得到错误的结果，原因是转型时，int的两个高位字节直接被扔掉，仅保留了低位的两个字节</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int i1 = <span class="number">1234567</span>;</span><br><span class="line">        short s1 = (short) i1; // <span class="number">-10617</span></span><br><span class="line">        System.out.println(s1);</span><br><span class="line">        int i2 = <span class="number">12345678</span>; //short <span class="number">32767</span></span><br><span class="line">        short s2 = (short) i2; // <span class="number">24910</span></span><br><span class="line">        System.out.println(s2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">-10617</span></span><br><span class="line"><span class="number">24910</span></span><br><span class="line"></span><br><span class="line">// 因此，强制转型的结果很可能是错的</span><br></pre></td></tr></table></figure><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">整数运算的结果永远是精确的；</span><br><span class="line">运算结果会自动提升；</span><br><span class="line">可以强制转型，但超出范围的强制转型会得到错误的结果；</span><br><span class="line">应该选择合适范围的整型（int或long），没有必要为了节省内存而使用byte和short进行整数运算。</span><br></pre></td></tr></table></figure><h2 id="浮点数计算"><a href="#浮点数计算" class="headerlink" title="浮点数计算"></a>浮点数计算</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*无法精确表示数值，不能做移位和位运算*</span><br><span class="line">由于浮点数存在运算误差，所以比较两个浮点数是否相等常常会出现错误的结果。正确的比较方法是判断两个浮点数之差的绝对值是否小于一个很小的数</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 比较x和y是否相等，先计算其差的绝对值:</span><br><span class="line">double r = Math.abs(x - y);</span><br><span class="line">// 再判断绝对值是否足够小:</span><br><span class="line"><span class="keyword">if</span> (r &lt; <span class="number">0.00001</span>) &#123;</span><br><span class="line">    // 可以认为相等</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    // 不相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="类型提升"><a href="#类型提升" class="headerlink" title="类型提升"></a>类型提升</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果参与运算的两个数其中一个是整型，那么整型可以自动提升到浮点型</span><br></pre></td></tr></table></figure><h3 id="溢出-1"><a href="#溢出-1" class="headerlink" title="溢出"></a>溢出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">*整数在除零时编译时不出错，运行时出错*</span><br><span class="line">*浮点数除零不会报错，会返回特殊值：*</span><br><span class="line"></span><br><span class="line">NaN:<span class="keyword">not</span> a number</span><br><span class="line">Infinity:无穷大</span><br><span class="line">-Infinity:负无穷大</span><br><span class="line"></span><br><span class="line">double d1 = <span class="number">0.0</span> / <span class="number">0</span>; // NaN</span><br><span class="line">double d2 = <span class="number">1.0</span> / <span class="number">0</span>; // Infinity</span><br><span class="line">double d3 = <span class="number">-1.0</span> / <span class="number">0</span>; // -Infinity</span><br><span class="line"></span><br><span class="line">这三种特殊值在实际运算中很少碰到，我们只需要了解即可</span><br></pre></td></tr></table></figure><h3 id="强制转换-整与浮"><a href="#强制转换-整与浮" class="headerlink" title="强制转换(整与浮)"></a>强制转换(整与浮)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可以将浮点数强制转型为整数。在转型时，浮点数的小数部分会被丢掉。如果转型后超过了整型能表示的最大范围，将返回整型的最大值。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int n1 = (int) <span class="number">12.3</span>; // <span class="number">12</span></span><br><span class="line">int n2 = (int) <span class="number">12.7</span>; // <span class="number">12</span></span><br><span class="line">int n2 = (int) <span class="number">-12.7</span>; // <span class="number">-12</span></span><br><span class="line">int n3 = (int) (<span class="number">12.7</span> + <span class="number">0.5</span>); // <span class="number">13</span></span><br><span class="line">int n4 = (int) <span class="number">1.2e20</span>; // <span class="number">2147483647</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">如果要进行四舍五入，可以对浮点数加上<span class="number">0.5</span>再强制转型</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        double d = <span class="number">2.6</span>;</span><br><span class="line">        int n = (int) (d + <span class="number">0.5</span>);</span><br><span class="line">        System.out.println(n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">浮点数常常无法精确表示，并且浮点数的运算结果可能有误差；</span><br><span class="line">比较两个浮点数通常比较它们的差的绝对值是否小于一个特定值；</span><br><span class="line">整型和浮点型运算时，整型会自动提升为浮点型；</span><br><span class="line">可以将浮点型强制转为整型，但超出范围后将始终返回整型的最大值。</span><br></pre></td></tr></table></figure><h2 id="布尔运算"><a href="#布尔运算" class="headerlink" title="布尔运算"></a>布尔运算</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">对于布尔类型boolean，永远只有true和false两个值。</span><br><span class="line">布尔运算是一种关系运算，包括以下几类：</span><br><span class="line"></span><br><span class="line">比较运算符：&gt;，&gt;&#x3D;，&lt;，&lt;&#x3D;，&#x3D;&#x3D;，!&#x3D;</span><br><span class="line">与运算 &amp;&amp;</span><br><span class="line">或运算 ||</span><br><span class="line">非运算 !</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">boolean isGreater = <span class="number">5</span> &gt; <span class="number">3</span>; // true</span><br><span class="line">int age = <span class="number">12</span>;</span><br><span class="line">boolean isZero = age == <span class="number">0</span>; // false</span><br><span class="line">boolean isNonZero = !isZero; // true</span><br><span class="line">boolean isAdult = age &gt;= <span class="number">18</span>; // false</span><br><span class="line">boolean isTeenager = age &gt;<span class="number">6</span> &amp;&amp; age &lt;<span class="number">18</span>; // true</span><br></pre></td></tr></table></figure><h3 id="关系运算符的优先级"><a href="#关系运算符的优先级" class="headerlink" title="关系运算符的优先级"></a>关系运算符的优先级</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!</span><br><span class="line">&gt;，&gt;&#x3D;，&lt;，&lt;&#x3D;</span><br><span class="line">&#x3D;&#x3D;，!&#x3D;</span><br><span class="line">&amp;&amp;</span><br><span class="line">||</span><br></pre></td></tr></table></figure><h3 id="短路运算"><a href="#短路运算" class="headerlink" title="短路运算"></a>短路运算</h3><h4 id="true-amp-amp-任意"><a href="#true-amp-amp-任意" class="headerlink" title="true&amp;&amp;任意"></a>true&amp;&amp;任意</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">布尔运算的一个重要特点是短路运算。如果一个布尔运算的表达式能提前确定结果，则后续的计算不再执行，直接返回结果。</span><br><span class="line"></span><br><span class="line">因为false &amp;&amp; x的结果总是false，无论x是true还是false，因此，与运算在确定第一个值为false后，不再继续计算，而是直接返回false</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        boolean b &#x3D; 5 &lt; 3;</span><br><span class="line">        boolean result &#x3D; b &amp;&amp; (5 &#x2F; 0 &gt; 0);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">false</span><br><span class="line"></span><br><span class="line">如果没有短路运算，&amp;&amp;后面的表达式会由于除数为0而报错，但实际上该语句并未报错，原因在于与运算是短路运算符，提前计算出了结果false</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HNRoOx" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/10/HNRoOx.png" alt="HNRoOx.png"></a></p><h4 id="true-任意"><a href="#true-任意" class="headerlink" title="true || 任意"></a>true || 任意</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">类似的，对于||运算，只要能确定第一个值为true，后续计算也不再进行，而是直接返回true：</span><br><span class="line"></span><br><span class="line">boolean result &#x3D; true || (5 &#x2F; 0 &gt; 0); &#x2F;&#x2F; true</span><br></pre></td></tr></table></figure><h4 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a>三元运算符</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Java还提供一个三元运算符b ? x : y，它根据第一个布尔表达式的结果，分别返回后续两个表达式之一的计算结果</span><br><span class="line"></span><br><span class="line">b为true返回x; b为false返回y</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意到三元运算b ? x : y会首先计算b，如果b为true，则只计算x，否则，只计算y。此外，x和y的类型必须相同，因为返回值不是boolean，而是x和y之一。</span><br></pre></td></tr></table></figure><h4 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">与运算和或运算是短路运算；</span><br><span class="line">三元运算b ? x : y后面的类型必须相同，三元运算也是“短路运算”，只计算x或y。</span><br></pre></td></tr></table></figure><h2 id="字符和字符串"><a href="#字符和字符串" class="headerlink" title="字符和字符串"></a>字符和字符串</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在Java中，字符和字符串是两个不同的类型</span><br></pre></td></tr></table></figure><h3 id="字符"><a href="#字符" class="headerlink" title="字符"></a>字符</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">字符类型char是基本数据类型，它是character的缩写。一个char保存一个Unicode字符</span><br><span class="line"></span><br><span class="line">因为Java在内存中总是使用Unicode表示字符，所以，一个英文字符和一个中文字符都用一个char类型表示，它们都占用两个字节。要显示一个字符的Unicode编码，只需将char类型直接赋值给int类型即可：</span><br><span class="line"></span><br><span class="line">int n1 &#x3D; &#39;A&#39;; &#x2F;&#x2F; 字母“A”的Unicodde编码是65</span><br><span class="line">int n2 &#x3D; &#39;中&#39;; &#x2F;&#x2F; 汉字“中”的Unicode编码是20013</span><br><span class="line">还可以直接用转义字符\u+Unicode编码来表示一个字符：</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 注意是十六进制:</span><br><span class="line">char c3 &#x3D; &#39;\u0041&#39;; &#x2F;&#x2F; &#39;A&#39;，因为十六进制0041 &#x3D; 十进制65</span><br><span class="line">char c4 &#x3D; &#39;\u4e2d&#39;; &#x2F;&#x2F; &#39;中&#39;，因为十六进制4e2d &#x3D; 十进制20013</span><br></pre></td></tr></table></figure><h3 id="字符串-1"><a href="#字符串-1" class="headerlink" title="字符串"></a>字符串</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">和char类型不同，字符串类型String是引用类型，我们用双引号<span class="string">"..."</span>表示字符串。一个字符串可以存储<span class="number">0</span>个到任意个字符：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">""</span>; // 空字符串，包含<span class="number">0</span>个字符</span><br><span class="line">String s1 = <span class="string">"A"</span>; // 包含一个字符</span><br><span class="line">String s2 = <span class="string">"ABC"</span>; // 包含<span class="number">3</span>个字符</span><br><span class="line">String s3 = <span class="string">"中文 ABC"</span>; // 包含<span class="number">6</span>个字符，其中有一个空格</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">因为字符串使用双引号<span class="string">"..."</span>表示开始和结束，那如果字符串本身恰好包含一个<span class="string">"字符怎么表示？例如，"</span>abc<span class="string">"xyz"</span>，编译器就无法判断中间的引号究竟是字符串的一部分还是表示字符串结束。这个时候，我们需要借助转义字符\：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">"abc\"xyz"</span>; // 包含<span class="number">7</span>个字符: a, b, c, <span class="string">", x, y, z</span></span><br><span class="line"><span class="string">因为\是转义字符，所以，两个\\表示一个\字符：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">String s = "</span>abc\\xyz<span class="string">"; // 包含7个字符: a, b, c, \, x, y, z</span></span><br><span class="line"><span class="string">常见的转义字符包括：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">\" 表示字符"</span></span><br><span class="line">\<span class="string">' 表示字符'</span></span><br><span class="line">\\ 表示字符\</span><br><span class="line">\n 表示换行符</span><br><span class="line">\r 表示回车符</span><br><span class="line">\t 表示Tab</span><br><span class="line">\u<span class="comment">#### 表示一个Unicode编码的字符</span></span><br><span class="line">例如：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">"ABC\n\u4e2d\u6587"</span>; // 包含<span class="number">6</span>个字符: A, B, C, 换行符, 中, 文</span><br></pre></td></tr></table></figure><h3 id="字符串连接"><a href="#字符串连接" class="headerlink" title="字符串连接"></a>字符串连接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Java的编译器对字符串做了特殊照顾，可以使用+连接任意字符串和其他数据类型，这样极大地方便了字符串的处理。例如：</span><br><span class="line"></span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String s1 = <span class="string">"Hello"</span>;</span><br><span class="line">        String s2 = <span class="string">"world"</span>;</span><br><span class="line">        String s = s1 + <span class="string">" "</span> + s2 + <span class="string">"!"</span>;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如果用+连接字符串和其他数据类型，会将其他数据类型先自动转型为字符串，再连接：</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int age = <span class="number">25</span>;</span><br><span class="line">        String s = <span class="string">"age is "</span> + age;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // 请将下面一组int值视为字符的Unicode码，把它们拼成一个字符串：</span><br><span class="line">        int a = <span class="number">72</span>;</span><br><span class="line">        int b = <span class="number">105</span>;</span><br><span class="line">        int c = <span class="number">65281</span>;</span><br><span class="line">        // FIXME</span><br><span class="line"> String s = <span class="string">""</span>+<span class="string">'\u0048'</span> +<span class="string">'\u0069'</span>  + <span class="string">'\uff01'</span>;</span><br><span class="line">        System.out.println(s);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public class array &#123;    </span><br><span class="line">  public static void main(String[] args)&#123;        </span><br><span class="line">    int a = <span class="number">72</span>;        </span><br><span class="line">    int b = <span class="number">105</span>;        </span><br><span class="line">    int c = <span class="number">65281</span>;        </span><br><span class="line">    // FIXME:        </span><br><span class="line">    String s = <span class="string">""</span>+(char)a + (char)b + (char)c;        </span><br><span class="line">    System.out.println(s);    </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多行字符串"><a href="#多行字符串" class="headerlink" title="多行字符串"></a>多行字符串</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">如果我们要表示多行字符串，使用+号连接会非常不方便：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">"first line \n"</span></span><br><span class="line">         + <span class="string">"second line \n"</span></span><br><span class="line">         + <span class="string">"end"</span>;</span><br><span class="line">从Java <span class="number">13</span>开始，字符串可以用<span class="string">"""..."""</span>表示多行字符串（Text Blocks）了</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String s = <span class="string">"""</span></span><br><span class="line"><span class="string">                   SELECT * FROM</span></span><br><span class="line"><span class="string">                     users</span></span><br><span class="line"><span class="string">                   WHERE id &gt; 100</span></span><br><span class="line"><span class="string">                   ORDER BY name DESC</span></span><br><span class="line"><span class="string">                   """</span>;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">上述多行字符串实际上是<span class="number">5</span>行，在最后一个DESC后面还有一个\n。如果我们不想在字符串末尾加一个\n，就需要这么写：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">""" </span></span><br><span class="line"><span class="string">           SELECT * FROM</span></span><br><span class="line"><span class="string">             users</span></span><br><span class="line"><span class="string">           WHERE id &gt; 100</span></span><br><span class="line"><span class="string">           ORDER BY name DESC"""</span>;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">还需要注意到，多行字符串前面共同的空格会被去掉，即：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">"""</span></span><br><span class="line"><span class="string">...........SELECT * FROM</span></span><br><span class="line"><span class="string">...........  users</span></span><br><span class="line"><span class="string">...........WHERE id &gt; 100</span></span><br><span class="line"><span class="string">...........ORDER BY name DESC</span></span><br><span class="line"><span class="string">..........."""</span>;</span><br><span class="line">用.标注的空格都会被去掉。</span><br><span class="line"></span><br><span class="line">如果多行字符串的排版不规则，那么，去掉的空格就会变成这样：</span><br><span class="line"></span><br><span class="line">String s = <span class="string">"""</span></span><br><span class="line"><span class="string">.........  SELECT * FROM</span></span><br><span class="line"><span class="string">.........    users</span></span><br><span class="line"><span class="string">.........WHERE id &gt; 100</span></span><br><span class="line"><span class="string">.........  ORDER BY name DESC</span></span><br><span class="line"><span class="string">.........  """</span>;</span><br><span class="line">即总是以最短的行首空格为基准。</span><br></pre></td></tr></table></figure><h3 id="不可变特性"><a href="#不可变特性" class="headerlink" title="不可变特性"></a>不可变特性</h3><p><a href="https://imgtu.com/i/HUnuM8" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HUnuM8.md.png" alt="HUnuM8.md.png"></a></p><h3 id="空值"><a href="#空值" class="headerlink" title="空值"></a>空值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">引用类型的变量可以指向一个空值null，它表示不存在，即该变量不指向任何对象。例如：</span><br><span class="line"></span><br><span class="line">String s1 = null; // s1是null</span><br><span class="line">String s2; // 没有赋初值值，s2也是null</span><br><span class="line">String s3 = s1; // s3也是null</span><br><span class="line">String s4 = <span class="string">""</span>; // s4指向空字符串，不是null</span><br><span class="line">注意要区分空值null和空字符串<span class="string">""</span>，空字符串是一个有效的字符串对象，它不等于null</span><br></pre></td></tr></table></figure><h3 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Java的字符类型char是基本类型，字符串类型String是引用类型；</span><br><span class="line">基本类型的变量是“持有”某个数值，引用类型的变量是“指向”某个对象；</span><br><span class="line">引用类型的变量可以是空值null；</span><br><span class="line">要区分空值null和空字符串<span class="string">""</span></span><br></pre></td></tr></table></figure><h2 id="数组类型"><a href="#数组类型" class="headerlink" title="数组类型"></a>数组类型</h2><h4 id="法一"><a href="#法一" class="headerlink" title="法一"></a>法一</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">使用数组来表示“一组”int类型。代码如下：</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // <span class="number">5</span>位同学的成绩:</span><br><span class="line">        int[] ns = new int[<span class="number">5</span>];</span><br><span class="line">        ns[<span class="number">0</span>] = <span class="number">68</span>;</span><br><span class="line">        ns[<span class="number">1</span>] = <span class="number">79</span>;</span><br><span class="line">        ns[<span class="number">2</span>] = <span class="number">91</span>;</span><br><span class="line">        ns[<span class="number">3</span>] = <span class="number">85</span>;</span><br><span class="line">        ns[<span class="number">4</span>] = <span class="number">62</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">定义一个数组类型的变量，使用数组类型“类型[]”，例如，int[]。和单个基本类型变量不同，数组变量初始化必须使用new int[<span class="number">5</span>]表示创建一个可容纳<span class="number">5</span>个int元素的数组。</span><br><span class="line">Java的数组有几个特点：</span><br><span class="line">数组所有元素初始化为默认值，整型都是<span class="number">0</span>，浮点型是<span class="number">0.0</span>，布尔型是false；</span><br><span class="line">数组一旦创建后，大小就不可改变。</span><br><span class="line">要访问数组中的某一个元素，需要使用索引。数组索引从<span class="number">0</span>开始，例如，<span class="number">5</span>个元素的数组，索引范围是<span class="number">0</span>~<span class="number">4</span>。</span><br><span class="line">可以修改数组中的某一个元素，使用赋值语句，例如，ns[<span class="number">1</span>] = <span class="number">79</span>;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">可以用数组变量.length获取数组大小</span><br><span class="line">数组是引用类型，在使用索引访问数组元素时，如果索引超出范围，运行时将报错</span><br></pre></td></tr></table></figure><h4 id="法二"><a href="#法二" class="headerlink" title="法二"></a>法二</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">也可以在定义数组时直接指定初始化的元素，这样就不必写出数组大小，而是由编译器自动推算数组大小。例如：</span><br><span class="line">public class Main &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // <span class="number">5</span>位同学的成绩:</span><br><span class="line">        int[] ns = new int[] &#123; <span class="number">68</span>, <span class="number">79</span>, <span class="number">91</span>, <span class="number">85</span>, <span class="number">62</span> &#125;;</span><br><span class="line">        System.out.println(ns.length); // 编译器自动推算数组大小为<span class="number">5</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">还可以进一步简写为：</span><br><span class="line">int[] ns = &#123; <span class="number">68</span>, <span class="number">79</span>, <span class="number">91</span>, <span class="number">85</span>, <span class="number">62</span> &#125;;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意数组是引用类型，并且数组大小不可变。</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HUNHEt" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HUNHEt.md.png" alt="HUNHEt.md.png"></a></p><h4 id="字符串数组"><a href="#字符串数组" class="headerlink" title="字符串数组"></a>字符串数组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如果数组元素不是基本类型，而是一个引用类型，那么，修改数组元素会有哪些不同？</span><br><span class="line">字符串是引用类型，因此我们先定义一个字符串数组：</span><br><span class="line"></span><br><span class="line">String[] names = &#123;</span><br><span class="line">    <span class="string">"ABC"</span>, <span class="string">"XYZ"</span>, <span class="string">"zoo"</span></span><br><span class="line">&#125;;xxxxxxxxxx 如果数组元素不是基本类型，而是一个引用类型，那么，修改数组元素会有哪些不同？字符串是引用类型，因此我们先定义一个字符串数组：String[] names = &#123;    <span class="string">"ABC"</span>, <span class="string">"XYZ"</span>, <span class="string">"zoo"</span>&#125;;[![HUNHEt.md.png](https://s4.ax1x.com/<span class="number">2022</span>/<span class="number">02</span>/<span class="number">11</span>/HUNHEt.md.png)](https://imgtu.com/i/HUNHEt)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HUUBPf" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HUUBPf.md.png" alt="HUUBPf.md.png"></a></p><h4 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">数组是同一数据类型的集合，数组一旦创建后，大小就不可变；</span><br><span class="line"></span><br><span class="line">可以通过索引访问数组元素，但索引超出范围将报错；</span><br><span class="line"></span><br><span class="line">数组元素可以是值类型（如int）或引用类型（如String），但数组本身是引用类型；</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="廖雪峰java笔记" scheme="http://tianyong.fun/categories/%E5%BB%96%E9%9B%AA%E5%B3%B0java%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第五周 第四章 精讲Shuffle执行过程及源码分析输入输出</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%BA%94%E5%91%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%B2%BE%E8%AE%B2Shuffle%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E5%8F%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%BA%94%E5%91%A8-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%B2%BE%E8%AE%B2Shuffle%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E5%8F%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA.html</id>
    <published>2022-02-09T10:56:36.000Z</published>
    <updated>2022-02-13T06:01:30.796Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第五周-第四章-精讲Shuffle执行过程及源码分析输入输出"><a href="#第五周-第四章-精讲Shuffle执行过程及源码分析输入输出" class="headerlink" title="第五周 第四章 精讲Shuffle执行过程及源码分析输入输出"></a>第五周 第四章 精讲Shuffle执行过程及源码分析输入输出</h1><h2 id="Shuffle过程详解"><a href="#Shuffle过程详解" class="headerlink" title="Shuffle过程详解"></a>Shuffle过程详解</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">咱们前面简单说过，shuffer是一个网络拷贝的过程，是指通过网络把数据从map端拷贝到reduce端的过</span><br><span class="line">程，下面我们来详细分析一下这个过程</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HwABhq" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HwABhq.png" alt="HwABhq.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来根据这张图分析一下shuffle的一些细节信息，</span><br><span class="line">  首先看map阶段，最左边有一个inputsplit，最终会产生一个map任务，map任务在执行的时候会把k1,v1转化为k2,v2，这些数据会先临时存储到一个内存缓冲区中，这个内存缓冲区的大小默认是100M（io.sort.mb属性），当达到内存缓冲区大小的80%（io.sort.spill.percent）也就是80M的时候，会把内存中的数据溢写到本地磁盘中（mapred.local.dir），一直到map把所有的数据都计算完，最后会把内存缓冲区中的数据一次性全部刷新到本地磁盘文件中，在这个图里面表示产生了3个临时文件，每个临时文件中有3个分区，这是由于map阶段中对数据做了分区，所以数据在存储的时候，在每个临时文件中也划分为了3块，最后需要对这些临时文件进行合并，合并为一个大文件，因为一个map任务最终只会产生一个文件，这个合并之后的文件也是有3个分区的，这3个分区的数据会被shuffle线程分别拷贝到三个不同的reduce节点，图里面只显示了一个reduce节点，下面还有两个没有显示。不同map任务中的相同分区的数据会在同一个reduce节点进行合并，合并以后会执行reduce的功能，最终产生结果数据。</span><br><span class="line">  在这里shuffle其实是横跨map端和reduce端的，它主要是负责把map端产生的数据通过网络拷贝到reduce阶段进行统一聚合计算</span><br></pre></td></tr></table></figure><h2 id="Hadoop中序列化机制"><a href="#Hadoop中序列化机制" class="headerlink" title="Hadoop中序列化机制"></a>Hadoop中序列化机制</h2><p><a href="https://imgtu.com/i/HwA0Nn" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HwA0Nn.png" alt="HwA0Nn.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  我们的map阶段在读取数据的是需要从hdfs中读取的，这里面需要经过磁盘IO和网络IO，不过正常情况下map任务会执行本地计算，也就是map任务会被分发到数据所在的节点进行计算，这个时候，网络io几乎就没有了，就剩下了磁盘io，再往后面看，map阶段执行完了以后，数据会被写入到本地磁盘文件，这个时候也需要经过磁盘io，后面的shuffle拷贝数据其实也需要先经过磁盘io把数据从本地磁盘读出来再通过网络发送到reduce节点，再写入reduce节点的本地磁盘，然后reduce阶段在执行的时候会经过磁盘io读取本地文件中的数据，计算完成以后还会经过磁盘io和网络io把数据写入到hdfs中。</span><br><span class="line">  经过我们刚才的分析，其实在这里面占得比重最高的是磁盘io，所以说影响mapreduce任务执行效率的主要原因就是磁盘io，如果想要提高任务执行效率，就需要从这方面着手分析。</span><br><span class="line">当程序在向磁盘中写数据以及从磁盘中读取数据的时候会对数据进行序列化和反序列化，磁盘io这些步骤我们省略不了，但是我们可以从序列化和反序列化这一块来着手做一些优化，</span><br><span class="line">首先我们分析一下序列化和反序列化，看这个图，当我们想把内存中的数据写入到文件中的时候，会对数据序列化，然后再写入，这个序列化其实就是把内存中的对象信息转成二进制的形式，方便存储到文件中，默认java中的序列化会把对象及其父类、超类的整个继承体系信息都保存下来，这样存储的信息太大了，就会导致写入文件的信息过大，这样写入是会额外消耗性能的。</span><br><span class="line">反序列化也是一样，reduce端想把文件中的对象信息加载到内存中，如果文件很大，在加载的时候也会额外消耗很多性能，所以如果我们把对象存储的信息尽量精简，那么就可以提高数据写入和读取消耗的性能。</span><br><span class="line">  基于此，hadoop官方实现了自己的序列化和反序列化机制，没有使用java中的序列化机制，所以</span><br><span class="line">hadoop中的数据类型没有沿用java中的数据类型，而是自己单独设计了一些writable的实现了，例如、</span><br><span class="line">longwritable、text等</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">那我们来看一下Hadoop中提供的常用的基本数据类型的序列化类</span><br><span class="line"></span><br><span class="line">Java基本类型 Writable 序列化大小(字节)</span><br><span class="line">布尔型（boolean） BooleanWritable 1</span><br><span class="line">字节型（byte） ByteWritable 1</span><br><span class="line">整型（int） IntWritable 4</span><br><span class="line">VIntWritable 1~5</span><br><span class="line">浮点型（float） FloatWritable 4</span><br><span class="line">长整型（long） LongWritable 8</span><br><span class="line">VLongWritable 1~9</span><br><span class="line">双精度浮点型（double） DoubleWritable 8</span><br><span class="line"></span><br><span class="line">在这需要注意一下</span><br><span class="line">Text等价于java.lang.String的Writable，针对UTF-8序列</span><br><span class="line">NullWritable是单例，获取实例使用NullWritable.get()</span><br></pre></td></tr></table></figure><h3 id="hadoop自己实现的序列化的特点"><a href="#hadoop自己实现的序列化的特点" class="headerlink" title="hadoop自己实现的序列化的特点"></a>hadoop自己实现的序列化的特点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 紧凑: 高效使用存储空间</span><br><span class="line">2. 快速: 读写数据的额外开销小</span><br><span class="line">3. 可扩展: 可透明地读取老格式的数据</span><br><span class="line">4. 互操作: 支持多语言的交互</span><br></pre></td></tr></table></figure><h3 id="java中序列化的不足"><a href="#java中序列化的不足" class="headerlink" title="java中序列化的不足"></a>java中序列化的不足</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 不精简，附加信息多，不太适合随机访问</span><br><span class="line">2. 存储空间大，递归地输出类的超类描述直到不再有超类</span><br></pre></td></tr></table></figure><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">前面我们分析了Java中的序列化和Hadoop中的序列化，其实最主要的区别就是针对相同的数据，Java中的序列化会占用较大的存储空间，而Hadoop中的序列化可以节省很多存储空间，这样在海量数据计算的场景下，可以减少数据传输的大小，极大的提高计算效率</span><br></pre></td></tr></table></figure><h4 id="java序列化对象"><a href="#java序列化对象" class="headerlink" title="java序列化对象"></a>java序列化对象</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.mc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * java中的序列化</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">javaSerialize</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">// 创建student对象，并设置id和name属性</span></span><br><span class="line">        StudentJava studentJava = <span class="keyword">new</span> StudentJava();</span><br><span class="line">        studentJava.setId(<span class="number">1L</span>);</span><br><span class="line">        studentJava.setName(<span class="string">"Hadoop"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将student当前状态写入本地文件中</span></span><br><span class="line">        FileOutputStream fos =<span class="keyword">new</span> FileOutputStream(<span class="string">"D:\\student_java.txt"</span>);</span><br><span class="line">        ObjectOutputStream oos = <span class="keyword">new</span> ObjectOutputStream(fos);</span><br><span class="line">        oos.writeObject(studentJava);</span><br><span class="line">        oos.close();</span><br><span class="line">        fos.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StudentJava</span> <span class="keyword">implements</span> <span class="title">Serializable</span></span>&#123; <span class="comment">// 一个文件只能有一个主类</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> Id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(<span class="keyword">long</span> id)</span> </span>&#123;</span><br><span class="line">        Id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="hadoop序列化对象"><a href="#hadoop序列化对象" class="headerlink" title="hadoop序列化对象"></a>hadoop序列化对象</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.mc;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hadoop序列化机制</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HadoopSerialize</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//创建student对象并设置name,id属性</span></span><br><span class="line">        StudentWritable studentWritable = <span class="keyword">new</span> StudentWritable();</span><br><span class="line">        studentWritable.setId(<span class="number">1L</span>);</span><br><span class="line">        studentWritable.setName(<span class="string">"Hadoop"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将student对象当前状态写入到本地文件中</span></span><br><span class="line">        FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="string">"D:\\student_hadoop.txt"</span>);</span><br><span class="line">        ObjectOutputStream oos = <span class="keyword">new</span> ObjectOutputStream(fos);</span><br><span class="line">        studentWritable.write(oos); <span class="comment">// 与java序列化不同的地方</span></span><br><span class="line">        oos.close();</span><br><span class="line">        fos.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StudentWritable</span> <span class="keyword">implements</span> <span class="title">Writable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> Id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(<span class="keyword">long</span> id)</span> </span>&#123;</span><br><span class="line">        Id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span>  <span class="comment">// 多的部分</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        out.writeLong(<span class="keyword">this</span>.Id);</span><br><span class="line">        out.writeUTF(<span class="keyword">this</span>.name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="comment">// 多的部分</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.Id=in.readLong();</span><br><span class="line">        <span class="keyword">this</span>.name=in.readUTF();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">执行这两个代码，最终会在D盘下产生两个文件，查看这两个文件的大小，最终发现Java序列化的文件大小是Hadoop序列化文件大小的10倍左右。</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HwGZge" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HwGZge.png" alt="HwGZge.png"></a></p><p><a href="https://imgtu.com/i/HwGV3D" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HwGV3D.png" alt="HwGV3D.png"></a></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.IDEA快速编写属性对应的方法</span><br><span class="line">2.IDEA快速覆盖继承类的方法的方法</span><br></pre></td></tr></table></figure><h2 id="InputFormat分析"><a href="#InputFormat分析" class="headerlink" title="InputFormat分析"></a>InputFormat分析</h2><p><a href="https://imgtu.com/i/HwhRpT" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HwhRpT.md.png" alt="HwhRpT.md.png"></a></p><h3 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Hadoop中有一个抽象类是InputFormat，InputFormat抽象类是MapReduce输入数据的顶层基类，这个抽象类中只定义了两个方法:</span><br><span class="line">  一个是getSplits方法</span><br><span class="line">  另一个是createRecordReader方法</span><br></pre></td></tr></table></figure><h3 id="InputFormat的子类"><a href="#InputFormat的子类" class="headerlink" title="InputFormat的子类"></a>InputFormat的子类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">这个抽象类下面有三个子继承类，</span><br><span class="line">DBInputFormat是操作数据库的，</span><br><span class="line">FileInputFormat是操作文件类型数据的，</span><br><span class="line">DelegatingInputFormat是用在处理多个输入时使用的</span><br><span class="line">这里面比较常见的也就是FileInputFormat了，FileInputFormat是所有以文件作为数据源的基类，</span><br><span class="line">FileInputFormat保存job输入的所有文件，并实现了对输入文件计算splits的方法，至于获得文件中数据</span><br><span class="line">的方法是由子类实现的。</span><br></pre></td></tr></table></figure><h4 id="FileInputFormat的子类"><a href="#FileInputFormat的子类" class="headerlink" title="FileInputFormat的子类"></a>FileInputFormat的子类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat下面还有一些子类：</span><br><span class="line">CombineFileInputFormat：处理小文件问题的，后面我们再详细分析</span><br><span class="line"> TextInputFormat：是默认的处理类，处理普通文本文件，他会把文件中每一行作为一个记录，将每一行的起始偏移量作为key，每一行的内容作为value，这里的key和value就是我们之前所说的k1,v1 它默认以换行符或回车键作为一行记录</span><br><span class="line">NLineInputFormat：可以动态指定一次读取多少行数据</span><br><span class="line">这 里 面 的 TextInputFormat 是 我 们 处 理 文 本 数 据 的 默 认 处 理 类 ， TextInputFormat 的 顶 层 基 类 是</span><br><span class="line">InputFormat，下面我们先来看一下这个抽象类的源码</span><br></pre></td></tr></table></figure><h4 id="详细分析一下getSplits方法的具体实现代码"><a href="#详细分析一下getSplits方法的具体实现代码" class="headerlink" title="详细分析一下getSplits方法的具体实现代码"></a>详细分析一下getSplits方法的具体实现代码</h4><h5 id="下载源码-hadoop-3-2-2-src-tar-gz"><a href="#下载源码-hadoop-3-2-2-src-tar-gz" class="headerlink" title="下载源码 hadoop-3.2.2-src.tar.gz"></a>下载源码 hadoop-3.2.2-src.tar.gz</h5><h5 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将D:\code\IDEA\hadoop-3.2.2-src\hadoop-mapreduce-project\hadoop-mapreduce-client\hadoop-mapreduce-client-core作为IDEA的项目</span><br></pre></td></tr></table></figure><h5 id="下载依赖"><a href="#下载依赖" class="headerlink" title="下载依赖"></a>下载依赖</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.将maven的配置文件里加上镜像，这样下载依赖会快些</span><br><span class="line">2.可以就用idea自动下载，但容易卡死，且过程可视性差；建议用cmd(打开路径D:\code\IDEA\hadoop-3.2.2-src\hadoop-mapreduce-project\hadoop-mapreduce-client\hadoop-mapreduce-client-core)</span><br><span class="line">3.执行mvn clean package&#x2F;compile -DskipTests</span><br><span class="line">4.由于用国内镜像下载依赖可能会漏下依赖(已遇到);改回maven的配置文件里的镜像设置</span><br><span class="line">5.可能会遇到IDEA Cannot Resolve Symbol 问题的解决方法汇总(博客里有解决方法)</span><br></pre></td></tr></table></figure><h5 id="getsplits源码剖析"><a href="#getsplits源码剖析" class="headerlink" title="getsplits源码剖析"></a>getsplits源码剖析</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">需要将项目里的java文件夹设置为root source(选中后右键mark as),这样设置后查看源码ctrl 左键 才会快速关联</span><br><span class="line">1.找到项目里的InputFormat</span><br><span class="line">2.选中getsplits方法后 ctrl 左 ，选继承类FileInputFormat,再看方法的具体实现细节</span><br></pre></td></tr></table></figure><h6 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SPLIT_SLOP=<span class="number">1.1</span></span><br><span class="line">文件剩余字节大小/<span class="number">1134217728</span>[<span class="number">128</span>M] &gt; <span class="number">1.1</span></span><br><span class="line">意思就是当文件剩余大小bytesRemaining与splitSize的比值大于<span class="number">1.1</span>的时候，就继续切分</span><br><span class="line">否则，剩下的直接作为一个InputSplit</span><br><span class="line"></span><br><span class="line">敲黑板，划重点：只要bytesRemaining/splitSize&lt;=<span class="number">1.1</span>就会停止划分，将剩下的作为一个InputSplit</span><br><span class="line"></span><br><span class="line">也就是说当默认splitsize=<span class="number">128</span>M时，inputsplit可能：</span><br><span class="line">&lt;<span class="number">128</span>M</span><br><span class="line">=<span class="number">128</span>M</span><br><span class="line">&gt;<span class="number">128</span>M</span><br></pre></td></tr></table></figure><h6 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1. 一个1G的文件，会产生多少个map任务？ 8</span><br><span class="line">Block块默认是128M，所以1G的文件会产生8个Block块</span><br><span class="line">默认情况下InputSplit的大小和Block块的大小一致，每一个InputSplit会产生一个map任务</span><br><span class="line">所以：1024&#x2F;128&#x3D;8个map任务</span><br><span class="line">2. 1000个文件，每个文件100KB，会产生多少个map任务？</span><br><span class="line">一个文件，不管再小，都会占用一个block，所以这1000个小文件会产生1000个Block，那最终会产生1000个InputSplit，也就对应着会产生1000个map任务</span><br><span class="line">3. 一个140M的文件，会产生多少个map任务？</span><br><span class="line">根据前面的分析</span><br><span class="line">140M的文件会产生2个Block，那对应的就会产生2个InputSplit了？</span><br><span class="line">注意：这个有点特殊，140M&#x2F;128M&#x3D;1.09375&lt;1.1</span><br><span class="line">所以，这个文件只会产生一个InputSplit，也最终也就只会产生1个map 任务。</span><br><span class="line"></span><br><span class="line">这个文件其实再稍微大1M就可以产生2个map 任务了</span><br></pre></td></tr></table></figure><h6 id="实战140-141"><a href="#实战140-141" class="headerlink" title="实战140 141"></a>实战140 141</h6><h6 id="生成140-141大小的文件"><a href="#生成140-141大小的文件" class="headerlink" title="生成140 141大小的文件"></a>生成140 141大小的文件</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.mc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.FileWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenerateDat</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        generate_140M();</span><br><span class="line">        generate_141M();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">generate_140M</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String fileName = <span class="string">"D:\\s_name_140.dat"</span>;</span><br><span class="line">        System.out.println(<span class="string">"start: 开始生成140M文件-&gt;"</span> + fileName);</span><br><span class="line">        BufferedWriter bfw = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(fileName));</span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (num &lt; <span class="number">8201592</span>) &#123;</span><br><span class="line">            bfw.write(<span class="string">"zhangsan beijing"</span>);</span><br><span class="line">            bfw.newLine();</span><br><span class="line">            num++;</span><br><span class="line">            <span class="keyword">if</span> (num % <span class="number">10000</span> == <span class="number">0</span>) &#123;</span><br><span class="line">                bfw.flush();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"end: 140M文件已生成"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">generate_141M</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String fileName = <span class="string">"D:\\s_name_141.dat"</span>;</span><br><span class="line">        System.out.println(<span class="string">"start: 开始生成141M文件-&gt;"</span> + fileName);</span><br><span class="line">        BufferedWriter bfw = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(fileName));</span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (num &lt; <span class="number">8221592</span>) &#123;</span><br><span class="line">            bfw.write(<span class="string">"zhangsan beijing"</span>);</span><br><span class="line">            bfw.newLine();</span><br><span class="line">            num++;</span><br><span class="line">            <span class="keyword">if</span> (num % <span class="number">10000</span> == <span class="number">0</span>) &#123;</span><br><span class="line">                bfw.flush();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="打jar包，上传数据到hdfs，提交任务到集群"><a href="#打jar包，上传数据到hdfs，提交任务到集群" class="headerlink" title="打jar包，上传数据到hdfs，提交任务到集群"></a>打jar包，上传数据到hdfs，提交任务到集群</h6><h6 id="结果查看"><a href="#结果查看" class="headerlink" title="结果查看"></a>结果查看</h6><p> <strong>141</strong></p><p><a href="https://imgtu.com/i/HBnBCQ" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HBnBCQ.md.png" alt="HBnBCQ.md.png"></a></p><p><strong>140</strong></p><p><a href="https://imgtu.com/i/HBnD3j" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/12/HBnD3j.md.png" alt="HBnD3j.md.png"></a></p><h5 id="createRecordReader方法"><a href="#createRecordReader方法" class="headerlink" title="createRecordReader方法"></a>createRecordReader方法</h5><h6 id="看TextInputFormat对这个方法的实现"><a href="#看TextInputFormat对这个方法的实现" class="headerlink" title="看TextInputFormat对这个方法的实现"></a>看TextInputFormat对这个方法的实现</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：如果这个InputSplit不是第一个InputSplit，我们将会丢掉读取出来的第一行</span><br><span class="line">因为我们总是通过next()方法多读取一行(会多读取下一个InputSplit的第一行)</span><br><span class="line">这就解释了这个问题：如果一行数据被拆分到了两个InputSplit中，会不会有问题？PPT中通过一个例子详细分析了这个问题</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HD1cmd" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/13/HD1cmd.md.png" alt="HD1cmd.md.png"></a></p><h2 id="OutputFormat分析"><a href="#OutputFormat分析" class="headerlink" title="OutputFormat分析"></a>OutputFormat分析</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">前 面 我 们 分 析 了 InputFormat ， 下 面 我 们 来 分 析 一 下 OutputFormat ， 顾 名 思 义 ， 这 个 是 控 制MapReduce输出的</span><br><span class="line"></span><br><span class="line">OutputFormat是输出数据的顶层基类</span><br><span class="line">FileOutputFormat：文件数据处理基类</span><br><span class="line">TextOutputFormat：默认文本文件处理类</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">这几个其实和InputFormat中的那几个文本处理类是对应着的，当然了针对输出数据还有其它类型的处理</span><br><span class="line">类，我们在这先分析最常见的文本文件处理类，其他类型的等我们遇到具体场景再具体分析。</span><br><span class="line">我们来看一下OutputFormat的源码，这个类主要由三个方法:</span><br><span class="line">getRecordWriter</span><br><span class="line">checkOutputSpecs <span class="comment">//检测输出路径是否存在</span></span><br><span class="line">getOutputCommitter</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第五周 第三章 深入 MapReduce</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%BA%94%E5%91%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%B7%B1%E5%85%A5-MapReduce.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E4%BA%94%E5%91%A8-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%B7%B1%E5%85%A5-MapReduce.html</id>
    <published>2022-02-09T10:55:32.000Z</published>
    <updated>2022-02-16T14:35:36.469Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第五周-第三章-深入-MapReduce"><a href="#第五周-第三章-深入-MapReduce" class="headerlink" title="第五周 第三章 深入 MapReduce"></a>第五周 第三章 深入 MapReduce</h1><h2 id="MapReduce任务日志查看"><a href="#MapReduce任务日志查看" class="headerlink" title="MapReduce任务日志查看"></a>MapReduce任务日志查看</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">如果想要查看mapreduce任务执行过程产生的日志信息怎么办呢？</span><br><span class="line">是不是在提交任务的时候直接在这个控制台上就能看到了？先不要着急，我们先在代码中增加一些日志信息，在实际工作中做调试的时候这个也是很有必要的</span><br><span class="line">在自定义mapper类的map函数中增加一个输出，将k1,v1的值打印出来</span><br><span class="line"></span><br><span class="line">在自定义reducer类中的reduce方法中增加一个输出，将k2,v2和k3,v3的值打印出来</span><br></pre></td></tr></table></figure><h3 id="开启yarn的日志聚合功能方式"><a href="#开启yarn的日志聚合功能方式" class="headerlink" title="开启yarn的日志聚合功能方式"></a>开启yarn的日志聚合功能方式</h3><h4 id="自定义日志"><a href="#自定义日志" class="headerlink" title="自定义日志"></a>自定义日志</h4><h5 id="map函数修改"><a href="#map函数修改" class="headerlink" title="map函数修改"></a>map函数修改</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable k1, Text v1, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="comment">// k1代表每一行数据的行首偏移量，v1代表的是每一行的数据</span></span><br><span class="line">            <span class="comment">// 需要做的是：把每一行数据的单词切割出来</span></span><br><span class="line">            System.out.println("&lt;k1, v1&gt;: &lt;"+k1.get()+", "+v1.toString()+"&gt;"); # 增加处</span><br><span class="line">            String[] words = v1.toString().split(<span class="string">" "</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words)&#123;</span><br><span class="line">                <span class="comment">// 把切割出来的单词，封装成&lt;k2, 1&gt;</span></span><br><span class="line">                Text k2 = <span class="keyword">new</span> Text(word);</span><br><span class="line">                LongWritable v2 = <span class="keyword">new</span> LongWritable(<span class="number">1L</span>);</span><br><span class="line">                context.write(k2,v2);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//super.map(key, value, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h5 id="reduce函数修改"><a href="#reduce函数修改" class="headerlink" title="reduce函数修改"></a>reduce函数修改</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text k2, Iterable&lt;LongWritable&gt; v2s, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(LongWritable v2:v2s)&#123;</span><br><span class="line">                System.out.println("&lt;k2, v2&gt;: &lt;"+k2.toString()+", "+v2.get()+"&gt;"); # 增加处</span><br><span class="line">                sum += v2.get();</span><br><span class="line">            &#125;</span><br><span class="line">            Text k3 = k2;</span><br><span class="line">            LongWritable v3 = <span class="keyword">new</span> LongWritable(sum);</span><br><span class="line">            System.out.println("&lt;k3, v3&gt;: &lt;"+k3.toString()+", "+v3.get()+"&gt;"); # 增加处</span><br><span class="line">            context.write(k3, v3);</span><br><span class="line">            <span class="comment">// super.reduce(key, values, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h5 id="打包，上传，提交任务到集群"><a href="#打包，上传，提交任务到集群" class="headerlink" title="打包，上传，提交任务到集群"></a>打包，上传，提交任务到集群</h5><h5 id="结果查看"><a href="#结果查看" class="headerlink" title="结果查看"></a>结果查看</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">等待任务执行结束，我们发现在控制台上是看不到任务中的日志信息的，为什么呢？因为我们在这相当于是通过一个客户端把任务提交到集群里面去执行了，所以日志是存在在集群里面的。想要查看需要需要到一个特殊的地方查看这些日志信息</span><br><span class="line">由于程序是提交到集群执行，所以在linux的终端上是看不到的</span><br><span class="line"></span><br><span class="line">先进入到yarn的web界面，访问<span class="number">8088</span>端口，点击对应任务的history链接(在此之前先把bigdata02,bigdata03与ip的映射在windows的hosts文件上配置好)</span><br><span class="line">http://bigdata01:<span class="number">8088</span>/</span><br><span class="line">        </span><br><span class="line">注意了，在这里我们发现这个链接是打不来的，</span><br><span class="line">这里有两个原因:</span><br><span class="line">  第一个原因是没有windows的hosts文件中没有配置bigdata02和bigdata03这两个主机名和ip的映射关系，先去把这两个主机名配置到hosts文件里面，之前的bigdata01已经配置进去了</span><br><span class="line">  第二个原因就是这里必须要启动historyserver进程才可以，并且还要开启日志聚合功能，才能在web界面上直接查看任务对应的日志信息，因为默认情况下任务的日志是散落在nodemanager节点上的，想要查看需要找到对应的nodemanager节点上去查看，这样就很不方便，通过日志聚合功能我们可以把之前本来散落在nodemanager节点上的日志统一收集到hdfs上的指定目录中，这样就可以在yarn的web界面中直接查看了</span><br></pre></td></tr></table></figure><h6 id="打开日志聚合功能"><a href="#打开日志聚合功能" class="headerlink" title="打开日志聚合功能"></a>打开日志聚合功能</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">那我们就来开启日志聚合功能。开启日志聚合功能需要修改yarn-site.xml的配置，增加</span><br><span class="line">yarn.log-aggregation-enable和yarn.log.server.url这两个参数</span><br><span class="line"></span><br><span class="line">注意：修改这个配置想要生效需要重启集群，每个节点都要修改</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">添加部分</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.log-aggregation-enable&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.log.server.url&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;http:&#x2F;&#x2F;bigdata01:19888&#x2F;jobhistory&#x2F;logs&#x2F;&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">启动historyserver进程，需要在集群的所有节点上都启动这个进程</span><br><span class="line"></span><br><span class="line">[root@bigdata01 hadoop-3.2.0]# bin&#x2F;mapred --daemon start historyserver</span><br><span class="line">[root@bigdata01 hadoop-3.2.0]# jps</span><br><span class="line">4232 SecondaryNameNode</span><br><span class="line">5192 JobHistoryServer</span><br><span class="line">4473 ResourceManager</span><br><span class="line">3966 NameNode</span><br><span class="line">5231 Jps</span><br><span class="line"></span><br><span class="line">其它节点也需执行</span><br><span class="line"></span><br><span class="line">重新再提交mapreduce任务</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  此时再进入yarn的8088界面，点击任务对应的history链接就可以打开了。</span><br><span class="line">  此时，点击对应map和reduce后面的链接就可以点进去查看日志信息了，点击map后面的数字1，可以</span><br><span class="line">  点击这个界面中的logs文字链接，可以查看详细的日志信息 </span><br><span class="line">  </span><br><span class="line">  最终可以在界面中看到很多日志信息，我们刚才使用sout输出的日志信息需要到Log Type: stdout这里来</span><br><span class="line">查看，在这里可以看到，k1和v1的值</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HdADit" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdADit.png" alt="HdADit.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  想要查看reduce输出的日志信息需要到reduce里面查看，操作流程是一样的，可以看到k2,v2和k3,v3的</span><br><span class="line">值</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HdA0II" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdA0II.png" alt="HdA0II.png"></a></p><h4 id="使用logger"><a href="#使用logger" class="headerlink" title="使用logger"></a>使用logger</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">咱们刚才的输出是使用syout输出的，这个其实是不正规的，标准的日志写法是需要使用logger进行输出的</span><br></pre></td></tr></table></figure><h5 id="修改map函数"><a href="#修改map函数" class="headerlink" title="修改map函数"></a>修改map函数</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line">        Logger logger = LoggerFactory.getLogger(myMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 需要实现map函数</span></span><br><span class="line"><span class="comment">         * 这个函数就是可以接受&lt;k1,v1&gt;, 产生&lt;k2,v2&gt;</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> k1</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> v1</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable k1, Text v1, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="comment">// k1代表每一行数据的行首偏移量，v1代表的是每一行的数据</span></span><br><span class="line">            <span class="comment">// 需要做的是：把每一行数据的单词切割出来</span></span><br><span class="line">            logger.info(<span class="string">"&lt;k1, v1&gt;: &lt;"</span>+k1.get()+<span class="string">", "</span>+v1.toString()+<span class="string">"&gt;"</span>);</span><br><span class="line">            <span class="comment">//System.out.println("&lt;k1, v1&gt;: &lt;"+k1.get()+", "+v1.toString()+"&gt;");</span></span><br><span class="line">            String[] words = v1.toString().split(<span class="string">" "</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words)&#123;</span><br><span class="line">                <span class="comment">// 把切割出来的单词，封装成&lt;k2, 1&gt;</span></span><br><span class="line">                Text k2 = <span class="keyword">new</span> Text(word);</span><br><span class="line">                LongWritable v2 = <span class="keyword">new</span> LongWritable(<span class="number">1L</span>);</span><br><span class="line">                context.write(k2,v2);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//super.map(key, value, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h5 id="修改reduce函数"><a href="#修改reduce函数" class="headerlink" title="修改reduce函数"></a>修改reduce函数</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line">        Logger logger = LoggerFactory.getLogger(myReducer.class); #！！！</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 对&lt;k2, &#123;v2...&#125;&gt;的数据进行累加求和，生成&lt;k3,v3&gt;</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> k2</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> v2s</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text k2, Iterable&lt;LongWritable&gt; v2s, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(LongWritable v2:v2s)&#123;</span><br><span class="line">                logger.info("&lt;k2, v2&gt;: &lt;"+k2.toString()+", "+v2.get()+"&gt;"); #！！！</span><br><span class="line">                <span class="comment">//System.out.println("&lt;k2, v2&gt;: &lt;"+k2.toString()+", "+v2.get()+"&gt;");</span></span><br><span class="line">                sum += v2.get();</span><br><span class="line">            &#125;</span><br><span class="line">            Text k3 = k2;</span><br><span class="line">            LongWritable v3 = <span class="keyword">new</span> LongWritable(sum);</span><br><span class="line">            logger.info("&lt;k3, v3&gt;: &lt;"+k3.toString()+", "+v3.get()+"&gt;"); #！！！</span><br><span class="line">            <span class="comment">//System.out.println("&lt;k3, v3&gt;: &lt;"+k3.toString()+", "+v3.get()+"&gt;");</span></span><br><span class="line">            context.write(k3, v3);</span><br><span class="line">            <span class="comment">// super.reduce(key, values, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h5 id="打包，上传，提交任务到集群-1"><a href="#打包，上传，提交任务到集群-1" class="headerlink" title="打包，上传，提交任务到集群"></a>打包，上传，提交任务到集群</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">重新编译打包上传，重新提交最新的jar包，这个时候再查看日志就需要到Log Type: syslog中查看日志了。</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HdeR10" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdeR10.md.png" alt="HdeR10.md.png"></a></p><p><a href="https://imgtu.com/i/Hde2pq" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/Hde2pq.md.png" alt="Hde2pq.md.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这是工作中比较常用的查看日志的方式，但是还有一种使用命令查看的方式，这种方式面试的时候一般喜欢问</span><br></pre></td></tr></table></figure><h3 id="面试爱问的日志查看方式-面试"><a href="#面试爱问的日志查看方式-面试" class="headerlink" title="面试爱问的日志查看方式(面试)"></a>面试爱问的日志查看方式(面试)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> yarn logs -applicationId application_158771356 | grep k1,v1</span><br><span class="line">     </span><br><span class="line">注意:后面指定的是任务id，任务id可以到yarn的web界面上查看。</span><br><span class="line">执行这个命令可以看到很多的日志信息，我们通过grep筛选一下日志</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这种方式也需要大家能够记住并且掌握住，首先是面试的时候可能会问到，还有就是针对某一些艰难的场景下，无法使用yarn的web界面查看日志，就需要使用yarn logs命令了</span><br></pre></td></tr></table></figure><h2 id="停止Hadoop集群中的任务"><a href="#停止Hadoop集群中的任务" class="headerlink" title="停止Hadoop集群中的任务"></a>停止Hadoop集群中的任务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  如果一个mapreduce任务处理的数据量比较大的话，这个任务会执行很长时间，可能几十分钟或者几个小时都有可能，假设一个场景，任务执行了一半了我们发现我们的代码写的有问题，需要修改代码重新提交执行，这个时候之前的任务就没有必要再执行了，没有任何意义了，最终的结果肯定是错误的，所以我们就想把它停掉，要不然会额外浪费集群的资源，如何停止呢？</span><br><span class="line">我在提交任务的窗口中按ctrl+c是不是就可以停止？</span><br><span class="line">注意了，不是这样的，我们前面说过，这个任务是提交到集群执行的，你在提交任务的窗口中执行ctrl+c对已经提交到集群中的任务是没有任何影响的。</span><br><span class="line">  我们可以验证一下，执行ctrl+c之后你再到yarn的8088界面查看，会发现任务依然存在。</span><br><span class="line">所以需要使用hadoop集群的命令去停止正在运行的任务</span><br><span class="line">使用yarn application -kill命令，后面指定任务id即可</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 hadoop-3.2.0]# yarn application -kill application_15877135678</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HdGYSe" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdGYSe.md.png" alt="HdGYSe.md.png"></a></p><p><a href="https://imgtu.com/i/HdlgVf" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdlgVf.md.png" alt="HdlgVf.md.png"></a></p><h2 id="MapReduce程序扩展"><a href="#MapReduce程序扩展" class="headerlink" title="MapReduce程序扩展"></a>MapReduce程序扩展</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  咱们前面说过MapReduce任务是由map阶段和reduce阶段组成的但是我们也说过，reduce阶段不是必须的，那也就意味着MapReduce程序可以只包含map阶段。</span><br><span class="line">  什么场景下会只需要map阶段呢？</span><br><span class="line">当数据只需要进行普通的过滤、解析等操作，不需要进行聚合，这个时候就不需要使用reduce阶段了，在代码层面该如何设置呢？</span><br><span class="line">  很简单，在组装Job的时候设置reduce的task数目为0就可以了。并且Reduce代码也不需要写了。</span><br></pre></td></tr></table></figure><h3 id="map阶段编写"><a href="#map阶段编写" class="headerlink" title="map阶段编写"></a>map阶段编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">myMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line">        Logger logger = LoggerFactory.getLogger(myMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 需要实现map函数</span></span><br><span class="line"><span class="comment">         * 这个函数就是可以接受&lt;k1,v1&gt;, 产生&lt;k2,v2&gt;</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> k1</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> v1</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable k1, Text v1, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="comment">// k1代表每一行数据的行首偏移量，v1代表的是每一行的数据</span></span><br><span class="line">            <span class="comment">// 需要做的是：把每一行数据的单词切割出来</span></span><br><span class="line">            logger.info(<span class="string">"&lt;k1, v1&gt;: &lt;"</span>+k1.get()+<span class="string">", "</span>+v1.toString()+<span class="string">"&gt;"</span>);</span><br><span class="line">            <span class="comment">//System.out.println("&lt;k1, v1&gt;: &lt;"+k1.get()+", "+v1.toString()+"&gt;");</span></span><br><span class="line">            String[] words = v1.toString().split(<span class="string">" "</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words)&#123;</span><br><span class="line">                <span class="comment">// 把切割出来的单词，封装成&lt;k2, 1&gt;</span></span><br><span class="line">                Text k2 = <span class="keyword">new</span> Text(word);</span><br><span class="line">                LongWritable v2 = <span class="keyword">new</span> LongWritable(<span class="number">1L</span>);</span><br><span class="line">                context.write(k2,v2);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//super.map(key, value, context);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="main编写"><a href="#main编写" class="headerlink" title="main编写"></a>main编写</h3> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="keyword">if</span>(args.length!=<span class="number">2</span>)&#123;</span><br><span class="line">               System.exit(<span class="number">100</span>);</span><br><span class="line">               System.out.println(<span class="string">"缺少路径参数！！！"</span>);</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="comment">// 指定Job需要的配置参数</span></span><br><span class="line">           Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">           <span class="comment">// 创建一个Job</span></span><br><span class="line">           Job job = Job.getInstance(conf);</span><br><span class="line">           <span class="comment">// 注意：这一行必须设置，否者在集群中执行时找不到WordCountJob这个类</span></span><br><span class="line">           job.setJarByClass(WordCountJobNoReduce<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"> </span><br><span class="line">           <span class="comment">// 指定输入路径，可以是文件也可以是目录(目录里只有一个文件时可以); 注意FileInputFormat别选成hadoop1.x的了</span></span><br><span class="line">           FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">           <span class="comment">// 指定输出路径(只能是hdfs上一个不存在的目录); 注意FileOutFormat别选成hadoop1.x的了</span></span><br><span class="line">           FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"> </span><br><span class="line">           <span class="comment">// 指定map相关代码</span></span><br><span class="line">           job.setMapperClass(myMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">           <span class="comment">// 指定k2类型</span></span><br><span class="line">           job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">           <span class="comment">// 指定v2类型</span></span><br><span class="line">           job.setMapOutputValueClass(LongWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"> </span><br><span class="line">           <span class="comment">// 禁用reduce</span></span><br><span class="line">           job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line">           <span class="comment">// 提交job</span></span><br><span class="line">           job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"> </span><br><span class="line">       &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line"> </span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="打包，上传，提交到集群，结果查看"><a href="#打包，上传，提交到集群，结果查看" class="headerlink" title="打包，上传，提交到集群，结果查看"></a>打包，上传，提交到集群，结果查看</h3><p><a href="https://imgtu.com/i/HdtUOJ" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdtUOJ.png" alt="HdtUOJ.png"></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这里发现map执行到100%以后任务就执行成功了，reduce还是0%，因为就没有reduce阶段了。</span><br><span class="line">查看输出结果，注意，这里的文件名就是part-m-00000了</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/HdtNy4" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdtNy4.png" alt="HdtNy4.png"></a></p><p><a href="https://imgtu.com/i/HdttlF" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://s4.ax1x.com/2022/02/11/HdttlF.png" alt="HdttlF.png"></a></p><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
    
  </entry>
  
</feed>
