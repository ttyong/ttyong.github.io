<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>TianYong&#39;s Blog</title>
  
  <subtitle>比你优秀的人都努力，有什么理由不努力！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://tianyong.fun/"/>
  <updated>2023-06-20T09:37:00.536Z</updated>
  <id>http://tianyong.fun/</id>
  
  <author>
    <name>TTYONG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2022黑马MySql数据库入门到精通 基础篇-3</title>
    <link href="http://tianyong.fun/2022%E9%BB%91%E9%A9%ACMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A-%E5%9F%BA%E7%A1%80%E7%AF%87-3.html"/>
    <id>http://tianyong.fun/2022%E9%BB%91%E9%A9%ACMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A-%E5%9F%BA%E7%A1%80%E7%AF%87-3.html</id>
    <published>2023-06-20T09:37:00.000Z</published>
    <updated>2023-06-20T09:37:00.536Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2022黑马MySql数据库入门到精通 基础篇-2</title>
    <link href="http://tianyong.fun/2022%E9%BB%91%E9%A9%ACMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A-%E5%9F%BA%E7%A1%80%E7%AF%87-2.html"/>
    <id>http://tianyong.fun/2022%E9%BB%91%E9%A9%ACMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A-%E5%9F%BA%E7%A1%80%E7%AF%87-2.html</id>
    <published>2023-06-20T09:36:53.000Z</published>
    <updated>2023-06-20T09:36:53.814Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2022黑马MySql数据库入门到精通 基础篇-1</title>
    <link href="http://tianyong.fun/2022%E9%BB%91%E9%A9%ACMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A-%E5%9F%BA%E7%A1%80%E7%AF%87-1.html"/>
    <id>http://tianyong.fun/2022%E9%BB%91%E9%A9%ACMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A-%E5%9F%BA%E7%A1%80%E7%AF%87-1.html</id>
    <published>2023-06-20T09:36:39.000Z</published>
    <updated>2023-06-20T09:36:39.133Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-数据分析引擎之Impala-2</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E%E4%B9%8BImpala-2.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E%E4%B9%8BImpala-2.html</id>
    <published>2023-06-18T15:47:50.000Z</published>
    <updated>2023-06-21T07:57:43.724Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="数据分析引擎之Impala-2"><a href="#数据分析引擎之Impala-2" class="headerlink" title="数据分析引擎之Impala-2"></a>数据分析引擎之Impala-2</h1><h2 id="3-Impala-高级内容"><a href="#3-Impala-高级内容" class="headerlink" title="3 Impala 高级内容"></a>3 Impala 高级内容</h2><h3 id="Impala之refresh命令"><a href="#Impala之refresh命令" class="headerlink" title="Impala之refresh命令"></a>Impala之refresh命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">refresh的主要功能是负责重新加载指定表的最新元数据信息，以及增量加载表中新的数据文件的位置信息。</span><br><span class="line"></span><br><span class="line">为什么要刷新表的最新元数据信息呢？</span><br><span class="line"></span><br><span class="line">如果Impala中获取到的表的元数据不是最新的，那么在执行查询时得到的结果就不准确了。</span><br><span class="line"></span><br><span class="line">正常情况下，我们在Impala中对表执行的操作都是通过Catalog服务管理的，表的元数据信息都是会实时更新的，不会导致元数据信息不准确。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">但是针对一些特殊情况，会导致Impala无法自动感知到最新的元数据变化：</span><br><span class="line"></span><br><span class="line">1：当Impala中的表对应的HDFS目录中的数据文件发生了变化的时候，也就是我们使用hdfs的put命令向表的数据目录中添加了新的文件，或者删除了老的文件，此时Impala中维护的元数据信息是感知不到这些数据文件变化的，这样会导致在impala中查询时获取的还是之前的老数据。</span><br><span class="line"></span><br><span class="line">2：当我们在Hive中对Impala的表或者是Hive自己的表执行了alter table、insert、load data以及其他对表产生修改的SQL语句时，也会出现这种问题，这也就意味着Impala是无法自动识别到Hive中元数据的变化情况。</span><br><span class="line"></span><br><span class="line">下面我们来演示一下这个问题：</span><br></pre></td></tr></table></figure><h4 id="第一种情况"><a href="#第一种情况" class="headerlink" title="第一种情况"></a>第一种情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">首先查询一下之前创建的外部表im_external_table中的数据：</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:05:33 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;9e401c30460cf400:430872e00000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 3 row(s) in 0.57s</span><br><span class="line"></span><br><span class="line">然后在这个表对应的数据目录中再添加一个数据文件：</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put im_external_table.dat &#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat.2</span><br><span class="line"></span><br><span class="line">接下来再查询一下这个表中的数据：</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:05:33 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;9e401c30460cf400:430872e00000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 3 row(s) in 0.57s</span><br><span class="line"></span><br><span class="line">此时发现查询出的数据还是之前的3条，现在其实应该是6条数据的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">我们尝试连到cdh03这个节点上执行查询，看看结果是什么样的：</span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh03:21000</span><br><span class="line">[cdh03:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 16:50:54 (Coordinator: http:&#x2F;&#x2F;cdh03:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh03:25000&#x2F;query_plan?query_id&#x3D;7f468abf085ce6c9:39a269c000000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 3 row(s) in 0.45s</span><br><span class="line"></span><br><span class="line">结果发现是一样的，都是返回3条数据。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">那我们到Hive中查询一下看看：</span><br><span class="line">hive&gt; select * from im_external_table;</span><br><span class="line">OK</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">Time taken: 7.494 seconds, Fetched: 6 row(s)</span><br><span class="line"></span><br><span class="line">在Hive中发现是没有问题的，可以正常识别到最新的6条数据，从这一点上来看，还是Hive比较好用。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">想要让Impala识别到这个表中数据文件的变化情况，就需要使用refresh刷新这个表的元数据了。</span><br><span class="line">在任意一个Impalad节点中执行就行了，不需要在所有节点中都执行：</span><br><span class="line">[cdh02:21000] default&gt; refresh im_external_table;</span><br><span class="line">Query: refresh im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:17:17 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;544612cf1ae43866:49d3db5500000000</span><br><span class="line">Fetched 0 row(s) in 0.63s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">此时在cdh02节点中查询这个表中的数据，发现可以获取到最新的6条数据了。</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:18:16 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;1d4f432a45dce8d2:818cde9700000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 6 row(s) in 0.69s</span><br><span class="line"></span><br><span class="line">到cdh03中查询也是一样的</span><br></pre></td></tr></table></figure><h4 id="第二种情况"><a href="#第二种情况" class="headerlink" title="第二种情况"></a>第二种情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">接下来我们演示一下第二种情况：</span><br><span class="line">hive&gt; load data local inpath &#39;&#x2F;root&#x2F;im_external_table.dat&#39; into table im_external_table;</span><br><span class="line">Loading data to table default.im_external_table</span><br><span class="line">OK</span><br><span class="line">Time taken: 4.09 seconds</span><br><span class="line"></span><br><span class="line">在Hive中使用load data向外部表im_external_table中继续添加数据文件：</span><br><span class="line"></span><br><span class="line">其实这个操作就是将数据文件加载到了表对应的数据目录中，和我们前面使用hdfs的put命令达到的效果是一样的，所以这种方式加载的数据Impala也是识别不到的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">我们先到Hive中查询验证一下：</span><br><span class="line">hive&gt; select * from im_external_table;</span><br><span class="line">OK</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">Time taken: 0.323 seconds, Fetched: 9 row(s)</span><br><span class="line"></span><br><span class="line">此时可以查到9条数据，这是对的。</span><br><span class="line"></span><br><span class="line">然后我们通过impala进行查询</span><br><span class="line">结果发现查询到的还是6条数据，Impala没有识别到刚才Hive最新加载的数据。</span><br><span class="line"></span><br><span class="line">所以还需要使用refresh刷新这个表的元数据了：</span><br><span class="line">[cdh02:21000] default&gt; refresh im_external_table;      </span><br><span class="line">Query: refresh im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:27:13 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;a4accef838a1907:af9a27d400000000</span><br><span class="line">Fetched 0 row(s) in 0.57s</span><br><span class="line"></span><br><span class="line">刷新之后，再查询表中的最新数据</span><br><span class="line"></span><br><span class="line">这样就可以了</span><br></pre></td></tr></table></figure><h4 id="第三种情况"><a href="#第三种情况" class="headerlink" title="第三种情况"></a>第三种情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">当你使用HDFS命令从表的数据目录中删除一个文件，在没有使用refresh 刷新表的时候，还是可以从表中查询到对应的数据：</span><br><span class="line">使用hdfs命令从外部表im_external_table对应的数据目录中删除一个文件：</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# hdfs dfs -ls &#x2F;data&#x2F;im_external_table</span><br><span class="line">Found 3 items</span><br><span class="line">-rw-r--r--   2 root supergroup         86 2022-08-17 15:06 &#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat</span><br><span class="line">-rw-r--r--   2 root supergroup         86 2022-08-17 16:51 &#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat.2</span><br><span class="line">-rwxrwxrwx   2 root supergroup         86 2022-08-17 17:21 &#x2F;data&#x2F;im_external_table&#x2F;im_external_table_copy_1.dat</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# hdfs dfs -rm -r &#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat.2</span><br><span class="line">22&#x2F;08&#x2F;17 17:31:14 INFO fs.TrashPolicyDefault: Moved: &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat.2&#39; to trash at: hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;user&#x2F;root&#x2F;.Trash&#x2F;Current&#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat.2</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# hdfs dfs -ls &#x2F;data&#x2F;im_external_table                  </span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   2 root supergroup         86 2022-08-17 15:06 &#x2F;data&#x2F;im_external_table&#x2F;im_external_table.dat</span><br><span class="line">-rwxrwxrwx   2 root supergroup         86 2022-08-17 17:21 &#x2F;data&#x2F;im_external_table&#x2F;im_external_table_copy_1.dat</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">本来这个表中有3个数据文件，现在删除1个数据文件之后，还剩下2个。</span><br><span class="line"></span><br><span class="line">到Hive中查询一下这个表最新的数据：</span><br><span class="line">hive&gt; select * from im_external_table;</span><br><span class="line">OK</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line">Time taken: 0.264 seconds, Fetched: 6 row(s)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">此时发现只剩下6条数据了，这是正确的。</span><br><span class="line"></span><br><span class="line">然后到Impala中查询一下：</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:32:43 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;c84a66bdb914d9f8:881769fb00000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 9 row(s) in 0.46s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">此时发现还是可以查到已经删除的数据文件中的数据，这是因为那些数据被缓存到了内存中，此时需要重新使用refresh刷新元数据才能获取到最新的：</span><br><span class="line">[cdh02:21000] default&gt; refresh im_external_table;      </span><br><span class="line">Query: refresh im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:33:57 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;f243b446e42c15d3:8c2d24c000000000</span><br><span class="line">Fetched 0 row(s) in 0.62s</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 17:33:59 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;e34d92b7bde5d898:ed17982000000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 6 row(s) in 1.03s</span><br><span class="line"></span><br><span class="line">使用refresh刷新后，就可以查询到最新的数据了。</span><br></pre></td></tr></table></figure><h3 id="invalidate-metadata命令"><a href="#invalidate-metadata命令" class="headerlink" title="invalidate metadata命令"></a>invalidate metadata命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">我们前面讲的refresh，是负责重新加载指定表的最新元数据信息，以及增量加载表中新的数据文件的位置信息，这个操作可以认为是增量更新，所以说他是轻量级的，性能开销较小。</span><br><span class="line"></span><br><span class="line">而现在要讲的这个invalidate metadata，他可以将表的元数据标记为过期，属于全量更新，性能开销较大。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Impala在对一个元数据标记为过期的表进行查询的时候，会自动重新加载这个表最新的元数据。</span><br><span class="line">但是针对一个拥有很多分区的大表来说，执行invalidate metadata这个操作，成本相当高，因为它会重新加载这个表的所有元数据信息。此时使用refresh的话会比较好，因为它只需要增量加载新增加的数据文件的位置数据即可，成本比较低。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">invalidate metadata命令的语法格式的这样的：</span><br><span class="line">invalidate metadata [ table_name ]</span><br><span class="line"></span><br><span class="line">他的后面可以指定表名，也可以不指定表名。</span><br><span class="line"></span><br><span class="line">如果不指定表名，则Impala中缓存的所有表的元数据信息都会被标记为过期。</span><br><span class="line">如果指定了表名，则只会将指定的表的元数据信息标记为过期。</span><br><span class="line"></span><br><span class="line">针对单张表而言，invalidate metadata的性能开销也比refresh要高。在向表中添加了数据文件之后，建议优先使用refresh。</span><br><span class="line"></span><br><span class="line">如果不确定哪个表的元数据发送了变化，想要全量更新表的元数据信息，建议使用invalidate metadata，这样比较方便，此时就不考虑性能开销了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">下面我们来演示一个invalidate metadata的典型使用场景</span><br><span class="line"></span><br><span class="line">假设我在Hive中创建了一个表：h_t1</span><br><span class="line">create table h_t1 (</span><br><span class="line">  id int,</span><br><span class="line">  name string</span><br><span class="line">);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">在Hive中可以查到这个表，也可以正常操作这个表(此时表中没有数据)：</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">h_t1</span><br><span class="line">im_external_partition_table</span><br><span class="line">im_external_table</span><br><span class="line">im_inner_table</span><br><span class="line">im_t1</span><br><span class="line">Time taken: 0.167 seconds, Fetched: 5 row(s)</span><br><span class="line">hive&gt; select * from h_t1;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.279 seconds</span><br><span class="line"></span><br><span class="line">但是在Impala中却找不到这个表，并且也无法使用。</span><br><span class="line">[cdh02:21000] default&gt; show tables;</span><br><span class="line">Query: show tables</span><br><span class="line">+-----------------------------+</span><br><span class="line">| name                        |</span><br><span class="line">+-----------------------------+</span><br><span class="line">| im_external_partition_table |</span><br><span class="line">| im_external_table           |</span><br><span class="line">| im_inner_table              |</span><br><span class="line">| im_t1                       |</span><br><span class="line">+-----------------------------+</span><br><span class="line">Fetched 4 row(s) in 0.02s</span><br><span class="line">[cdh02:21000] default&gt; select * from h_t1;</span><br><span class="line">Query: select * from h_t1</span><br><span class="line">Query submitted at: 2022-08-17 18:10:45 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: AnalysisException: Could not resolve table reference: &#39;h_t1&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">此时使用refresh就不好使了，因为impala中现在没有识别到这个表，使用refresh也会提示表不存在。</span><br><span class="line">[cdh02:21000] default&gt; refresh h_t1;</span><br><span class="line">Query: refresh h_t1</span><br><span class="line">Query submitted at: 2022-08-17 18:11:19 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: AnalysisException: Table does not exist: default.h_t1</span><br><span class="line"></span><br><span class="line">想要解决这个问题，就只能使用invalidate metadata了。</span><br><span class="line">[cdh02:21000] default&gt; invalidate metadata;</span><br><span class="line">Query: invalidate metadata</span><br><span class="line">Query submitted at: 2022-08-17 18:13:21 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;a04e1b083fdf92b0:a33f98fa00000000</span><br><span class="line">Fetched 0 row(s) in 2.78s</span><br><span class="line"></span><br><span class="line">此时再获取最新的表信息就可以看到了。</span><br><span class="line">[cdh02:21000] default&gt; show tables;              </span><br><span class="line">Query: show tables</span><br><span class="line">+-----------------------------+</span><br><span class="line">| name                        |</span><br><span class="line">+-----------------------------+</span><br><span class="line">| h_t1                        |</span><br><span class="line">| im_external_partition_table |</span><br><span class="line">| im_external_table           |</span><br><span class="line">| im_inner_table              |</span><br><span class="line">| im_t1                       |</span><br><span class="line">+-----------------------------+</span><br><span class="line">Fetched 5 row(s) in 0.02s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">这样就可以正常使用了。</span><br><span class="line">[cdh02:21000] default&gt; select * from h_t1;</span><br><span class="line">Query: select * from h_t1</span><br><span class="line">Query submitted at: 2022-08-17 18:14:44 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;da4aa121cbb177bc:145a901300000000</span><br><span class="line">Fetched 0 row(s) in 5.24s</span><br><span class="line"></span><br><span class="line">这个操作对Impala共享使用Hive中的元数据提供了技术支持。</span><br><span class="line"></span><br><span class="line">所以我们在工作中，通过Hive创建的表，在Impala中都是可以使用的，只是需要先同步一下元数据信息。</span><br></pre></td></tr></table></figure><h3 id="Impala的数据存储和数据压缩"><a href="#Impala的数据存储和数据压缩" class="headerlink" title="Impala的数据存储和数据压缩"></a>Impala的数据存储和数据压缩</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">前面我们在学习Hive的时候，详细分析了数据存储格式和数据压缩格式，那么这些数据存储格式和数据压缩格式在Impala中也是支持的。</span><br><span class="line"></span><br><span class="line">Impala支持对TextFile、SequenceFile、Avro、RCFile、ORC、Parquet等数据存储格式进行读取，但是对于某些Impala支持的不太好的数据存储格式，Impala只能对其进行查询操作，无法写入数据。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201450384.png" alt="image-20230620144954392"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-存储格式：常见的数据存储格式，Hive中都支持，Impala也是可以都读取的。</span><br><span class="line">-Impala是否可以直接创建表：意思是说在Impala中是否可以在创建表的时候指定这些存储格式，目前我们使用的Impala3.2.0版本，这些都是支持的。</span><br><span class="line">-Impala是否可以直接插入数据：意思是说在Impala中是否可以直接使用insert into语句向这些数据存储格式的表中插入数据。目前来看只有TextFile和PARQUET格式支持，其他的数据格式需要在Hive中使用insert into语句插入数据。或者在Impala中使用load data命令也可以，但是前提是需要先把数据整理成对应的数据格式。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这是数据存储相关的内容。</span><br><span class="line"></span><br><span class="line">针对数据压缩，建议参考前面在Hive扩展内容中讲的数据压缩步骤，在Hive中进行设置。</span><br><span class="line"></span><br><span class="line">其实在实际工作中还是建议在Hive中创建和管理表，然后在Impala中只查询，这样是比较方便的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">下面演示一下Impala中RCFile格式的使用。</span><br><span class="line"></span><br><span class="line">在impala中创建表：im_t1_rcfile</span><br><span class="line">create table im_t1_rcfile (</span><br><span class="line">  id int,</span><br><span class="line">  name string</span><br><span class="line">)stored as rcfile;</span><br><span class="line"></span><br><span class="line">从表im_t1中查询数据，然后使用insert into向表im_t1_rcfile中插入数据：</span><br><span class="line">[cdh02:21000] default&gt; insert into im_t1_rcfile select id,name from im_t1;</span><br><span class="line">Query: insert into im_t1_rcfile select id,name from im_t1</span><br><span class="line">Query submitted at: 2022-08-22 16:28:18 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;3d40a3f6a8fcede7:6cb6af9500000000</span><br><span class="line">ERROR: Cannot write to table with format RC_FILE. Impala only supports writing to TEXT and PARQUET.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">此时发现insert语句执行报错，错误日志提示说不能向RCFILE格式的表中写入数据，目前Impala中只能支持向Text和PARQUET格式的表中写入数据。</span><br><span class="line"></span><br><span class="line">所以这种情况下就需要在Hive中使用insert语句向这个表中插入数据了。</span><br><span class="line">hive&gt; insert into im_t1_rcfile select id,name from im_t1;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">上面的SQL执行成功之后就可以在Hive中或者Impala中查询表im_t1_rcfile中的数据了。</span><br><span class="line">在Hive中查询。</span><br><span class="line">hive&gt; select * from im_t1_rcfile;</span><br><span class="line">OK</span><br><span class="line">2       ls</span><br><span class="line">1       zs</span><br><span class="line"></span><br><span class="line">在Impala中查询。</span><br><span class="line"></span><br><span class="line">注意：需要先刷新表，因为我们是在Hive中向这个表里面添加了数据，Impala中默认是无法识别数据变化的。</span><br><span class="line">[cdh02:21000] default&gt; select * from im_t1_rcfile;</span><br><span class="line">Query: select * from im_t1_rcfile</span><br><span class="line">Query submitted at: 2022-08-22 16:41:53 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;5e477ef6db24bd4e:41cc43b100000000</span><br><span class="line">Fetched 0 row(s) in 0.15s</span><br><span class="line">[cdh02:21000] default&gt; refresh im_t1_rcfile;</span><br><span class="line">Query: refresh im_t1_rcfile</span><br><span class="line">Query submitted at: 2022-08-22 16:42:08 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;a34752b078041d31:c508e9f600000000</span><br><span class="line">Fetched 0 row(s) in 0.29s</span><br><span class="line">[cdh02:21000] default&gt; select * from im_t1_rcfile;</span><br><span class="line">Query: select * from im_t1_rcfile</span><br><span class="line">Query submitted at: 2022-08-22 16:42:10 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;8c45b2e0d93bc9c4:b6abd30100000000</span><br><span class="line">+----+------+</span><br><span class="line">| id | name |</span><br><span class="line">+----+------+</span><br><span class="line">| 2  | ls   |</span><br><span class="line">| 1  | zs   |</span><br><span class="line">+----+------+</span><br><span class="line">Fetched 2 row(s) in 0.14s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">所以为了避免在Impala中操作表遇到问题，建议在Hive中统一创建、管理表，只在Impala中提供快速查询服务，并且最好在每次查询之前先刷新一下表，这样可以保证每次查询的都是最新的数据。</span><br></pre></td></tr></table></figure><h3 id="Impala-SQL-VS-Hive-SQL"><a href="#Impala-SQL-VS-Hive-SQL" class="headerlink" title="Impala SQL VS Hive SQL"></a>Impala SQL VS Hive SQL</h3><h4 id="Impala-SQL中不支持的特性"><a href="#Impala-SQL中不支持的特性" class="headerlink" title="Impala SQL中不支持的特性"></a>Impala SQL中不支持的特性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">下面总结一些在Hive SQL中支持，但是在Impala SQL中不支持的特性，大家以后在使用Impala的时候需要留意：</span><br><span class="line">-不支持Date数据类型。（前面已演示过。）</span><br><span class="line">-load data时不支持local。（前面已演示过。）</span><br><span class="line">-SQL中不支持多个distinct。</span><br><span class="line"></span><br><span class="line">简单来说就是在一个SQL的select语句中不能使用多个distinct。</span><br></pre></td></tr></table></figure><h5 id="SQL中不支持多个distinct"><a href="#SQL中不支持多个distinct" class="headerlink" title="SQL中不支持多个distinct"></a>SQL中不支持多个distinct</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">举个例子：</span><br><span class="line">在impala中，select语句中使用1个distinct是没有问题的。</span><br><span class="line">[cdh02:21000] default&gt; select count(distinct id) from im_t1;</span><br><span class="line">Query: select count(distinct id) from im_t1</span><br><span class="line">Query submitted at: 2022-08-22 16:44:40 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;774f8823c028e167:32b025a400000000</span><br><span class="line">+--------------------+</span><br><span class="line">| count(distinct id) |</span><br><span class="line">+--------------------+</span><br><span class="line">| 2                  |</span><br><span class="line">+--------------------+</span><br><span class="line">Fetched 1 row(s) in 1.19s</span><br><span class="line">[cdh02:21000] default&gt; select count(distinct name) from im_t1;        </span><br><span class="line">Query: select count(distinct name) from im_t1</span><br><span class="line">Query submitted at: 2022-08-22 16:45:36 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;945efae0a14826a:eac4102400000000</span><br><span class="line">+----------------------+</span><br><span class="line">| count(distinct name) |</span><br><span class="line">+----------------------+</span><br><span class="line">| 2                    |</span><br><span class="line">+----------------------+</span><br><span class="line">Fetched 1 row(s) in 0.57s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">在impala中，select语句中使用多个distinct语句是会报错的：</span><br><span class="line">[cdh02:21000] default&gt; select count(distinct id),count(distinct name) from im_t1;</span><br><span class="line">Query: select count(distinct id),count(distinct name) from im_t1</span><br><span class="line">Query submitted at: 2022-08-22 16:45:51 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;9647a6c4a515b813:94d79b5200000000</span><br><span class="line">ERROR: ExecQueryFInstances rpc query_id&#x3D;9647a6c4a515b813:94d79b5200000000 failed: Failed to get minimum memory reservation of 136.01 MB on daemon cdh02:22000 for query 9647a6c4a515b813:94d79b5200000000 due to following error: Memory limit exceeded: Could not allocate memory while trying to increase reservation.</span><br><span class="line">Query(9647a6c4a515b813:94d79b5200000000) could not allocate 136.01 MB without exceeding limit.</span><br><span class="line">Error occurred on backend cdh02:22000</span><br><span class="line">Memory left in process limit: 143.38 MB</span><br><span class="line">Query(9647a6c4a515b813:94d79b5200000000): Reservation&#x3D;0 ReservationLimit&#x3D;204.80 MB OtherMemory&#x3D;0 Total&#x3D;0 Peak&#x3D;0</span><br><span class="line">Memory is likely oversubscribed. Reducing query concurrency or configuring admission control may help avoid this error.</span><br><span class="line"></span><br><span class="line">提示的是内存相关的错误，但是这个表里面就只有2条数据，其实还是因为它不支持这种语法。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在Hive中是可以支持这种语法的：</span><br><span class="line">hive&gt; select count(distinct id),count(distinct name) from im_t1;</span><br><span class="line">OK</span><br><span class="line">2       2</span><br><span class="line">Time taken: 66.222 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure><h5 id="不支持常见的复合数据类型"><a href="#不支持常见的复合数据类型" class="headerlink" title="不支持常见的复合数据类型"></a>不支持常见的复合数据类型</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-不支持常见的复合数据类型。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">例如在Hive中支持的array、map、struct这些复合数据类型，Impala中都不支持。</span><br><span class="line">验证一下：</span><br><span class="line">在Impala中执行下面这几个SQL建表语句(Hive中复合数据类型的建表语句)都是会报错的：</span><br><span class="line">[cdh02:21000] default&gt; create table stu(</span><br><span class="line">                     &gt;   id int,</span><br><span class="line">                     &gt;   name string,</span><br><span class="line">                     &gt;   favors array&lt;string&gt;</span><br><span class="line">                     &gt; )row format delimited</span><br><span class="line">                     &gt; fields terminated by &#39;\t&#39;</span><br><span class="line">                     &gt; collection items terminated by &#39;,&#39;</span><br><span class="line">                     &gt; lines terminated by &#39;\n&#39;;</span><br><span class="line">Query: create table stu(</span><br><span class="line">  id int,</span><br><span class="line">  name string,</span><br><span class="line">  favors array&lt;string&gt;</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by &#39;\t&#39;</span><br><span class="line">collection items terminated by &#39;,&#39;</span><br><span class="line">lines terminated by &#39;\n&#39;</span><br><span class="line">ERROR: ParseException: Syntax error in line 7:</span><br><span class="line">collection items terminated by &#39;,&#39;</span><br><span class="line">^</span><br><span class="line">Encountered: IDENTIFIER</span><br><span class="line">Expected: AS, CACHED, ESCAPED, LINES, LOCATION, STORED, TBLPROPERTIES, UNCACHED, WITH</span><br><span class="line"></span><br><span class="line">CAUSED BY: Exception: Syntax error</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[cdh02:21000] default&gt; create table stu2(</span><br><span class="line">                     &gt; id int,</span><br><span class="line">                     &gt; name string,</span><br><span class="line">                     &gt; scores  map&lt;string,int&gt;</span><br><span class="line">                     &gt; )row format delimited</span><br><span class="line">                     &gt; fields terminated by &#39;\t&#39;</span><br><span class="line">                     &gt; collection items terminated by &#39;,&#39;</span><br><span class="line">                     &gt; map keys terminated by &#39;:&#39;</span><br><span class="line">                     &gt; lines terminated by &#39;\n&#39;;</span><br><span class="line">Query: create table stu2(</span><br><span class="line">id int,</span><br><span class="line">name string,</span><br><span class="line">scores  map&lt;string,int&gt;</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by &#39;\t&#39;</span><br><span class="line">collection items terminated by &#39;,&#39;</span><br><span class="line">map keys terminated by &#39;:&#39;</span><br><span class="line">lines terminated by &#39;\n&#39;</span><br><span class="line">ERROR: ParseException: Syntax error in line 7:</span><br><span class="line">collection items terminated by &#39;,&#39;</span><br><span class="line">^</span><br><span class="line">Encountered: IDENTIFIER</span><br><span class="line">Expected: AS, CACHED, ESCAPED, LINES, LOCATION, STORED, TBLPROPERTIES, UNCACHED, WITH</span><br><span class="line"></span><br><span class="line">CAUSED BY: Exception: Syntax error</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[cdh02:21000] default&gt; create table stu3(</span><br><span class="line">                     &gt; id int,</span><br><span class="line">                     &gt; name string,</span><br><span class="line">                     &gt; address  struct&lt;home_addr:string,office_addr:string&gt;</span><br><span class="line">                     &gt; )row format delimited</span><br><span class="line">                     &gt; fields terminated by &#39;\t&#39;</span><br><span class="line">                     &gt; collection items terminated by &#39;,&#39;</span><br><span class="line">                     &gt; lines terminated by &#39;\n&#39;;</span><br><span class="line">Query: create table stu3(</span><br><span class="line">id int,</span><br><span class="line">name string,</span><br><span class="line">address  struct&lt;home_addr:string,office_addr:string&gt;</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by &#39;\t&#39;</span><br><span class="line">collection items terminated by &#39;,&#39;</span><br><span class="line">lines terminated by &#39;\n&#39;</span><br><span class="line">ERROR: ParseException: Syntax error in line 7:</span><br><span class="line">collection items terminated by &#39;,&#39;</span><br><span class="line">^</span><br><span class="line">Encountered: IDENTIFIER</span><br><span class="line">Expected: AS, CACHED, ESCAPED, LINES, LOCATION, STORED, TBLPROPERTIES, UNCACHED, WITH</span><br><span class="line"></span><br><span class="line">CAUSED BY: Exception: Syntax error</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">那我们在Hive中创建的复合数据类型，在Impala中是否支持查询呢？</span><br><span class="line"></span><br><span class="line">下面验证一下，到Hive中创建一个带有复合数据类型(Hive中的复合数据类型案例中的建表语句)的表：</span><br><span class="line">hive&gt; create table student (</span><br><span class="line">    &gt;   id int comment &#39;id&#39;,</span><br><span class="line">    &gt;   name string comment &#39;name&#39;,</span><br><span class="line">    &gt;   favors array&lt;string&gt; ,</span><br><span class="line">    &gt;   scores map&lt;string, int&gt;,</span><br><span class="line">    &gt;   address struct&lt;home_addr:string,office_addr:string&gt;</span><br><span class="line">    &gt; ) row format delimited</span><br><span class="line">    &gt; fields terminated by &#39;\t&#39;</span><br><span class="line">    &gt; collection items terminated by &#39;,&#39;</span><br><span class="line">    &gt; map keys terminated by &#39;:&#39;</span><br><span class="line">    &gt; lines terminated by &#39;\n&#39;;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.556 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">准备测试数据：</span><br><span class="line">[root@cdh01 ~]# vi student.data</span><br><span class="line">1       zhangsan        english,sing,swing      chinese:80,math:90,english:100  bj,sh</span><br><span class="line">2       lisi    games,coding    chinese:89,english:70,math:88   gz,sz</span><br><span class="line"></span><br><span class="line">加载测试数据：</span><br><span class="line">hive&gt; load data local inpath &#39;&#x2F;root&#x2F;student.data&#39; into table student;</span><br><span class="line">Loading data to table default.student</span><br><span class="line">OK</span><br><span class="line">Time taken: 2.937 seconds</span><br><span class="line"></span><br><span class="line">在Hive中是可以正常查询的：</span><br><span class="line">hive&gt; select * from student;</span><br><span class="line">OK</span><br><span class="line">1       zhangsan        [&quot;english&quot;,&quot;sing&quot;,&quot;swing&quot;]      &#123;&quot;chinese&quot;:80,&quot;math&quot;:90,&quot;english&quot;:100&#125;        &#123;&quot;home_addr&quot;:&quot;bj&quot;,&quot;office_addr&quot;:&quot;sh&quot;&#125;</span><br><span class="line">2       lisi    [&quot;games&quot;,&quot;coding&quot;]      &#123;&quot;chinese&quot;:89,&quot;english&quot;:70,&quot;math&quot;:88&#125; &#123;&quot;home_addr&quot;:&quot;gz&quot;,&quot;office_addr&quot;:&quot;sz&quot;&#125;</span><br><span class="line">Time taken: 0.761 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">到Impala中查询：</span><br><span class="line"></span><br><span class="line">注意：需要先刷新元数据，否则无法识别在Hive中创建的表。</span><br><span class="line">[cdh02:21000] default&gt; invalidate metadata;</span><br><span class="line">Query: invalidate metadata</span><br><span class="line">Query submitted at: 2022-08-22 17:17:14 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;ea41e49792f60f79:6f565cc400000000</span><br><span class="line">Fetched 0 row(s) in 4.48s</span><br><span class="line"></span><br><span class="line">查询：</span><br><span class="line">[cdh02:21000] default&gt; select * from student;</span><br><span class="line">Query: select * from student</span><br><span class="line">Query submitted at: 2022-08-22 17:17:25 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: NotImplementedException: Scan of table &#39;default.student&#39; in format &#39;TEXT&#39; is not supported because the table has a column &#39;favors&#39; with a complex type &#39;ARRAY&lt;STRING&gt;&#39;.</span><br><span class="line">Complex types are supported for these file formats: PARQUET.</span><br><span class="line"></span><br><span class="line">发现查询的时候报错了，提示Text数据类型不支持Array这些复合数据类型。</span><br><span class="line">但是在PARQUET数据存储格式中是支持这些数据类型的。</span><br></pre></td></tr></table></figure><h5 id="不支持collect-list-set-函数"><a href="#不支持collect-list-set-函数" class="headerlink" title="不支持collect_list()/set()函数"></a>不支持collect_list()/set()函数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Impala中不支持collect_list()和collect_set()函数。</span><br><span class="line">在Impala中创建表：student_favors</span><br><span class="line"></span><br><span class="line">[cdh02:21000] default&gt; create external table student_favors(</span><br><span class="line">                     &gt; name string,</span><br><span class="line">                     &gt; favor string</span><br><span class="line">                     &gt; )row format delimited</span><br><span class="line">                     &gt; fields terminated by &#39;\t&#39;</span><br><span class="line">                     &gt; location &#39;&#x2F;data&#x2F;student_favors&#39;;</span><br><span class="line">Query: create external table student_favors(</span><br><span class="line">name string,</span><br><span class="line">favor string</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by &#39;\t&#39;</span><br><span class="line">location &#39;&#x2F;data&#x2F;student_favors&#39;</span><br><span class="line">+-------------------------+</span><br><span class="line">| summary                 |</span><br><span class="line">+-------------------------+</span><br><span class="line">| Table has been created. |</span><br><span class="line">+-------------------------+</span><br><span class="line">Fetched 1 row(s) in 0.40s</span><br><span class="line"></span><br><span class="line">准备测试数据：</span><br><span class="line">[root@cdh01 ~]# vi student_favors.data </span><br><span class="line">zs      swing</span><br><span class="line">zs      footbal</span><br><span class="line">zs      sing</span><br><span class="line">zs      codeing</span><br><span class="line">zs      swing</span><br><span class="line"></span><br><span class="line">加载数据。</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put student_favors.data  &#x2F;data&#x2F;student_favors</span><br><span class="line"></span><br><span class="line">在Impala中查询数据（先刷新表）。</span><br><span class="line">[cdh02:21000] default&gt; refresh student_favors;</span><br><span class="line">[cdh02:21000] default&gt; select name,concat_ws(&#39;,&#39;,collect_list(favor)) as favor_list from student_favors group by name;</span><br><span class="line">Query: select name,concat_ws(&#39;,&#39;,collect_list(favor)) as favor_list from student_favors group by name</span><br><span class="line">Query submitted at: 2022-08-22 17:39:23 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: AnalysisException: default.collect_list() unknown</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">错误提示collect_list()和collect_set()是未知函数。</span><br></pre></td></tr></table></figure><h5 id="不支持split-、explode-函数"><a href="#不支持split-、explode-函数" class="headerlink" title="不支持split()、explode()函数"></a>不支持split()、explode()函数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Impala中不支持split()、explode()函数。</span><br><span class="line">在Impala中创建表：student_favors_2</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">准备测试数据：</span><br><span class="line">[root@cdh01 ~]# vi student_favors_2.data </span><br><span class="line">zs      swing,footbal,sing</span><br><span class="line">ls      codeing,swing</span><br><span class="line"></span><br><span class="line">加载数据：</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put student_favors_2.data &#x2F;data&#x2F;student_favors_2</span><br><span class="line"></span><br><span class="line">在Impala中查询数据（先刷新表）。</span><br><span class="line">[cdh02:21000] default&gt; refresh student_favors;</span><br><span class="line">[cdh02:21000] default&gt; select split(favorlist,&#39;,&#39;) from student_favors_2;</span><br><span class="line">Query: select split(favorlist,&#39;,&#39;) from student_favors_2</span><br><span class="line">Query submitted at: 2022-08-22 17:41:52 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: AnalysisException: default.split() unknown</span><br><span class="line">[cdh02:21000] default&gt; select explode(&#39;&#39;) from student_favors_2;</span><br><span class="line">Query: select explode(&#39;&#39;) from student_favors_2</span><br><span class="line">Query submitted at: 2022-08-22 17:45:48 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: AnalysisException: default.explode() unknown</span><br><span class="line">[cdh02:21000] default&gt; select name,favor_new from student_favors_2 lateral view explode(split(favorlist, &#39;,&#39;)) table1 as favor_new ;</span><br><span class="line">Query: select name,favor_new from student_favors_2 lateral view explode(split(favorlist, &#39;,&#39;)) table1 as favor_new</span><br><span class="line">Query submitted at: 2022-08-22 17:41:06 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">ERROR: ParseException: Syntax error in line 1:</span><br><span class="line">...new from student_favors_2 lateral view explode(split(f...</span><br><span class="line">                             ^</span><br><span class="line">Encountered: A reserved word cannot be used as an identifier: lateral</span><br><span class="line">Expected: ADD, ALTER, AND, ARRAY, AS, ASC, BETWEEN, BIGINT, BINARY, BLOCK_SIZE, BOOLEAN, CACHED, CASCADE, CHANGE, CHAR, COMMENT, COMPRESSION, CROSS, DATE, DATETIME, DECIMAL, DEFAULT, DESC, DIV, REAL, DROP, ELSE, ENCODING, END, FLOAT, FOLLOWING, FROM, FULL, GROUP, IGNORE, HAVING, ILIKE, IN, INNER, INTEGER, IREGEXP, IS, JOIN, LEFT, LIKE, LIMIT, LOCATION, MAP, NOT, NULL, NULLS, OFFSET, ON, OR, ORDER, PARTITION, PARTITIONED, PRECEDING, PRIMARY, PURGE, RANGE, RECOVER, REGEXP, RENAME, REPLACE, RESTRICT, RIGHT, RLIKE, ROW, ROWS, SELECT, SET, SMALLINT, SORT, STORED, STRAIGHT_JOIN, STRING, STRUCT, TABLESAMPLE, TBLPROPERTIES, THEN, TIMESTAMP, TINYINT, TO, UNCACHED, UNION, USING, VALUES, VARCHAR, WHEN, WHERE, WITH, COMMA, IDENTIFIER</span><br><span class="line"></span><br><span class="line">CAUSED BY: Exception: Syntax error</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">错误提示split()、explode()、lateral view都不支持。</span><br><span class="line"></span><br><span class="line">从这可以看出来，Impala SQL和Hive SQL在细节层面还是存在一些区别的，大家使用的时候需要注意，不过基础的SQL语句都是可以兼容的。</span><br></pre></td></tr></table></figure><h3 id="Impala和Hive的典型应用场景"><a href="#Impala和Hive的典型应用场景" class="headerlink" title="Impala和Hive的典型应用场景"></a>Impala和Hive的典型应用场景</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">针对Impala和Hive的典型应用场景</span><br><span class="line"></span><br><span class="line">在实际工作中，如果考虑稳定性，建议使用Hive，Hive的底层引擎可以考虑是MapReduce或者Tez。</span><br><span class="line"></span><br><span class="line">如果考虑执行效率，建议使用Impala或者Hive on Spark。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">针对Impala和Hive on Spark如何选择呢？</span><br><span class="line"></span><br><span class="line">-从SQL兼容程度上来说，Hive on Spark是优于Impala的，因为Hive中的一些高级SQL函数Impala是不支持的。</span><br><span class="line">-从任务执行的延迟上来说，Impala是优于Hive on Spark的，因为Hive on Spark每次执行都会提交一个Spark任务，这个任务的提交过程是需要消耗一定时间的。Impala的任务提交过程会更快。</span><br><span class="line">-从资源利用率角度来说，Hive on Spark是优于Impala的。因为Impala默认是需要安装自己的集群，这个集群资源只能运行Impala任务，而Hive on Spark是可以在YARN上执行的，YARN的资源是共享的。不过在CDH5版本之后，Impala也开始支持Impala on YARN模式，他通过一个叫做Llama(Long-Lived Application Master)的中间组件协调Yarn和Impala，向Yarn资源管理器申请计算资源。</span><br><span class="line">查看Impala的配置页面中的参数也可以看出来他目前支持ON YARN模式：</span><br><span class="line">http:&#x2F;&#x2F;cdh01:7180&#x2F;cmf&#x2F;services&#x2F;18&#x2F;config</span><br></pre></td></tr></table></figure><h3 id="Impala集成HBase"><a href="#Impala集成HBase" class="headerlink" title="Impala集成HBase"></a>Impala集成HBase</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">为了解决HBase无法使用SQL实现数据分析的问题，可以通过Hive来实现，也可以通过Impala来实现。</span><br><span class="line"></span><br><span class="line">通过Impala操作HBase时，需要在Hive中建表，然后把表同步到Impala中，无法直接在Impala中基于HBase创建表，因为Impala的CREATE TABLE功能中有很多语法并不支持。</span><br><span class="line">所以大致的流程是这样的：HBase-&gt;Hive-&gt;Impala。</span><br><span class="line"></span><br><span class="line">Impala不是直接读取HBase表的底层数据文件，而是通过HBase客户端API代码读取HBase表中的数据，只不过这些代码不需要我们开发了，我们直接写上层的SQL就可以了。</span><br></pre></td></tr></table></figure><h4 id="CDH平台中安装HBase"><a href="#CDH平台中安装HBase" class="headerlink" title="CDH平台中安装HBase"></a>CDH平台中安装HBase</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">目前CDH平台中还没有安装HBase集群，在使用之前，需要先安装HBase(一主两从)。</span><br><span class="line"></span><br><span class="line">添加服务。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201514862.png" alt="image-20230620151444679"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">选中 HBase</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201515119.png" alt="image-20230620151509739"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">点击右下角的继续按钮</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201515779.png" alt="image-20230620151529650"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">自定义角色分配，根据集群中节点的负载情况给HBase REST Server和HBase Thrift Server选择合适的节点即可。</span><br><span class="line">选好以后点击继续按钮</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201516811.png" alt="image-20230620151618579"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">默认不需要修改，直接点击继续按钮即可</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201516800.png" alt="image-20230620151641626"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">等待状态变为 已完成 ，点击继续按钮</span><br><span class="line"></span><br><span class="line">点击完成按钮即可</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201517037.png" alt="image-20230620151700762"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201517758.png" alt="image-20230620151711600"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">重启Zookeeper，点击重启按钮</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201517515.png" alt="image-20230620151739109"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">点击重启过时服务按钮</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201518808.png" alt="image-20230620151808720"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">等待状态变为已完成，然后点击完成按钮即可。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201518426.png" alt="image-20230620151826842"></p><h4 id="让Impala支持HBase"><a href="#让Impala支持HBase" class="headerlink" title="让Impala支持HBase"></a>让Impala支持HBase</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在Impala中修改配置，以支持HBase，否则Impala连不上HBase。</span><br><span class="line"></span><br><span class="line">进入impala的配置页面，选中HBase、然后点击 保存更改按钮。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201519398.png" alt="image-20230620151919324"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">重启Impala</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201519464.png" alt="image-20230620151940202"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">点击重启过时服务按钮</span><br><span class="line"></span><br><span class="line">选中 重新部署客户端配置，然后点击立即重启按钮。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201520311.png" alt="image-20230620152000974"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201520538.png" alt="image-20230620152012380"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">等待状态变为 已完成，点击完成按钮即可</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306201520810.png" alt="image-20230620152035512"></p><h4 id="HBase-gt-Hive-gt-Impala"><a href="#HBase-gt-Hive-gt-Impala" class="headerlink" title="HBase-&gt;Hive-&gt;Impala"></a>HBase-&gt;Hive-&gt;Impala</h4><h4 id="（1）在HBase中创建表"><a href="#（1）在HBase中创建表" class="headerlink" title="（1）在HBase中创建表"></a>（1）在HBase中创建表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">下面开始实际操作一下这个流程。</span><br><span class="line"></span><br><span class="line">（1）在HBase中创建表</span><br><span class="line">hbase(main):004:0&gt; create &#39;video_user&#39;,&#39;basic&#39;,&#39;extend&#39;</span><br><span class="line"></span><br><span class="line">解释：HBase的video_user表中存储用户信息，其中basic列族中存储用户基础信息，extend列族中存储用户扩展信息。</span><br><span class="line"></span><br><span class="line">（2）向HBase表中初始化测试数据</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;basic:name&#39;,&#39;zs001&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;basic:birthday&#39;,&#39;2006-07-21&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;basic:email&#39;,&#39;fx0i2724@yeah.net&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;basic:mobile&#39;,&#39;15208252251&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 01:10:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;extend:is_have_child&#39;,&#39;0&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;extend:phone_brand&#39;,&#39;huawei&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;extend:weight&#39;,&#39;67&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;100001&#39;,&#39;extend:height&#39;,&#39;160&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;basic:name&#39;,&#39;zs002&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;basic:birthday&#39;,&#39;2005-04-23&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;basic:email&#39;,&#39;emau0i5i@sina.com&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;basic:mobile&#39;,&#39;15105571420&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 01:21:13&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;extend:is_have_child&#39;,&#39;1&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;extend:phone_brand&#39;,&#39;huawei&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;extend:weight&#39;,&#39;63&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;200001&#39;,&#39;extend:height&#39;,&#39;168&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;basic:name&#39;,&#39;zs003&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;basic:birthday&#39;,&#39;2002-10-11&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;basic:email&#39;,&#39;824c1s@hotmail.com&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;basic:mobile&#39;,&#39;15701964301&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 01:25:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;extend:is_have_child&#39;,&#39;0&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;extend:phone_brand&#39;,&#39;oppo&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;extend:weight&#39;,&#39;53&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;300001&#39;,&#39;extend:height&#39;,&#39;170&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;basic:name&#39;,&#39;zs004&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;basic:birthday&#39;,&#39;2008-07-11&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;basic:email&#39;,&#39;mgq14kt@3721.net&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;basic:mobile&#39;,&#39;15802961143&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 01:30:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;extend:is_have_child&#39;,&#39;0&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;extend:phone_brand&#39;,&#39;iphone&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;extend:weight&#39;,&#39;68&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;400001&#39;,&#39;extend:height&#39;,&#39;180&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;basic:name&#39;,&#39;zs005&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;basic:birthday&#39;,&#39;2001-09-21&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;basic:email&#39;,&#39;i4dwzt54b@yahoo.com.cn&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;basic:mobile&#39;,&#39;13804117689&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 02:13:12&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;extend:is_have_child&#39;,&#39;1&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;extend:phone_brand&#39;,&#39;xiaomi&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;extend:weight&#39;,&#39;60&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;500001&#39;,&#39;extend:height&#39;,&#39;165&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;basic:name&#39;,&#39;zs006&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;basic:birthday&#39;,&#39;2002-11-11&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;basic:email&#39;,&#39;cc33o9ak@sina.com&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;basic:mobile&#39;,&#39;13206823730&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 02:15:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;extend:is_have_child&#39;,&#39;0&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;extend:phone_brand&#39;,&#39;iphone&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;extend:weight&#39;,&#39;69&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;600001&#39;,&#39;extend:height&#39;,&#39;175&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;basic:name&#39;,&#39;zs007&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;basic:birthday&#39;,&#39;2005-06-18&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;basic:email&#39;,&#39;56vptzo5x@yeah.net&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;basic:mobile&#39;,&#39;13307064763&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 02:20:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;extend:is_have_child&#39;,&#39;1&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;extend:phone_brand&#39;,&#39;xiaomi&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;extend:weight&#39;,&#39;55&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;700001&#39;,&#39;extend:height&#39;,&#39;177&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;basic:name&#39;,&#39;zs008&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;basic:birthday&#39;,&#39;2006-09-12&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;basic:email&#39;,&#39;t3929y3k4@163.com&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;basic:mobile&#39;,&#39;15200018067&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 02:30:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;extend:is_have_child&#39;,&#39;0&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;extend:phone_brand&#39;,&#39;huawei&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;extend:weight&#39;,&#39;57&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;800001&#39;,&#39;extend:height&#39;,&#39;170&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;basic:name&#39;,&#39;zs009&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;basic:birthday&#39;,&#39;2003-01-17&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;basic:email&#39;,&#39;9i07c7ix@msn.com&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;basic:mobile&#39;,&#39;15605340859&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 02:33:12&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;extend:is_have_child&#39;,&#39;1&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;extend:phone_brand&#39;,&#39;huawei&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;extend:weight&#39;,&#39;59&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;900001&#39;,&#39;extend:height&#39;,&#39;167&#39;</span><br><span class="line"></span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;basic:name&#39;,&#39;zs010&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;basic:birthday&#39;,&#39;2004-05-12&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;basic:email&#39;,&#39;ftewcpcj@3721.net&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;basic:mobile&#39;,&#39;13105938235&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;basic:r_time&#39;,&#39;2020-01-17 03:10:10&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;extend:is_have_child&#39;,&#39;1&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;extend:phone_brand&#39;,&#39;samsung&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;extend:weight&#39;,&#39;64&#39;</span><br><span class="line">put &#39;video_user&#39;,&#39;010001&#39;,&#39;extend:height&#39;,&#39;168&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">注意：为了避免rowkey出现热点，所以在向HBase中添加数据的时候，针对rowkey中的id字段的值进行了反转。</span><br><span class="line">例如：900001，其实真正的id值是100009。</span><br></pre></td></tr></table></figure><h4 id="（3）在Hive中创建外部表"><a href="#（3）在Hive中创建外部表" class="headerlink" title="（3）在Hive中创建外部表"></a>（3）在Hive中创建外部表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">create external table video_user(</span><br><span class="line">  id string,</span><br><span class="line">  name string,</span><br><span class="line">  birthday string,</span><br><span class="line">  email string,</span><br><span class="line">  mobile string,</span><br><span class="line">  r_time timestamp,</span><br><span class="line">  is_have_child int,</span><br><span class="line">  phone_brand string,</span><br><span class="line">  weight int,</span><br><span class="line">  height int</span><br><span class="line">)stored by &#39;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#39; </span><br><span class="line">with serdeproperties(</span><br><span class="line"> &quot;hbase.columns.mapping&quot;&#x3D;&quot;:key,basic:name,basic:birthday,basic:email,basic:mobile,basic:r_time,extend:is_have_child,extend:phone_brand,extend:weight,extend:height&quot;</span><br><span class="line">) </span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; &#x3D; &quot;video_user&quot;);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">-stored by后面指定的是表中数据存储的格式，这里表示使用HBase存储。</span><br><span class="line">-with serdeproperties里面指定的是序列化和反序列化相关的参数，通过hbase.columns.mapping指定hive表字段和hbase表字段之间的映射关系，其中第一个:key字段表示是hbase中的rowkey字段，后面的字段会按照顺序和hive表字段进行映射，hbase.columns.mapping的值中间不能有空格和换行符。</span><br><span class="line">-tblproperties里面指定表相关的信息，通过hbase.table.name指定hbase中的表名。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line"></span><br><span class="line">-id字段对应的是hbase中表的rowkey字段，这个字段类型建议指定为string类型，这样在SQL中对id进行过滤查询的时候可以将过滤条件翻译成针对HBase表中rowkey的条件查询，这样查询效率比较高。</span><br><span class="line">-由于impala不支持date字段，所以birthday字段需要设置为string类型，在使用层面其实是没有区别的。</span><br></pre></td></tr></table></figure><h4 id="（4）将表同步到Impala中"><a href="#（4）将表同步到Impala中" class="headerlink" title="（4）将表同步到Impala中"></a>（4）将表同步到Impala中</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000</span><br><span class="line">[cdh02:21000] default&gt; invalidate metadata;</span><br><span class="line">Query: invalidate metadata</span><br><span class="line">Query submitted at: 2022-08-29 16:41:26 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;594ca9e564be417c:184e33dc00000000</span><br><span class="line">Fetched 0 row(s) in 4.50s</span><br><span class="line">[cdh02:21000] default&gt; show tables;</span><br><span class="line">Query: show tables</span><br><span class="line">+-----------------------------+</span><br><span class="line">| name                        |</span><br><span class="line">+-----------------------------+</span><br><span class="line">| h_t1                        |</span><br><span class="line">| im_external_partition_table |</span><br><span class="line">| im_external_table           |</span><br><span class="line">| im_inner_table              |</span><br><span class="line">| im_t1                       |</span><br><span class="line">| im_t1_rcfile                |</span><br><span class="line">| student                     |</span><br><span class="line">| student_favors              |</span><br><span class="line">| student_favors_2            |</span><br><span class="line">| student_score               |</span><br><span class="line">| video_user                  |</span><br><span class="line">+-----------------------------+</span><br><span class="line">Fetched 11 row(s) in 0.02s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时就可以在Impala中操作video_user这个表了，其实对应的就是操作hbase中的video_user表。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[cdh02:21000] default&gt; select * from video_user;</span><br><span class="line">Query: select * from video_user</span><br><span class="line">Query submitted at: 2022-08-29 17:10:15 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;d043dd6b4f6a29f4:81435a5700000000</span><br><span class="line">+--------+------------+------------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">| id     | birthday   | email                  | mobile      | name  | r_time              | height | is_have_child | phone_brand | weight |</span><br><span class="line">+--------+------------+------------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">| 010001 | 2004-05-12 | ftewcpcj@3721.net      | 13105938235 | zs010 | 2020-01-17 03:10:10 | 168    | 1             | samsung     | 64     |</span><br><span class="line">| 100001 | 2006-07-21 | fx0i2724@yeah.net      | 15208252251 | zs001 | 2020-01-17 01:10:10 | 160    | 0             | huawei      | 67     |</span><br><span class="line">| 200001 | 2005-04-23 | emau0i5i@sina.com      | 15105571420 | zs002 | 2020-01-17 01:21:13 | 168    | 1             | huawei      | 63     |</span><br><span class="line">| 300001 | 2002-10-11 | 824c1s@hotmail.com     | 15701964301 | zs003 | 2020-01-17 01:25:10 | 170    | 0             | oppo        | 53     |</span><br><span class="line">| 400001 | 2008-07-11 | mgq14kt@3721.net       | 15802961143 | zs004 | 2020-01-17 01:30:10 | 180    | 0             | iphone      | 68     |</span><br><span class="line">| 500001 | 2001-09-21 | i4dwzt54b@yahoo.com.cn | 13804117689 | zs005 | 2020-01-17 02:13:12 | 165    | 1             | xiaomi      | 60     |</span><br><span class="line">| 600001 | 2002-11-11 | cc33o9ak@sina.com      | 13206823730 | zs006 | 2020-01-17 02:15:10 | 175    | 0             | iphone      | 69     |</span><br><span class="line">| 700001 | 2005-06-18 | 56vptzo5x@yeah.net     | 13307064763 | zs007 | 2020-01-17 02:20:10 | 177    | 1             | xiaomi      | 55     |</span><br><span class="line">| 800001 | 2006-09-12 | t3929y3k4@163.com      | 15200018067 | zs008 | 2020-01-17 02:30:10 | 170    | 0             | huawei      | 57     |</span><br><span class="line">| 900001 | 2003-01-17 | 9i07c7ix@msn.com       | 15605340859 | zs009 | 2020-01-17 02:33:12 | 167    | 1             | huawei      | 59     |</span><br><span class="line">+--------+------------+------------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">Fetched 10 row(s) in 12.63s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时这个SQL语句相当于我们使用Scan对HBase中的表进行全表扫描了</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">这样表示会根据hbase表中的rowkey进行查询</span><br><span class="line"></span><br><span class="line">[cdh02:21000] default&gt; select * from video_user where id &#x3D; &#39;100001&#39;;</span><br><span class="line">Query: select * from video_user where id &#x3D; &#39;100001&#39;</span><br><span class="line">Query submitted at: 2022-08-29 17:12:31 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;b043624845487ab2:a00f105800000000</span><br><span class="line">+--------+------------+-------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">| id     | birthday   | email             | mobile      | name  | r_time              | height | is_have_child | phone_brand | weight |</span><br><span class="line">+--------+------------+-------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">| 100001 | 2006-07-21 | fx0i2724@yeah.net | 15208252251 | zs001 | 2020-01-17 01:10:10 | 160    | 0             | huawei      | 67     |</span><br><span class="line">+--------+------------+-------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">Fetched 1 row(s) in 0.21s</span><br><span class="line"></span><br><span class="line">此时这个SQL语句相当于我们在使用HBase中的Scan扫描数据时传入了RowFilter这个基于rowkey的过滤器，这个操作的查询效率还是比较高的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">这样表示会根据hbase表中的某个普通字段进行查询</span><br><span class="line">[cdh02:21000] default&gt; select * from video_user where name &#x3D; &#39;zs002&#39;; </span><br><span class="line">Query: select * from video_user where name &#x3D; &#39;zs002&#39;</span><br><span class="line">Query submitted at: 2022-08-29 17:13:26 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;504ffd1cc5c62c73:a97d0f0200000000</span><br><span class="line">+--------+------------+-------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">| id     | birthday   | email             | mobile      | name  | r_time              | height | is_have_child | phone_brand | weight |</span><br><span class="line">+--------+------------+-------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">| 200001 | 2005-04-23 | emau0i5i@sina.com | 15105571420 | zs002 | 2020-01-17 01:21:13 | 168    | 1             | huawei      | 63     |</span><br><span class="line">+--------+------------+-------------------+-------------+-------+---------------------+--------+---------------+-------------+--------+</span><br><span class="line">Fetched 1 row(s) in 0.53s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时这个SQL语句相当于我们在使用HBase中的Scan扫描数据时传入了SingleColumnFilter过滤器，对普通列进行过滤查询，此时没有使用到rowkey，所以依然是全表扫描，效率一般。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">分组聚合查询：</span><br><span class="line">[cdh02:21000] default&gt; select is_have_child,count(*) from video_user group by is_have_child;</span><br><span class="line">Query: select is_have_child,count(*) from video_user group by is_have_child</span><br><span class="line">Query submitted at: 2022-08-29 17:14:49 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;ad4f2b0edb155853:5ec2ff0400000000</span><br><span class="line">+---------------+----------+</span><br><span class="line">| is_have_child | count(*) |</span><br><span class="line">+---------------+----------+</span><br><span class="line">| 0             | 5        |</span><br><span class="line">| 1             | 5        |</span><br><span class="line">+---------------+----------+</span><br><span class="line">Fetched 2 row(s) in 0.77s</span><br><span class="line"></span><br><span class="line">当然了，在Hive中执行这些查询操作也是可以的，只是查询速度没有在Impala中快。</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Impala" scheme="http://tianyong.fun/tags/Impala/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-数据分析引擎之Impala-1</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E%E4%B9%8BImpala-1.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E%E4%B9%8BImpala-1.html</id>
    <published>2023-06-18T15:47:42.000Z</published>
    <updated>2023-06-19T15:53:39.955Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="数据分析引擎之Impala-1"><a href="#数据分析引擎之Impala-1" class="headerlink" title="数据分析引擎之Impala-1"></a>数据分析引擎之Impala-1</h1><h2 id="1-快速了解Impala"><a href="#1-快速了解Impala" class="headerlink" title="1 快速了解Impala"></a>1 快速了解Impala</h2><h3 id="什么是Impala"><a href="#什么是Impala" class="headerlink" title="什么是Impala"></a>什么是Impala</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">咱们在最开始学习大数据的时候学到了MapReduce这个框架，他可以对海量数据进行分布式计算分析，但是由于需要一定学习成本，并且对非开发人员不够友好，所以后来出现了Hive这个数据分析工具。</span><br><span class="line">Hive的优点是可以通过SQL直接计算分析HDFS中的海量数据，不需要写代码。</span><br><span class="line">不过由于Hive底层引擎默认使用的是MapReduce，所以在Hive中提交的SQL任务的延迟度和计算效率相对一般。</span><br><span class="line"></span><br><span class="line">在工作中我们希望能够在页面中输入一个SQL语句，点击查询按钮之后，可以快速查看结果，最好是能够在秒级别返回结果，这种数据分析需求也可以称之为即席查询。</span><br><span class="line"></span><br><span class="line">此时如果使用Hive，基本上需要在分钟级别才能返回结果，因为Hive接收到用户在页面上输入的SQL之后，需要先把SQL转化为MapReduce、再把MapReduce任务提交到YARN集群中，这个流程就需要消耗几秒或者十几秒了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">此时就需要有一个可以支持低延迟，并且计算效率也比较高的数据分析引擎了，所以Impala就出现了。</span><br><span class="line">Impala的出现主要就是为了解决Hive执行效率低下的问题。</span><br><span class="line"></span><br><span class="line">所以MapReduce、Hive和Impala之间的发展历程是这样的：MapReduce-&gt;Hive-&gt;Impala。</span><br><span class="line"></span><br><span class="line">官方一点的解释：</span><br><span class="line">Impala是一个开源的基于内存的快速查询分析引擎。</span><br><span class="line"></span><br><span class="line">他可以直接使用Hive的Metastore，也就是说Hive中创建的表，Impala可以直接使用；并且兼容HiveSQL，但是不是100%兼容，大部分的SQL语法都是兼容的。</span><br><span class="line"></span><br><span class="line">下面我们来分析一下Impala的优点和缺点</span><br></pre></td></tr></table></figure><h3 id="Impala的优点"><a href="#Impala的优点" class="headerlink" title="Impala的优点"></a>Impala的优点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1：基于内存运算，中间结果不落盘，节省大量的I&#x2F;O开销；因为在MapReduce任务中，Map阶段产生的中间结果需要先写磁盘，再通过Shuffle拷贝到Reduce阶段，所以会产生大量的I&#x2F;O，因此计算效率不如Impala。</span><br><span class="line">2：底层计算引擎由C++编写，通过LLVM统一编译运行，效率更高。LLVM是一个编译器。注意了，Impala底层的计算引擎没有使用大数据生态圈中的计算框架，它是自己单独实现的。</span><br><span class="line">3：兼容HiveSQL语法，学习成本低，容易上手。ImpalaSQL支持SQL92标准，并具有自己的解析器和优化器。SQL92是数据库的一个ANSI标准，HiveSQL也支持SQL92标准。</span><br><span class="line">4：兼容Hive的Metastore，可以直接使用Hive中的表。</span><br><span class="line">5：支持数据本地化(Data Locality)特性，提高计算效率。其实就是说Impala支持数据本地计算，前提是impala的服务需要和HDFS的datanode节点部署在一起。</span><br><span class="line">6：支持列式存储数据格式，可以和HBase整合。也就是说Impala可以通过SQL计算HBase中的数据。</span><br><span class="line">7：支持多种文件格式，例如：TextFile、SequenceFile、RCFile、ORC和Parquet。其实只要是Hive支持的数据格式，目前Impala都是支持的。</span><br><span class="line">8：支持ODBC&#x2F;JDBC远程访问，这样就可以无缝对接到Web项目，在页面操作起来更方便。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这是Impala的一些优点。</span><br><span class="line">当然了，没有绝对完美的技术框架，所以Impala也有一些缺点，下面我们来分析一下：</span><br></pre></td></tr></table></figure><h3 id="Impala的缺点"><a href="#Impala的缺点" class="headerlink" title="Impala的缺点"></a>Impala的缺点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1：基于内存进行计算，对内存依赖性较大。基于内存计算，既是优点，也是缺点。</span><br><span class="line">2：使用C++编写，意味着维护难度增加，相对而言，Java程序维护起来比较简单。</span><br><span class="line">3：分区数量超过一万，性能严重下降，容易出现问题。主要还是因为它是基于内存计算，单个SQL任务计算的数据量过大，对内存依赖就很大了，所以容易出现问题。</span><br><span class="line">4：基于Hive，与Hive共存亡。因为Impala需要使用Hive的Metastore来存储元数据信息。</span><br><span class="line">5：稳定性不如Hive。主要也是因为Impala是基于内存的，所以稳定性相对来说一般。</span><br><span class="line"></span><br><span class="line">这是Impala的一些缺点。</span><br></pre></td></tr></table></figure><h3 id="Impala-Hive"><a href="#Impala-Hive" class="headerlink" title="Impala + Hive"></a>Impala + Hive</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Impala和Hive之间的关系从这个图里面可以比较清晰的进行了解</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192236510.png" alt="image-20230619223624219"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">最底层是HDFS，接着是MapReduce、Hive对MapReduce做了封装，提供了SQL支持。</span><br><span class="line">Hive的元数据信息存储在Metastore中，Metastore我们一般是使用MySQL。</span><br><span class="line"></span><br><span class="line">Impala自己使用C++实现了一套分布式计算引擎，也可以直接操作HDFS中的数据，并且和Hive共享一个Metastore。</span><br></pre></td></tr></table></figure><h3 id="Impala三大核心组件"><a href="#Impala三大核心组件" class="headerlink" title="Impala三大核心组件"></a>Impala三大核心组件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Impala架构中主要包含三大核心组件：</span><br><span class="line"></span><br><span class="line">-Impala daemon：简称为impalad，它是Impala集群中的核心守护进程，需要在多个节点启动，一般会和DataNode节点部署在一起；他主要负责向Statestore保持通信，汇报工作。同时负责接收客户端的请求，执行查询，并把结果返回给客户端。</span><br><span class="line">-Statestore daemon：简称为statestored，他主要负责收集集群中各个Impalad进程的资源信息、各节点健康状况、同步节点信息，以及负责Query的协调调度。</span><br><span class="line">-Catalog daemon：简称为catalogd，他主要负责分发表的元数据信息到各个Impalad中，以及接收来自Statestore的所有请求。</span><br></pre></td></tr></table></figure><h3 id="Impala的整体运行架构"><a href="#Impala的整体运行架构" class="headerlink" title="Impala的整体运行架构"></a>Impala的整体运行架构</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Impala的整体运行架构是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192240701.png" alt="image-20230619224010407"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这个图里面包含了客户端、Hive Metastore、HDFS NameNode、HDFS DataNode、HBase以及Impala中的Statestore、Catalog、Impalad这三个核心组件。</span><br><span class="line">其中Hive Metastore是负责维护Impala元数据信息的，HDFS和HBase都是可以作为Impala底层数据存储的组件</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">客户端向Impala发送请求时的整个执行流程是这样的：</span><br><span class="line">（1）客户端向某一个Impalad发送一个Query（SQL）。</span><br><span class="line">（2）Impalad将Query解析为具体的Planner（执行计划）, 然后交给当前机器的Coordinator（中心协调节点）。</span><br><span class="line">（3）Coordinator根据Planner，通过本机的Executor执行，并转发给其他有数据的Impalad。</span><br><span class="line">（4）多个Impalad的Executor之间会进行通信，可能需要一些数据的处理。</span><br><span class="line">（5）各个Impalad的Executor执行完成后，会将结果返回给Coordinator。</span><br><span class="line">（6）由Coordinator将汇聚的查询结果返回给客户端。</span><br></pre></td></tr></table></figure><h2 id="2-快速上手使用Impala"><a href="#2-快速上手使用Impala" class="headerlink" title="2 快速上手使用Impala"></a>2 快速上手使用Impala</h2><h3 id="Impala的安装部署"><a href="#Impala的安装部署" class="headerlink" title="Impala的安装部署"></a>Impala的安装部署</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">单独安装Impala是不靠谱的想法，尽快忘了它！！！，因为单独安装Impala需要自己编译、编译的时候需要依赖很多外部依赖，以及一些依赖冲突的问题，所以不建议单独安装。</span><br><span class="line"></span><br><span class="line">强烈推荐通过CDH平台安装Impala！！！CDH中集成的有Impala，安装非常方便，只需要点击下一步即可安装成功。</span><br><span class="line"></span><br><span class="line">咱们本套课程的配套电子书中提供了CDH的安装部署步骤，其中CDH的版本是6.2.1，这个CDH版本中集成的Impala是3.2.0版本。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注意了：想要安装CDH，对机器配置有一定的要求，如果本地环境不允许的话，不建议去折腾了，意义不大。</span><br><span class="line"></span><br><span class="line">自己本地没有CDH集群的话，针对Impala的内容大家暂时就无法在本地实操了，其实也不用特别担心，因为只要掌握了Hive的使用，想要使用Impala基本上可以直接上手。</span><br><span class="line"></span><br><span class="line">咱们本次课程主要讲一些Impala和Hive的区别，这些内容大家前期有个概念，了解一下即可。</span><br><span class="line">Impala的内容其实之前没有规划到课程中，后来考虑到个别同学反馈了，所以把这块内容扩展到课程中。</span><br><span class="line"></span><br><span class="line">我的个人建议，Impala这块内容作为【选学】即可。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Impala集群节点的规划是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192249528.png" alt="image-20230619224922160"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Impala中的Catalog和Statestore进程所在的节点可以认为是主节点，建议把这两个进程部署在一起，因为他们两个之间需要经常通信。</span><br><span class="line"></span><br><span class="line">Impala中的Daemon进程所在的节点可以认为是从节点，Daemon进程建议和Hadoop集群中的DataNode节点部署在一起，这样可以实现数据本地计算，提高计算效率。</span><br><span class="line">Daemon进程可以根据需要部署多个。</span><br><span class="line"></span><br><span class="line">想要使用Impala，是需要在CDH平台中安装的。</span><br><span class="line"></span><br><span class="line">下面演示一下如何在CDH平台中安装Impala。</span><br></pre></td></tr></table></figure><h3 id="CDH平台中安装Impala"><a href="#CDH平台中安装Impala" class="headerlink" title="CDH平台中安装Impala"></a>CDH平台中安装Impala</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">进入CM首页。</span><br><span class="line"></span><br><span class="line">注意：需要先启动Cloudera Management Service和Cluster 1。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">添加服务：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192256560.png" alt="image-20230619225626270"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">选择Impala，然后点击继续按钮：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192257398.png" alt="image-20230619225744765"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">如果cdh01主节点的内存足够使用的话，建议将StateStore和Catalog Server服务放到cdh01主节点中。</span><br><span class="line">Impala Daemon服务放在从节点中。</span><br><span class="line">当然了，也可以选择使用系统分配的，这样什么都不用改。</span><br><span class="line">点击继续按钮：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192303071.png" alt="image-20230619230300013"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">什么都不用改，点击继续按钮：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192303781.png" alt="image-20230619230328291"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">等待状态变为 已完成，然后点击继续按钮：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192304635.png" alt="image-20230619230400853"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">点击完成按钮即可：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192304737.png" alt="image-20230619230421779"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时Impala服务已经安装成功了，但是还需要重启HDFS服务，点击重启按钮：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192304058.png" alt="image-20230619230450678"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">确认更改信息，直接点击 重启过时服务按钮即可：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192305836.png" alt="image-20230619230549712"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：先选中【重新部署客户端配置】，然后再点击右下角的立即重启按钮：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192306573.png" alt="image-20230619230610504"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">等待服务重启成功，状态变为 已完成，最后点击完成按钮即可。到这位置，Impala就安装好了。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192306696.png" alt="image-20230619230636217"></p><h3 id="处理HDFS的权限问题"><a href="#处理HDFS的权限问题" class="headerlink" title="处理HDFS的权限问题"></a>处理HDFS的权限问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：由于我们现在默认使用的Linux中的root用户，所以在操作HDFS的时候会遇到一些权限问题，解决方案有2个：</span><br><span class="line"></span><br><span class="line">1：关闭HDFS的权限校验。(这种方式简单、直接、生产环境不推荐，测试环境推荐)。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192252632.png" alt="image-20230619225216524"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192252028.png" alt="image-20230619225257427"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192253017.png" alt="image-20230619225315978"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192253086.png" alt="image-20230619225343423"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2：先在Linux添加supergroup组，把root用户添加到supergroup里，再同步权限到HDFS。</span><br><span class="line">具体命令如下【这些命令需要在CDH集群中所有节点执行】。</span><br><span class="line">(这种方式相对比较麻烦，但是更合理，生产环境下推荐，测试环境不推荐)。</span><br><span class="line"></span><br><span class="line"># 添加supergroup组</span><br><span class="line">groupadd supergroup</span><br><span class="line"># root用户加入supergroup组</span><br><span class="line">usermod -a -G supergroup root</span><br><span class="line"># 同步系统的权限信息到HDFS</span><br><span class="line">sudo -u hdfs hdfs dfsadmin -refreshUserToGroupsMappings</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在测试环境建议使用第一种方式。</span><br></pre></td></tr></table></figure><h3 id="Impala的常见操作方式"><a href="#Impala的常见操作方式" class="headerlink" title="Impala的常见操作方式"></a>Impala的常见操作方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Impala可以支持多种操作方式，在不同的应用场景中，可以选择不同的操作方式。</span><br><span class="line"></span><br><span class="line">-在开发阶段，一般会使用impala-shell这个客户端命令行操作。</span><br><span class="line">-如果想要在某一个Web项目中提供基于Impala的即席查询功能，那么需要使用JDBC代码的方式操作Impala。</span><br><span class="line">-在日常查询使用的时候，特别是针对非开发人员，常见的是在Hue这种Web页面中进行操作，不需要连接Linux服务器，直接在浏览器页面中操作，非常方便。</span><br></pre></td></tr></table></figure><h4 id="impala-shell客户端命令行"><a href="#impala-shell客户端命令行" class="headerlink" title="impala-shell客户端命令行"></a>impala-shell客户端命令行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">进入cdh01机器：</span><br><span class="line">直接执行impala-shell脚本即可，因为CDH安装好Impala之后，会默认把Impala配置到环境变量中，所以它里面的脚本是可以在任意目录下使用的。</span><br><span class="line"></span><br><span class="line">在cdh01中直接执行impala-shell脚本：</span><br><span class="line">[root@cdh01 ~]# impala-shell </span><br><span class="line">Starting Impala Shell without Kerberos authentication</span><br><span class="line">Error connecting: TTransportException, Could not connect to cdh01:21000</span><br><span class="line">***********************************************************************************</span><br><span class="line">Welcome to the Impala shell.</span><br><span class="line">(Impala Shell v3.2.0-cdh6.2.1 (525e372) built on Wed Sep 11 01:30:44 PDT 2019)</span><br><span class="line"></span><br><span class="line">Press TAB twice to see a list of available commands.</span><br><span class="line">***********************************************************************************</span><br><span class="line">[Not connected] &gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">此时发现里面有报错信息，提示的是无法连接cdh01:21000。</span><br><span class="line">21000端口对应的是impalad服务的端口，但是在cdh01上并没有启动impalad服务，所以默认连不上，impala-shell默认会连接当前节点上的impalad服务。</span><br><span class="line">里面显示的也是[Not connected]，这种情况下是无法操作Impala的。</span><br><span class="line">因为在Impala中，只有连接到impalad所在的节点后才能执行查询操作，接受了连接的impalad节点将作为协调者运行查询任务。</span><br><span class="line"></span><br><span class="line">为了解决这个问题，可以通过下面三种方法：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">第一种方法：</span><br><span class="line">可以通过connect参数指定连接其它节点中的impalad服务。</span><br><span class="line">[Not connected] &gt; connect cdh02:21000;</span><br><span class="line">Connection lost, reconnecting...</span><br><span class="line">Error connecting: TTransportException, Could not connect to cdh01:21000</span><br><span class="line">Opened TCP connection to cdh02:21000</span><br><span class="line">Connected to cdh02:21000</span><br><span class="line">Server version: impalad version 3.2.0-cdh6.2.1 RELEASE (build 525e372410dd2ce206e2ad0f21f57cae7380c0cb)</span><br><span class="line">[cdh02:21000] default&gt; </span><br><span class="line"></span><br><span class="line">退出impala-shell客户端，使用ctrl+c无法强制退出：</span><br><span class="line">可以使用quit或者exit。</span><br><span class="line">[cdh02:21000] default&gt; quit;</span><br><span class="line">Goodbye root</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">第二种方法：</span><br><span class="line">也可以在启动impala-shell客户端的时候通过-i参数指定连接其它节点中的impalad服务。</span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000</span><br><span class="line">Starting Impala Shell without Kerberos authentication</span><br><span class="line">Opened TCP connection to cdh02:21000</span><br><span class="line">Connected to cdh02:21000</span><br><span class="line">Server version: impalad version 3.2.0-cdh6.2.1 RELEASE (build 525e372410dd2ce206e2ad0f21f57cae7380c0cb)</span><br><span class="line">***********************************************************************************</span><br><span class="line">Welcome to the Impala shell.</span><br><span class="line">(Impala Shell v3.2.0-cdh6.2.1 (525e372) built on Wed Sep 11 01:30:44 PDT 2019)</span><br><span class="line"></span><br><span class="line">After running a query, type SUMMARY to see a summary of where time was spent.</span><br><span class="line">***********************************************************************************</span><br><span class="line">[cdh02:21000] default&gt; </span><br><span class="line"></span><br><span class="line">退出impala-shell客户端：</span><br><span class="line">[cdh02:21000] default&gt; quit;</span><br><span class="line">Goodbye root</span><br><span class="line"></span><br><span class="line">注意：impalad服务的端口默认21000，如果没有修改的话，在使用-i和connect指定的时候，端口是可以省略不写的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">第三种方法：</span><br><span class="line">在impalad服务所在的节点(cdh02 或者cdh03)执行使用impala-shell脚本即可</span><br><span class="line"></span><br><span class="line">[root@cdh02 ~]# impala-shell </span><br><span class="line">Starting Impala Shell without Kerberos authentication</span><br><span class="line">Opened TCP connection to cdh02:21000</span><br><span class="line">Connected to cdh02:21000</span><br><span class="line">Server version: impalad version 3.2.0-cdh6.2.1 RELEASE (build 525e372410dd2ce206e2ad0f21f57cae7380c0cb)</span><br><span class="line">***********************************************************************************</span><br><span class="line">Welcome to the Impala shell.</span><br><span class="line">(Impala Shell v3.2.0-cdh6.2.1 (525e372) built on Wed Sep 11 01:30:44 PDT 2019)</span><br><span class="line"></span><br><span class="line">The &#39;-B&#39; command line flag turns off pretty-printing for query results. Use this</span><br><span class="line">flag to remove formatting from results you want to save for later, or to benchmark</span><br><span class="line">Impala.</span><br><span class="line">***********************************************************************************</span><br><span class="line">[cdh02:21000] default&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不过在实际工作中我们操作Impala一般都是在客户端节点操作的，所以还是需要通过-i或者connect参数指定impalad节点的。</span><br></pre></td></tr></table></figure><h5 id="h-–help"><a href="#h-–help" class="headerlink" title="-h / –help"></a>-h / –help</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">在impala-shell脚本后面还可以指定一些高级命令，下面我们来看一些比较常见的：</span><br><span class="line"></span><br><span class="line">-h &#x2F; --help：这个属于帮助命令，可以查看impala-shell脚本后面都可以支持哪些命令，以及这些命令的含义。</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# impala-shell -h</span><br><span class="line">Usage: impala_shell.py [options]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  -i IMPALAD, --impalad&#x3D;IMPALAD</span><br><span class="line">                        &lt;host:port&gt; of impalad to connect to</span><br><span class="line">                        [default: cdh01:21000]</span><br><span class="line">  -b KERBEROS_HOST_FQDN, --kerberos_host_fqdn&#x3D;KERBEROS_HOST_FQDN</span><br><span class="line">                        If set, overrides the expected hostname of the</span><br><span class="line">                        Impalad&#39;s kerberos service principal. impala-shell</span><br><span class="line">                        will check that the server&#39;s principal matches this</span><br><span class="line">                        hostname. This may be used when impalad is configured</span><br><span class="line">                        to be accessed via a load-balancer, but it is desired</span><br><span class="line">                        for impala-shell to talk to a specific impalad</span><br><span class="line">                        directly. [default: none]</span><br><span class="line">  -q QUERY, --query&#x3D;QUERY</span><br><span class="line">                        Execute a query without the shell [default: none]</span><br><span class="line">........</span><br></pre></td></tr></table></figure><h5 id="v：查询当前Impala的版本。"><a href="#v：查询当前Impala的版本。" class="headerlink" title="-v：查询当前Impala的版本。"></a>-v：查询当前Impala的版本。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@cdh01 ~]# impala-shell -v</span><br><span class="line">Impala Shell v3.2.0-cdh6.2.1 (525e372) built on Wed Sep 11 01:30:44 PDT 2019</span><br></pre></td></tr></table></figure><h5 id="B-–delimited：对Impala的查询结果进行格式化。"><a href="#B-–delimited：对Impala的查询结果进行格式化。" class="headerlink" title="-B / –delimited：对Impala的查询结果进行格式化。"></a>-B / –delimited：对Impala的查询结果进行格式化。</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">默认Impala中返回的结果数据是使用表格的样式格式化的，但是有时候我们想把impala查询的结果输出到文件中，便于后续其他的程序使用，这样就不希望把额外的表格输出到文件中了，只需要核心的数据内容即可。</span><br><span class="line">先来看一下默认的格式：</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000</span><br><span class="line">[cdh02:21000] default&gt; create table im_t1(id int,name string);</span><br><span class="line">[cdh02:21000] default&gt; insert into im_t1(id,name) values(1,&#39;zs&#39;);</span><br><span class="line">[cdh02:21000] default&gt; insert into im_t1(id,name) values(2,&#39;ls&#39;);</span><br><span class="line">[cdh02:21000] default&gt; select * from im_t1;</span><br><span class="line">Query: select * from im_t1</span><br><span class="line">Query submitted at: 2022-08-16 15:52:27 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;5c47ba992fa4a26e:130a8aa600000000</span><br><span class="line">+----+------+</span><br><span class="line">| id | name |</span><br><span class="line">+----+------+</span><br><span class="line">| 1  | zs   |</span><br><span class="line">| 2  | ls   |</span><br><span class="line">+----+------+</span><br><span class="line">Fetched 2 row(s) in 0.39s</span><br><span class="line">[cdh02:21000] default&gt; quit;</span><br><span class="line">Goodbye root</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">此时可以发现结果数据会使用表格进行格式化，这样其实看起来是比较清晰的，但是这种数据格式不便于后期使用。</span><br><span class="line"></span><br><span class="line">使用-B参数。</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000 -B</span><br><span class="line">[cdh02:21000] default&gt; select * from im_t1;</span><br><span class="line">Query: select * from im_t1</span><br><span class="line">Query submitted at: 2022-08-16 15:55:01 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;ef4080b39db068aa:9601e27400000000</span><br><span class="line">1       zs</span><br><span class="line">2       ls</span><br><span class="line">Fetched 2 row(s) in 0.35s</span><br><span class="line">[cdh02:21000] default&gt; quit;</span><br><span class="line">Goodbye root</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时可以看到结果数据就比较干净了，只有数据自身的内容，默认情况下字段之间的分隔符是制表符。</span><br></pre></td></tr></table></figure><h5 id="–output-delimiter：指定字段分隔符，默认-t"><a href="#–output-delimiter：指定字段分隔符，默认-t" class="headerlink" title="–output_delimiter：指定字段分隔符，默认\t"></a>–output_delimiter：指定字段分隔符，默认\t</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">在使用-B对数据结果进行格式化的时候，如果想自定义字段分隔符，还需要使用这个参数。</span><br><span class="line">使用逗号作为字段分隔符：</span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000 -B --output_delimiter &#39;,&#39;</span><br><span class="line">[cdh02:21000] default&gt; select * from im_t1;</span><br><span class="line">Query: select * from im_t1</span><br><span class="line">Query submitted at: 2022-08-16 15:57:41 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;c44e0ac395b5a6fd:831ea74700000000</span><br><span class="line">2,ls</span><br><span class="line">1,zs</span><br><span class="line">Fetched 2 row(s) in 0.35s</span><br><span class="line">[cdh02:21000] default&gt; quit;</span><br><span class="line">Goodbye root</span><br></pre></td></tr></table></figure><h5 id="o-–output-file：将查询结果输出到指定的文件中"><a href="#o-–output-file：将查询结果输出到指定的文件中" class="headerlink" title="-o / –output_file：将查询结果输出到指定的文件中"></a>-o / –output_file：将查询结果输出到指定的文件中</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">现在查询的结果还是输出在控制台中，想要将结果输出到文件中的话需要使用这个参数指定目标文件名。</span><br><span class="line"></span><br><span class="line">注意：这里不能使用hdfs路径，只能使用本地路径。</span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000 -B --output_delimiter &#39;,&#39; -o im_t1.dat</span><br><span class="line">[cdh02:21000] default&gt; select * from im_t1;</span><br><span class="line">Query: select * from im_t1</span><br><span class="line">Query submitted at: 2022-08-16 16:17:47 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;df43106813c0de1b:1dc183d000000000</span><br><span class="line">Fetched 2 row(s) in 0.35s</span><br><span class="line">[cdh02:21000] default&gt; quit;</span><br><span class="line">Goodbye root</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">此时发现在命令行中执行select语句是看不到返回结果的，因为这些结果数据会输出到im_t1.dat文件中。</span><br><span class="line">到当前目录下查看一下im_t1.dat文件中的内容：</span><br><span class="line">[root@cdh01 ~]# more im_t1.dat </span><br><span class="line">1,zs</span><br><span class="line">2,ls</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">但是这种方式用起来还是不方便，我们还需要先进入到impala-shell客户端里面之后才能执行查询命名，能不能在不进入impala-shell客户端的情况下实现这种需求呢？其实就是实现类似于hive -e这种效果。</span><br></pre></td></tr></table></figure><h5 id="q-–query：指定查询语句"><a href="#q-–query：指定查询语句" class="headerlink" title="-q / –query：指定查询语句"></a>-q / –query：指定查询语句</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">通过-q参数可以在命令行中指定sql语句，不需要进入impala-shell客户端里面，适合在脚本中封装impala sql语句。</span><br><span class="line"></span><br><span class="line">在演示之前，先把im_t1.dat文件删掉，这样对比起来比较清晰。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@cdh01 ~]# rm -rf im_t1.dat</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">然后使用-q指定select查询语句。</span><br><span class="line"></span><br><span class="line">[root@cdh01 ~]# impala-shell -i cdh02:21000 -B --output_delimiter &#39;,&#39; -q &#39;select * from im_t1&#39; -o im_t1.dat</span><br><span class="line">Starting Impala Shell without Kerberos authentication</span><br><span class="line">Opened TCP connection to cdh02:21000</span><br><span class="line">Connected to cdh02:21000</span><br><span class="line">Server version: impalad version 3.2.0-cdh6.2.1 RELEASE (build 525e372410dd2ce206e2ad0f21f57cae7380c0cb)</span><br><span class="line">Query: select * from im_t1</span><br><span class="line">Query submitted at: 2022-08-16 16:25:43 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;2442747abbbf7f81:77c65fec00000000</span><br><span class="line">Fetched 2 row(s) in 0.34s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">查看im_t1.dat文件中的内容：</span><br><span class="line">[root@cdh01 ~]# more im_t1.dat </span><br><span class="line">1,zs</span><br><span class="line">2,ls</span><br><span class="line"></span><br><span class="line">此时这条impala sql命令就可以封装到shell脚本中定时调度了。</span><br><span class="line">其实-q中指定的sql也可以使用insert into select这种形式的，这样就不需要使用-o指定输出文件路径信息了。</span><br><span class="line">-q里面可以指定多条SQL语句，多条SQL语句之间使用分割(;)隔开即可。</span><br></pre></td></tr></table></figure><h4 id="JDBC访问"><a href="#JDBC访问" class="headerlink" title="JDBC访问"></a>JDBC访问</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">下面看一下如何使用JDBC代码操作Impala。</span><br><span class="line"></span><br><span class="line">创建项目：db_impala</span><br><span class="line">创建package：com.imooc.impala</span><br><span class="line"></span><br><span class="line">向pom.xml中添加依赖，直接使用Hive的jdbc依赖即可。</span><br><span class="line">&lt;!-- Hive JDBC依赖 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hive&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hive-jdbc&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.1.2&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;exclusions&gt;</span><br><span class="line">        &lt;exclusion&gt;</span><br><span class="line">            &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;&#x2F;exclusion&gt;</span><br><span class="line">    &lt;&#x2F;exclusions&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">向resources目录中添加日志配置文件：log4j2.xml，文件内容如下：</span><br><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;Configuration status&#x3D;&quot;INFO&quot;&gt;</span><br><span class="line">    &lt;Appenders&gt;</span><br><span class="line">        &lt;Console name&#x3D;&quot;Console&quot; target&#x3D;&quot;SYSTEM_OUT&quot;&gt;</span><br><span class="line">            &lt;PatternLayout pattern&#x3D;&quot;%d&#123;YYYY-MM-dd HH:mm:ss&#125; [%t] %-5p %c&#123;1&#125;:%L - %msg%n&quot; &#x2F;&gt;</span><br><span class="line">        &lt;&#x2F;Console&gt;</span><br><span class="line">    &lt;&#x2F;Appenders&gt;</span><br><span class="line">    &lt;Loggers&gt;</span><br><span class="line">        &lt;Root level&#x3D;&quot;info&quot;&gt;</span><br><span class="line">            &lt;AppenderRef ref&#x3D;&quot;Console&quot; &#x2F;&gt;</span><br><span class="line">        &lt;&#x2F;Root&gt;</span><br><span class="line">    &lt;&#x2F;Loggers&gt;</span><br><span class="line">&lt;&#x2F;Configuration&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">创建类：ImpalaJdbcDemo</span><br><span class="line"></span><br><span class="line">代码如下：</span><br><span class="line">package com.imooc.impala;</span><br><span class="line"></span><br><span class="line">import java.sql.Connection;</span><br><span class="line">import java.sql.DriverManager;</span><br><span class="line">import java.sql.ResultSet;</span><br><span class="line">import java.sql.Statement;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * JDBC代码操作Impala</span><br><span class="line"> *</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class ImpalaJdbcDemo &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        &#x2F;&#x2F;指定jdbcurl链接，需要连接到impalad服务(cdh02或者cdh03)</span><br><span class="line">        String jdbcUrl &#x3D; &quot;jdbc:hive2:&#x2F;&#x2F;cdh03:21050&#x2F;;auth&#x3D;noSasl&quot;;</span><br><span class="line">        &#x2F;&#x2F;获取链接</span><br><span class="line">        Connection conn &#x3D; DriverManager.getConnection(jdbcUrl);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;获取Statement</span><br><span class="line">        Statement stmt &#x3D; conn.createStatement();</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;指定查询的sql</span><br><span class="line">        String sql &#x3D; &quot;select * from im_t1&quot;;</span><br><span class="line">        &#x2F;&#x2F;执行sql</span><br><span class="line">        ResultSet res &#x3D; stmt.executeQuery(sql);</span><br><span class="line">        &#x2F;&#x2F;循环读取结果</span><br><span class="line">        while(res.next())&#123;</span><br><span class="line">            System.out.println(res.getInt(&quot;id&quot;)+&quot;\t&quot;+res.getString(&quot;name&quot;));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Hue访问"><a href="#Hue访问" class="headerlink" title="Hue访问"></a>Hue访问</h4><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192326319.png" alt="image-20230619232622289"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192326216.png" alt="image-20230619232649293"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：第一次使用hue时，需要创建hue的账号，输入用户名和密码则会自动创建，这个账户将会是超级管理员账户。</span><br><span class="line"></span><br><span class="line">账号创建好之后会进入这个界面。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192327779.png" alt="image-20230619232756531"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在查询按钮中可以选择Hue支持查询的组件，里面默认是没有Impala的。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192328814.png" alt="image-20230619232830040"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">注意：默认CDH中提供的Hue里面是不支持访问Impala，需要在Hue配置中开启才可以。</span><br><span class="line"></span><br><span class="line">下面到Hue中进行配置，增加对Impala的支持。</span><br><span class="line"></span><br><span class="line">选中Impala、然后点击保存更改按钮。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192328428.png" alt="image-20230619232857541"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">保存更改后，需要重启Hue，因为配置发生了变化。</span><br><span class="line"></span><br><span class="line">点击重启过时服务按钮。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192329726.png" alt="image-20230619232941817"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192329706.png" alt="image-20230619232952645"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">选中重新部署客户端配置，然后点击立即重启按钮即可。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192330388.png" alt="image-20230619233024236"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">等待状态变为已完成，点击完成按钮即可。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192330988.png" alt="image-20230619233039862"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最终的效果是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192330606.png" alt="image-20230619233056256"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">此时就可以选择Impala编辑器来操作Impala了。</span><br><span class="line"></span><br><span class="line">在Hue中执行Impala SQL语句：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192331328.png" alt="image-20230619233124191"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192331448.png" alt="image-20230619233143575"></p><h3 id="Impala的常见使用"><a href="#Impala的常见使用" class="headerlink" title="Impala的常见使用"></a>Impala的常见使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Impala中的DDL和DML语句和Hive中的用法基本上是一样的，并且Impala中也支持内部表、外部表和分区表，下面我们来实际体验一下：</span><br></pre></td></tr></table></figure><h4 id="内部表的使用"><a href="#内部表的使用" class="headerlink" title="内部表的使用"></a>内部表的使用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">创建内部表：im_inner_table</span><br><span class="line"></span><br><span class="line">create table im_inner_table(</span><br><span class="line">  id int,</span><br><span class="line">  name string,</span><br><span class="line">  age int,</span><br><span class="line">  birthday timestamp</span><br><span class="line">)row format delimited </span><br><span class="line">fields terminated by &#39;\t&#39; </span><br><span class="line">lines terminated by &#39;\n&#39;;</span><br><span class="line"></span><br><span class="line">注意：Impala中日期类型不支持Date，只支持Timestamp。Hive中这两种日期类型都支持。</span><br></pre></td></tr></table></figure><h5 id="desc"><a href="#desc" class="headerlink" title="desc"></a>desc</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">查看表中的字段信息，以及详细建表语句。</span><br><span class="line"></span><br><span class="line">[cdh02:21000] default&gt; desc im_inner_table;</span><br><span class="line">Query: describe im_inner_table</span><br><span class="line">+----------+-----------+---------+</span><br><span class="line">| name     | type      | comment |</span><br><span class="line">+----------+-----------+---------+</span><br><span class="line">| id       | int       |         |</span><br><span class="line">| name     | string    |         |</span><br><span class="line">| age      | int       |         |</span><br><span class="line">| birthday | timestamp |         |</span><br><span class="line">+----------+-----------+---------+</span><br><span class="line">Fetched 4 row(s) in 0.06s</span><br><span class="line">[cdh02:21000] default&gt; show create table im_inner_table;</span><br><span class="line">Query: show create table im_inner_table</span><br><span class="line">+-------------------------------------------------------------------------------------------+</span><br><span class="line">| result                                                                                    |</span><br><span class="line">+-------------------------------------------------------------------------------------------+</span><br><span class="line">| CREATE TABLE default.im_inner_table (                                                     |</span><br><span class="line">|   id INT,                                                                                 |</span><br><span class="line">|   name STRING,                                                                            |</span><br><span class="line">|   age INT,                                                                                |</span><br><span class="line">|   birthday TIMESTAMP                                                                      |</span><br><span class="line">| )                                                                                         |</span><br><span class="line">| ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\t&#39; LINES TERMINATED BY &#39;\n&#39;                   |</span><br><span class="line">| WITH SERDEPROPERTIES (&#39;field.delim&#39;&#x3D;&#39;\t&#39;, &#39;line.delim&#39;&#x3D;&#39;\n&#39;, &#39;serialization.format&#39;&#x3D;&#39;\t&#39;) |</span><br><span class="line">| STORED AS TEXTFILE                                                                        |</span><br><span class="line">| LOCATION &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;im_inner_table&#39;                           |</span><br><span class="line">|                                                                                           |</span><br><span class="line">+-------------------------------------------------------------------------------------------+</span><br><span class="line">Fetched 1 row(s) in 0.04s</span><br><span class="line">[cdh02:21000] default&gt;</span><br></pre></td></tr></table></figure><h5 id="load加载数据"><a href="#load加载数据" class="headerlink" title="load加载数据"></a>load加载数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">表需要加载的数据文件为im_inner_table.dat，字段分隔符使用制表符，文件内容如下：</span><br><span class="line">[root@cdh01 ~]# vi im_inner_table.dat</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line"></span><br><span class="line">将此数据文件上传至hdfs中。</span><br><span class="line">因为impala中在使用load data命令加载数据时不支持local参数，所以需要指定hdfs路径。</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -mkdir &#x2F;data</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put im_inner_table.dat &#x2F;data</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">使用load data命令加载数据：</span><br><span class="line">[cdh02:21000] default&gt; load data inpath &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat&#39; into table im_inner_table;</span><br><span class="line">Query: load data inpath &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat&#39; into table im_inner_table</span><br><span class="line">ERROR: AnalysisException: Unable to LOAD DATA from hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat because Impala does not have WRITE permissions on its parent directory hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data</span><br><span class="line"></span><br><span class="line">执行报错，提示impala针对&#x2F;data目录没有写权限。</span><br><span class="line"></span><br><span class="line">因为Impala是使用impala用户操作hdfs，所以没有权限，可以考虑修改hdfs中&#x2F;data目录的读写权限。</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -chmod -R 777 &#x2F;data</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">再尝试加载数据：</span><br><span class="line">[cdh02:21000] default&gt; load data inpath &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat&#39; into table im_inner_table;</span><br><span class="line">Query: load data inpath &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat&#39; into table im_inner_table</span><br><span class="line">+----------------------------------------------------------+</span><br><span class="line">| summary                                                  |</span><br><span class="line">+----------------------------------------------------------+</span><br><span class="line">| Loaded 1 file(s). Total files in destination location: 1 |</span><br><span class="line">+----------------------------------------------------------+</span><br><span class="line">Fetched 1 row(s) in 0.39s</span><br><span class="line"></span><br><span class="line">提示数据加载成功。</span><br><span class="line">查询表中的数据：</span><br><span class="line">[cdh02:21000] default&gt; select * from im_inner_table;             </span><br><span class="line">Query: select * from im_inner_table</span><br><span class="line">Query submitted at: 2022-08-17 11:34:23 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;e241cccdd748bc56:e25e63af00000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 3 row(s) in 0.57s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：impala中第一次查询一个表的时候会有点慢，后续查询就快了。</span><br><span class="line"></span><br><span class="line">此时到HDFS中验证一下表中的数据文件：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192341003.png" alt="image-20230619234100763"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192341451.png" alt="image-20230619234111203"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Impala中的元数据会存储在Hive的Metastore中，所以我们到Hive对应的MySQL中查看一下表信息：</span><br><span class="line">CDH中Hive的元数据库名称默认就是：metastore。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192343505.png" alt="image-20230619234348237"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看表tbls中的数据：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306192344780.png" alt="image-20230619234421486"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">我们在impala中基于这个表执行一个group by功能，大家可以对比一下和Hive中执行的效率：</span><br><span class="line">[cdh02:21000] default&gt; select count(*),name from im_inner_table group by name;</span><br><span class="line">Query: select count(*),name from im_inner_table group by name</span><br><span class="line">Query submitted at: 2022-08-17 11:46:21 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;e43c81320d3157b:48ffbbfc00000000</span><br><span class="line">+----------+------+</span><br><span class="line">| count(*) | name |</span><br><span class="line">+----------+------+</span><br><span class="line">| 1        | ls   |</span><br><span class="line">| 1        | jack |</span><br><span class="line">| 1        | zs   |</span><br><span class="line">+----------+------+</span><br><span class="line">Fetched 3 row(s) in 0.46s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时发现在impala中执行是很快的，只需要0.4秒左右。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">下面在hive中执行，因为他们使用的是同一个元数据库，所以在hive中也可以看到这个表，并且也可以正常使用：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@cdh01 ~]# hive</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">im_inner_table</span><br><span class="line">im_t1</span><br><span class="line">Time taken: 5.503 seconds, Fetched: 2 row(s)</span><br><span class="line">hive&gt; select count(*),name from im_inner_table group by name;</span><br><span class="line">Query ID &#x3D; root_20220817114954_acf8dfbe-e2c2-44ec-9e1a-f70436f53d51</span><br><span class="line">Total jobs &#x3D; 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks not specified. Estimated from input data size: 1</span><br><span class="line">In order to change the average load for a reducer (in bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer&#x3D;&lt;number&gt;</span><br><span class="line">In order to limit the maximum number of reducers:</span><br><span class="line">  set hive.exec.reducers.max&#x3D;&lt;number&gt;</span><br><span class="line">In order to set a constant number of reducers:</span><br><span class="line">  set mapreduce.job.reduces&#x3D;&lt;number&gt;</span><br><span class="line">22&#x2F;08&#x2F;17 11:50:00 INFO client.RMProxy: Connecting to ResourceManager at cdh01&#x2F;192.168.1.101:8032</span><br><span class="line">22&#x2F;08&#x2F;17 11:50:01 INFO client.RMProxy: Connecting to ResourceManager at cdh01&#x2F;192.168.1.101:8032</span><br><span class="line">Starting Job &#x3D; job_1660295939533_0003, Tracking URL &#x3D; http:&#x2F;&#x2F;cdh01:8088&#x2F;proxy&#x2F;application_1660295939533_0003&#x2F;</span><br><span class="line">Kill Command &#x3D; &#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH-6.2.1-1.cdh6.2.1.p0.1425774&#x2F;lib&#x2F;hadoop&#x2F;bin&#x2F;hadoop job  -kill job_1660295939533_0003</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</span><br><span class="line">2022-08-17 11:50:31,713 Stage-1 map &#x3D; 0%,  reduce &#x3D; 0%</span><br><span class="line">2022-08-17 11:50:51,427 Stage-1 map &#x3D; 100%,  reduce &#x3D; 0%</span><br><span class="line">2022-08-17 11:51:06,828 Stage-1 map &#x3D; 100%,  reduce &#x3D; 100%, Cumulative CPU 19.05 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 19 seconds 50 msec</span><br><span class="line">Ended Job &#x3D; job_1660295939533_0003</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.05 sec   HDFS Read: 8701 HDFS Write: 140 HDFS EC Read: 0 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 19 seconds 50 msec</span><br><span class="line">OK</span><br><span class="line">1       jack</span><br><span class="line">1       ls</span><br><span class="line">1       zs</span><br><span class="line">Time taken: 75.01 seconds, Fetched: 3 row(s)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在hive中执行就比较慢了，大致需要75秒，而Impala执行只需要0.4秒（第一次大致需要0.57秒），所以他们之间的对比就非常明显了。</span><br></pre></td></tr></table></figure><h4 id="外部表的使用"><a href="#外部表的使用" class="headerlink" title="外部表的使用"></a>外部表的使用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">创建外部表：im_external_table</span><br><span class="line">create external table im_external_table(</span><br><span class="line">  id int,</span><br><span class="line">  name string,</span><br><span class="line">  age int,</span><br><span class="line">  birthday timestamp</span><br><span class="line">)row format delimited </span><br><span class="line">fields terminated by &#39;\t&#39; </span><br><span class="line">lines terminated by &#39;\n&#39;</span><br><span class="line">location &#39;&#x2F;data&#x2F;im_external_table&#39;;</span><br><span class="line"></span><br><span class="line">表需要加载的数据文件为im_external_table.dat，字段分隔符使用制表符，文件内容如下：</span><br><span class="line">[root@cdh01 ~]# vi im_external_table.dat</span><br><span class="line">1       zs      18      2001-01-01 10:10:10</span><br><span class="line">2       ls      17      2002-02-02 12:12:12</span><br><span class="line">3       jack    19      2000-09-21 18:10:10</span><br><span class="line"></span><br><span class="line">此时可以直接使用hdfs的put命令将数据文件上传到指定目录中，使用load data命令也可以。</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put im_external_table.dat &#x2F;data&#x2F;im_external_table</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">查询外部表中的数据：</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_table;</span><br><span class="line">Query: select * from im_external_table</span><br><span class="line">Query submitted at: 2022-08-17 15:07:09 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;b94b60c8dbdb4967:bbd4f2ff00000000</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| id | name | age | birthday            |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 |</span><br><span class="line">+----+------+-----+---------------------+</span><br><span class="line">Fetched 3 row(s) in 4.35s</span><br><span class="line">[cdh02:21000] default&gt; select count(*),name from im_external_table group by name;</span><br><span class="line">Query: select count(*),name from im_external_table group by name</span><br><span class="line">Query submitted at: 2022-08-17 15:07:28 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;ae4cdaeafd180dbc:5bbda11b00000000</span><br><span class="line">+----------+------+</span><br><span class="line">| count(*) | name |</span><br><span class="line">+----------+------+</span><br><span class="line">| 1        | ls   |</span><br><span class="line">| 1        | jack |</span><br><span class="line">| 1        | zs   |</span><br><span class="line">+----------+------+</span><br><span class="line">Fetched 3 row(s) in 0.47s</span><br></pre></td></tr></table></figure><h4 id="分区表的使用"><a href="#分区表的使用" class="headerlink" title="分区表的使用"></a>分区表的使用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">分区表也可以分为外部分区表和内部分区表，在这里我们以外部分区表为例演示一下：</span><br><span class="line"></span><br><span class="line">创建外部分区表：im_external_partition_table</span><br><span class="line"></span><br><span class="line">create external table im_external_partition_table(</span><br><span class="line">  id int,</span><br><span class="line">  name string,</span><br><span class="line">  age int,</span><br><span class="line">  birthday timestamp</span><br><span class="line">)partitioned by(dt string)</span><br><span class="line">row format delimited </span><br><span class="line">fields terminated by &#39;\t&#39; </span><br><span class="line">lines terminated by &#39;\n&#39;</span><br><span class="line">location &#39;&#x2F;data&#x2F;im_external_partition_table&#39;;</span><br><span class="line"></span><br><span class="line">注意：现在直接使用load data向分区中加载数据是会报错的，他会提示分区不存在。(Hive中这样执行是可以的。)</span><br><span class="line"></span><br><span class="line">[cdh02:21000] default&gt; load data inpath &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat&#39; into table im_external_partition_table partition(dt&#x3D;&#39;20220101&#39;);</span><br><span class="line">Query: load data inpath &#39;hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_inner_table.dat&#39; into table im_external_partition_table partition(dt&#x3D;&#39;20220101&#39;)</span><br><span class="line">ERROR: AnalysisException: Partition spec does not exist: (dt&#x3D;&#39;20220101&#39;).</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">此时需要先到HDFS里面创建分区目录，再使用alter的方式添加分区，这种思路也是正常的操作流程，因为在实际工作中，外部分区表的数据是由专门的程序负责写入的。</span><br><span class="line"></span><br><span class="line">手工在HDFS中创建分区表需要的分区目录，并且上传数据文件：</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -mkdir -p &#x2F;data&#x2F;im_external_partition_table&#x2F;20220101</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -mkdir -p &#x2F;data&#x2F;im_external_partition_table&#x2F;20220102</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put im_external_table.dat &#x2F;data&#x2F;im_external_partition_table&#x2F;20220101</span><br><span class="line">[root@cdh01 ~]# hdfs dfs -put im_external_table.dat &#x2F;data&#x2F;im_external_partition_table&#x2F;20220102</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">在impala中添加分区。</span><br><span class="line"></span><br><span class="line">[cdh02:21000] default&gt; alter table im_external_partition_table add partition(dt&#x3D;&#39;20220101&#39;) location &#39;&#x2F;data&#x2F;im_external_partition_table&#x2F;20220101&#39;;</span><br><span class="line">Query: alter table im_external_partition_table add partition(dt&#x3D;&#39;20220101&#39;) location &#39;&#x2F;data&#x2F;im_external_partition_table&#x2F;20220101&#39;</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| summary                                    |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| New partition has been added to the table. |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">Fetched 1 row(s) in 6.16s</span><br><span class="line">[cdh02:21000] default&gt; alter table im_external_partition_table add partition(dt&#x3D;&#39;20220102&#39;) location &#39;&#x2F;data&#x2F;im_external_partition_table&#x2F;20220102&#39;;</span><br><span class="line">Query: alter table im_external_partition_table add partition(dt&#x3D;&#39;20220102&#39;) location &#39;&#x2F;data&#x2F;im_external_partition_table&#x2F;20220102&#39;</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| summary                                    |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| New partition has been added to the table. |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">Fetched 1 row(s) in 0.18s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">查询表中的分区信息：</span><br><span class="line">[cdh02:21000] default&gt; show partitions im_external_partition_table;</span><br><span class="line">Query: show partitions im_external_partition_table</span><br><span class="line">+----------+-------+--------+------+--------------+-------------------+--------+-------------------+-------------------------------------------------------------+</span><br><span class="line">| dt       | #Rows | #Files | Size | Bytes Cached | Cache Replication | Format | Incremental stats | Location                                                    |</span><br><span class="line">+----------+-------+--------+------+--------------+-------------------+--------+-------------------+-------------------------------------------------------------+</span><br><span class="line">| 20220101 | -1    | 1      | 86B  | NOT CACHED   | NOT CACHED        | TEXT   | false             | hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_external_partition_table&#x2F;20220101 |</span><br><span class="line">| 20220102 | -1    | 1      | 86B  | NOT CACHED   | NOT CACHED        | TEXT   | false             | hdfs:&#x2F;&#x2F;cdh01:8020&#x2F;data&#x2F;im_external_partition_table&#x2F;20220102 |</span><br><span class="line">| Total    | -1    | 2      | 172B | 0B           |                   |        |                   |                                                             |</span><br><span class="line">+----------+-------+--------+------+--------------+-------------------+--------+-------------------+-------------------------------------------------------------+</span><br><span class="line">Fetched 3 row(s) in 0.03s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">查询表中的数据：</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_partition_table;</span><br><span class="line">Query: select * from im_external_partition_table</span><br><span class="line">Query submitted at: 2022-08-17 16:08:40 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;1e486988e548514d:6c432b1700000000</span><br><span class="line">+----+------+-----+---------------------+----------+</span><br><span class="line">| id | name | age | birthday            | dt       |</span><br><span class="line">+----+------+-----+---------------------+----------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 | 20220101 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 | 20220101 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 | 20220101 |</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 | 20220102 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 | 20220102 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 | 20220102 |</span><br><span class="line">+----+------+-----+---------------------+----------+</span><br><span class="line">Fetched 6 row(s) in 0.56s</span><br><span class="line">[cdh02:21000] default&gt; select * from im_external_partition_table where dt&#x3D;&#39;20220101&#39;;</span><br><span class="line">Query: select * from im_external_partition_table where dt&#x3D;&#39;20220101&#39;</span><br><span class="line">Query submitted at: 2022-08-17 16:08:51 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;6040eadaa0e73718:2fe9f99000000000</span><br><span class="line">+----+------+-----+---------------------+----------+</span><br><span class="line">| id | name | age | birthday            | dt       |</span><br><span class="line">+----+------+-----+---------------------+----------+</span><br><span class="line">| 1  | zs   | 18  | 2001-01-01 10:10:10 | 20220101 |</span><br><span class="line">| 2  | ls   | 17  | 2002-02-02 12:12:12 | 20220101 |</span><br><span class="line">| 3  | jack | 19  | 2000-09-21 18:10:10 | 20220101 |</span><br><span class="line">+----+------+-----+---------------------+----------+</span><br><span class="line">Fetched 3 row(s) in 0.53s</span><br><span class="line">[cdh02:21000] default&gt; select name,count(*) from im_external_partition_table group by name;      </span><br><span class="line">Query: select name,count(*) from im_external_partition_table group by name</span><br><span class="line">Query submitted at: 2022-08-17 16:09:28 (Coordinator: http:&#x2F;&#x2F;cdh02:25000)</span><br><span class="line">Query progress can be monitored at: http:&#x2F;&#x2F;cdh02:25000&#x2F;query_plan?query_id&#x3D;cc4f17d9431288eb:304a855700000000</span><br><span class="line">+------+----------+</span><br><span class="line">| name | count(*) |</span><br><span class="line">+------+----------+</span><br><span class="line">| ls   | 2        |</span><br><span class="line">| jack | 2        |</span><br><span class="line">| zs   | 2        |</span><br><span class="line">+------+----------+</span><br><span class="line">Fetched 3 row(s) in 0.46s</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Impala" scheme="http://tianyong.fun/tags/Impala/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-极速上手内存数据库Redis-2</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93Redis-2.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93Redis-2.html</id>
    <published>2023-06-14T16:35:34.000Z</published>
    <updated>2023-06-14T16:39:34.600Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Redis" scheme="http://tianyong.fun/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-极速上手内存数据库Redis-1</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93Redis-1.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93Redis-1.html</id>
    <published>2023-06-14T16:35:17.000Z</published>
    <updated>2023-06-20T09:39:21.633Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="极速上手内存数据库Redis-1"><a href="#极速上手内存数据库Redis-1" class="headerlink" title="极速上手内存数据库Redis-1"></a>极速上手内存数据库Redis-1</h1><h2 id="快速了解Redis"><a href="#快速了解Redis" class="headerlink" title="快速了解Redis"></a>快速了解Redis</h2><h3 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Redis是一种面向 “Key-Value” 数据类型的内存数据库，可以满足我们对海量数据的快速读写需求</span><br><span class="line">注意：首先Redis是一种内存数据库，它的数据都是放在内存里面的，</span><br><span class="line">然后Redis中存储的数据都是key-value类型的</span><br><span class="line">其中redis中的key只能是字符串，value支持多种数据类型</span><br><span class="line"></span><br><span class="line">常见的有string、hash、list、set、sortedset等</span><br><span class="line"></span><br><span class="line">字符串 string</span><br><span class="line">哈希 hash，类似于java中的hashmap</span><br><span class="line">字符串列表 list</span><br><span class="line">字符串集合 set 不重复，无序</span><br><span class="line">有序集合sorted set ，不重复，有序</span><br></pre></td></tr></table></figure><h3 id="Redis的特点"><a href="#Redis的特点" class="headerlink" title="Redis的特点"></a>Redis的特点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">接下来看一下Redis的一些特点</span><br><span class="line"></span><br><span class="line">高性能：Redis读的速度是11W次&#x2F;s,写的速度是8.1W次&#x2F;s</span><br><span class="line">原子性：保证数据的准确性</span><br><span class="line">持久存储：支持两种方式的持久化，RDB和AOF，可以把内存中的数据持久化到磁盘中</span><br><span class="line">支持主从：master-slave架构，可以实现负载均衡、高可用</span><br><span class="line">支持集群：从3.0版本开始支持</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：Redis是一个 单线程 的服务，作者之所以这么设计，主要是为了保证redis的快速，高效，如果涉及了多线程，就需要使用锁机制来解决并发问题，这样执行效率反而会打折扣。</span><br><span class="line"></span><br><span class="line">注意：Redis是一个 NoSQL 数据库，NoSQL的全称是not only sql，不仅仅是SQL，泛指非关系型数据库，这种类型的数据库不支持SQL语法。</span><br></pre></td></tr></table></figure><h3 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主要应用在高并发和实时请求的场景，例如：新浪微博</span><br><span class="line"></span><br><span class="line">hash：关注列表、粉丝列表</span><br><span class="line">string：微博数，粉丝数(避免使用select count(*) from …)</span><br></pre></td></tr></table></figure><h3 id="使用Redis存储数据"><a href="#使用Redis存储数据" class="headerlink" title="使用Redis存储数据"></a>使用Redis存储数据</h3><h4 id="Redis安装部署"><a href="#Redis安装部署" class="headerlink" title="Redis安装部署"></a>Redis安装部署</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">下面来看一下redis的安装部署，首先下载redis</span><br><span class="line">使用此链接下载，可以显示Redis目前所有的版本</span><br><span class="line">http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;</span><br><span class="line"></span><br><span class="line">我们选择目前比较稳定的5.0.9版本。</span><br><span class="line"></span><br><span class="line">将下载好的安装包上传到bigdata04机器的&#x2F;data&#x2F;soft目录下</span><br><span class="line">1：解压</span><br><span class="line">[root@bigdata04 soft]# tar -zxvf redis-5.0.9.tar.gz</span><br><span class="line">2：编译+安装</span><br><span class="line">[root@bigdata04 soft]# cd redis-5.0.9</span><br><span class="line">[root@bigdata04 redis-5.0.9]# make</span><br><span class="line">[root@bigdata04 redis-5.0.9]# make install</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">只要不报错就说明编译安装成功。</span><br><span class="line"></span><br><span class="line">注意：由于redis需要依赖于C语言环境，如果你安装的centos镜像是精简版，会缺失c语言的依赖，所以需要安装C语言环境才可以编译成功。</span><br><span class="line"></span><br><span class="line">我们在这使用的centos镜像是完整版，里面是包含C语言环境的，所以就不存在这个问题了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">3：修改redis.conf配置文件</span><br><span class="line">[root@bigdata04 redis-5.0.9]# vi redis.conf</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &#x2F;data&#x2F;soft&#x2F;redis-5.0.9&#x2F;log</span><br><span class="line">bind 127.0.0.1 192.168.182.103</span><br><span class="line"></span><br><span class="line">daemonize参数的值默认是no，表示在前台启动Redis，但是Redis是一个数据库，我们希望把它放到后台运行，所以将参数的值改为yes</span><br><span class="line"></span><br><span class="line">logfile 参数的值默认为空，表示redis会将日志输出到&#x2F;dev&#x2F;null里面，也就是不保存了，建议在这设置一个日志路径记录redis的日志，便于后期排查问题。</span><br><span class="line"></span><br><span class="line">bind 参数可以绑定指定ip，这样就可以通过这里指定的ip来访问redis服务了，可以在后面指定当前机器的本地回环地址(127.0.0.1)和内网地址(192.168.182.103)，</span><br><span class="line">指定本地回环地址是为了能够在本机自己连自己比较方便。</span><br><span class="line">指定内网地址是为了能够让公司局域网内的其它服务器也能连到这个redis</span><br><span class="line">如果你这台机器有外网地址的话不建议在这配置，因为使用外网地址的话就不安全了，容易受到网络攻击。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">4：启动redis</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-server redis.conf </span><br><span class="line"></span><br><span class="line">5：验证</span><br><span class="line">注意：redis不是java程序，所以使用jps命令查不到，需要使用ps命令查看redis的进程</span><br><span class="line">[root@bigdata04 redis-5.0.9]# ps -ef|grep redis</span><br><span class="line">root       5828      1  0 16:12 ?        00:00:00 redis-server 127.0.0.1:6379</span><br><span class="line"></span><br><span class="line">6：连接redis数据库</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli </span><br><span class="line">127.0.0.1:6379&gt; </span><br><span class="line"></span><br><span class="line">注意：使用redis-cli默认可以连接本地的redis</span><br><span class="line">其实redis-cli后面省略了-h 127.0.0.1 和 -p 6379</span><br><span class="line"></span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli -h 127.0.0.1 -p 6379</span><br><span class="line"></span><br><span class="line">此时使用内网ip也能连接，这样其实我们就可以在其它安装有redis-cli客户端的机器上连接这个redis服务了。</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli -h 192.168.182.103 -p 6379</span><br><span class="line">192.168.182.103:6379&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">7：停止redis数据库</span><br><span class="line">暴力一点的方式是使用kill命令直接杀进程</span><br><span class="line">不过redis提供的有停止命令</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; shutdown</span><br><span class="line">not connected&gt; </span><br><span class="line"></span><br><span class="line">或者这样停止也是可以的</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli shutdown</span><br></pre></td></tr></table></figure><h3 id="Redis基础命令"><a href="#Redis基础命令" class="headerlink" title="Redis基础命令"></a>Redis基础命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">下面我们来看一下Redis中的基础命令</span><br><span class="line">先启动redis服务，使用redis-cli客户端连到redis数据库里面</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-server redis.conf</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli </span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h4 id="获得符合规则的键：keys"><a href="#获得符合规则的键：keys" class="headerlink" title="获得符合规则的键：keys"></a>获得符合规则的键：keys</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">keys 后面可以指定正则表达式</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br><span class="line">127.0.0.1:6379&gt; set a 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1)&quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; keys a*</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; keys a+</span><br><span class="line">(empty list or set)</span><br></pre></td></tr></table></figure><h4 id="scan"><a href="#scan" class="headerlink" title="scan"></a>scan</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注意：在生产环境下建议禁用keys命令，因为这个命令会查询过滤redis中的所有数据，可能会造成服务阻塞，影响redis执行效率。</span><br><span class="line"></span><br><span class="line">如果有类似的查询需求建议使用scan</span><br><span class="line">scan命令用于迭代当前数据库中的key集合</span><br><span class="line">它支持增量式迭代，每次执行只会返回少量元素，所以它可以用于生产环境，而不会出现像keys命令那样可能会阻塞服务器的问题。</span><br><span class="line"></span><br><span class="line">SCAN命令是一个基于游标的迭代器。这意味着命令每次被调用都需要使用上一次调用返回的游标作为该次调用的游标参数，以此来延续之前的迭代过程</span><br><span class="line">当SCAN命令的游标参数被设置为0时，服务器将开始一次新的迭代，而当服务器向用户返回值为0的游标时，表示迭代已结束。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">向redis中初始化一批数据</span><br><span class="line">127.0.0.1:6379&gt; set a1 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a2 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a3 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a4 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a5 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a6 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a7 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a8 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a9 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set a10 1</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">使用scan迭代数据，后面游标参数指定为0，表示从头开始迭代key</span><br><span class="line">127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) &quot;3&quot;</span><br><span class="line">2)  1) &quot;a9&quot;</span><br><span class="line">    2) &quot;a3&quot;</span><br><span class="line">    3) &quot;a1&quot;</span><br><span class="line">    4) &quot;a10&quot;</span><br><span class="line">    5) &quot;a8&quot;</span><br><span class="line">    6) &quot;a5&quot;</span><br><span class="line">    7) &quot;a4&quot;</span><br><span class="line">    8) &quot;a&quot;</span><br><span class="line">    9) &quot;a7&quot;</span><br><span class="line">   10) &quot;a6&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">SCAN 命令的返回值是一个包含两个元素的数组，</span><br><span class="line">第一个元素是用于进行下一次迭代的新游标，</span><br><span class="line">而第二个元素则是一个数组， 这个数组中包含了所有被迭代出来的元素。</span><br><span class="line"></span><br><span class="line">默认情况下scan返回10条数据</span><br><span class="line">所以这样执行效果也是一样的</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; scan 0 count 10</span><br><span class="line">1) &quot;3&quot;</span><br><span class="line">2)  1) &quot;a9&quot;</span><br><span class="line">    2) &quot;a3&quot;</span><br><span class="line">    3) &quot;a1&quot;</span><br><span class="line">    4) &quot;a10&quot;</span><br><span class="line">    5) &quot;a8&quot;</span><br><span class="line">    6) &quot;a5&quot;</span><br><span class="line">    7) &quot;a4&quot;</span><br><span class="line">    8) &quot;a&quot;</span><br><span class="line">    9) &quot;a7&quot;</span><br><span class="line">   10) &quot;a6&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scan命令此时返回的游标为3</span><br><span class="line"></span><br><span class="line">注意，游标的值并不等于返回的数据量。</span><br><span class="line"></span><br><span class="line">如果想要继续往下面迭代数据的话，下一次执行scan的时候需要指定之前返回的游标，redis会根据这个游标继续往下面迭代</span><br><span class="line">127.0.0.1:6379&gt; scan 3 count 10</span><br><span class="line">1) &quot;0&quot;</span><br><span class="line">2) 1) &quot;a2&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这一次使用scan命令，返回的游标为0，表示迭代已经结束，整个redis中的key都被迭代完了。</span><br><span class="line">redis中一共有11个key，第一次使用scan 0获取到了10个key，第二次获取到了1个key，没有问题。</span><br><span class="line"></span><br><span class="line">注意：大家在下面练习的时候可能会发现你那边第一次返回的游标和我这边显示的不一样，那也很正常，因为你会发现你返回的这个数据集的顺序也是不一样的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">所以，如果redis中有很多key，我们可以使用scan命令来迭代，一次迭代一部分，不至于造成阻塞，如果redis中的key比较少，那么使用keys * 也是可以的。</span><br><span class="line"></span><br><span class="line">如果想要在迭代key的时候对key进行过滤，可以在scan后面指定match参数，match后面可以指定正则表达式</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; scan 0 match a[1-5] count 10</span><br><span class="line">1) &quot;3&quot;</span><br><span class="line">2) 1) &quot;a3&quot;</span><br><span class="line">   2) &quot;a1&quot;</span><br><span class="line">   3) &quot;a5&quot;</span><br><span class="line">   4) &quot;a4&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时实际返回的key的数量是4个，但是游标还是3，相当于还是迭代了10条数据，只不过不满足条件的没有返回而已。</span><br></pre></td></tr></table></figure><h4 id="判断键是否存在：exists"><a href="#判断键是否存在：exists" class="headerlink" title="判断键是否存在：exists"></a>判断键是否存在：exists</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; exists a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; exists b</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><h4 id="删除键：del"><a href="#删除键：del" class="headerlink" title="删除键：del"></a>删除键：del</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; del a</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：del也支持一次删除多个key</span><br><span class="line">127.0.0.1:6379&gt; del a1 a2</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><h4 id="获得键值的类型：type"><a href="#获得键值的类型：type" class="headerlink" title="获得键值的类型：type"></a>获得键值的类型：type</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">返回值可能是这五种类型（string,hash,list,set,zset）</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; set a 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; type a</span><br><span class="line">string</span><br><span class="line"></span><br><span class="line">这个命令可以帮我们快速识别某一个key中存储的数据是什么类型的，因为针对存储了不同类型值的key，操作的命令是不一样的。</span><br></pre></td></tr></table></figure><h4 id="帮助命令：help"><a href="#帮助命令：help" class="headerlink" title="帮助命令：help"></a>帮助命令：help</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; help set</span><br><span class="line">  SET key value [EX seconds] [PX milliseconds] [NX|XX]</span><br><span class="line">  summary: Set the string value of a key</span><br><span class="line">  since: 1.0.0</span><br><span class="line">  group: string</span><br></pre></td></tr></table></figure><h4 id="退出客户端：quit-exit"><a href="#退出客户端：quit-exit" class="headerlink" title="退出客户端：quit/exit"></a>退出客户端：quit/exit</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; quit</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">不过我还是习惯使用ctrl+c退出redis-cli客户端</span><br><span class="line"></span><br><span class="line">最后有一点需要注意：</span><br><span class="line"></span><br><span class="line">Redis的命令不区分大小写，但是key的名称需要区分大小写！</span><br></pre></td></tr></table></figure><h3 id="Redis多数据库特性"><a href="#Redis多数据库特性" class="headerlink" title="Redis多数据库特性"></a>Redis多数据库特性</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Redis默认支持16个数据库，通过databases参数控制的</span><br><span class="line">这个参数在redis.conf配置文件中</span><br><span class="line"></span><br><span class="line">[root@bigdata04 redis-5.0.9]# cat redis.conf | grep databases</span><br><span class="line"># Set the number of databases. The default database is DB 0, you can select</span><br><span class="line"># dbid is a number between 0 and &#39;databases&#39;-1</span><br><span class="line">databases 16</span><br><span class="line"># Compress string objects using LZF when dump .rdb databases?</span><br></pre></td></tr></table></figure><h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">每个数据库对外都是以一个从0开始的递增数字命名，不支持自定义</span><br><span class="line"></span><br><span class="line">Redis默认选择的是0号数据库，可以通过 select 命令切换</span><br><span class="line">127.0.0.1:6379&gt; select 0</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; select 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[1]&gt; select 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[2]&gt; select 15</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[15]&gt; select 16</span><br><span class="line">(error) ERR DB index is out of range</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一般在工作中会使用2~3个数据库，可以根据业务类型来分库，不同业务的数据存到不同的库里面</span><br><span class="line">还有一种用法是，一个库作为测试库，一个库作为正式库</span><br><span class="line">如果没有特殊需求，一般使用0号数据库就可以了，这个库使用起来比较方便，默认就是0号库，不需要使用select切换。</span><br><span class="line">具体在工作中怎么用都行，只要理解它的特性就可以了。</span><br><span class="line"></span><br><span class="line">但是有一点需要注意：多个数据库之间并不是完全隔离的，如果使用flushall命令，则会清空redis中所有数据库内的数据。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">并且我们在redis中使用多个库，并不能提高redis的存储能力，因为默认这16个库共用redis的内存存储空间，如果想要提高redis的存储能力，需要给我们的服务器增加内存才可以。</span><br></pre></td></tr></table></figure><h4 id="flushall"><a href="#flushall" class="headerlink" title="flushall"></a>flushall</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379[15]&gt; set x 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[15]&gt; flushall</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[15]&gt; keys *</span><br><span class="line">(empty list or set)</span><br><span class="line">127.0.0.1:6379[15]&gt; select 0</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br></pre></td></tr></table></figure><h4 id="flushdb"><a href="#flushdb" class="headerlink" title="flushdb"></a>flushdb</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">如果只想清空当前数据库中的数据，可以使用flushdb</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; select 15</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[15]&gt; set a 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[15]&gt; keys *</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379[15]&gt; flushdb</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h2 id="2-Redis核心实践"><a href="#2-Redis核心实践" class="headerlink" title="2 Redis核心实践"></a>2 Redis核心实践</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">下面来看一下redis中的常用数据类型</span><br><span class="line"></span><br><span class="line">注意：这些数据类型都是针对于redis中的value而言的，因为key都是字符串</span><br><span class="line"></span><br><span class="line">string</span><br><span class="line">hash</span><br><span class="line">list</span><br><span class="line">set</span><br><span class="line">sorted set</span><br></pre></td></tr></table></figure><h3 id="Redis数据类型之string"><a href="#Redis数据类型之string" class="headerlink" title="Redis数据类型之string"></a>Redis数据类型之string</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">字符串类型是redis中最基本的数据类型，它能存储任何形式的内容，包含二进制数据，甚至是一张图片</span><br><span class="line">一个字符串类型的值存储的最大容量是1GB，一般情况下我们存储的单条数据肯定是达不到的这个限值的，所以大家不用担心</span><br><span class="line">string类型比较适合存储类型单一的数据</span><br><span class="line">针对string类型主要有下面这些常见命令：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306150117971.png" alt="image-20230615011423719"></p><h4 id="添加数据-set"><a href="#添加数据-set" class="headerlink" title="添加数据 set"></a>添加数据 set</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set str a</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h4 id="查询数据-get"><a href="#查询数据-get" class="headerlink" title="查询数据 get"></a>查询数据 get</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; get str</span><br><span class="line">&quot;a&quot;</span><br></pre></td></tr></table></figure><h4 id="一次添加多条数据"><a href="#一次添加多条数据" class="headerlink" title="一次添加多条数据"></a>一次添加多条数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; mset str1 a1 str2 a2</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h4 id="一次查询多条数据"><a href="#一次查询多条数据" class="headerlink" title="一次查询多条数据"></a>一次查询多条数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; mget str1 str2</span><br><span class="line">1) &quot;a1&quot;</span><br><span class="line">2) &quot;a2&quot;</span><br></pre></td></tr></table></figure><h4 id="递增1"><a href="#递增1" class="headerlink" title="递增1"></a>递增1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1属于特殊的字符串</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set num 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; incr num &#x2F;&#x2F; incr属于原子命令</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; get num</span><br><span class="line">&quot;2&quot;</span><br></pre></td></tr></table></figure><h4 id="递减1"><a href="#递减1" class="headerlink" title="递减1"></a>递减1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; decr num</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; get num</span><br><span class="line">&quot;1&quot;</span><br></pre></td></tr></table></figure><h4 id="递增指定数值-整数类型"><a href="#递增指定数值-整数类型" class="headerlink" title="递增指定数值(整数类型)"></a>递增指定数值(整数类型)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incrby num 2</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; get num</span><br><span class="line">&quot;3&quot;</span><br><span class="line">127.0.0.1:6379&gt; incrby num 2.1</span><br><span class="line">(error) ERR value is not an integer or out of range[注意：增量数值只支持integer类型]</span><br></pre></td></tr></table></figure><h4 id="递减指定数值-整数类型"><a href="#递减指定数值-整数类型" class="headerlink" title="递减指定数值(整数类型)"></a>递减指定数值(整数类型)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; decrby num 2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; get num</span><br><span class="line">&quot;1&quot;</span><br></pre></td></tr></table></figure><h4 id="递增指定数值-float类型"><a href="#递增指定数值-float类型" class="headerlink" title="递增指定数值(float类型)"></a>递增指定数值(float类型)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incrbyfloat num 2.1</span><br><span class="line">&quot;3.1&quot;</span><br><span class="line">127.0.0.1:6379&gt; get num</span><br><span class="line">&quot;3.1&quot;</span><br></pre></td></tr></table></figure><h4 id="获取指定key的value长度"><a href="#获取指定key的value长度" class="headerlink" title="获取指定key的value长度"></a>获取指定key的value长度</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; get str</span><br><span class="line">&quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; strlen str</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; set str abcd</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; strlen str</span><br><span class="line">(integer) 4</span><br></pre></td></tr></table></figure><h3 id="Redis数据类型之hash"><a href="#Redis数据类型之hash" class="headerlink" title="Redis数据类型之hash"></a>Redis数据类型之hash</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hash类型的值存储了字段和字段值的映射(就是hash里还包含key-value)，字段和字段值只能是字符串，不支持其他数据类型</span><br><span class="line">hash类型的值至多存储2的32次方-1个字段，一般情况下我们也达不到这个极限</span><br><span class="line">hash类型比较适合存储对象，因为对象里面是有一些属性和值的，我们就可以把这些属性和值存储到这个hash类型里面</span><br><span class="line">针对hash类型主要有下面这些常见命令：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">命令格式解释</span><br><span class="line">hsethset key field value向hash中添加字段和值</span><br><span class="line">hgethget key field获取hash中指定字段的值</span><br><span class="line">hgetallhgetall key获取hash中所有的字段和值</span><br><span class="line">hexistshexists key field判断hash中是否包含指定字段</span><br><span class="line">hincrbyhincrby key field num对hash中指定字段的值递增</span><br><span class="line">hdelhdel key field删除hash中指定的字段</span><br><span class="line">hkeys&#x2F;hvalshkeys&#x2F;hvals key获取hash中所有字段或字段值</span><br><span class="line">hlenhlen key获取hash中所有字段的数量</span><br></pre></td></tr></table></figure><h4 id="添加数据-hset"><a href="#添加数据-hset" class="headerlink" title="添加数据 hset"></a>添加数据 hset</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset user:1 name zs &#x2F;&#x2F; user:1看成key，这里只是为了方便识别是哪一个用户，不一定要是这种样子；name zs看成value，value里包含了key value</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><h4 id="查询数据-hget"><a href="#查询数据-hget" class="headerlink" title="查询数据 hget"></a>查询数据 hget</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hget user:1 name</span><br><span class="line">&quot;zs&quot;</span><br></pre></td></tr></table></figure><h4 id="向一个hash中同时添加多个k-v-hmset"><a href="#向一个hash中同时添加多个k-v-hmset" class="headerlink" title="向一个hash中同时添加多个k-v hmset"></a>向一个hash中同时添加多个k-v hmset</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hmset user:2 name lisi age 18</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h4 id="查询一个hash数据中多个k的值-hmget"><a href="#查询一个hash数据中多个k的值-hmget" class="headerlink" title="查询一个hash数据中多个k的值 hmget"></a>查询一个hash数据中多个k的值 hmget</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hmget user:2 name age</span><br><span class="line">1) &quot;lisi&quot;</span><br><span class="line">2) &quot;18&quot;</span><br></pre></td></tr></table></figure><h4 id="查询一个hash数据中的所有k-v-hgetall"><a href="#查询一个hash数据中的所有k-v-hgetall" class="headerlink" title="查询一个hash数据中的所有k-v hgetall"></a>查询一个hash数据中的所有k-v hgetall</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hgetall user:2</span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;lisi&quot;</span><br><span class="line">3) &quot;age&quot;</span><br><span class="line">4) &quot;18&quot;</span><br></pre></td></tr></table></figure><h4 id="判断一个hash数据中是否存在指定k-hexists"><a href="#判断一个hash数据中是否存在指定k-hexists" class="headerlink" title="判断一个hash数据中是否存在指定k hexists"></a>判断一个hash数据中是否存在指定k hexists</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hexists user:2 name</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hexists user:2 city</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><h4 id="对一个hash数据中指定k的v进行递增-hincrby"><a href="#对一个hash数据中指定k的v进行递增-hincrby" class="headerlink" title="对一个hash数据中指定k的v进行递增 hincrby"></a>对一个hash数据中指定k的v进行递增 hincrby</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hincrby user:2 age 1</span><br><span class="line">(integer) 19</span><br><span class="line">127.0.0.1:6379&gt; hget user:2 age</span><br><span class="line">&quot;19&quot;</span><br></pre></td></tr></table></figure><h4 id="删除一个hash数据中的指定k-hdel"><a href="#删除一个hash数据中的指定k-hdel" class="headerlink" title="删除一个hash数据中的指定k hdel"></a>删除一个hash数据中的指定k hdel</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset user:2 city beijing</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; hdel user:2 city</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><h4 id="获取一个hash数据中的所有k-hkeys"><a href="#获取一个hash数据中的所有k-hkeys" class="headerlink" title="获取一个hash数据中的所有k hkeys"></a>获取一个hash数据中的所有k hkeys</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hkeys user:2</span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;age&quot;</span><br></pre></td></tr></table></figure><h4 id="获取一个hash数据中的所有v-hvals"><a href="#获取一个hash数据中的所有v-hvals" class="headerlink" title="获取一个hash数据中的所有v hvals"></a>获取一个hash数据中的所有v hvals</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hvals user:2</span><br><span class="line">1) &quot;lisi&quot;</span><br><span class="line">2) &quot;19&quot;</span><br></pre></td></tr></table></figure><h4 id="获取一个hash数据中有多少个k-hlen"><a href="#获取一个hash数据中有多少个k-hlen" class="headerlink" title="获取一个hash数据中有多少个k hlen"></a>获取一个hash数据中有多少个k hlen</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hlen user:2</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><h3 id="Redis数据类型之list"><a href="#Redis数据类型之list" class="headerlink" title="Redis数据类型之list"></a>Redis数据类型之list</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">list是一个有序的字符串列表，列表内部是使用双向链表(linked list)实现的</span><br><span class="line">list列表类型的值最多可以存储2的32次方-1个元素，一般我们也达不到这个限值</span><br><span class="line">list类型比较适合作为队列使用，使用lpush+rpop可以实现先进先出的队列</span><br><span class="line"></span><br><span class="line">针对list类型主要有下面这些常见命令：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">命令格式解释</span><br><span class="line">lpushlpush key value从列表左侧添加元素</span><br><span class="line">rpushrpush key value从列表右侧添加元素</span><br><span class="line">lpoplpop key从列表左侧弹出元素</span><br><span class="line">rpoprpop key从列表右侧弹出元素</span><br><span class="line">llenllen key获取列表的长度</span><br><span class="line">lrangelrange key start stop获取列表指定区间的元素</span><br><span class="line">lindexlindex key index获取列表指定角标的元素</span><br><span class="line">lsetlset key index value修改列表中指定角标的元素</span><br></pre></td></tr></table></figure><h4 id="添加元素-左侧添加-lpush"><a href="#添加元素-左侧添加-lpush" class="headerlink" title="添加元素(左侧添加) lpush"></a>添加元素(左侧添加) lpush</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush list1 a &#x2F;&#x2F; list1相当于key</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; lpush list1 b</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><h4 id="取出元素-左侧取元素-lpop"><a href="#取出元素-左侧取元素-lpop" class="headerlink" title="取出元素(左侧取元素) lpop"></a>取出元素(左侧取元素) lpop</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpop list1</span><br><span class="line">&quot;b&quot;</span><br><span class="line">127.0.0.1:6379&gt; lpop list1</span><br><span class="line">&quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; lpop list1</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><h4 id="添加元素-右侧添加-rpush"><a href="#添加元素-右侧添加-rpush" class="headerlink" title="添加元素(右侧添加) rpush"></a>添加元素(右侧添加) rpush</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; rpush list2 x</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; rpush list2 y</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><h4 id="取出元素-右侧取元素-rpop"><a href="#取出元素-右侧取元素-rpop" class="headerlink" title="取出元素(右侧取元素) rpop"></a>取出元素(右侧取元素) rpop</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; rpop list2</span><br><span class="line">&quot;y&quot;</span><br><span class="line">127.0.0.1:6379&gt; rpop list2</span><br><span class="line">&quot;x&quot;</span><br></pre></td></tr></table></figure><h4 id="列表长度-llen"><a href="#列表长度-llen" class="headerlink" title="列表长度 llen"></a>列表长度 llen</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush list3 a b c d</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; llen list3</span><br><span class="line">(integer) 4</span><br></pre></td></tr></table></figure><h4 id="获取列表中的元素-lrange"><a href="#获取列表中的元素-lrange" class="headerlink" title="获取列表中的元素 lrange"></a>获取列表中的元素 lrange</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange list3 0 -1</span><br><span class="line">1) &quot;d&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;a&quot;</span><br></pre></td></tr></table></figure><h4 id="查询指定角标元素-lindex"><a href="#查询指定角标元素-lindex" class="headerlink" title="查询指定角标元素 lindex"></a>查询指定角标元素 lindex</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lindex list3 1</span><br><span class="line">&quot;c&quot;</span><br></pre></td></tr></table></figure><h4 id="修改指定角标元素-lset"><a href="#修改指定角标元素-lset" class="headerlink" title="修改指定角标元素 lset"></a>修改指定角标元素 lset</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lset list3 1 m</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lrange list3 0 -1</span><br><span class="line">1) &quot;d&quot;</span><br><span class="line">2) &quot;m&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;a&quot;</span><br></pre></td></tr></table></figure><h3 id="Redis数据类型之set"><a href="#Redis数据类型之set" class="headerlink" title="Redis数据类型之set"></a>Redis数据类型之set</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set是一个集合</span><br><span class="line">set集合中的元素都是不重复的，无序的</span><br><span class="line">set集合类型的值最多可以存储2的32次方-1个元素</span><br><span class="line">set集合比较适合用在去重的场景下，因为它里面的元素是都不重复的</span><br><span class="line"></span><br><span class="line">针对set类型主要有下面这些常见命令：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">命令格式解释</span><br><span class="line">saddsadd key value向集合中添加元素</span><br><span class="line">smemberssmembers key获取集合中所有元素</span><br><span class="line">sremsrem key value从集合中删除指定元素</span><br><span class="line">sismembersismember key value判断集合中是否包含指定元素</span><br><span class="line">sdiffsdiff key1 key2获取两个集合的差集</span><br><span class="line">sintersinter key1 key2获取两个集合的交集</span><br><span class="line">sunionsunion key1 key2获取两个集合的并集</span><br><span class="line">scardscard key获取集合中元素的数量</span><br></pre></td></tr></table></figure><h4 id="向集合中添加元素-sadd"><a href="#向集合中添加元素-sadd" class="headerlink" title="向集合中添加元素 sadd"></a>向集合中添加元素 sadd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd set1 a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd set1 b</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><h4 id="获取集合中所有元素-smembers"><a href="#获取集合中所有元素-smembers" class="headerlink" title="获取集合中所有元素 smembers"></a>获取集合中所有元素 smembers</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; smembers set1</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;a&quot;</span><br></pre></td></tr></table></figure><h4 id="删除集合中的元素-srem"><a href="#删除集合中的元素-srem" class="headerlink" title="删除集合中的元素 srem"></a>删除集合中的元素 srem</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; srem set1 a</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><h4 id="判断元素是否存在集合中-sismember"><a href="#判断元素是否存在集合中-sismember" class="headerlink" title="判断元素是否存在集合中 sismember"></a>判断元素是否存在集合中 sismember</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sismember set1 b</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sismember set1 a</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><h4 id="两个集合取差集-sdiff"><a href="#两个集合取差集-sdiff" class="headerlink" title="两个集合取差集 sdiff"></a>两个集合取差集 sdiff</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd set2 a b c</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; sadd set3 a b x</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; sdiff set2 set3</span><br><span class="line">1) &quot;c&quot;</span><br><span class="line">127.0.0.1:6379&gt; sdiff set3 set2</span><br><span class="line">1) &quot;x&quot;</span><br></pre></td></tr></table></figure><h4 id="两个集合取交集-sinter"><a href="#两个集合取交集-sinter" class="headerlink" title="两个集合取交集 sinter"></a>两个集合取交集 sinter</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sinter set2 set3</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;a&quot;</span><br></pre></td></tr></table></figure><h4 id="两个集合取并集-sunion"><a href="#两个集合取并集-sunion" class="headerlink" title="两个集合取并集 sunion"></a>两个集合取并集 sunion</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sunion set2 set3</span><br><span class="line">1) &quot;c&quot;</span><br><span class="line">2) &quot;a&quot;</span><br><span class="line">3) &quot;x&quot;</span><br><span class="line">4) &quot;b&quot;</span><br></pre></td></tr></table></figure><h4 id="获取集合长度-获取集合中元素的个数-scard"><a href="#获取集合长度-获取集合中元素的个数-scard" class="headerlink" title="获取集合长度(获取集合中元素的个数) scard"></a>获取集合长度(获取集合中元素的个数) scard</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scard set3</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure><h3 id="Redis数据类型之sorted-set"><a href="#Redis数据类型之sorted-set" class="headerlink" title="Redis数据类型之sorted set"></a>Redis数据类型之sorted set</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">有序集合，在集合类型的基础上为集合中的每个元素都关联了一个分数，根据分数进行排序，这样就实现了有序。</span><br><span class="line">sorted set比较适合用在获取TopN的场景，因为它里面的数据是有序的</span><br><span class="line"></span><br><span class="line">针对sorted set类型主要有下面这些常见命令：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令格式解释</span><br><span class="line">zaddzadd key value向集合中添加元素</span><br><span class="line">zscorezscore key value获取集合中指定元素的分值</span><br><span class="line">zrangezrange key value获取集合指定元素的排名(正序)</span><br><span class="line">zrevrange格式同上获取集合指定元素的排名(倒序)</span><br><span class="line">zincrbyzincrby key num value给集合中指定元素增加分值</span><br><span class="line">zcardzcard key获取集合中元素的数量</span><br><span class="line">zremzrem key value从集合中删除指定元素</span><br></pre></td></tr></table></figure><h4 id="向集合中添加元素-zadd"><a href="#向集合中添加元素-zadd" class="headerlink" title="向集合中添加元素 zadd"></a>向集合中添加元素 zadd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd zset1 5 a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 3 b</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 4 c</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><h4 id="查询集合中指定元素的分值-zscore"><a href="#查询集合中指定元素的分值-zscore" class="headerlink" title="查询集合中指定元素的分值 zscore"></a>查询集合中指定元素的分值 zscore</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zscore zset1 a</span><br><span class="line">&quot;5&quot;</span><br></pre></td></tr></table></figure><h4 id="根据角标获取集合中的元素-按照正序-zrange"><a href="#根据角标获取集合中的元素-按照正序-zrange" class="headerlink" title="根据角标获取集合中的元素(按照正序) zrange"></a>根据角标获取集合中的元素(按照正序) zrange</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange zset1 0 -1</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">3) &quot;a&quot;</span><br></pre></td></tr></table></figure><h4 id="根据角标获取集合中的元素-按照倒序-zrevrange"><a href="#根据角标获取集合中的元素-按照倒序-zrevrange" class="headerlink" title="根据角标获取集合中的元素(按照倒序) zrevrange"></a>根据角标获取集合中的元素(按照倒序) zrevrange</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrevrange zset1 0 -1</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">3) &quot;b&quot;</span><br></pre></td></tr></table></figure><h4 id="对集合中元素的分值进行递增-zincrby"><a href="#对集合中元素的分值进行递增-zincrby" class="headerlink" title="对集合中元素的分值进行递增 zincrby"></a>对集合中元素的分值进行递增 zincrby</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zincrby zset1 3 a</span><br><span class="line">&quot;8&quot;</span><br><span class="line">127.0.0.1:6379&gt; zscore zset1 a</span><br><span class="line">&quot;8&quot;</span><br></pre></td></tr></table></figure><h4 id="获取集合中元素的个数-zcard"><a href="#获取集合中元素的个数-zcard" class="headerlink" title="获取集合中元素的个数 zcard"></a>获取集合中元素的个数 zcard</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zcard zset1</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure><h4 id="删除集合中的元素-zrem"><a href="#删除集合中的元素-zrem" class="headerlink" title="删除集合中的元素 zrem"></a>删除集合中的元素 zrem</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrem zset1 a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zrange zset1 0 -1</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;c&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line"></span><br><span class="line">1：+inf(正无穷) -inf(负无穷)，在给集合中的元素设置分值的时候可以使用这两个特殊数值。</span><br><span class="line">2：set命令：如果key持有其它类型值，set会覆盖旧值，无视类型</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151532937.png" alt="image-20230615153122935"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：使用set命令时要注意，假如某个key已经存储了其它非string类型，使用set命令赋值后会变成string类型。工作中一定要注意</span><br></pre></td></tr></table></figure><h3 id="案例：存储高一班的学员信息"><a href="#案例：存储高一班的学员信息" class="headerlink" title="案例：存储高一班的学员信息"></a>案例：存储高一班的学员信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">需求：将学员的姓名、年龄、性别、住址信息保存到Redis中</span><br><span class="line">分析一下：</span><br><span class="line">在这里我们可以把学生认为是一个对象，学生对象具备了多个属性信息，姓名，年龄，性别，住址信息</span><br><span class="line">所以针对学生信息非常适合使用hash类型进行存储</span><br><span class="line">我们可以给学生生成一个编号拼接到key里面，姓名、年龄、性别、住址信息存储到hash类型的value中</span><br><span class="line"></span><br><span class="line">注意：这里面针对key的命名，stu是student的简写，尽量不要写太多字符，否则会额外占用内存空间的，后面的:1，表示这个学生的编号是1，后期如果我们想获取所有学员的key，就可以使用这个规则进行过滤了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hmset stu:1 name xiaoming age 18 sex 0 address beijing</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; hgetall stu:1</span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;xiaoming&quot;</span><br><span class="line">3) &quot;age&quot;</span><br><span class="line">4) &quot;18&quot;</span><br><span class="line">5) &quot;sex&quot;</span><br><span class="line">6) &quot;0&quot;</span><br><span class="line">7) &quot;address&quot;</span><br><span class="line">8) &quot;beijing&quot;</span><br><span class="line">127.0.0.1:6379&gt; hget user:1 age</span><br><span class="line">&quot;18&quot;</span><br></pre></td></tr></table></figure><h2 id="3-Redis封装工具类技巧"><a href="#3-Redis封装工具类技巧" class="headerlink" title="3 Redis封装工具类技巧"></a>3 Redis封装工具类技巧</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在这我们以java代码为例，演示一下如何使用java代码操作redis</span><br><span class="line"></span><br><span class="line">我们需要借助于第三方jar包jedis来操作</span><br><span class="line">首先在idea中创建maven项目db_redis</span><br><span class="line">在pom.xml文件中添加jedis依赖</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;redis.clients&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jedis&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.3.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：jedis的版本号和redis的版本号不是一一对应的。</span><br></pre></td></tr></table></figure><h3 id="单连接方式"><a href="#单连接方式" class="headerlink" title="单连接方式"></a>单连接方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">接下来使用单连接的方式操作redis</span><br><span class="line">代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.redis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 单连接方式操作redis</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisSingle</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注意：此代码能够正常执行的前提是</span></span><br><span class="line"><span class="comment">     * 1：redis所在服务器的防火墙需要关闭</span></span><br><span class="line"><span class="comment">     * 2：redis.conf中的bind参数需要指定192.168.182.103</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//获取jedis连接</span></span><br><span class="line">        Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"192.168.182.103"</span>,<span class="number">6379</span>);</span><br><span class="line">        <span class="comment">//向redis中添加数据，key=imooc，value=hello bigdata!</span></span><br><span class="line">        jedis.set(<span class="string">"imooc"</span>,<span class="string">"hello bigdata!"</span>);</span><br><span class="line">        <span class="comment">//从redis中查询key=imooc的value的值</span></span><br><span class="line">        String value = jedis.get(<span class="string">"imooc"</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(value);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//关闭jedis连接</span></span><br><span class="line">        jedis.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">代码执行效果如下：</span><br><span class="line">hello bigdata!</span><br><span class="line"></span><br><span class="line">此时到redis中确认一下：</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;imooc&quot;</span><br><span class="line">127.0.0.1:6379&gt; get imooc</span><br><span class="line">&quot;hello bigdata!&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">其实在这你会发现，我们前面讲的那些在redis-cli中使用的命令，和jedis中提供的函数名称是一一对应的。切换到代码中来使用也是可以直接上手的。</span><br></pre></td></tr></table></figure><h3 id="连接池方式"><a href="#连接池方式" class="headerlink" title="连接池方式"></a>连接池方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">接下来使用连接池的方式操作redis</span><br><span class="line">代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.redis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPoolConfig;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 连接池的方式操作redis</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisPool</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//创建连接池配置对象</span></span><br><span class="line">        JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">        <span class="comment">//连接池中最大空闲连接数</span></span><br><span class="line">        poolConfig.setMaxIdle(<span class="number">10</span>);</span><br><span class="line">        <span class="comment">//连接池中创建的最大连接数</span></span><br><span class="line">        poolConfig.setMaxTotal(<span class="number">100</span>);</span><br><span class="line">        <span class="comment">//创建连接的超时时间</span></span><br><span class="line">        poolConfig.setMaxWaitMillis(<span class="number">2000</span>);</span><br><span class="line">        <span class="comment">//表示从连接池中获取连接的时候会先测试一下连接是否可用，这样可以保证取出的连接都是可用的</span></span><br><span class="line">        poolConfig.setTestOnBorrow(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取jedis连接池</span></span><br><span class="line">        JedisPool jedisPool = <span class="keyword">new</span> JedisPool(poolConfig, <span class="string">"192.168.182.103"</span>, <span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从jedis连接池中取出一个连接</span></span><br><span class="line">        Jedis jedis = jedisPool.getResource();</span><br><span class="line">        String value = jedis.get(<span class="string">"imooc"</span>);</span><br><span class="line">        System.out.println(value);</span><br><span class="line">        <span class="comment">//注意：此处的close方法有两层含义</span></span><br><span class="line">        <span class="comment">//1：如果jedis是直接创建的单连接，此时表示直接关闭这个连接</span></span><br><span class="line">        <span class="comment">//2：如果jedis是从连接池中获取的连接，此时会把这个连接返回给连接池</span></span><br><span class="line">        jedis.close();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//关闭jedis连接池</span></span><br><span class="line">        jedisPool.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">执行结果：</span><br><span class="line">hello bigdata!</span><br></pre></td></tr></table></figure><h3 id="案例：提取RedisUtils工具类"><a href="#案例：提取RedisUtils工具类" class="headerlink" title="案例：提取RedisUtils工具类"></a>案例：提取RedisUtils工具类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">基于redis连接池的方式提取RedisUtils工具类</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.redis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPoolConfig;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 基于redis连接池提取redis工具类</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisUtils</span> </span>&#123;</span><br><span class="line">    <span class="comment">//私有化构造函数，禁止new</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">RedisUtils</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> JedisPool jedisPool = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Jedis <span class="title">getJedis</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(jedisPool==<span class="keyword">null</span>)&#123;</span><br><span class="line">            JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">            poolConfig.setMaxIdle(<span class="number">10</span>);</span><br><span class="line">            poolConfig.setMaxTotal(<span class="number">100</span>);</span><br><span class="line">            poolConfig.setMaxWaitMillis(<span class="number">2000</span>);</span><br><span class="line">            poolConfig.setTestOnBorrow(<span class="keyword">true</span>);</span><br><span class="line">            jedisPool = <span class="keyword">new</span> JedisPool(poolConfig, <span class="string">"192.168.182.103"</span>, <span class="number">6379</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> jedisPool.getResource();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向连接池返回连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">returnResource</span><span class="params">(Jedis jedis)</span></span>&#123;</span><br><span class="line">        jedis.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用工具类代码</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.redis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestRedisUtils</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//获取连接</span></span><br><span class="line">        Jedis jedis = RedisUtils.getJedis();</span><br><span class="line">        String value = jedis.get(<span class="string">"imooc"</span>);</span><br><span class="line">        System.out.println(value);</span><br><span class="line">        <span class="comment">//向连接池返回连接</span></span><br><span class="line">        RedisUtils.returnResource(jedis);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-Redis高级特性"><a href="#4-Redis高级特性" class="headerlink" title="4 Redis高级特性"></a>4 Redis高级特性</h2><h3 id="expire-生存时间"><a href="#expire-生存时间" class="headerlink" title="expire 生存时间"></a>expire 生存时间</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Redis中可以使用expire命令设置一个键的生存时间，到时间后Redis会自动删除它</span><br><span class="line"></span><br><span class="line">它的一个典型应用场景是：手机验证码</span><br><span class="line"></span><br><span class="line">我们平时在登录或者注册的时候，手机会接收到一个验证码，上面会提示验证码的过期时间，过了这个时间之后这个验证码就不能用了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">expire支持以下操作</span><br><span class="line"></span><br><span class="line">命令格式解释</span><br><span class="line">expireexpire key seconds设置key的过期时间(单位：秒)</span><br><span class="line">ttlttl key获取key的剩余有效时间</span><br><span class="line">persistpersist key取消key的过期时间</span><br><span class="line">expireatexpireat key timestamp设置UNIX时间戳的过期时间</span><br></pre></td></tr></table></figure><h4 id="设置key的过期时间"><a href="#设置key的过期时间" class="headerlink" title="设置key的过期时间"></a>设置key的过期时间</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set abc 123</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; expire abc 200</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><h4 id="获取key的剩余有效时间"><a href="#获取key的剩余有效时间" class="headerlink" title="获取key的剩余有效时间"></a>获取key的剩余有效时间</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ttl abc</span><br><span class="line">(integer) 192</span><br></pre></td></tr></table></figure><h4 id="取消key的过期时间"><a href="#取消key的过期时间" class="headerlink" title="取消key的过期时间"></a>取消key的过期时间</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; persist abc</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时再查看这个key的剩余有效时间，返回的值是-1，-1表示这个key是一个永久存在的key</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ttl abc</span><br><span class="line">(integer) -1</span><br></pre></td></tr></table></figure><h4 id="还可以通过expireat指定key在指定时间点过期"><a href="#还可以通过expireat指定key在指定时间点过期" class="headerlink" title="还可以通过expireat指定key在指定时间点过期"></a>还可以通过expireat指定key在指定时间点过期</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">先获取当前时间戳</span><br><span class="line">[root@bigdata04 ~]# date +%s</span><br><span class="line">1768618628</span><br><span class="line">127.0.0.1:6379&gt; expireat abc 1768618638</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">过一会再查看这个key的剩余有效时间，返回的是-2，表示这个key被删除了，不存在了</span><br><span class="line">127.0.0.1:6379&gt; ttl abc</span><br><span class="line">(integer) -2</span><br><span class="line">127.0.0.1:6379&gt; exists abc</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">总结一下：</span><br><span class="line">当key永久存在的时候，执行ttl返回的是-1，</span><br><span class="line">当key被设置了过期时间之后，执行ttl返回的就是这个key剩余的有效时间</span><br><span class="line">当key已经被删除了，不存在的时候，执行ttl返回的是-2</span><br></pre></td></tr></table></figure><h3 id="pipeline-管道"><a href="#pipeline-管道" class="headerlink" title="pipeline 管道"></a>pipeline 管道</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">针对批量操作数据或者批量初始化数据的时候使用，效率高</span><br><span class="line">Redis的pipeline功能在命令行中没有实现，在Java客户端(jedis)中是可以使用的</span><br><span class="line"></span><br><span class="line">它的原理是这样的</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151124245.png" alt="image-20230615112427787"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">不使用管道的时候，我们每执行一条命令都需要和redis服务器交互一次</span><br><span class="line">使用管道之后，可以实现一次提交一批命令，这一批命令只需要和redis服务器交互一次，所以就提高了性能。</span><br><span class="line">这个功能就类似于mysql中的batch批处理。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">接下来看一个案例</span><br><span class="line">案例：初始化10万条数据</span><br><span class="line">需求：使用普通方式一条一条添加和使用管道批量初始化进行对比分析</span><br><span class="line"></span><br><span class="line">代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.redis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Pipeline;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * pipeline(管道)的使用</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PipelineOp</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1：不使用管道</span></span><br><span class="line">        Jedis jedis = RedisUtils.getJedis();</span><br><span class="line">        <span class="keyword">long</span> start_time = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100000</span>;i++)&#123;</span><br><span class="line">            jedis.set(<span class="string">"a"</span>+i,<span class="string">"a"</span>+i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> end_time = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">"不使用管道，耗时："</span>+(end_time-start_time));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2：使用管道</span></span><br><span class="line">        Pipeline pipelined = jedis.pipelined();</span><br><span class="line">        start_time = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100000</span>;i++)&#123;</span><br><span class="line">            pipelined.set(<span class="string">"b"</span>+i,<span class="string">"b"</span>+i);</span><br><span class="line">        &#125;</span><br><span class="line">        pipelined.sync();</span><br><span class="line">        end_time = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">"使用管道，耗时："</span>+(end_time-start_time));</span><br><span class="line"></span><br><span class="line">        RedisUtils.returnResource(jedis);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果如下：</span><br><span class="line"></span><br><span class="line">不使用管道，耗时：40887</span><br><span class="line">使用管道，耗时：180</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在代码执行的过程中，我们可以使用info命令观察数据库中的数据条数</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; info</span><br><span class="line"># Keyspace</span><br><span class="line">db0:keys&#x3D;200000,expires&#x3D;1,avg_ttl&#x3D;389945</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">从这可以看出来，针对海量数据的初始化，管道可以显著提高初始化性能。</span><br></pre></td></tr></table></figure><h3 id="info命令"><a href="#info命令" class="headerlink" title="info命令"></a>info命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在redis-cli中使用&gt;info</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">这里面参数比较多</span><br><span class="line">在这我们主要关注几个重点的参数</span><br><span class="line"></span><br><span class="line"># Redis 服务器版本</span><br><span class="line">redis_version:5.0.9</span><br><span class="line"># Redis服务的可执行文件路径</span><br><span class="line">executable:&#x2F;data&#x2F;soft&#x2F;redis-5.0.9&#x2F;redis-server</span><br><span class="line"># 启动Redis时使用的配置文件路径</span><br><span class="line">config_file:&#x2F;data&#x2F;soft&#x2F;redis-5.0.9&#x2F;redis.conf</span><br><span class="line"># 已连接客户端的数量</span><br><span class="line">connected_clients:1</span><br><span class="line"># Redis目前存储数据使用的内容</span><br><span class="line">used_memory_human:15.01M</span><br><span class="line"># Redis可以使用的内存总量，和服务器的内存有关</span><br><span class="line">total_system_memory_human:1.78G</span><br><span class="line"># db0表示0号数据库，keys：表示0号数据库的key总量，expires：表示0号数据库失效被删除的key总量</span><br><span class="line">db0:keys&#x3D;200001,expires&#x3D;1,avg_ttl&#x3D;389945</span><br></pre></td></tr></table></figure><h3 id="Redis的持久化"><a href="#Redis的持久化" class="headerlink" title="Redis的持久化"></a>Redis的持久化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Redis持久化简单理解就是把内存中的数据持久化到磁盘中 可以保证Reids重启之后还能恢复之前的数据</span><br><span class="line">Redis支持两种持久化，可以 单独使用 或者 组合使用</span><br><span class="line"></span><br><span class="line">RDB 和 AOF</span><br><span class="line">RDB是Redis默认的持久化机制</span><br></pre></td></tr></table></figure><h4 id="Redis持久化之RDB"><a href="#Redis持久化之RDB" class="headerlink" title="Redis持久化之RDB"></a>Redis持久化之RDB</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RDB持久化是通过快照完成的，当符合一定条件时Redis会自动将内存中的所有数据执行快照操作并存储到硬盘上，默认存储在dump.rdb文件中</span><br><span class="line"></span><br><span class="line">[root@bigdata04 redis-5.0.9]# ll</span><br><span class="line">....</span><br><span class="line">-rw-r--r--.  1 root root 2955661 Jan 17 12:12 dump.rdb</span><br><span class="line">......</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Redis什么时候会执行快照？</span><br><span class="line"></span><br><span class="line">Redis执行快照的时机是由以下参数控制的，这些参数是在redis.conf文件中的</span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"></span><br><span class="line">save 900 1 表示900秒内至少一个key被更改则进行快照</span><br><span class="line">这里面的三个时机哪个先满足都会执行快照操作。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RDB的优点：由于存储的有数据快照文件，恢复数据很方便</span><br><span class="line">RDB的缺点：会丢失最后一次快照以后更改的所有数据，因为两次快照之间是由一个时间差的，这一段时间之内修改的数据可能会丢。(但是如果是正常关闭redis是不会丢掉最后修改的内容)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151555393.png" alt="image-20230615155333458"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis重启的时候就会根据dump.rdb进行恢复数据，所以可以将这个本地文件拷贝到其它位置或者节点进行备份。</span><br></pre></td></tr></table></figure><h4 id="Redis持久化之AOF"><a href="#Redis持久化之AOF" class="headerlink" title="Redis持久化之AOF"></a>Redis持久化之AOF</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AOF持久化是通过日志文件的方式，默认情况下没有开启，可以通过appendonly参数开启</span><br><span class="line">[root@bigdata04 redis-5.0.9]# vi redis.conf </span><br><span class="line">....</span><br><span class="line">appendonly yes</span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">AOF日志文件的保存位置和RDB文件相同，都是dir参数设置的，默认的文件名是appendonly.aof</span><br><span class="line"></span><br><span class="line">在情况下(修改文件配置后)，重启redis，进入redis shell后info，发现数据没了</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151552005.png" alt="image-20230615155255242"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">但是RDB持久化的数据还在，但重启后info发现数据库里数据没了。这是因为同时开启两种持久化，默认选择AOF，此时生成的appendonly.aof还是空的，读不到之前的数据</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151553800.png" alt="image-20230615155333458"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">可以用&gt;config set appendonly yes</span><br><span class="line">这种方式优雅地转换，这样临时开启后，会自动往appendonly.aof里写数据</span><br><span class="line">然后再永久设置conf配置文件里的相关设置，以后重启后就可以恢复数据了</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">注意：dir参数的值为. 表示当前目录，也就是说我们在哪个目录下启动redis，rdb快照文件和aof日志文件就产生在哪个目录下。</span><br><span class="line"></span><br><span class="line">可以试验一下，换一个目录启动redis，发下redis中的数据是空的。关闭之后，重新在之前的目录启动redis，数据又回来了。</span><br><span class="line"></span><br><span class="line">AOF方式只会记录用户的写命令，添加、修改、删除之类的命令，查询命令不会记录，因为查询命令不会影响数据的内容。</span><br><span class="line"></span><br><span class="line">那redis什么时候会把用户的写命令同步到aof文件中呢？</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151602879.png" alt="image-20230615160210401"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">默认是每秒钟执行一次同步操作。appendfsync everysec</span><br><span class="line">也可以实现每执行一次写操作就执行一次同步操作，appendfsync always，但是这样效率会有点低。</span><br><span class="line">或者使用appendfsync no，表示不主动进行同步，由操作系统来做，30秒执行一次。</span><br><span class="line"></span><br><span class="line">如果大家对数据的丢失确实是0容忍的话，可以使用always。</span><br><span class="line">不过一般情况下，redis中存储的都是一些缓存数据，就算丢了也没关系，程序还会继续往里面写新数据，不会造成多大影响。</span><br></pre></td></tr></table></figure><h3 id="Redis-的安全策略"><a href="#Redis-的安全策略" class="headerlink" title="Redis 的安全策略"></a>Redis 的安全策略</h3><h4 id="设置数据库密码"><a href="#设置数据库密码" class="headerlink" title="设置数据库密码"></a>设置数据库密码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">默认情况下访问redis只要网络能通就可以直接访问，这样其实是有一些不安全的，不过我们一般会限制只能在内网访问，这样其实问题也不大。</span><br><span class="line"></span><br><span class="line">redis针对这个问题，也支持给数据库设置密码，在redis.conf中配置</span><br><span class="line"></span><br><span class="line">[root@bigdata04 redis-5.0.9]# vi redis.conf </span><br><span class="line">....</span><br><span class="line">requirepass admin</span><br><span class="line">....</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">重启redis服务</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli shutdown</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-server redis.conf</span><br><span class="line"></span><br><span class="line">重新连接redis</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli </span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; get imooc</span><br><span class="line">(error) NOAUTH Authentication required.</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; auth admin</span><br><span class="line">OK</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt;get imooc</span><br><span class="line">hello bigdata!</span><br><span class="line"></span><br><span class="line">在代码层面，以后在使用的时候时候就需要使用auth方法先校验权限了。</span><br><span class="line"><span class="keyword">package</span> com.imooc.redis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 单连接方式操作redis</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisSingle</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注意：此代码能够正常执行的前提是</span></span><br><span class="line"><span class="comment">     * 1：redis所在服务器的防火墙需要关闭</span></span><br><span class="line"><span class="comment">     * 2：redis.conf中的bind参数需要指定192.168.182.103</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//获取jedis连接</span></span><br><span class="line">        Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"192.168.182.103"</span>,<span class="number">6379</span>);</span><br><span class="line">        <span class="comment">//使用密码</span></span><br><span class="line">        jedis.auth(<span class="string">"admin"</span>);</span><br><span class="line">        <span class="comment">//向redis中添加数据，key=imooc，value=hello bigdata!</span></span><br><span class="line">        jedis.set(<span class="string">"imooc"</span>,<span class="string">"hello bigdata!"</span>);</span><br><span class="line">        <span class="comment">//从redis中查询key=imooc的value的值</span></span><br><span class="line">        String value = jedis.get(<span class="string">"imooc"</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(value);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭jedis连接</span></span><br><span class="line">        jedis.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">注意：在实际工作中一般不会设置密码，因为我们在这设置的密码是明文的，其实意义也不大，针对别有用心的人，你这样设置是没有意义的。</span><br><span class="line"></span><br><span class="line">所以在实际工作中我们一般只需要控制好redis服务器的访问权限就可以了，redis服务器的访问权限其实就是使用bind参数来设置的。</span><br><span class="line"></span><br><span class="line">所以再把刚才设置的密码取消掉，直接把对应的配置注释掉即可</span><br><span class="line">[root@bigdata04 redis-5.0.9]# vi redis.conf </span><br><span class="line">#requirepass admin</span><br></pre></td></tr></table></figure><h4 id="bind参数的应用"><a href="#bind参数的应用" class="headerlink" title="bind参数的应用"></a>bind参数的应用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在实际工作中，我们的服务器至少会有3个ip地址</span><br><span class="line"></span><br><span class="line">-127.0.0.1 这个是本机回环地址</span><br><span class="line">-192.168.182.103 这个是本机的内网地址</span><br><span class="line">-还有一个是外网地址</span><br><span class="line"></span><br><span class="line">我们一般会使用bind绑定内网ip，这样其实就限制了redis服务器的访问范围，不会暴露在外网，只需要运维同学做好网络的访问限制就可以了，此时我们就可以认为redis是安全的了。</span><br></pre></td></tr></table></figure><h4 id="命令重命名"><a href="#命令重命名" class="headerlink" title="命令重命名"></a>命令重命名</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">咱们前面讲过一个命令是flushall，这个命令是很危险的，它可以把redis中的所有数据全部清空</span><br><span class="line">所以在实际工作中一般需要将这个命令给禁用掉，防止误操作。</span><br><span class="line"></span><br><span class="line">在redis.conf配置文件中进行设置</span><br><span class="line"></span><br><span class="line">[root@bigdata04 redis-5.0.9]# vi redis.conf </span><br><span class="line">....</span><br><span class="line">rename-command flushall &quot;&quot;</span><br><span class="line">....</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">这样修改之后，就把flushall命令给禁用掉了</span><br><span class="line">重启redis服务</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli shutdown</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-server redis.conf</span><br><span class="line"></span><br><span class="line">重新连接redis</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli </span><br><span class="line">127.0.0.1:6379&gt; flushall</span><br><span class="line">(error) ERR unknown command &#96;flushall&#96;, with args beginning with: </span><br><span class="line">127.0.0.1:6379&gt; </span><br><span class="line"></span><br><span class="line">此时会提示未知命令。</span><br><span class="line"></span><br><span class="line">其实我们还可以选择，在重命名的时候给这个命令起一个别名，这样后期如果想使用的时候也是可以使用的。</span><br><span class="line">我们现在在后面直接指定的是空字符串 就是直接禁用了，如果指定一个其它字符串，就相当于起别名了。</span><br></pre></td></tr></table></figure><h3 id="一个Redis实例最多能存放多少key？"><a href="#一个Redis实例最多能存放多少key？" class="headerlink" title="一个Redis实例最多能存放多少key？"></a>一个Redis实例最多能存放多少key？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">一个Redis实例最多能存放多少key？</span><br><span class="line">有没有限制？</span><br><span class="line"></span><br><span class="line">Redis本身是不会限制存储多少key的，但是Redis是基于内存的，它的存储极限是系统中的可用内存值，如果内存存满了，那就无法再存储key了。</span><br></pre></td></tr></table></figure><h3 id="Redis监控命令-monitor"><a href="#Redis监控命令-monitor" class="headerlink" title="Redis监控命令-monitor"></a>Redis监控命令-monitor</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">这个monitor命令是一把双刃剑。</span><br><span class="line">在实际工作中要慎用。</span><br><span class="line">先演示一下：</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli </span><br><span class="line">127.0.0.1:6379&gt; monitor</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">执行代码RedisSingle.java中的代码</span><br><span class="line">然后会发现monitor监控到我们对redis的所有操作</span><br><span class="line"></span><br><span class="line">monitor可以监控我们对redis的所有操作，如果在线上的服务器上打开了这个功能，这里面就会频繁打印出来我们对redis数据库的所有操作，这样会影响redis的性能，所以说要慎用。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">但是在某些特殊的场景下面它是很有用的</span><br><span class="line">之前在工作中我遇到过一个很奇怪的问题，redis中的一个key总是会莫名其妙的消失</span><br><span class="line">我的一个程序会定时向redis中写入一个key，但是我发现这个key刚写进去，然后一会就没了，很奇怪，当时我仔细排查了我的代码，里面既没有设置失效时间，也没有使用删除功能。</span><br><span class="line">所以这个key不是我的代码删的，肯定是有其它的代码会删除这个key，但是到底是哪的代码？</span><br><span class="line">这个时候就不好排查了，我们的业务机有几十台，根本无从下手。</span><br><span class="line">这个时候我突然想到了monitor这个命令，虽然开启monitor会影响redis的性能，但是这个时候需要排查问题，使用一会也是可以接受的。</span><br><span class="line">所以就打开了monitor，打开之后屏幕上就打印出来很多命令，这样根本就看不清，没办法追踪，数据太多了。</span><br><span class="line">所以又想到了这个办法，结合grep命令来操作，这样就可以过滤出来对指定key的所有操作了。</span><br><span class="line"></span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli monitor | grep key</span><br><span class="line">1768629282.484868 [0 192.168.182.1:52364] &quot;del&quot; &quot;key&quot;</span><br><span class="line"></span><br><span class="line">通过这条数据我们可以分析出来到底是哪台机器上的程序删除了这个key。然后再排查这台机器上都有哪些程序，对应的去排查代码，这样就快多了，最终发现是有一个代码里面会定时删除这个key。</span><br><span class="line"></span><br><span class="line">这个就是monitor的典型应用。</span><br></pre></td></tr></table></figure><h2 id="5-Redis核心复盘"><a href="#5-Redis核心复盘" class="headerlink" title="5 Redis核心复盘"></a>5 Redis核心复盘</h2><h3 id="Redis架构演进"><a href="#Redis架构演进" class="headerlink" title="Redis架构演进"></a>Redis架构演进</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">现在我们使用的Redis是单机的，单机的Redis存在单点故障的问题，</span><br><span class="line">所以Redis提供了主从复制的方案</span><br></pre></td></tr></table></figure><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Redis的复制功能支持多个数据库之间的数据同步</span><br><span class="line">通过Redis的复制功能可以很好的实现数据库的 读写分离，提高服务器的负载能力。</span><br><span class="line">主数据库(Master)主要进行写操作，而从数据库(Slave)负责读操作</span><br><span class="line">一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库</span><br><span class="line"></span><br><span class="line">看这个图</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151205372.png" alt="image-20230615120503900"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">这个就是redis的主从复制架构</span><br><span class="line">master节点，是主数据库，负责写操作，下面的3个slave节点是从数据库，负责读操作。</span><br><span class="line">当我们把数据写入到master节点之后，master节点会把数据同步给下面的3个从节点。</span><br><span class="line">这就是Redis的主从复制架构。</span><br><span class="line"></span><br><span class="line">这种架构其实存在一个问题，如果主节点挂了，从节点是无法自动切换为主节点的。所以这个时候只能读数据，不能写数据。这样肯定还是存在单点故障的。</span><br><span class="line">所以redis在这个架构的基础上又提供了sentinel 哨兵机制。</span><br></pre></td></tr></table></figure><h3 id="Sentinel"><a href="#Sentinel" class="headerlink" title="Sentinel"></a>Sentinel</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这个sentinel哨兵机制提供了三个功能</span><br><span class="line"></span><br><span class="line">-监控：Sentinel实时监控主服务器和从服务器运行状态</span><br><span class="line">-提醒：当被监控的某个Redis服务器出现问题时，Sentinel 可以向系统管理员发送通知， 也可以通过API向其它程序发送通知</span><br><span class="line">-自动故障转移：当一个主服务器不能正常工作时，Sentinel可以将一个从服务器升级为主服务器，并对其它从服务器进行配置，让它们使用新的主服务器。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151207517.png" alt="image-20230615120718376"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">上面这两个sentine1和sentinel2就是使用redis启动的哨兵服务。</span><br><span class="line">他们两个可以监控下面的这个主从架构的redis，当发现master宕机之后，会把slave切换为，master。</span><br><span class="line"></span><br><span class="line">这里面涉及两个概念，大家需要注意一下</span><br><span class="line">一个是主观下线状态，一个是客观下线状态</span><br><span class="line"></span><br><span class="line">主观下线状态表示是单个sentinel实例对节点做出的下线判断</span><br><span class="line">客观下线状态表示是多个sentinel实例对主节点做出的下线判断</span><br><span class="line"></span><br><span class="line">主节点：具有主观下线状态和客观下线状态</span><br><span class="line">从节点：只有主观下线状态</span><br><span class="line"></span><br><span class="line">注意：针对主节点，它具有主观下线状态和客观下线状态，在这个架构里面，如果sentinel1</span><br><span class="line">认为master节点挂了，那么会给它标记为主观下线状态，此时，并不会进行故障转移，有可能是sentinel1误判了，当sentinel2也认为master节点挂了，那么此时会给master标记为客观下线状态，因为这个时候不是一个人认为它挂了，当被标记为客观下线状态之后，此时就会进行故障转移了，slave节点就会变成master节点了。</span><br><span class="line"></span><br><span class="line">针对从节点而言，只有主观下线状态，就算是误判也没有什么影响。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">这就是Redis中的sentinel哨兵机制。</span><br><span class="line"></span><br><span class="line">sentinel哨兵机制虽然解决了主从节点故障自动转移的问题，但是还存在一个问题，针对这种架构，不管你使用多少台机器，redis的最终存储能力还是和单台机器有关的。</span><br><span class="line">如果我们想存储海量数据的话，这种架构理论上是实现不了的。</span><br><span class="line"></span><br><span class="line">基于此，Redis提供了集群这种架构。</span><br></pre></td></tr></table></figure><h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Redis集群是一个无中心的分布式Redis存储架构，可以在多个节点之间数据共享，解决了Redis高可用、可扩展等问题</span><br><span class="line"></span><br><span class="line">一个Redis集群包含16384个哈希槽（hash slot），数据库中的每个数据都属于这16384个哈希槽中的一个</span><br><span class="line">集群使用公式 CRC16(key) % 16384 来计算键key属于哪个槽，集群中的每一个节点负责维护一部分哈希槽</span><br><span class="line"></span><br><span class="line">集群中的每个节点都有1个至N个复制品，其中一个是主节点其余的是从节点，如果主节点下线了，集群就会把这个主节点的一个从节点设置为新的主节点，继续工作</span><br><span class="line"></span><br><span class="line">注意：如果某一个主节点和它所有的从节点都下线的话，集群就会停止工作了</span><br><span class="line"></span><br><span class="line">看这个图</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306151211766.png" alt="image-20230615121104729" style="zoom:67%;"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">里面红色的表示是5个master节点，此时redis集群的存储能力就是这5个master节点内存的总和。</span><br><span class="line">针对每一个master节点，外面都有两个从节点，master节点宕机之后，对应的slave节点会自动切换为master节点，保证集群的稳定性和可用性。</span><br><span class="line">如果master1和slave1、slave10这三个节点都宕机了，那么此时集群就无法使用了。</span><br><span class="line"></span><br><span class="line">针对Redis集群而言，它是一个无中心节点的分布式存储架构。</span><br><span class="line">我们在操作集群的时候，可以连接到集群的任意一个节点去操作，都是可以的，在使用的时候不用管数据到底存储在哪个节点上面，这个是redis底层去处理的，我们只需要连接到任意一台机器去操作即可。</span><br><span class="line"></span><br><span class="line">集群架构里面已经包含了主从架构和sentinel的功能，不需要单独配置了。</span><br></pre></td></tr></table></figure><blockquote></blockquote><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Redis" scheme="http://tianyong.fun/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-快速上手NoSQL数据库HBase-3</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93HBase-3.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93HBase-3.html</id>
    <published>2023-06-13T01:24:28.000Z</published>
    <updated>2023-06-23T02:39:35.183Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="快速上手NoSQL数据库HBase-3"><a href="#快速上手NoSQL数据库HBase-3" class="headerlink" title="快速上手NoSQL数据库HBase-3"></a>快速上手NoSQL数据库HBase-3</h1><h2 id="5-HBase调优策略和扩展内容"><a href="#5-HBase调优策略和扩展内容" class="headerlink" title="5 HBase调优策略和扩展内容"></a>5 HBase调优策略和扩展内容</h2><h3 id="HBase-调忧策略"><a href="#HBase-调忧策略" class="headerlink" title="HBase 调忧策略"></a>HBase 调忧策略</h3><h4 id="预分区"><a href="#预分区" class="headerlink" title="预分区"></a>预分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HBase默认新建的表中只有一个Region，这个Region的Rowkey是没有边界的，即没有startRowkey和endRowkey，在数据写入时，所有数据都会写入这个默认的Region</span><br><span class="line"></span><br><span class="line">随着数据量的不断增加，此Region已经不能承受不断增长的数据量，会进行Split，分裂成2个Region。</span><br><span class="line">在这个过程中，会产生两个问题：</span><br><span class="line">-数据往一个Region上写,会有写热点问题。</span><br><span class="line">-Region split会消耗宝贵的集群IO资源。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">基于此我们可以控制在建表的时候，创建多个空Region，并确定每个Region的起始和终止Rowkey，这样只要我们设计的Rowkey能均匀的命中各个Region，就不会存在写热点问题。Region分裂的几率也会大大降低。当然随着数据量的不断增长，该分裂还是要进行分裂的。</span><br><span class="line"></span><br><span class="line">像这种预先给HBase表创建多个Region的方式，称之为预分区。</span><br><span class="line">hbase(main):001:0&gt; create &#39;t20&#39;, &#39;c1&#39;, SPLITS &#x3D;&gt; [&#39;10&#39;, &#39;20&#39;, &#39;30&#39;, &#39;40&#39;]</span><br><span class="line">Created table t20</span><br><span class="line">Took 3.3741 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t20</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">到HBase的界面中查看这个表的region信息</span><br><span class="line">http:&#x2F;&#x2F;bigdata01:16010&#x2F;</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221558757.png" alt="image-20230622155802533"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221558404.png" alt="image-20230622155817107"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">通过这个图可以看出来，此时创建的这个表会提前创建多个Region。</span><br><span class="line"></span><br><span class="line">默认情况下创建的表是只有1个Region的。</span><br><span class="line">以表t1为例：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221559398.png" alt="image-20230622155938448"></p><h4 id="RowKey的设计原则"><a href="#RowKey的设计原则" class="headerlink" title="RowKey的设计原则"></a>RowKey的设计原则</h4><h5 id="Rowkey长度原则"><a href="#Rowkey长度原则" class="headerlink" title="Rowkey长度原则"></a>Rowkey长度原则</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Rowkey底层存储是一个二进制流，可以是任意字符串，最大长度 64kb ，实际应用中一般是10-100字节，以byte[]形式保存，一般设计为定长。</span><br><span class="line">建议越短越好，不要超过16个字节，原因如下：</span><br><span class="line"></span><br><span class="line">-数据的持久化文件HFile中是按照KeyValue存储的，如果Rowkey过长，比如超过100字节，1000w行数据，Rowkey就要占用100*1000w&#x3D;10亿字节，将近1G数据，这样会极大影响HFile的存储效率；</span><br><span class="line"></span><br><span class="line">-MemStore会缓存部分数据到内存，如果Rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。</span><br><span class="line"></span><br><span class="line">-目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性</span><br></pre></td></tr></table></figure><h5 id="Rowkey散列原则"><a href="#Rowkey散列原则" class="headerlink" title="Rowkey散列原则"></a>Rowkey散列原则</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Rowkey散列原则，主要是为了避免数据热点问题。</span><br><span class="line">虽然我们可以在建表的时候提前设计预分区，但是假设数据的Rowkey都是手机号，那么都是1开头，按照前面的设计，那么所有的数据都会写到10-20之间的Region中，仍然没有做到负载均衡。</span><br><span class="line">如何保证我们的数据能够均匀的分布到预先设计好的分区中呢？</span><br><span class="line">解决思路（以手机号为例）：</span><br><span class="line"></span><br><span class="line">-手机号反转，将手机号的最后一位前置，这样第一位就是0-9之间的任意一个数字了。</span><br><span class="line">-按照一定规则使用hashCode获取余数，拼在手机号前面。例如：根据手机号后四位使用hashCode获取余数。这里的规则一定要是可以反推出来的，这样后期还可以根据这个规则找到对应的手机号，尽量不要使用随机数。</span><br></pre></td></tr></table></figure><h5 id="Rowkey唯一性原则"><a href="#Rowkey唯一性原则" class="headerlink" title="Rowkey唯一性原则"></a>Rowkey唯一性原则</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">必须在设计上保证其唯一性，因为Rowkey相同则会覆盖</span><br><span class="line">Rowkey是HBase里面唯一的索引,对于某些查询频繁的限定条件可以把它的内容存放在Rowkey里面，提高查询效率。</span><br><span class="line">例如：需要经常使用姓名和年龄这两个字段进行查询，那么可以考虑把姓名和年龄拼接到一块作为Rowkey。</span><br></pre></td></tr></table></figure><h4 id="列族的设计原则"><a href="#列族的设计原则" class="headerlink" title="列族的设计原则"></a>列族的设计原则</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在设计列族的时候，建议把经常读取的字段存储到一个列族中，不经常读取的字段放到另一个列族中。</span><br><span class="line">这样在读取部分数据的时候，就只需要读取一个列族文件即可，可以提高读取效率。</span><br></pre></td></tr></table></figure><h4 id="批量处理"><a href="#批量处理" class="headerlink" title="批量处理"></a>批量处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Table.get(Get)方法可以根据一个指定的Rowkey获取一行记录，同样HBase提供了另一个方法：通过调用Table.get(List)方法可以根据一个指定的Rowkey列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络IO开销，这样可以带来明显的性能提升。</span><br><span class="line">同理Table.delete(List) 和Table.put(List)</span><br><span class="line"></span><br><span class="line">如果一次操作的数据量不是特别多，例如：100~1000条左右的数据量，可以考虑这种方式。</span><br><span class="line">如果是一次需要批量操作上千万的数据，建议使用前面讲的批量导入导出方法，效率更高。</span><br></pre></td></tr></table></figure><h4 id="Region的request计数"><a href="#Region的request计数" class="headerlink" title="Region的request计数"></a>Region的request计数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HBase UI界面table Regions中的Requests参数值</span><br><span class="line">这个参数的意义在于，可以分析哪个Region被频繁请求，是否存在读写热点的问题。</span><br><span class="line"></span><br><span class="line">注意：HBase集群重启之后，Requests参数值会被清空。</span><br><span class="line"></span><br><span class="line">以student表为例：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221606296.png" alt="image-20230622160612884"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221606147.png" alt="image-20230622160625041"></p><h4 id="HBase核心参数优化"><a href="#HBase核心参数优化" class="headerlink" title="HBase核心参数优化"></a>HBase核心参数优化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hbase.hregion.majorcompaction</span><br><span class="line">配置大合并的间隔时间，默认为604800000毫秒(7天)，可设置为0，禁止自动的大合并，大合并的执行可能会持续数小时，为减少对业务的影响，建议在业务低峰期进行手动或者通过脚本或者API定期进行大合并。</span><br><span class="line"></span><br><span class="line">hbase.hregion.max.filesize</span><br><span class="line">默认为10737418240 Byte(10G)，当Region达到这个阈值时，会自动分裂。Region分裂会有短暂的Region下线时间(通常在5s以内)，为减少对业务端的影响，建议调大该值，并在业务低峰期定时手动进行分裂。</span><br><span class="line"></span><br><span class="line">hbase.regionserver.handler.count</span><br><span class="line">默认30，对于大负载的Put（达到了M范围）或是大范围的Scan操作，handler数目不易过大，易造成OOM（内存溢出）。 对于小负载的put、get，delete等操作，handler数要适当调大。handler属于一个处理器，实现底层数据的发送。</span><br><span class="line"></span><br><span class="line">hbase.hregion.memstore.flush.size</span><br><span class="line">默认值134217728 Byte (128M)，单位字节，这个参数是Memstore中数据持久化到Storefile的时机，超过该阈值，则会把Memstore中的数据持久化到Storefile中，如果Regionserver的JVM内存比较充足(例如：16G以上)，可以适当调大该值，例如：调整为256M。这样可以减少Memstore中数据溢写文件的次数。</span><br><span class="line"></span><br><span class="line">hbase.hregion.memstore.block.multiplier</span><br><span class="line">默认值4，如果一个Memstore的内存大小已经超过hbase.hregion.memstore.flush.size * hbase.hregion.memstore.block.multiplier，则会阻塞该Memstore的写操作，为避免阻塞，可以适当调大，例如6~8，但如果太大，则会有OOM的风险。 如果在Regionserver日志中出现&quot;Blocking updates for ‘’ on region : memstore size &lt;多少M&gt; is &gt;&#x3D; than blocking &lt;多少M&gt; size&quot;的信息时，说明这个值该调整了。</span><br><span class="line"></span><br><span class="line">hbase.hstore.compaction.min</span><br><span class="line">默认值为3，如果任何一个Store里的Storefile总数超过该值，会触发默认的合并操作，可以设置5~8，在手动的定期大合并中进行Storefile文件的合并，减少合并的次数，不过这会延长合并的时间</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">这些参数其实偏向于运维岗位的范畴，开发人员可以作为了解即可。</span><br><span class="line">如果想要修改这些参数的话需要在hbase-site.xml中进行修改。</span><br><span class="line"></span><br><span class="line">这些参数的默认值是在hbase-default.xml中的。</span><br><span class="line"></span><br><span class="line">而hbase-default.xml文件在hbase-common-2.2.7.jar里面。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221607392.png" alt="image-20230622160714030"></p><h3 id="HBase扩展内容"><a href="#HBase扩展内容" class="headerlink" title="HBase扩展内容"></a>HBase扩展内容</h3><h4 id="【扩展】Hive与HBase-整合"><a href="#【扩展】Hive与HBase-整合" class="headerlink" title="【扩展】Hive与HBase 整合"></a>【扩展】Hive与HBase 整合</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Hive提供了与HBase的集成，可以在HBase表上使用HQL语句进行查询，插入操作以及进行join和union等复杂查询。</span><br><span class="line"></span><br><span class="line">Hive整合HBase后的使用场景：</span><br><span class="line"></span><br><span class="line">-通过Hive把数据加载到HBase中，数据源可以是文件也可以是Hive中的表。</span><br><span class="line">-通过整合，让HBase支持JOIN、GROUP等SQL查询语法。</span><br><span class="line">-通过整合，不仅可完成HBase的数据实时查询，也可以使用Hive查询HBase中的数据完成复杂的数据分析。</span><br><span class="line"></span><br><span class="line">注意：Hive查询HBase中的数据，性能一般，并不能发挥HBase中根据Rowkey查询性能较高的特性。了解即可，实际工作中基本不会这样使用。</span><br><span class="line"></span><br><span class="line">如果确实既有海量数据读写需求，还有SQL查询需求，可以考虑将数据存储两份，HBase中维护实时读写的数据，然后定时将数据导出到HDFS中，在Hive中映射表提供SQL查询服务。</span><br></pre></td></tr></table></figure><h4 id="【扩展】Phoenix（凤凰）"><a href="#【扩展】Phoenix（凤凰）" class="headerlink" title="【扩展】Phoenix（凤凰）"></a>【扩展】Phoenix（凤凰）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Phoenix是构建在HBase上的一个SQL层，可以用标准的JDBC APIs来创建表，插入数据和对数据进行查询。</span><br><span class="line"></span><br><span class="line">Phoenix完全使用Java编写，作为HBase内嵌的JDBC驱动。Phoenix查询引擎会将SQL查询转换为一个或多个HBase扫描，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。</span><br><span class="line"></span><br><span class="line">Phoenix通过以下方式使我们可以少写代码，并且性能比我们自己写代码更好：</span><br><span class="line"></span><br><span class="line">-将SQL编译成原生的HBase scans。</span><br><span class="line">-确定scan关键字的最佳开始和结束</span><br><span class="line">-让scan并行执行</span><br></pre></td></tr></table></figure><h4 id="【扩展】协处理器coprocessor"><a href="#【扩展】协处理器coprocessor" class="headerlink" title="【扩展】协处理器coprocessor"></a>【扩展】协处理器coprocessor</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">HBase作为列族数据库最经常被人诟病的特性包括：无法轻易建立“二级索引”，难以执行求和、计数、排序等操作。</span><br><span class="line"></span><br><span class="line">比如，在旧版本的(&lt;0.92)HBase中，统计数据表的总行数，需要使用Counter方法，执行一次MapReduce Job才能得到。虽然HBase在数据存储层中集成了MapReduce，能够有效用于数据表的分布式计算。然而在很多情况下，做一些简单的相加或者聚合计算的时候，如果直接将计算过程放置在server端，能够减少通讯开销，从而获得很好的性能提升。于是，HBase在0.92之后引入了协处理器(coprocessors)，实现一些激动人心的新特性：能够轻易建立二次索引、复杂过滤器以及访问控制等。</span><br><span class="line"></span><br><span class="line">协处理器有两种：observer和 endpoint</span><br><span class="line"></span><br><span class="line">-Observer 允许集群在正常的客户端操作过程中可以有不同的行为表现</span><br><span class="line">-Endpoint 允许扩展集群的能力，对客户端应用开放新的运算命令</span><br><span class="line">-Observer 类似于 RDBMS 中的触发器，主要在服务端工作</span><br><span class="line">-Endpoint 类似于 RDBMS 中的存储过程，主要在服务端工作</span><br><span class="line">-Observer 可以实现权限管理、优先级设置、监控、ddl 控制、二级索引等功能</span><br><span class="line">-Endpoint 可以实现 min、max、avg、sum、distinct、group by 等功能</span><br></pre></td></tr></table></figure><h4 id="【扩展】Elasticsearch-HBase"><a href="#【扩展】Elasticsearch-HBase" class="headerlink" title="【扩展】Elasticsearch + HBase"></a>【扩展】Elasticsearch + HBase</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">HBase里面只有RowKey作为一级索引， 如果要对表里的非RowKey字段进行数据检索和查询， 往往要通过MapReduce&#x2F;Spark等分布式计算框架进行，硬件资源消耗和时间延迟都会比较高。</span><br><span class="line"></span><br><span class="line">由于HBase不支持多条件查询，不提供二级索引，难以满足用户对检索功能多样性和高效率两方面的需求。</span><br><span class="line"></span><br><span class="line">本方案通过提出数据与索引的分离，利用HBase数据库的存储模式灵活多变，容纳海量数据等特点，结合Elasticsearch (简称为ES，ES是一个支持分布式的全文检索工具)的快速建立索引和提供多样化的查询接口等优势，构建基于ES的HBase二级索引方案。</span><br><span class="line"></span><br><span class="line">思路：将索引数据存储于ES中，做查询时，先到ES中查询，转换为统一的RowKey后，再拿RowKey到HBase中快速定位。</span><br><span class="line"></span><br><span class="line">注意：针对Elasticsearch +HBase架构设计会在后续更新的【仿百度搜索引擎】项目中实现。</span><br></pre></td></tr></table></figure><h4 id="【扩展】HBase实现分页功能"><a href="#【扩展】HBase实现分页功能" class="headerlink" title="【扩展】HBase实现分页功能"></a>【扩展】HBase实现分页功能</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">核心思路：</span><br><span class="line">使用PageFilter过滤器+循环动态设置startRow实现</span><br><span class="line"></span><br><span class="line">注意：循环动态设置startRow时，需要在上一次获取到的rowkey后面补0，表示新的开始，因为默认startRow中包含这一行数据</span><br><span class="line"></span><br><span class="line">正常情况PageFilter返回的结果数量可能大于设定的值，因为服务器集群的PageFilter是隔离的，只能保证每个Region返回的数据量不会超过PageFilter中设置的值。</span><br><span class="line"></span><br><span class="line">注意：想要解决返回数据超过设置数量的问题，可以考虑对获取到的数据进行截取，只保留需要的数据条数，下一次读取时根据上次截取的位置开始往后读取。</span><br><span class="line">当PageFilter和其它Filter一起使用时，需要将PageFilter加入到FilterList的末尾，否则会出现结果个数小于你期望的数量。</span><br><span class="line"></span><br><span class="line">首先创建一个带有预分区的表，并且向表里面初始化一批测试数据。</span><br><span class="line">create &#39;test&#39;, &#39;info&#39;,&#39;date&#39;, SPLITS &#x3D;&gt; [&#39;10&#39;, &#39;20&#39;, &#39;30&#39;, &#39;40&#39;]</span><br><span class="line"></span><br><span class="line">put &#39;test&#39;,&#39;10001&#39;,&#39;info:name&#39;,&#39;zs&#39;</span><br><span class="line">put &#39;test&#39;,&#39;10001&#39;,&#39;info:address&#39;,&#39;bj&#39;</span><br><span class="line">put &#39;test&#39;,&#39;10001&#39;,&#39;date:start_time&#39;,&#39;2021-01-01&#39;</span><br><span class="line">put &#39;test&#39;,&#39;10001&#39;,&#39;date:end_time&#39;,&#39;2021-01-01&#39;</span><br><span class="line"></span><br><span class="line">put &#39;test&#39;,&#39;10002&#39;,&#39;info:name&#39;,&#39;ww&#39;</span><br><span class="line">put &#39;test&#39;,&#39;10002&#39;,&#39;info:address&#39;,&#39;sh&#39;</span><br><span class="line">put &#39;test&#39;,&#39;10002&#39;,&#39;date:start_time&#39;,&#39;2021-01-02&#39;</span><br><span class="line">put &#39;test&#39;,&#39;10002&#39;,&#39;date:end_time&#39;,&#39;2021-01-02&#39;</span><br><span class="line"></span><br><span class="line">put &#39;test&#39;,&#39;20001&#39;,&#39;info:name&#39;,&#39;ls&#39;</span><br><span class="line">put &#39;test&#39;,&#39;20001&#39;,&#39;info:address&#39;,&#39;hz&#39;</span><br><span class="line">put &#39;test&#39;,&#39;20001&#39;,&#39;date:start_time&#39;,&#39;2021-01-01&#39;</span><br><span class="line">put &#39;test&#39;,&#39;20001&#39;,&#39;date:end_time&#39;,&#39;2021-01-01&#39;</span><br><span class="line"></span><br><span class="line">put &#39;test&#39;,&#39;20002&#39;,&#39;info:name&#39;,&#39;jack&#39;</span><br><span class="line">put &#39;test&#39;,&#39;20002&#39;,&#39;info:address&#39;,&#39;sh&#39;</span><br><span class="line">put &#39;test&#39;,&#39;20002&#39;,&#39;date:start_time&#39;,&#39;2021-01-02&#39;</span><br><span class="line">put &#39;test&#39;,&#39;20002&#39;,&#39;date:end_time&#39;,&#39;2021-01-02&#39;</span><br><span class="line"></span><br><span class="line">put &#39;test&#39;,&#39;30001&#39;,&#39;info:name&#39;,&#39;ls&#39;</span><br><span class="line">put &#39;test&#39;,&#39;30001&#39;,&#39;info:address&#39;,&#39;hz&#39;</span><br><span class="line">put &#39;test&#39;,&#39;30001&#39;,&#39;date:start_time&#39;,&#39;2021-01-01&#39;</span><br><span class="line">put &#39;test&#39;,&#39;30001&#39;,&#39;date:end_time&#39;,&#39;2021-01-01&#39;</span><br><span class="line"></span><br><span class="line">put &#39;test&#39;,&#39;30002&#39;,&#39;info:name&#39;,&#39;tom&#39;</span><br><span class="line">put &#39;test&#39;,&#39;30002&#39;,&#39;info:address&#39;,&#39;lz&#39;</span><br><span class="line">put &#39;test&#39;,&#39;30002&#39;,&#39;date:start_time&#39;,&#39;2021-01-02&#39;</span><br><span class="line">put &#39;test&#39;,&#39;30002&#39;,&#39;date:end_time&#39;,&#39;2021-01-02&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">代码如下：</span><br><span class="line"></span><br><span class="line">package com.imooc.hbase;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.CompareOperator;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.*;</span><br><span class="line">import org.apache.hadoop.hbase.filter.FilterList;</span><br><span class="line">import org.apache.hadoop.hbase.filter.PageFilter;</span><br><span class="line">import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;</span><br><span class="line">import org.apache.hadoop.hbase.filter.SubstringComparator;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.Comparator;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 结合Scan实现分页功能</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class PageFilterOp &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        &#x2F;&#x2F;获取配置</span><br><span class="line">        Configuration conf &#x3D; HBaseConfiguration.create();</span><br><span class="line">        &#x2F;&#x2F;指定HBase使用的zk的地址，多个都逗号隔开</span><br><span class="line">        conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;bigdata01:2181,bigdata02:2181,bigdata03:2181&quot;);</span><br><span class="line">        &#x2F;&#x2F;指定HBase在hdfs上的根目录</span><br><span class="line">        conf.set(&quot;hbase.rootdir&quot;,&quot;hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase&quot;);</span><br><span class="line">        &#x2F;&#x2F;创建HBase连接，负责对HBase中数据的增删改查(DML操作)</span><br><span class="line">        Connection conn &#x3D; ConnectionFactory.createConnection(conf);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;获取到test表的链接</span><br><span class="line">        Table table &#x3D; conn.getTable(TableName.valueOf(&quot;test&quot;));</span><br><span class="line"></span><br><span class="line">        Scan scan &#x3D; new Scan();</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;组装Filter列表</span><br><span class="line">        FilterList filterList &#x3D; new FilterList();</span><br><span class="line"></span><br><span class="line">        SingleColumnValueFilter singleColumnValueFilter &#x3D; new SingleColumnValueFilter(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;name&quot;), CompareOperator.EQUAL, new SubstringComparator(&quot;w&quot;));</span><br><span class="line">        &#x2F;&#x2F;注意：如果用到了多个filter，其中包含pagefilter，那么pagefilter需要放在fiterlist的最后一个</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;每页的数据量</span><br><span class="line">        int pageSize &#x3D; 2;</span><br><span class="line">        &#x2F;&#x2F;注意：pagefilter返回的数据总数会超过这里设置的数量，需要自己在程序内部处理</span><br><span class="line">        PageFilter pageFilter &#x3D; new PageFilter(pageSize);</span><br><span class="line">        filterList.addFilter(pageFilter);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;给scan设置Filter</span><br><span class="line">        scan.setFilter(filterList);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;记录上一次返回的分页数据中的最大的Rowkey，最开始为null</span><br><span class="line">        byte[] lastRowKey &#x3D; null;&#x2F;&#x2F;Bytes.toBytes(&quot;10002&quot;);</span><br><span class="line"></span><br><span class="line">        if(lastRowKey &#x3D;&#x3D; null)&#123;&#x2F;&#x2F;第一次查询，查询第一页数据</span><br><span class="line">            &#x2F;&#x2F;设置一个不存在的Rowkey</span><br><span class="line">            scan.withStartRow(Bytes.toBytes(&quot;-1&quot;));</span><br><span class="line">        &#125;else&#123;&#x2F;&#x2F;查询第二页或者其他页数的数据</span><br><span class="line">            &#x2F;&#x2F;注意：在这里需要在lastRowkey后面补0，否则会把当前这条数据也返回过来，这样就重复了，补0之后可以保证返回的都是新数据</span><br><span class="line">            scan.withStartRow(Bytes.add(lastRowKey,Bytes.toBytes(&quot;0&quot;)));</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;记录每次迭代的数据条数</span><br><span class="line">        int rowCount &#x3D; 0;</span><br><span class="line">        &#x2F;&#x2F;获取结果</span><br><span class="line">        ResultScanner scanner &#x3D; table.getScanner(scan);</span><br><span class="line">        for (Result res: scanner) &#123;</span><br><span class="line">            byte[] rowkey_bytes &#x3D; res.getRow();</span><br><span class="line">            byte[] name_bytes &#x3D; res.getValue(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;name&quot;));</span><br><span class="line">            String rowkey_str &#x3D; new String(rowkey_bytes);</span><br><span class="line">            String name_str &#x3D; new String(name_bytes);</span><br><span class="line">            System.out.println(&quot;Rowkey:&quot;+ rowkey_str +&quot;,name:&quot;+ name_str);</span><br><span class="line">            rowCount++;</span><br><span class="line">            &#x2F;&#x2F;scan返回的数据是基于rowkey有序的，直接判断数据条数即可。</span><br><span class="line">            if (rowCount &#x3D;&#x3D; pageSize) &#123;&#x2F;&#x2F;当前页面数据获取完毕，退出循环</span><br><span class="line">                System.out.println(&quot;lastRowKey:&quot;+rowkey_str);</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【扩展】封装HBaseUtils工具类"><a href="#【扩展】封装HBaseUtils工具类" class="headerlink" title="【扩展】封装HBaseUtils工具类"></a>【扩展】封装HBaseUtils工具类</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">要求：</span><br><span class="line"></span><br><span class="line">通过静态方法维护HBase连接。</span><br><span class="line">提供公共的put和get方法。</span><br><span class="line">代码如下</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * HBase工具类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseUtil</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">HBaseUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Connection conn  = getConn();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Connection <span class="title">getConn</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//获取hbase的链接</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定hbase使用的zk地址</span></span><br><span class="line">        <span class="comment">//注意：需要在执行hbasejava代码的机器上配置zk和hbase集群的主机名和ip的映射关系</span></span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>,<span class="string">"bigdata01:2181"</span>);</span><br><span class="line">        <span class="comment">//指定hbase在hdfs上的根目录</span></span><br><span class="line">        conf.set(<span class="string">"hbase.rootdir"</span>,<span class="string">"hdfs://bigdata01:9000/hbase"</span>);</span><br><span class="line">        <span class="comment">//创建HBase数据库链接</span></span><br><span class="line">        Connection co = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            co = ConnectionFactory.createConnection(conf);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            System.out.println(<span class="string">"获取链接失败："</span>+e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> co;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对外提供的方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cfs</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String tableName,String... cfs)</span><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Admin admin = conn.getAdmin();</span><br><span class="line">        ArrayList&lt;ColumnFamilyDescriptor&gt; cfArr = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (String cf: cfs) &#123;</span><br><span class="line">            ColumnFamilyDescriptor cfDesc = ColumnFamilyDescriptorBuilder</span><br><span class="line">                    .newBuilder(Bytes.toBytes(cf))</span><br><span class="line">                    .build();</span><br><span class="line">            cfArr.add(cfDesc);</span><br><span class="line">        &#125;</span><br><span class="line">        TableDescriptor tableDesc = TableDescriptorBuilder</span><br><span class="line">                .newBuilder(TableName.valueOf(tableName))</span><br><span class="line">                .setColumnFamilies(cfArr)</span><br><span class="line">                .build();</span><br><span class="line">        admin.createTable(tableDesc);</span><br><span class="line">        admin.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加一个单元格(列)的数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> rowKey</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> columnFamily</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> column</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put2HBaseCell</span><span class="params">(String tableName,String rowKey,String columnFamily,String column,String value)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Put put = <span class="keyword">new</span> Put(Bytes.toBytes(rowKey));</span><br><span class="line">        put.addColumn(Bytes.toBytes(columnFamily),Bytes.toBytes(column),Bytes.toBytes(value));</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 向hbase中添加一批数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put2HBaseList</span><span class="params">(String tableName, List&lt;Put&gt; list)</span><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        table.put(list);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        HBaseUtil.put2HBaseCell(<span class="string">"user"</span>,<span class="string">"1002008"</span>,<span class="string">"info"</span>,<span class="string">"name"</span>,<span class="string">"abc"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="HBase常见问题总结"><a href="#HBase常见问题总结" class="headerlink" title="HBase常见问题总结"></a>HBase常见问题总结</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-HBase Put 功能初始化数据过慢，考虑使用批量导入。</span><br><span class="line">-统一各个系统的字符集，非utf8的要做转换。</span><br><span class="line">-对表做预分区，同时Rowkey做MD5哈希取余数。</span><br><span class="line">-在HBase客户端节点中需要配置HBase集群所有节点的主机名和IP的映射关系。</span><br><span class="line">-每日全量数据入库，数据实际发生变化的条数不多，浪费资源，所以用T-2的数据和T-1的数据做对比，只入库发生变化的数据。</span><br><span class="line">-Scan大表超时，最好限制一个范围，尝试调整RPC请求的超时时间，hbase.rpc.timeout，可以适当调大。</span><br><span class="line">-默认建表version&#x3D;1，手动修改version&#x3D;3，可以查找之前修改的记录。</span><br><span class="line">-HBase第一次查询数据很慢，建议提前初始化链接。</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="HBase" scheme="http://tianyong.fun/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-快速上手NoSQL数据库HBase-2</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93HBase-2.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93HBase-2.html</id>
    <published>2023-06-13T01:24:19.000Z</published>
    <updated>2023-06-23T02:40:09.213Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="快速上手NoSQL数据库HBase-2"><a href="#快速上手NoSQL数据库HBase-2" class="headerlink" title="快速上手NoSQL数据库HBase-2"></a>快速上手NoSQL数据库HBase-2</h1><h2 id="3-深入HBase架构原理"><a href="#3-深入HBase架构原理" class="headerlink" title="3 深入HBase架构原理"></a>3 深入HBase架构原理</h2><h3 id="Region概念解释"><a href="#Region概念解释" class="headerlink" title="Region概念解释"></a>Region概念解释</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Region可以翻译为区域，在HBase里面，一个表中的数据，会按照行被横向划分为多个Region。</span><br><span class="line">每个Region，按照存储的Rowkey的最小行键和最大行键指定的，使用区间[start Rowkey,end Rowkey)</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">-如果一个文件中数据量很大的时候，从这个大文件中读取数据肯定会比较慢</span><br><span class="line">-打开一个小文件查找数据和打开一个大文件查找数据的效率是不一样的</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306212347130.png" alt="image-20230621234751043" style="zoom: 67%;"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在这个图里面，表t1刚创建的时候默认只有1个Region，后来数据量多了以后，Region会自动分裂，这样就产生了多个Region。</span><br><span class="line">那么我们在查询数据的时候，首先要知道数据在哪个Region中，再从Region中读取数据。</span><br><span class="line"></span><br><span class="line">如何知道数据在哪个Region中呢？</span><br><span class="line">我们在向表中插入数据的时候，Rowkey是必须指定，不能缺少的，并且Rowkey在存储的时候是有序存储的。</span><br><span class="line">那么我们在定位数据的时候，就可以拿Rowkey到对应的Region中进行对比，每个Region中都会有一个最小Rowkey和最大Rowkey，这样就能很快的判断出来我们要找的数据是不是在这个Region中了。</span><br><span class="line"></span><br><span class="line">其实每个Region中的最大Rowkey是有一个地方进行维护的，HBase内部默认提供了一个目录表来维护这个关系。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果表t1有两个列族c1和c2，那么在存储的时候，列族c1中的数据是一个独立的文件，列族c2中的数据也会是一个独立的文件，也就是说，每一个列族中的数据在底层存储的时候都是一个单独的文件。</span><br><span class="line">如下图所示，当表有多个Region的时候，每个Region内部的每个列族是一个单独的文件。</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306212352303.png" alt="image-20230621235252969" style="zoom: 67%;"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">所以说我们在设计列族的时候，可以把经常读取的列存储到一个列族中，不经常读取的列放到另一个列族中。</span><br><span class="line">这样我们在读取部分列的数据的时候，就只需要读取对应列族文件中的数据，提高读取效率。</span><br><span class="line"></span><br><span class="line">在这里有几个问题：</span><br><span class="line"></span><br><span class="line">-如果一个列族中如果有2个列，那么这2个列会存储到2个列族文件中吗？不会的。</span><br><span class="line">-一行记录，会不会分到多个文件中存储？ 会</span><br><span class="line">-一个列族中的数据，会不会在多个Region中存储？会</span><br><span class="line">-一个Region中，会不会存储多个列族文件？会</span><br></pre></td></tr></table></figure><h3 id="HBase物理架构"><a href="#HBase物理架构" class="headerlink" title="HBase物理架构"></a>HBase物理架构</h3><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306212355799.png" alt="image-20230621235550517" style="zoom:67%;"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">主要包含以下内容：</span><br><span class="line"></span><br><span class="line">Zookeeper：为HBase集群提供基础服务。</span><br><span class="line">HBase Master：HBase集群的主节点。</span><br><span class="line">HBase Regionserver：HBase集群的从节点。</span><br><span class="line">Client：客户端节点。</span><br></pre></td></tr></table></figure><h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper为HBase集群提供协调服务，它管理着HMaster和HRegionServer的状态(available&#x2F;alive等)，并且会在HRegionServer宕机时通知给HMaster。</span><br><span class="line"></span><br><span class="line">ZooKeeper协调HBase集群所有节点的共享信息，在HMaster和HRegionServer连接到ZooKeeper后会创建Ephemeral（临时）节点，并使用心跳机制监控这个节点的存活状态，如果某个临时节点失效，则HMaster会收到通知，并做相应的处理，这块需要通过Watcher监视器实现。</span><br><span class="line"></span><br><span class="line">另外，HMaster通过监听ZooKeeper中的临时节点(默认：&#x2F;hbase&#x2F;rs&#x2F;*)来监控HRegionServer的加入和宕机。在第一个HMaster连接到ZooKeeper时会创建临时节点(默认：&#x2F;hbasae&#x2F;master)来表示Active的HMaster，后面加入进来的HMaster则监听该临时节点，如果当前Active的HMaster宕机，则该临时节点消失，因此其他HMaster会得到通知，然后将自身转换成Active的HMaster，在变为Active的HMaster之前，它会先在&#x2F;hbase&#x2F;back-masters&#x2F;下创建自己的临时节点。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">对Zookeeper的作用总结一下，一共有3点：</span><br><span class="line"></span><br><span class="line">-Zookeeper维护HBase集群的信息</span><br><span class="line">-HRegionserver启动的时候会在Zookeeper的&#x2F;hbase&#x2F;rs下面创建节点信息</span><br><span class="line">-HMaster会在Zookeeper的&#x2F;hbase下创建master节点 多余的HMaster会监听这个节点，发现这个节点失效的时候，会接管这个角色。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">登录Zookeeper，查看HBase的一些节点信息，HBase默认会在Zookeeper的根节点下面创建hbase节点</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls &#x2F;hbase</span><br><span class="line">[backup-masters, draining, flush-table-proc, hbaseid, master, master-maintenance, meta-region-server, namespace, online-snapshot, rs, running, splitWAL, switch, table]</span><br><span class="line"></span><br><span class="line">在Zookeeper中查看HBase的从节点信息，这里面显示的内容表示目前HBase集群有2个从节点bigdata02和bigdata03</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] ls &#x2F;hbase&#x2F;rs</span><br><span class="line">[bigdata02,16020,1777443334673, bigdata03,16020,1777443333539]</span><br></pre></td></tr></table></figure><h4 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">HMaster是HBase集群的主节点，HBase集群支持多个HMaster节点，可以实现HA。</span><br><span class="line">通过ZooKeeper的选举机制保证同时只有一个HMaster处于Active状态，其他的HMaster处于备份状态。一般情况下会启动两个HMaster，备份状态的HMaster会定期和Active HMaster通信以获取其最新状态，从而保证它是实时更新的，因此如果启动了多个HMaster反而增加了Active HMaster的负担。</span><br><span class="line"></span><br><span class="line">HMaster主要有以下职责：</span><br><span class="line">-管理HRegionServer，实现其负载均衡。</span><br><span class="line">-管理和分配Region，比如在Region分裂时分配新的Region；在HRegionServer退出时迁移里面的Region到其他HRegionServer上。</span><br><span class="line">-管理namespace和table的元数据（这些元数据实际存储在HDFS上面）</span><br><span class="line">-权限控制（ACL）</span><br></pre></td></tr></table></figure><h4 id="HRegionserver"><a href="#HRegionserver" class="headerlink" title="HRegionserver"></a>HRegionserver</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HRegionserver是HBase集群的从节点。</span><br><span class="line"></span><br><span class="line">HRegionServer一般建议和DataNode部署在同一台机器上，这样可以实现数据的本地化特性，因为DataNode是存储数据的，HBase的数据也是存储在HDFS上的，HRegionServer就是管理数据的，所以这样的话可以尽量保证HRegionServer读取本地的数据，只有磁盘IO，节省了网络IO。</span><br></pre></td></tr></table></figure><h3 id="HBase架构详解"><a href="#HBase架构详解" class="headerlink" title="HBase架构详解"></a>HBase架构详解</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220009491.png" alt="image-20230622000928203"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">图中虚线下面是HDFS部分 上面是HBase的部分</span><br><span class="line">Client(客户端)想要连接HBase的时候，需要先连接Zookeeper。</span><br><span class="line">首先会找Zookeeper中&#x2F;hbase&#x2F;meta-region-server这个节点，这个节点里面保存了HBase中meta表的数据（Region）所在的Regionserve节点信息。</span><br><span class="line">在Zookeeper执行get命令查看节点上的信息，显示出来的有乱码，不过大致可以看出来，里面显示的是bigdata03，也就意味着meta表的Region是在bigdata03这个节点上的。</span><br><span class="line">注意：大家在查看的时候显示的不一定是bigdata03节点，也可能是其他的节点。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] get &#x2F;hbase&#x2F;meta-region-server</span><br><span class="line">�master:16000)��K,&#125;�PBUF</span><br><span class="line"></span><br><span class="line">        bigdata03_x0010_�&#125;�ªڵ4_x0010_</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">我们也可以通过HBase的UI界面进行查看验证。</span><br><span class="line">先在系统表中找到这个meta表</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220012225.png" alt="image-20230622001256147"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">然后点击进去，显示的这个表确实是在bigdata03这个节点上面</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220013589.png" alt="image-20230622001323492"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们可以在这里点击bigdata03:16030这个链接，然后进入到这个界面</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220014851.png" alt="image-20230622001458992"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">最终会发现meta表的数据确实就是在bigdata03这个节点上面的。</span><br><span class="line"></span><br><span class="line">客户端到Zookeeper中找到这个信息以后，就把这个信息加载到缓存中了，这样就不用每次都去重新加载了</span><br><span class="line"></span><br><span class="line">meta表中存储了所有表的相关信息，可能会有很多，都加载到内存的话可能会扛不住的，所以客户端并不会加载meta表中的所有数据，只会把meta表中我们目前需要的相关数据加载到内存。</span><br><span class="line"></span><br><span class="line">meta表里面存储的有HBase中所有表对应的RegionServer节点信息</span><br><span class="line"></span><br><span class="line">scan ‘hbase:meta’ 可以看到这个meta表里面的详细信息。</span><br><span class="line">所以客户端这个时候其实就可以获取到表对应RegionServer的IP和端口信息了，通过RPC机制就可以通信了。</span><br></pre></td></tr></table></figure><h4 id="详解HRegionServer"><a href="#详解HRegionServer" class="headerlink" title="详解HRegionServer"></a>详解HRegionServer</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">下面就来详细看一下HRegionServer里面的内容</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220019532.png" alt="image-20230622001912173" style="zoom: 67%;"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HRegionServer里面有2块内容，一个是HLog ，另一个是HRegion(其实就是我们前面分析的Region，是同一个意思，Region是HRegion的简称)。</span><br><span class="line"></span><br><span class="line">在一个HRegionServer里面，HLog只有一个，HRegion会有多个，这个框后面是有三个点，表示是多个的意思。</span><br><span class="line">HLog是负责记录日志的，针对这个HRegionServer中的所有写操作，包括put、delete等操作，只要是会对数据产生变化的操作，都会记录到这个日志中，再把数据写到对应的HRegion中。</span><br><span class="line"></span><br><span class="line">HRegion就是负责存储实际数据了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">看一下HRegion内部：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220021198.png" alt="image-20230622002106137"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">每一个Store对应一个列族，所以一个HRegion里面可能会有多个Store。</span><br><span class="line">向HRegionserver中写数据的时候，会先写HLog，然后在把数据写入HRegion的时候，会根据指定的列族信息写入到不同的Store里面，我们之前在向表中put数据的时候，表名和列族名称都是必须要指定的。</span><br><span class="line"></span><br><span class="line">Store里面包含两部分：MemStore 和 StoreFile。</span><br><span class="line">用户写入的数据首先会放入MemStore【基于内存的Store】里面，当这个MemStore写满了以后，会把数据持久化到StoreFile中，每一次内存满了持久化的时候都会生成一个StoreFile，StoreFile底层对应的是一个HFile文件。</span><br><span class="line">HFile文件会通过下面的DFS Client写入到HDFS中。</span><br><span class="line">最终HLog和HFile都是用DFS Client写入到HDFS中的。</span><br></pre></td></tr></table></figure><h3 id="HBase物理存储模型"><a href="#HBase物理存储模型" class="headerlink" title="HBase物理存储模型"></a>HBase物理存储模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HBase中表的数据是存储在Region中的，表中的数据会越来越多，Region就会分裂，分裂出来的多个Region会分布到多个节点上面，因为单台机器的存储能力是有限的，这样对后期数据并行读取也有好处，有利于扩展。</span><br><span class="line">这样就可以保证一个表能存储海量数据，存放Region的服务器称之为Region Server。</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220028244.png" alt="image-20230622002810617" style="zoom: 80%;"><h3 id="WAL-Write-Ahead-Logging-预写日志系统"><a href="#WAL-Write-Ahead-Logging-预写日志系统" class="headerlink" title="WAL(Write-Ahead Logging)预写日志系统"></a>WAL(Write-Ahead Logging)预写日志系统</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WAL最重要的作用是灾难恢复。和MySQL 的Binlog类似，它记录所有的数据改动。一旦服务器崩溃，通过重放log可以恢复崩溃之前的数据。这也就意味如果写入WAL失败，整个写入操作将认为失败。</span><br><span class="line">HBase中，HLog是WAL的实现类。一个HRegionServer对应一个HLog实例。</span><br><span class="line"></span><br><span class="line">WAL数据是存储在HDFS上面的，点进去可以看到是一个一个的文件。</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220031358.png" alt="image-20230622003106817" style="zoom:80%;"><h3 id="HFile介绍"><a href="#HFile介绍" class="headerlink" title="HFile介绍"></a>HFile介绍</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HFile是HBase中重要的一个存在，可以说是HBase架构中最小的结构，HBase的底层数据都在HFile中。</span><br><span class="line">HFile从根本上来说是HDFS中的文件，只是它有自己特殊的格式。</span><br><span class="line"></span><br><span class="line">HFile文件由6部分组成：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306220035927.png" alt="image-20230622003528698"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Data(数据块): 保存表中的数据(key-value的形式)，这部分可以被压缩，每个数据块都有一个Magic头,负责存储偏移量和第一个Key。</span><br><span class="line">Meta(元数据块)：存储用户自定义的key-value。</span><br><span class="line">File Info：定长，记录了文件的一些元信息，例如：AVG_KEY_LEN，AVG_VALUE_LEN，LAST_KEY等</span><br><span class="line">Data Index(数据块索引)：记录了每个数据块（Data）的起始索引。</span><br><span class="line">Meta Index(元数据块索引)：记录了每个元数据块（Meta）的起始索引。</span><br><span class="line">Trailer：定长，用于指向其他数据块的起始点。</span><br></pre></td></tr></table></figure><h3 id="BloomFilter布隆过滤器"><a href="#BloomFilter布隆过滤器" class="headerlink" title="BloomFilter布隆过滤器"></a>BloomFilter布隆过滤器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">布隆过滤器是一种比较巧妙的概率型数据结构，可以用来告诉你 “某样东西一定不存在或者可能存在”。</span><br><span class="line">也就是说它告诉你某样东西不存在的话就一定不存在。</span><br><span class="line">如果它告诉你某样东西存在，也可能实际是不存在的。</span><br><span class="line"></span><br><span class="line">布隆过滤器是hbase中的高级功能，它能够减少特定访问模式（get&#x2F;scan）下的查询时间。进而提高HBase集群的吞吐率。</span><br><span class="line"></span><br><span class="line">当我们随机查询数据时，如果采用HBase的块索引机制，HBase会加载很多块文件。如果采用布隆过滤器后，它能够准确判断该HFile的所有数据块中，是否含有我们查询的数据，从而大大减少不必要的块加载，进而提高HBase集群的吞吐率。</span><br><span class="line"></span><br><span class="line">对于HBase而言，当我们选择采用布隆过滤器之后，HBase会在生成HFile时包含一份布隆过滤器结构的数据，开启布隆过滤器会有一定的存储及内存开销。但是在大多数情况下，这些负担相对于布隆过滤器带来的好处来说是可以接受的。</span><br></pre></td></tr></table></figure><h3 id="HFile-compaction（合并）机制"><a href="#HFile-compaction（合并）机制" class="headerlink" title="HFile compaction（合并）机制"></a>HFile compaction（合并）机制</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">当MemStore超过阀值的时候，就会持久化生成一个（StoreFile）HFile。</span><br><span class="line">因此随着数据不断写入，HFile的数量将会越来越多，HFile数量过多会降低读性能，因为每次查询数据都需要加载多个HFile文件。为了避免对读性能的影响，可以对这些HFile进行合并操作，把多个HFile合并成一个HFile。</span><br><span class="line"></span><br><span class="line">合并操作需要对HBase中的数据进行多次的重新读写，这个过程会产生大量的IO。因此可以发现合并机制的本质就是以IO操作换取后续读性能的提高。</span><br><span class="line"></span><br><span class="line">合并操作分为major（大合并）和minor（小合并）两种。</span><br><span class="line"></span><br><span class="line">minor（小合并）：只做部分文件的合并操作，生成新文件设置成激活状态，然后删除老的HFile文件(标记为删除状态，在major合并时删除)。小合并的过程一般较快，而且IO相对较低。</span><br><span class="line"></span><br><span class="line">major（大合并）：对Region下(同列族)的所有HFile执行合并操作，最终的结果是合并出一个HFile文件。在生成新的HFile时，会忽略掉已经标记为删除的数据、ttl过期的数据、版本超过限定的数据。大合并会产生大量的IO操作，对HBase的读写性能产生较大影响。</span><br><span class="line"></span><br><span class="line">注意：一般情况下，大合并会持续很长时间，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会关闭自动触发大合并功能，改为手动在业务低峰期触发。</span><br></pre></td></tr></table></figure><h3 id="Region-Split（分裂）机制"><a href="#Region-Split（分裂）机制" class="headerlink" title="Region Split（分裂）机制"></a>Region Split（分裂）机制</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">前面我们分析了HFile文件的合并机制，当HFile文件合并多次之后，会导致Region中的数据过大，此时就需要涉及Region的分裂机制了。</span><br><span class="line">当HBase中的一个表刚被创建的时候，HBase默认只会分配一个Region给这个表。也就是说这个时候，所有的读写请求都会访问到同一个RegionServer中的同一个Region中，出现读写热点问题。</span><br><span class="line">并且当Region管理的数据量过多，或HFile文件较大时，都会影响性能。</span><br><span class="line"></span><br><span class="line">为了达到负载均衡，当Region达到一定的大小时就会将一个Region分裂成两个新的子Region，并对父 Region进行清除处理。</span><br><span class="line"></span><br><span class="line">HMaster会根据Balance策略，重新分配Region所属的RegionServer，最大化的发挥分布式系统的优点。</span><br><span class="line"></span><br><span class="line">触发Region Split的条件：</span><br><span class="line">-ConstantSizeRegionSplitPolicy （0.94版本前）：</span><br><span class="line">一个Region中最大HFile文件的大小大于设置的阈值（hbase.hregion.max.filesize）之后才会触发切分，HFile文件大小为压缩后的文件大小（针对启用压缩的场景），默认文件大小的阈值为10G。</span><br><span class="line">这种策略简单粗暴，但是弊端相当大。</span><br><span class="line">阈值设置偏大的话，对大表友好，小表可能不会触发分裂，极端情况下小表可能就只会有一个Region。</span><br><span class="line">阈值设置偏小的话，对小表友好，但一个大表可能会在集群中产生大量的Region，对于集群管理来说不是好事。</span><br><span class="line"></span><br><span class="line">-IncreasingToUpperBoundRegionSplitPolicy （0.94版本~2.x版本默认切分策略）：</span><br><span class="line">一个Region中最大HFile文件的大小大于设置的阈值就会触发切分，区别是这个阈值并不像 ConstantSizeRegionSplitPolicy是一个固定的值，这里的阈值是会不断调整的。调整规则和Region所属表在当前RegionServer上的Region个数有关系。</span><br><span class="line">公式：调整后的阈值 &#x3D; Region个数的3次方 * flush_size * 2</span><br><span class="line">注意：这里的阈值不会无限增大，会通过hbase.hregion.max.filesize来进行限制，不能超过这个参数的大小。</span><br><span class="line">这种策略能够自适应大小表，集群规模大的情况下，对大表很优秀，对小表会产生大量小Region（比第一种策略好一些）。</span><br></pre></td></tr></table></figure><h3 id="Region-Balance-负载均衡策略"><a href="#Region-Balance-负载均衡策略" class="headerlink" title="Region Balance(负载均衡策略)"></a>Region Balance(负载均衡策略)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Region分裂之后就会涉及到Region的负载均衡。</span><br><span class="line"></span><br><span class="line">HBase的HMaster进程会自动根据指定策略挑选出一些Region，并将这些Region分配到负载比较低的RegionServer上。</span><br><span class="line"></span><br><span class="line">由于HBase的所有数据都是写入到HDFS文件系统中的， 因此HBase的Region移动其实是非常轻量级。在做Region移动的时候，保持这个Region对应的HDFS文件位置不变，只需要将Region的元数据分配到对应的RegionServer中即可。</span><br><span class="line"></span><br><span class="line">官方目前支持两种挑选Region的策略：</span><br><span class="line">DefaultLoadBalancer和StochasticLoadBalancer。</span><br><span class="line">-DefaultLoadBalancer：这种策略能够保证每个RegionServer中的Region个数基本上都相等。</span><br><span class="line">-StochasticLoadBalancer：这种策略非常复杂，简单来讲是一种综合权衡6个因素的均衡策略。</span><br><span class="line"></span><br><span class="line">采用6个因素加权的方式算出一个代价值，这个代价值用来评估当前Region分布是否均衡，越均衡代价值越低。</span><br><span class="line">-每台服务器读请求数(ReadRequestCostFunction)</span><br><span class="line">-每台服务器写请求数(WriteRequestCostFunction)</span><br><span class="line">-Region个数(RegionCountSkewCostFunction)</span><br><span class="line">-移动代价(MoveCostFunction)</span><br><span class="line">-数据Locality(TableSkewCostFunction)</span><br><span class="line">-每张表占据RegionServer中Region个数上限(LocalityCostFunction)</span><br></pre></td></tr></table></figure><h2 id="4-HBase高级用法"><a href="#4-HBase高级用法" class="headerlink" title="4 HBase高级用法"></a>4 HBase高级用法</h2><h3 id="列族高级设置"><a href="#列族高级设置" class="headerlink" title="列族高级设置"></a>列族高级设置</h3><h4 id="生存时间-TTL"><a href="#生存时间-TTL" class="headerlink" title="生存时间(TTL)"></a>生存时间(TTL)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">应用系统经常需要从数据库里删除老数据，配置此项，可使数据增加生命周期，超过该配置时间的数据，将会在大合并时“被删除”。（单位：秒）</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):009:0&gt; create &#39;t3&#39;, &#123;NAME &#x3D;&gt; &#39;cf1&#39;, TTL &#x3D;&gt; &#39;18000&#39;&#125;</span><br><span class="line">Created table t3</span><br><span class="line">Took 1.2689 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t3</span><br><span class="line">hbase(main):053:0&gt; desc &#39;t3&#39;</span><br><span class="line">Table t3 is ENABLED                                                   </span><br><span class="line">t3                                                                    </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, NEW_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP</span><br><span class="line">_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;1800</span><br><span class="line">0 SECONDS (5 HOURS)&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, B</span><br><span class="line">LOOMFILTER &#x3D;&gt; &#39;ROW&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;&gt; &#39;NONE&#39;, BLOC</span><br><span class="line">KCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                               </span><br><span class="line"></span><br><span class="line">1 row(s)</span><br><span class="line">Quota is disabled</span><br><span class="line">Took 0.0359 seconds</span><br></pre></td></tr></table></figure><h4 id="版本数"><a href="#版本数" class="headerlink" title="版本数"></a>版本数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在0.96的版本之前默认每个列族是3个version， 0.96之后每个列族是1个version，在大合并时，会遗弃过期的版本。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):010:0&gt; create &#39;t4&#39;, &#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; 3&#125;</span><br><span class="line">Created table t4</span><br><span class="line">Took 1.2638 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t4</span><br><span class="line">hbase(main):011:0&gt; desc &#39;t4&#39;</span><br><span class="line">Table t4 is ENABLED                                                   </span><br><span class="line">t4                                                                    </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; &#39;3&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NEW</span><br><span class="line">_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DAT</span><br><span class="line">A_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER&#39;</span><br><span class="line">, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;,</span><br><span class="line"> CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_O</span><br><span class="line">N_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;&gt;</span><br><span class="line"> &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;</span><br></pre></td></tr></table></figure><h4 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HFile可以被压缩并存放在HDFS上。这有助于节省硬盘IO，但是读写数据时压缩和解压缩会抬高CPU利用率。</span><br><span class="line">压缩是表定义的一部分，可以在建表或修改表结构时设定。建议打开表的压缩，除非你确定不会从压缩中受益。只有在数据不能被压缩或者因为某种原因服务器的CPU利用率有限制要求的情况下，有可能会关闭压缩特性。</span><br><span class="line"></span><br><span class="line">HBase可以使用多种压缩编码，包括LZO、SNAPPY和GZIP</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):012:0&gt; create &#39;t5&#39;,&#123;NAME &#x3D;&gt; &#39;cf1&#39;, COMPRESSION &#x3D;&gt; &#39;SNAPPY&#39;&#125;</span><br><span class="line">Created table t5</span><br><span class="line">Took 1.3364 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t5</span><br><span class="line">hbase(main):013:0&gt; desc &#39;t5&#39;</span><br><span class="line">Table t5 is ENABLED                                                   </span><br><span class="line">t5                                                                    </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NEW</span><br><span class="line">_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DAT</span><br><span class="line">A_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER&#39;</span><br><span class="line">, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;,</span><br><span class="line"> CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_O</span><br><span class="line">N_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;&gt;</span><br><span class="line"> &#39;SNAPPY&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;</span><br></pre></td></tr></table></figure><h4 id="数据块-BLOCKSIZE-大小的配置"><a href="#数据块-BLOCKSIZE-大小的配置" class="headerlink" title="数据块(BLOCKSIZE)大小的配置"></a>数据块(BLOCKSIZE)大小的配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">随机查询：数据块越小，索引越大，查找性能更好</span><br><span class="line">顺序查询：更好的顺序扫描，需要更大的数据块</span><br><span class="line">所以在使用的时候根据业务需求来判断是随机查询需求多还是顺序查询需求多，根据具体的场景而定。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):014:0&gt; create &#39;t6&#39;,&#123;NAME &#x3D;&gt; &#39;cf1&#39;, BLOCKSIZE &#x3D;&gt; &#39;65537&#39;&#125;</span><br><span class="line">Created table t6</span><br><span class="line">Took 1.2451 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t6</span><br><span class="line">hbase(main):015:0&gt; desc &#39;t6&#39;</span><br><span class="line">Table t6 is ENABLED                                                   </span><br><span class="line">t6                                                                    </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NEW</span><br><span class="line">_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DAT</span><br><span class="line">A_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER&#39;</span><br><span class="line">, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;,</span><br><span class="line"> CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_O</span><br><span class="line">N_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;&gt;</span><br><span class="line"> &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65537&#39;&#125;</span><br></pre></td></tr></table></figure><h4 id="数据块缓存"><a href="#数据块缓存" class="headerlink" title="数据块缓存"></a>数据块缓存</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果一张表或表里的某个列族只被顺序化扫描访问或者很少被访问，这个时候就算Get或Scan花费时间是否有点儿长，你也不会很在意。在这种情况下，你可以选择关闭那些列族的缓存。</span><br><span class="line">如果你只是执行很多顺序化扫描，你会多次倒腾缓存，并且可能会滥用缓存把应该放进缓存获得性能提升的数据给排挤出去。如果关闭缓存，不仅可以避免上述情况发生，而且还可以让出更多缓存给其他表和同一个表的其他列族使用。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):016:0&gt; create &#39;t7&#39;,&#123;NAME &#x3D;&gt; &#39;cf1&#39;, BLOCKCACHE &#x3D;&gt; &#39;false&#39;&#125;</span><br><span class="line">Created table t7</span><br><span class="line">Took 2.2954 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t7</span><br><span class="line">hbase(main):017:0&gt; desc &#39;t7&#39;</span><br><span class="line">Table t7 is ENABLED                                                   </span><br><span class="line">t7                                                                    </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NEW</span><br><span class="line">_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DAT</span><br><span class="line">A_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER&#39;</span><br><span class="line">, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;,</span><br><span class="line"> CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_O</span><br><span class="line">N_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;&gt;</span><br><span class="line"> &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;false&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;</span><br></pre></td></tr></table></figure><h4 id="布隆过滤器-Bloom-filters"><a href="#布隆过滤器-Bloom-filters" class="headerlink" title="布隆过滤器(Bloom filters)"></a>布隆过滤器(Bloom filters)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HBase中存储额外的索引层次会占用额外的空间。布隆过滤器随着它们的索引对象的数据增长而增长，所以行级布隆过滤器比列标识符级布隆过滤器占用空间要少。当空间不是问题的时候，它们可以帮助你榨干系统的性能潜力。</span><br><span class="line"></span><br><span class="line">BLOOMFILTER参数的默认值是ROW，表示是行级布隆过滤器。</span><br><span class="line">使用行级布隆过滤器需要设置为ROW，使用列标识符级布隆过滤器需要设置为ROWCOL。</span><br><span class="line">行级布隆过滤器在数据块里检查特定行键是否不存在，列标识符级布隆过滤器检查行和列标识符联合体是否不存在。</span><br><span class="line">ROWCOL布隆过滤器的开销要高于ROW布隆过滤器。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):018:0&gt; create &#39;t8&#39;,&#123;NAME &#x3D;&gt; &#39;cf1&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROWCOL&#39;&#125;</span><br><span class="line">Created table t8</span><br><span class="line">Took 1.2484 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t8</span><br><span class="line">hbase(main):019:0&gt; desc &#39;t8&#39;</span><br><span class="line">Table t8 is ENABLED                                                   </span><br><span class="line">t8                                                                    </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;cf1&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NEW</span><br><span class="line">_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DAT</span><br><span class="line">A_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER&#39;</span><br><span class="line">, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROWCO</span><br><span class="line">L&#39;, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOM</span><br><span class="line">S_ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION</span><br><span class="line"> &#x3D;&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;</span><br></pre></td></tr></table></figure><h3 id="Scan-全表扫描"><a href="#Scan-全表扫描" class="headerlink" title="Scan (全表扫描)"></a>Scan (全表扫描)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HBase中的Scan操作，类似于SQL中的select * from ...</span><br><span class="line">例子：</span><br><span class="line"></span><br><span class="line">scan &#39;hbase:meta&#39;</span><br><span class="line">scan &#39;hbase:meta&#39;,&#123;COLUMNS &#x3D;&gt; &#39;info:regioninfo&#39;&#125;</span><br><span class="line">scan &#39;t1&#39;,&#123;COLUMNS&#x3D;&gt;&#39;c1&#39;,TIMERANGE&#x3D;&gt;[1303668804,1303668904]&#125;</span><br><span class="line">scan &#39;t1&#39;,&#123;REVERSED&#x3D;&gt;true&#125;</span><br></pre></td></tr></table></figure><h4 id="Scan的Java-API用法"><a href="#Scan的Java-API用法" class="headerlink" title="Scan的Java API用法"></a>Scan的Java API用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Scan 在Java API中支持以下用法：</span><br><span class="line"></span><br><span class="line">scan.addFamily(); &#x2F;&#x2F;指定列族</span><br><span class="line">scan.addColumn(); &#x2F;&#x2F;指定列，如果没有调用任何addFamily或Column，会返回所有的columns；</span><br><span class="line">scan.readAllVersions(); &#x2F;&#x2F;读取所有版本数据。</span><br><span class="line">scan.readVersions(3); &#x2F;&#x2F;读取最新3个版本的数据</span><br><span class="line">scan.setTimeRange(); &#x2F;&#x2F;指定最大的时间戳和最小的时间戳，只有在此范围内的cell才能被获取.</span><br><span class="line">scan.setTimeStamp(); &#x2F;&#x2F;指定时间戳</span><br><span class="line">scan.setFilter(); &#x2F;&#x2F;指定Filter来过滤掉不需要的信息</span><br><span class="line">scan.withStartRow(); &#x2F;&#x2F;指定开始的行。如果不指定，则从表头开始</span><br><span class="line">scan.withStopRow(); &#x2F;&#x2F;指定结束的行（不含此行）</span><br><span class="line">scan.setBatch(); &#x2F;&#x2F;指定最多返回的Cell数目。用于防止一行中有过多的数据，导致OutofMemory错误。</span><br><span class="line">scan.setCaching(); &#x2F;&#x2F;指定scan底层每次连接返回的数据条数，默认值为1，适当调大可以提高查询性能，设置太大会比较耗内存</span><br></pre></td></tr></table></figure><h5 id="常见的Filter"><a href="#常见的Filter" class="headerlink" title="常见的Filter"></a>常见的Filter</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在进行Scan的时候，可以添加Filter实现数据过滤</span><br></pre></td></tr></table></figure><h6 id="RowFilter"><a href="#RowFilter" class="headerlink" title="RowFilter"></a>RowFilter</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">RowFilter：对Rowkey进行过滤。</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;小于等于 x</span><br><span class="line">Filter filter &#x3D; new RowFilter(CompareOperator.LESS_OR_EQUAL,new BinaryComparator(Bytes.toBytes(“x”)));</span><br><span class="line">&#x2F;&#x2F;正则 以x结尾</span><br><span class="line">Filter filter &#x3D; new RowFilter(CompareOperator.EQUAL,new RegexStringComparator(&quot;.*x&quot;));</span><br><span class="line">&#x2F;&#x2F;包含 x</span><br><span class="line">Filter filter &#x3D; new RowFilter(CompareOperator.EQUAL, new SubstringComparator(“x”));</span><br><span class="line">&#x2F;&#x2F;开头 x</span><br><span class="line">Filter filter &#x3D; new RowFilter(CompareOperator.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(“x”)));</span><br><span class="line"></span><br><span class="line">CompareOperator.其他比较参数</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">LESS   小于   </span><br><span class="line">LESS_OR_EQUAL  小于等于   </span><br><span class="line">EQUAL 等于   </span><br><span class="line">NOT_EQUAL  不等于   </span><br><span class="line">GREATER_OR_EQUAL 大于等于</span><br><span class="line">GREATER  大于</span><br><span class="line">NO_OP 排除所有</span><br></pre></td></tr></table></figure><h6 id="PrefixFilter"><a href="#PrefixFilter" class="headerlink" title="PrefixFilter"></a>PrefixFilter</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PrefixFilter：筛选出具有特定前缀的行键的数据。</span><br><span class="line">Filter pf &#x3D; new PrefixFilter(Bytes.toBytes(“前缀”));</span><br></pre></td></tr></table></figure><h6 id="ValueFilter"><a href="#ValueFilter" class="headerlink" title="ValueFilter"></a>ValueFilter</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ValueFilter：按照具体的值来筛选列中的数据，这会把一行中值不能满足的列过滤掉</span><br><span class="line">Filter vf &#x3D; new ValueFilter(CompareOperator.EQUAL, new SubstringComparator(“ROW2_QUAL1”));</span><br></pre></td></tr></table></figure><h5 id="Scan和Filter结合的案例"><a href="#Scan和Filter结合的案例" class="headerlink" title="Scan和Filter结合的案例"></a>Scan和Filter结合的案例</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：在执行下面代码之前，先创建表，初始化一批数据</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; create &#39;s1&#39;,&#39;c1&#39;,&#39;c2&#39;</span><br><span class="line">Created table s1</span><br><span class="line">Took 2.2063 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - s1</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;a&#39;,&#39;c1:name&#39;,&#39;zs&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;a&#39;,&#39;c1:age&#39;,&#39;18&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;a&#39;,&#39;c2:score&#39;,&#39;99&#39;</span><br><span class="line"></span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;b&#39;,&#39;c1:name&#39;,&#39;jack&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;b&#39;,&#39;c1:age&#39;,&#39;21&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;b&#39;,&#39;c2:score&#39;,&#39;85&#39;</span><br><span class="line"></span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;c&#39;,&#39;c1:name&#39;,&#39;tom&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;c&#39;,&#39;c1:age&#39;,&#39;31&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;c&#39;,&#39;c2:score&#39;,&#39;79&#39;</span><br><span class="line"></span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;d&#39;,&#39;c1:name&#39;,&#39;lili&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;d&#39;,&#39;c1:age&#39;,&#39;27&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;d&#39;,&#39;c2:score&#39;,&#39;65&#39;</span><br><span class="line"></span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;e&#39;,&#39;c1:name&#39;,&#39;ww&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;e&#39;,&#39;c1:age&#39;,&#39;35&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;e&#39;,&#39;c2:score&#39;,&#39;100&#39;</span><br><span class="line"></span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;f&#39;,&#39;c1:name&#39;,&#39;jessic&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;f&#39;,&#39;c1:age&#39;,&#39;12&#39;</span><br><span class="line">hbase(main):026:0&gt; put &#39;s1&#39;,&#39;f&#39;,&#39;c2:score&#39;,&#39;77&#39;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.hbase;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 全表扫描Scan+Filter</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 注意：首先需要创建表s1,然后初始化一批数据</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseScanFilter</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取配置</span></span><br><span class="line">        Configuration conf = HBaseConfiguration.create();</span><br><span class="line">        <span class="comment">//指定HBase使用的zk的地址，多个都逗号隔开</span></span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"bigdata01:2181,bigdata02:2181,bigdata03:2181"</span>);</span><br><span class="line">        <span class="comment">//指定HBase在hdfs上的根目录</span></span><br><span class="line">        conf.set(<span class="string">"hbase.rootdir"</span>,<span class="string">"hdfs://bigdata01:9000/hbase"</span>);</span><br><span class="line">        <span class="comment">//创建HBase连接，负责对HBase中数据的增删改查(DML操作)</span></span><br><span class="line">        Connection conn = ConnectionFactory.createConnection(conf);</span><br><span class="line">        <span class="comment">//获取Table对象，指定要操作的表名，表需要提前创建好</span></span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(<span class="string">"s1"</span>));</span><br><span class="line"></span><br><span class="line">        Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">        <span class="comment">//范围查询：指定查询区间，提高查询性能</span></span><br><span class="line">        <span class="comment">//这是一个左闭右开的区间，也就是查询的结果中包含左边的，不包含右边的</span></span><br><span class="line">        scan.withStartRow(Bytes.toBytes(<span class="string">"a"</span>));</span><br><span class="line">        scan.withStopRow(Bytes.toBytes(<span class="string">"f"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//添加Filter对数据进行过滤：使用RowFilter进行过滤，获取Rowkey小于等于d的数据</span></span><br><span class="line">        Filter filter = <span class="keyword">new</span> RowFilter(CompareOperator.LESS_OR_EQUAL,<span class="keyword">new</span> BinaryComparator(Bytes.toBytes(<span class="string">"d"</span>)));</span><br><span class="line">        scan.setFilter(filter);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取查询结果</span></span><br><span class="line">        ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">        <span class="comment">//迭代查询结果</span></span><br><span class="line">        <span class="keyword">for</span> (Result result: scanner) &#123;</span><br><span class="line">            List&lt;Cell&gt; cells = result.listCells();</span><br><span class="line">            <span class="comment">//RowKey</span></span><br><span class="line">            <span class="keyword">byte</span>[] row_key = result.getRow();</span><br><span class="line">            <span class="keyword">for</span> (Cell cell: cells) &#123;</span><br><span class="line">                <span class="comment">//注意：下面获取的信息都是字节类型的，可以通过new String(bytes)转为字符串</span></span><br><span class="line">                <span class="comment">//列族</span></span><br><span class="line">                <span class="keyword">byte</span>[] famaily_bytes = CellUtil.cloneFamily(cell);</span><br><span class="line">                <span class="comment">//列</span></span><br><span class="line">                <span class="keyword">byte</span>[] column_bytes = CellUtil.cloneQualifier(cell);</span><br><span class="line">                <span class="comment">//值</span></span><br><span class="line">                <span class="keyword">byte</span>[] value_bytes = CellUtil.cloneValue(cell);</span><br><span class="line">                System.out.println(<span class="string">"Rowkey："</span>+<span class="keyword">new</span> String(row_key)+<span class="string">",列族："</span>+<span class="keyword">new</span> String(famaily_bytes)+<span class="string">",列："</span>+<span class="keyword">new</span> String(column_bytes)+<span class="string">",值："</span>+<span class="keyword">new</span> String(value_bytes));</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">"================================================================"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        table.close();</span><br><span class="line">        conn.close();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="批量导入"><a href="#批量导入" class="headerlink" title="批量导入"></a>批量导入</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">批量导入两种方式：</span><br><span class="line"></span><br><span class="line">-利用MapReduce中封装好的方法。在map阶段，把数据封装成Put操作，直接将数据入库。</span><br><span class="line">-利用Bulkload。首先使用MapReduce直接生成HFile文件，然后再通过Bulkload将HFile文件直接加载到表中。</span><br><span class="line"></span><br><span class="line">Bulkload的优势：通过MR生成HBase底层HFile文件，直接加载到表中，省去了大部分的RPC和写过程。</span><br></pre></td></tr></table></figure><h4 id="批量导入之-MapReduce"><a href="#批量导入之-MapReduce" class="headerlink" title="批量导入之 MapReduce"></a>批量导入之 MapReduce</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">首先初始化输入数据：</span><br><span class="line">在linux中创建文件：hbase_import.dat</span><br><span class="line">内容如下：</span><br><span class="line"></span><br><span class="line">注意：字段分隔符为制表符</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 soft]# vi hbase_import.dat</span><br><span class="line">a       c1      name    zs</span><br><span class="line">a       c1      age     18</span><br><span class="line">b       c1      name    ls</span><br><span class="line">b       c1      age     29</span><br><span class="line">c       c1      name    ww</span><br><span class="line">c       c1      age     31</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">把hbase_import.dat上传到HDFS中</span><br><span class="line">[root@bigdata04 soft]# hdfs dfs -put hbase_import.dat &#x2F;</span><br><span class="line"></span><br><span class="line">在HBase中创建需要用到的表batch1</span><br><span class="line">hbase(main):027:0&gt; create &#39;batch1&#39;,&#39;c1&#39;</span><br><span class="line">Created table batch1</span><br><span class="line">Took 1.3600 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - batch1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时项目的pom.xml文件中除了添加hbase-client的依赖，还需要添加hadoop-client和hbase-mapreduce的依赖，否则代码报错</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hadoop&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hadoop-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.2.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hbase&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hbase-mapreduce&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.2.7&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">详细代码如下：</span><br></pre></td></tr></table></figure><h5 id="BatchImportMR"><a href="#BatchImportMR" class="headerlink" title="BatchImportMR"></a>BatchImportMR</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.hbase;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 批量导入：</span></span><br><span class="line"><span class="comment"> * 1：利用MapReduce中封装好的方法。</span></span><br><span class="line"><span class="comment"> * 在map阶段，把数据封装成Put操作，直接将数据入库</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 注意：需要提前创建表batch1</span></span><br><span class="line"><span class="comment"> * create 'batch1','c1'</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BatchImportMR</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">BatchImportMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>, <span class="title">Put</span>&gt;</span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function">                <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] strs = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line">            <span class="keyword">if</span>(strs.length==<span class="number">4</span>)&#123;</span><br><span class="line">                String rowkey = strs[<span class="number">0</span>];</span><br><span class="line">                String columnFamily = strs[<span class="number">1</span>];</span><br><span class="line">                String name = strs[<span class="number">2</span>];</span><br><span class="line">                String val = strs[<span class="number">3</span>];</span><br><span class="line">                Put put = <span class="keyword">new</span> Put(rowkey.getBytes());</span><br><span class="line">                put.addColumn(columnFamily.getBytes(),name.getBytes(),val.getBytes());</span><br><span class="line">                context.write(NullWritable.get(),put);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(args.length!=<span class="number">2</span>)&#123;</span><br><span class="line">            <span class="comment">//如果传递的参数不够，程序直接退出</span></span><br><span class="line">            System.exit(<span class="number">100</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String inPath = args[<span class="number">0</span>];</span><br><span class="line">        String outTableName = args[<span class="number">1</span>];</span><br><span class="line">        <span class="comment">//设置属性对应参数</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"hbase.table.name"</span>,outTableName);</span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>,<span class="string">"bigdata01:2181,bigdata02:2181,bigdata03:2181"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//封装Job</span></span><br><span class="line">        Job job = Job.getInstance(conf, <span class="string">"Batch Import HBase Table："</span> + outTableName);</span><br><span class="line">        job.setJarByClass(BatchImportMR<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定输入路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job,<span class="keyword">new</span> Path(inPath));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定map相关的代码</span></span><br><span class="line">        job.setMapperClass(BatchImportMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapOutputKeyClass(NullWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapOutputValueClass(Put<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        TableMapReduceUtil.initTableReducerJob(outTableName,<span class="keyword">null</span>,job);</span><br><span class="line">        TableMapReduceUtil.addDependencyJars(job);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//禁用Reduce</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">对代码打jar包：</span><br><span class="line">在打jar包之前，需要对pom.xml中的依赖添加&lt;scope&gt;provided&lt;&#x2F;scope&gt;配置</span><br><span class="line"></span><br><span class="line">注意：hbase-client和hbase-mapreduce不能设置provided，这两个依赖需要打进jar包里面，否则会提示找不到对应的类。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hbase&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hbase-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.2.7&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hadoop&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hadoop-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;3.2.0&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hbase&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hbase-mapreduce&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.2.7&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">        &lt;scope&gt;provided&lt;&#x2F;scope&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;&#x2F;dependencies&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">还需要添加maven打包配置</span><br><span class="line"></span><br><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;!-- compiler插件, 设定JDK版本 --&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.3.2&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;encoding&gt;UTF-8&lt;&#x2F;encoding&gt;</span><br><span class="line">                &lt;source&gt;1.8&lt;&#x2F;source&gt;</span><br><span class="line">                &lt;target&gt;1.8&lt;&#x2F;target&gt;</span><br><span class="line">                &lt;showWarnings&gt;true&lt;&#x2F;showWarnings&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;artifactId&gt;maven-assembly-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;descriptorRefs&gt;</span><br><span class="line">                    &lt;descriptorRef&gt;jar-with-dependencies&lt;&#x2F;descriptorRef&gt;</span><br><span class="line">                &lt;&#x2F;descriptorRefs&gt;</span><br><span class="line">                &lt;archive&gt;</span><br><span class="line">                    &lt;manifest&gt;</span><br><span class="line">                        &lt;mainClass&gt;&lt;&#x2F;mainClass&gt;</span><br><span class="line">                    &lt;&#x2F;manifest&gt;</span><br><span class="line">                &lt;&#x2F;archive&gt;</span><br><span class="line">            &lt;&#x2F;configuration&gt;</span><br><span class="line">            &lt;executions&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;id&gt;make-assembly&lt;&#x2F;id&gt;</span><br><span class="line">                    &lt;phase&gt;package&lt;&#x2F;phase&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;single&lt;&#x2F;goal&gt;</span><br><span class="line">                    &lt;&#x2F;goals&gt;</span><br><span class="line">                &lt;&#x2F;execution&gt;</span><br><span class="line">            &lt;&#x2F;executions&gt;</span><br><span class="line">        &lt;&#x2F;plugin&gt;</span><br><span class="line">    &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">执行打jar包命令</span><br><span class="line">C:\Users\yehua&gt;d:</span><br><span class="line"></span><br><span class="line">D:\&gt;cd IdeaProjects\db_hbase</span><br><span class="line"></span><br><span class="line">D:\IdeaProjects\db_hbase&gt;mvn clean package -DskipTests</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building db_hbase 1.0-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-clean-plugin:2.4.1:clean (default-clean) @ db_hbase ---</span><br><span class="line">[INFO] Deleting D:\IdeaProjects\db_hbase\target</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-jar-plugin:2.3.2:jar (default-jar) @ db_hbase ---</span><br><span class="line">[INFO] Building jar: D:\IdeaProjects\db_hbase\target\db_hbase-1.0-SNAPSHOT.jar</span><br><span class="line">[INFO]</span><br><span class="line">[INFO] --- maven-assembly-plugin:2.2-beta-5:single (make-assembly) @ db_hbase ---</span><br><span class="line">[INFO] Building jar: D:\IdeaProjects\db_hbase\target\db_hbase-1.0-SNAPSHOT-jar-with-dependencies.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 7.491s</span><br><span class="line">[INFO] Finished at: Sun Nov 22 12:01:56 CST 2020</span><br><span class="line">[INFO] Final Memory: 99M&#x2F;356M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">将生成的db_hbase-1.0-SNAPSHOT-jar-with-dependencies.jar上传到bigdata04机器上</span><br><span class="line">然后向集群中提交此MapReduce任务</span><br><span class="line"></span><br><span class="line">注意：需要确保Hadoop集群、Zookeeper集群、HBase集群可以正常工作</span><br><span class="line">[root@bigdata04 hadoop-3.2.0]# hadoop jar db_hbase-1.0-SNAPSHOT-jar-with-dependencies.jar com.imooc.hbase.BatchImportMR hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase_import.dat batch1</span><br><span class="line"></span><br><span class="line">执行成功之后，查询HBase中batch1表中的结果如下：</span><br><span class="line"></span><br><span class="line">hbase(main):013:0&gt; scan &#39;batch1&#39;</span><br><span class="line">ROW                COLUMN+CELL                                        </span><br><span class="line"> a                 column&#x3D;c1:age, timestamp&#x3D;1778305406350, value&#x3D;18   </span><br><span class="line"> a                 column&#x3D;c1:name, timestamp&#x3D;1778305406350, value&#x3D;zs  </span><br><span class="line"> b                 column&#x3D;c1:age, timestamp&#x3D;1778305406350, value&#x3D;29   </span><br><span class="line"> b                 column&#x3D;c1:name, timestamp&#x3D;1778305406350, value&#x3D;ls  </span><br><span class="line"> c                 column&#x3D;c1:age, timestamp&#x3D;1778305406350, value&#x3D;31   </span><br><span class="line"> c                 column&#x3D;c1:name, timestamp&#x3D;1778305406350, value&#x3D;ww  </span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.0455 seconds</span><br></pre></td></tr></table></figure><h4 id="批量导入之-BulkLoad"><a href="#批量导入之-BulkLoad" class="headerlink" title="批量导入之 BulkLoad"></a>批量导入之 BulkLoad</h4><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306221529788.png" alt="image-20230622152857361"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">测试数据继续使用hdfs中的hbase_import.dat</span><br><span class="line"></span><br><span class="line">在hbase中创建需要用到的表batch2</span><br><span class="line"></span><br><span class="line">hbase(main):027:0&gt; create &#39;batch2&#39;,&#39;c1&#39;</span><br><span class="line">Created table batch2</span><br><span class="line">Took 1.3600 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - batch2</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">想要实现BulkLoad需要两步</span><br><span class="line">第一步：先生成HFile文件</span><br><span class="line">代码如下：</span><br><span class="line"></span><br><span class="line">注意：此代码会生成底层的HFile文件</span><br></pre></td></tr></table></figure><h5 id="BatchImportBulkLoad"><a href="#BatchImportBulkLoad" class="headerlink" title="BatchImportBulkLoad"></a>BatchImportBulkLoad</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">package com.imooc.hbase;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.client.Put;</span><br><span class="line">import org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line">import org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 批量导入</span><br><span class="line"> *</span><br><span class="line"> * 2.利用BulkLoad</span><br><span class="line"> * 在map阶段，把数据封装成put操作，将数据生成HBase的底层存储文件HFile</span><br><span class="line"> * 再将生成的HFile文件加载到表中</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class BatchImportBulkLoad &#123;</span><br><span class="line">    public static class BulkLoadMapper extends Mapper&lt;LongWritable, Text, ImmutableBytesWritable, Put&gt;&#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context)</span><br><span class="line">                throws IOException, InterruptedException &#123;</span><br><span class="line">            String[] strs &#x3D; value.toString().split(&quot;\t&quot;);</span><br><span class="line">            if(strs.length&#x3D;&#x3D;4)&#123;</span><br><span class="line">                String rowkey &#x3D; strs[0];</span><br><span class="line">                String columnFamily &#x3D; strs[1];</span><br><span class="line">                String name &#x3D; strs[2];</span><br><span class="line">                String val &#x3D; strs[3];</span><br><span class="line">                ImmutableBytesWritable rowkeyWritable &#x3D; new ImmutableBytesWritable(rowkey.getBytes());</span><br><span class="line">                Put put &#x3D; new Put(rowkey.getBytes());</span><br><span class="line">                put.addColumn(columnFamily.getBytes(),name.getBytes(),val.getBytes());</span><br><span class="line">                context.write(rowkeyWritable,put);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        if(args.length!&#x3D;3)&#123;</span><br><span class="line">            &#x2F;&#x2F;如果传递的参数不够，程序直接退出</span><br><span class="line">            System.exit(100);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String inPath &#x3D; args[0];</span><br><span class="line">        String outPath &#x3D; args[1];</span><br><span class="line">        String outTableName &#x3D; args[2];</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;设置属性对应参数</span><br><span class="line">        Configuration conf &#x3D; new Configuration();</span><br><span class="line">        conf.set(&quot;hbase.table.name&quot;,outTableName);</span><br><span class="line">        conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;bigdata01:2181,bigdata02:2181,bigdata03:2181&quot;);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;封装Job</span><br><span class="line">        Job job &#x3D; Job.getInstance(conf, &quot;Batch Import HBase Table：&quot; + outTableName);</span><br><span class="line">        job.setJarByClass(BatchImportBulkLoad.class);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;指定输入路径</span><br><span class="line">        FileInputFormat.setInputPaths(job,new Path(inPath));</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;指定输出路径[如果输出路径存在，就将其删除]</span><br><span class="line">        FileSystem fs &#x3D; FileSystem.get(conf);</span><br><span class="line">        Path output &#x3D; new Path(outPath);</span><br><span class="line">        if(fs.exists(output))&#123;</span><br><span class="line">            fs.delete(output,true);</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job, output);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;指定map相关的代码</span><br><span class="line">        job.setMapperClass(BulkLoadMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(ImmutableBytesWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(Put.class);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;禁用Reduce</span><br><span class="line">        job.setNumReduceTasks(0);</span><br><span class="line"></span><br><span class="line">        Connection connection &#x3D; ConnectionFactory.createConnection(conf);</span><br><span class="line">        TableName tableName &#x3D; TableName.valueOf(outTableName);</span><br><span class="line">        HFileOutputFormat2.configureIncrementalLoad(job,connection.getTable(tableName),connection.getRegionLocator(tableName));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(true);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">打jar包</span><br><span class="line">D:\IdeaProjects\db_hbase&gt;mvn clean package -DskipTests</span><br><span class="line">....</span><br><span class="line">[INFO] META-INF&#x2F;native&#x2F; already added, skipping</span><br><span class="line">[INFO] org&#x2F; already added, skipping</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 34.460s</span><br><span class="line">[INFO] Finished at: Sun Nov 22 17:47:48 CST 2020</span><br><span class="line">[INFO] Final Memory: 115M&#x2F;1075M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">向集群中提交任务</span><br><span class="line">[root@bigdata04 hadoop-3.2.0]# hadoop jar db_hbase-1.0-SNAPSHOT-jar-with-dependencies.jar com.imooc.hbase.BatchImportBulkLoad hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase_import.dat hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase_out batch2</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">第二步：加载HFile文件</span><br><span class="line">在HBase客户端节点上执行下面命令，把HFile数据转移到表对应的region中。</span><br><span class="line">[root@bigdata04 hbase-2.2.7]# hbase org.apache.hadoop.hbase.tool.BulkLoadHFilesTool hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase_out batch2</span><br><span class="line"></span><br><span class="line">查看表batch2中的数据</span><br><span class="line">hbase(main):001:0&gt; scan &#39;batch2&#39;</span><br><span class="line">ROW                COLUMN+CELL                                        </span><br><span class="line"> a                 column&#x3D;c1:age, timestamp&#x3D;1778308217857, value&#x3D;18   </span><br><span class="line"> a                 column&#x3D;c1:name, timestamp&#x3D;1778308217857, value&#x3D;zs  </span><br><span class="line"> b                 column&#x3D;c1:age, timestamp&#x3D;1778308217857, value&#x3D;29   </span><br><span class="line"> b                 column&#x3D;c1:name, timestamp&#x3D;1778308217857, value&#x3D;ls  </span><br><span class="line"> c                 column&#x3D;c1:age, timestamp&#x3D;1778308217857, value&#x3D;31   </span><br><span class="line"> c                 column&#x3D;c1:name, timestamp&#x3D;1778308217857, value&#x3D;ww  </span><br><span class="line">3 row(s)</span><br><span class="line">Took 1.0230 seconds</span><br></pre></td></tr></table></figure><h3 id="批量导出"><a href="#批量导出" class="headerlink" title="批量导出"></a>批量导出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">批量导出两种方式：</span><br><span class="line"></span><br><span class="line">利用TableMapReduceUtil将数据导出 (需要开发MapReduce代码)</span><br><span class="line">利用HBase内部提供的Export工具类</span><br></pre></td></tr></table></figure><h4 id="批量导出之TableMapReduceUtil"><a href="#批量导出之TableMapReduceUtil" class="headerlink" title="批量导出之TableMapReduceUtil"></a>批量导出之TableMapReduceUtil</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">将HBase中的表batch1中的数据导出到hdfs上面</span><br><span class="line">表batch1中的数据如下：</span><br><span class="line"></span><br><span class="line">hbase(main):001:0&gt; scan &#39;batch1&#39;</span><br><span class="line">ROW                COLUMN+CELL                                        </span><br><span class="line"> a                 column&#x3D;c1:age, timestamp&#x3D;1778305406350, value&#x3D;18   </span><br><span class="line"> a                 column&#x3D;c1:name, timestamp&#x3D;1778305406350, value&#x3D;zs  </span><br><span class="line"> b                 column&#x3D;c1:age, timestamp&#x3D;1778305406350, value&#x3D;29   </span><br><span class="line"> b                 column&#x3D;c1:name, timestamp&#x3D;1778305406350, value&#x3D;ls  </span><br><span class="line"> c                 column&#x3D;c1:age, timestamp&#x3D;1778305406350, value&#x3D;31   </span><br><span class="line"> c                 column&#x3D;c1:name, timestamp&#x3D;1778305406350, value&#x3D;ww  </span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.7332 seconds</span><br></pre></td></tr></table></figure><h5 id="BatchExportTableMapReduceUtil"><a href="#BatchExportTableMapReduceUtil" class="headerlink" title="BatchExportTableMapReduceUtil"></a>BatchExportTableMapReduceUtil</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">package com.imooc.hbase;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.hbase.client.Result;</span><br><span class="line">import org.apache.hadoop.hbase.client.Scan;</span><br><span class="line">import org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line">import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;</span><br><span class="line">import org.apache.hadoop.hbase.mapreduce.TableMapper;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 批量导出</span><br><span class="line"> * 1.利用TableMapReduceUtil将数据导出</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class BatchExportTableMapReduceUtil &#123;</span><br><span class="line">    public static class BatchExportMapper extends TableMapper&lt;Text,Text&gt;&#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void map(ImmutableBytesWritable key, Result result, Context context)</span><br><span class="line">                throws IOException, InterruptedException &#123;</span><br><span class="line">            &#x2F;&#x2F;key在这里就是hbase的Rowkey</span><br><span class="line">            &#x2F;&#x2F;result是scan返回的每行结果</span><br><span class="line">            byte[] name &#x3D; null;</span><br><span class="line">            byte[] age &#x3D; null;</span><br><span class="line">            try&#123;</span><br><span class="line">                name &#x3D; result.getValue(&quot;c1&quot;.getBytes(), &quot;name&quot;.getBytes());</span><br><span class="line">            &#125;catch (Exception e)&#123;&#125;</span><br><span class="line">            try&#123;</span><br><span class="line">                age &#x3D; result.getValue(&quot;c1&quot;.getBytes(), &quot;age&quot;.getBytes());</span><br><span class="line">            &#125;catch (Exception e)&#123;&#125;</span><br><span class="line"></span><br><span class="line">            String v2 &#x3D; ((name&#x3D;&#x3D;null || name.length&#x3D;&#x3D;0)?&quot;NULL&quot;:new String(name))+&quot;\t&quot;+((age&#x3D;&#x3D;null || age.length&#x3D;&#x3D;0)?&quot;NULL&quot;:new String(age));</span><br><span class="line"></span><br><span class="line">            context.write(new Text(key.get()),new Text(v2));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        if(args.length!&#x3D;2)&#123;</span><br><span class="line">            &#x2F;&#x2F;如果传递的参数不够，程序直接退出</span><br><span class="line">            System.exit(100);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String inTableName &#x3D; args[0];</span><br><span class="line">        String outPath &#x3D; args[1];</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;设置属性对应参数</span><br><span class="line">        Configuration conf &#x3D; new Configuration();</span><br><span class="line">        conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;bigdata01:2181,bigdata02:2181,bigdata03:2181&quot;);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;组装Job</span><br><span class="line">        Job job &#x3D; Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(BatchExportTableMapReduceUtil.class);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;设置map相关的配置</span><br><span class="line">        job.setMapperClass(BatchExportMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;禁用Reduce</span><br><span class="line">        job.setNumReduceTasks(0);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;设置输入信息</span><br><span class="line">        TableMapReduceUtil.initTableMapperJob(inTableName,new Scan(),BatchExportMapper.class,Text.class,Text.class,job);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;设置输出路径</span><br><span class="line">        FileOutputFormat.setOutputPath(job,new Path(outPath));</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(true);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">打jar包</span><br><span class="line">D:\IdeaProjects\db_hbase&gt;mvn clean package -DskipTests</span><br><span class="line">......</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 34.797s</span><br><span class="line">[INFO] Finished at: Mon Nov 23 11:03:26 CST 2020</span><br><span class="line">[INFO] Final Memory: 66M&#x2F;1129M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">将jar包是上传到bigdata04上面，然后向集群提交任务</span><br><span class="line">[root@bigdata04 hadoop-3.2.0]# hadoop jar db_hbase-1.0-SNAPSHOT-jar-with-dependencies.jar com.imooc.hbase.BatchExportTableMapReduceUtil batch1 hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;batch1</span><br><span class="line"></span><br><span class="line">查看导出结果数据：</span><br><span class="line">[root@bigdata04 hadoop-3.2.0]# hdfs dfs -cat &#x2F;batch1&#x2F;*</span><br><span class="line">a       zs      18</span><br><span class="line">b       ls      29</span><br><span class="line">c       ww      31</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：想要导出什么格式的数据，具体的逻辑代码在map函数内部根据需求实现即可。</span><br></pre></td></tr></table></figure><h4 id="批量导出之HBase内部方法"><a href="#批量导出之HBase内部方法" class="headerlink" title="批量导出之HBase内部方法"></a>批量导出之HBase内部方法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">使用HBase提供的Export工具类直接导出数据</span><br><span class="line">[root@bigdata04 ~]# hbase org.apache.hadoop.hbase.mapreduce.Export batch1 hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;batch2</span><br><span class="line"></span><br><span class="line">注意：此种方式导出的数据格式是固定的</span><br><span class="line">数据中的k1和v1是&lt;ImmutableBytesWritable key, Result result&gt;形式的</span><br><span class="line"></span><br><span class="line">查看结果是这样的：</span><br><span class="line">注意：直接使用cat命令查看会显示乱码，因为不是普通的文本文件</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ~]# hdfs dfs -cat &#x2F;batch2&#x2F;*</span><br><span class="line">SEQ1org.apache.hadoop.hbase.io.ImmutableBytesWritable%org.apache.hadoop.hbase.client.Result#&#123;MdAa;</span><br><span class="line">_x0019_</span><br><span class="line">a_x0012_c1age 218</span><br><span class="line"></span><br><span class="line">a_x0012_c1name 2zs (Ab;</span><br><span class="line">_x0019_</span><br><span class="line">b_x0012_c1age 229</span><br><span class="line"></span><br><span class="line">b_x0012_c1name 2ls (Ac;</span><br><span class="line">_x0019_</span><br><span class="line">c_x0012_c1age 231</span><br><span class="line"></span><br><span class="line">c_x0012_c1name 2ww (</span><br><span class="line"></span><br><span class="line">建议优先选择使用第一种，更加灵活，根据需求导出希望的数据格式。</span><br></pre></td></tr></table></figure><h3 id="HBase连接池"><a href="#HBase连接池" class="headerlink" title="HBase连接池"></a>HBase连接池</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">注意：HBase2.1.2之后的版本，无需创建HBase线程池，HBase2.1.2提供的代码已经封装好，只需创建调用即可。</span><br><span class="line">Connection conn &#x3D; ConnectionFactory.createConnection(conf);</span><br><span class="line">&#x2F;&#x2F;conn在获取Table的时候，底层默认会从线程池中获取一个连接</span><br><span class="line">Table table &#x3D; conn.getTable(TableName.valueOf(&quot;s1&quot;));</span><br><span class="line"></span><br><span class="line">所以table在用完之后可以直接调用close方法即可，在程序关闭的时候调用conn的close方法即可。</span><br><span class="line"></span><br><span class="line">查看源码最终可以追踪到这里：</span><br><span class="line"></span><br><span class="line">org.apache.hadoop.hbase.client.ConnectionImplementation</span><br><span class="line">默认会创建一个线程池，256个连接。</span><br><span class="line">private ThreadPoolExecutor getBatchPool() &#123;</span><br><span class="line">  if (batchPool &#x3D;&#x3D; null) &#123;</span><br><span class="line">    synchronized (this) &#123;</span><br><span class="line">      if (batchPool &#x3D;&#x3D; null) &#123;</span><br><span class="line">        int threads &#x3D; conf.getInt(&quot;hbase.hconnection.threads.max&quot;, 256);</span><br><span class="line">        this.batchPool &#x3D; getThreadPool(threads, threads, &quot;-shared&quot;, null);</span><br><span class="line">        this.cleanupPool &#x3D; true;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return this.batchPool;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="HBase" scheme="http://tianyong.fun/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-快速上手NoSQL数据库HBase-1</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93HBase-1.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93HBase-1.html</id>
    <published>2023-06-13T01:24:14.000Z</published>
    <updated>2023-06-21T15:45:55.950Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="快速上手NoSQL数据库HBase-1"><a href="#快速上手NoSQL数据库HBase-1" class="headerlink" title="快速上手NoSQL数据库HBase-1"></a>快速上手NoSQL数据库HBase-1</h1><h2 id="1-快速了解HBase"><a href="#1-快速了解HBase" class="headerlink" title="1 快速了解HBase"></a>1 快速了解HBase</h2><h3 id="HBase简介"><a href="#HBase简介" class="headerlink" title="HBase简介"></a>HBase简介</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在前面我们学习过了Hive，一句话概括Hive就是一个数据仓库，更像一个传统意义上的SQL数据库，主要用作数据仓库数据分析，更加强调离线的数据分析，为公司各个业务部门提供数据支撑。</span><br><span class="line"></span><br><span class="line">但是在我们大数据的处理过程中，不光需要进行OLAP的操作，在有些情况下，也经常需要对数据进行记录级别的更新、删除等操作，也就是OLTP（联机事务处理）的操作，这是Hive所办不到的，那么这个时候就不能用Hive来为我们处理OLTP的业务了，因为Hive不支持事务，那我们使用Oracle总可以吧，当然对于一定范围内的数据是OK，没有问题的，但是当数据量达到亿级别，甚至更高的时候，Oracle的性能也会下降的非常厉害，几乎就瘫掉了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">比如有这么一个例子：公司原来的业务系统使用的是Oracle，目前数据量大约10亿条，处理响应非常慢。为了平缓的迁移到大数据平台，那么决定使用hive替换oracle，这种方案怎么样？</span><br><span class="line">这个方案不怎么样。</span><br><span class="line">我们都知道Oracle是关系型数据库，强调的是事务，更适合OLTP的应用场景。而Hive是数据仓库，更强调的是在大数据基础上的强大的查询和分析能力，更适合于OLAP的应用场景，显然是无法来帮我们完成业务需求的。</span><br><span class="line">既然传统的SQL无法解决我们的这种需求，那么就需要另辟蹊径了——NoSQL（Not only SQL），使用NoSQL数据库来满足我们的业务需求，在Hadoop生态圈中一个比较典型的NoSQL数据库就是HBase，从字面意思上来看就是Hadoop Database，Hadoop生态圈的数据库，可以提供这种OLTP的操作，解决我们刚才提出的问题。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">那么，HBase到底是一个怎么样的NoSQL数据库呢？我们来看一下。</span><br><span class="line"></span><br><span class="line">1.HBase – Hadoop Database：是一个高可靠 、高性能、面向列、可伸缩的NoSQL数据库(Key-Value类型)</span><br><span class="line">高可靠：指的是HBase集群支持多个主节点，多个从节点，集群可靠性比较高，并且HBase的数据是存储在HDFS上的，数据可靠性也比较高。</span><br><span class="line">高性能：指的是HBase可以存储上亿或者十亿级别的数据，实现毫秒级别查询。</span><br><span class="line">面向列：指的是HBase数据的存储方式，是按照列存储的。</span><br><span class="line">可伸缩：指的是HBase集群可以方便的添加或者删除一个节点。</span><br><span class="line"></span><br><span class="line">2.HBase使用HDFS作为其文件存储系统。</span><br><span class="line">HBase数据库的数据是存储在HDFS上面的。</span><br><span class="line"></span><br><span class="line">3.HBase支持对海量数据的增删改查。</span><br><span class="line">这里大家可能会有一个疑问，HDFS是不支持修改删除的，为什么HBase也是基于HDFS存储数据的，却可以支持修改删除呢？</span><br><span class="line">这是因为HBase自己封装了一个中间层，在中间层针对删除的数据会做一个特殊标记，这样在查询的时候就会过滤掉已经标记为删除状态的数据，这样间接支持了删除功能。</span><br></pre></td></tr></table></figure><h3 id="列式存储简介"><a href="#列式存储简介" class="headerlink" title="列式存储简介"></a>列式存储简介</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">传统的关系型数据库，如MySQL、Oracle等采用 行存储 的方式来存储数据</span><br><span class="line">先来解释一下行存储的概念</span><br><span class="line">咱们在MySQL中使用的select… where…语句，select后面的字段表示从行中查询哪些字段，where是过滤查询哪些行的。</span><br><span class="line">MySQL存储的时候都是按行存储的，对于关系型数据库而言，按行存储查询起来效率是比较高的。</span><br><span class="line"></span><br><span class="line">绝大多数传统意义上的RDBMS都采用行存储的方式来存储数据，基于此一般都适合SQL查询，并且适合一次性查询出所有列、适合范围查询的情况。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">缺点是不适合查询少量字段的情况。就算是你只需要查询某一个列的数据，底层也需要读取这一行中所有列的数据，最后只过滤出来你需要的某个列，这是由它的底层数据结构而定的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在基于行式存储的数据库中， 数据是 按照行数据为基础逻辑存储单元 进行存储的， 一行中的数据在存储介质中以连续存储形式存在。</span><br><span class="line">列式存储是相对于行式存储来说的，在基于列式存储 的数据库中，数据是 按照列为基础逻辑存储单元 进行存储的，一列中的数据在存储介质中以连续存储形式存在。</span><br></pre></td></tr></table></figure><h4 id="列式存储的优点"><a href="#列式存储的优点" class="headerlink" title="列式存储的优点"></a>列式存储的优点</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">行式数据库在做一些列分析时，必须将所有列的信息全部读取出来，而列式数据库由于其是按列存取，因此只需在特定列做I&#x2F;O即可完成查询与分析，效率节省90%。</span><br><span class="line">列式数据库在每列上还有专门的列压缩算法进一步提高数据库性能，这是行式数据库不具备的。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211623535.png" alt="image-20230621162349232"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Row-based（Row-based store）：行式存储。</span><br><span class="line">Column-based （Cloumn-based store）：列式存储。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">从这个图里面可以看出来：</span><br><span class="line">行式存储数据库中的数据在底层存储的时候，每一行的数据作为一个基础逻辑存储单元进行存储。</span><br><span class="line">列式存储数据库中的数据在底层存储的时候，每一列的数据作为一个基础逻辑存储单元进行存储。</span><br></pre></td></tr></table></figure><h3 id="HBase典型应用场景"><a href="#HBase典型应用场景" class="headerlink" title="HBase典型应用场景"></a>HBase典型应用场景</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211626184.png" alt="image-20230621162607346"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.半结构化或非结构化数据</span><br><span class="line">对于数据结构字段不够确定或杂乱无章，很难按一个概念去进行抽取的数据适合用HBase进行存储。</span><br><span class="line">比如文章的tag(标签)信息，会不断的增加、删除。</span><br><span class="line"></span><br><span class="line">解释：每个文章的标签信息是不一样的，并且标签也会经常变化，用户可能随时对文章的标签信息进行修改。</span><br><span class="line">如果使用MySQL存储，可以选择把文章的所有标签信息通过逗号分割拼接成一个字符串存储到一个字段里面，这样存储的时候方便了，但是使用的时候比较麻烦，每次都需要解析这个字符串进行处理。</span><br><span class="line">当然也可以选择在MySQL中将每一个标签都存储到一个独立的字段中，这样使用起来比较方便，但是这样表结构就需要经常变化了，可能会存在某一篇文章有10个标签信息（需要10个标签字段），另一篇文章只有1个标签信息的情况（只需要1个标签字段），这样表结构中至少需要增加10个标签字段，这样就会存在字段冗余的情况，额外浪费存储空间。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2.记录非常稀疏</span><br><span class="line">RDBMS(关系型数据库)的每一行有多少列是固定的，值为null的列浪费了存储空间。</span><br><span class="line">HBase中值为null的列不会被存储，这样既节省了空间又提高了读性能。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">3.多版本数据</span><br><span class="line">HBase中某一个列的值可以有任意数量的版本值，因此对于需要存储历史记录的数据，用HBase就非常方便了。</span><br><span class="line">解释：Mysql上如果想要保存一个数据的多个历史版本数据的话只能存储多行记录，而HBase只需要针对某个列存储多个历史版本即可，通过时间戳可以定位历史版本的数据。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">4.超大数据量</span><br><span class="line">当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。</span><br><span class="line">随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开存储，一些join查询不能用了，需要借助中间层。</span><br><span class="line">随着数据量的进一步增加，一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。</span><br><span class="line">经历过这些事的人都知道过程是多么的折腾。采用HBase就简单了，只需要加机器即可，HBase会自动水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）。</span><br></pre></td></tr></table></figure><h3 id="HBase应用案例"><a href="#HBase应用案例" class="headerlink" title="HBase应用案例"></a>HBase应用案例</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211633553.png" alt="image-20230621163320045"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">淘宝在2011年之前所有的后端持久化存储基本上都是在MySQL上进行的，MySQL由于开源，并且生态系统良好，本身拥有分库分表等多种解决方案，因此很长一段时间内都可以满足淘宝大量业务的需求。</span><br><span class="line">但是由于业务的多样化发展，有越来越多的业务系统的需求开始发生了变化。一般来说有以下几类变化：</span><br><span class="line">1.数据量变得越来越多，事实上现在淘宝几乎任何一个与用户相关的在线业务的数据量都在亿级别，每日系统调用次数从亿到百亿都有，且历史数据不能轻易删除。这需要有一个海量分布式文件系统，能对TB级甚至PB级别的数据提供在线服务</span><br><span class="line">2.数据量的增长很快且不一定能准确预计，大多数应用系统从上线起在一段时间内数据量都呈很快的上升趋势，因此从成本的角度考虑对系统水平扩展能力有比较强烈的需求，且不希望存在单点制约</span><br><span class="line">3.只需要简单的k-v读取，没有复杂的join等需求。但对系统的并发能力以及吞吐量、响应延时有非常高的需求，并且希望系统能够保持强一致性</span><br><span class="line">4.通常系统的写入非常频繁，尤其是大量系统依赖于实时的日志分析</span><br><span class="line">5.希望能够快速读取批量数据</span><br><span class="line">6.Schema(表结构信息)灵活多变，可能经常更新列属性或新增列</span><br><span class="line">7.希望能够方便使用，有良好且语义清晰的java接口</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">腾讯产品与技术的发展迅速，几乎任何一个与用户相关的在线业务的数据量都在亿级别，每日系统调用次数从亿到百亿，对海量数据的高效插入和快速读取变得越来越重要。</span><br><span class="line">而传统关系型数据库模式固定、强调参照完整性、数据的逻辑与物理形式相对独立等，比较适用于中小规模的数据，但对于数据的规模和并发读写方面进行大规模扩展时，RDBMS性能会大大降低，分布式更为困难。</span><br><span class="line">腾讯为什么会选择HBase？</span><br><span class="line"></span><br><span class="line">1.高可靠性。HBase是运行在Hadoop上的NoSQL数据库，它的数据由HDFS做了数据冗余，具有高可靠性。</span><br><span class="line">2.同时TDW（腾讯分布式数据仓库）五年的稳定运行，8800台的集群规模，证明了其服务于海量数据的能力。</span><br><span class="line">3.高并发读写。使用日志文件（HLOG）和内存存储来将随机写转换成顺序写，保证稳定的数据插入速率；读写分离，这两种操作没有冲突。</span><br><span class="line">4.优雅的伸缩性。HBase服务能力可以随服务器的增长而线性增长；HBase中表的数据表按Key 值范围自动分片，散布于不同的机器上，实现自动负载均衡；支持百亿行×百万列×上万个版本。</span><br><span class="line">5.低延迟。数据按列存储，数据即索引。</span><br><span class="line">6.低成本。历史数据不能轻易删除，数据量变得越来越多，尤其是对于日志类存储，写多读少。而HBase可构建在廉价的PC上，此外，HBase支持较多的压缩算法。</span><br></pre></td></tr></table></figure><h3 id="HBase的优缺点总结"><a href="#HBase的优缺点总结" class="headerlink" title="HBase的优缺点总结"></a>HBase的优缺点总结</h3><h4 id="HBase的优点"><a href="#HBase的优点" class="headerlink" title="HBase的优点"></a>HBase的优点</h4><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211839974.png" alt="image-20230621183955700"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">支持动态列：支持随时动态增加或者减少列。例如：第一条数据有10列，第二条数据可以有100列，互相不影响，也不需要修改表结构。</span><br></pre></td></tr></table></figure><h4 id="HBase的缺点"><a href="#HBase的缺点" class="headerlink" title="HBase的缺点"></a>HBase的缺点</h4><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211841286.png" alt="image-20230621184122750"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">不支持SQL数据分析：HBase属于NoSQL数据库，所以不支持常见的SQL语法。</span><br><span class="line">不擅长多条件组合查询：HBase中根据多个列进行组合条件查询相当于全表扫描，所以效率不高。</span><br><span class="line">不适合大范围扫描查询：大范围扫描效率不高，数据量过大时容易导致扫描超时或者失败。</span><br></pre></td></tr></table></figure><h3 id="HBase逻辑存储模型之名词解释"><a href="#HBase逻辑存储模型之名词解释" class="headerlink" title="HBase逻辑存储模型之名词解释"></a>HBase逻辑存储模型之名词解释</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211842493.png" alt="image-20230621184225370"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">-命名空间（Namespace）：命名空间类似于MySQL中的Database。</span><br><span class="line">-表（Table）：表类似于MySQL中的Table。</span><br><span class="line">-行（Row）：行类似于MySQL中的行。</span><br><span class="line">-行键（Rowkey）：行键类似于MySQL中的主键。在MySQL中，主键不是必须的。在HBase中，行键在每一行中是必须存在的。HBase号称上亿条数据可以实现毫秒级查询，其实是需要根据Rowkey查询的，如果涉及其它列的组合查询，查询效率也一般。</span><br><span class="line">-列族（ColumnFamily）：列族在MySQL中没有对应的概念。在HBase中，列族是一批列的集合，在创建表的时候，列族必须定义。</span><br><span class="line">-列（Column）：列类似于在MySQL中的列。在HBase中创建表的时候，列不需要提前定义，也不能提前定义，后期在向表中添加数据的时候，动态指定列。</span><br><span class="line">-时间戳（Timestamp ）：默认插入值的时候会带有时间戳，是HBase自带的，不需要在表定义的时候指定。时间戳和值是一一对应的，时间戳的类型是64位整型。时间戳可以由 HBase (在数据写入时)自动赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由用户显式赋值，针对某个列，不同版本的数据按照时间戳倒序排序，即最新的数据排在最前面。HBase在查询的时候，默认返回列中最新版本的数据。</span><br><span class="line">-数据类型（DataType）：MySQL中，数据类型多种多样，常见的有int、varchar、date、datetime等等。在HBase中，数据类型只有一种，就是byte[]（字节数组），不管是什么数据类型，在HBase中存储的时候统一都会转化为byte[]。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">什么是逻辑存储模型呢？简单来说就是我们操作HBase的时候能够直观看到的一些东西</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211847007.png" alt="image-20230621184735696"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">这个图的意思表示在HBase中有一张表，表里面有2个列族，c1和c2</span><br><span class="line">目前这个表里面有1条数据，这条数据的RowKey是 隔壁老王</span><br><span class="line">其中列族c1里面只有1列，是age，列族c2里面有2列，car和house</span><br><span class="line">针对列族c1中的age列的值而言，有4个历史版本：T1,T2,T3,T5。</span><br><span class="line"></span><br><span class="line">想要定位某一列的值，流程是这样的：HBase Table --&gt; RowKey --&gt; ColumnFamily --&gt; Column --&gt; TimeStamp</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">想要达到图中这个数据效果，需要对表执行以下这些步骤：</span><br><span class="line"></span><br><span class="line">第一次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c1中的age列，值为27，此时这一列的值会对应的产生一个时间戳 T1，表示数据的产生时间</span><br><span class="line"></span><br><span class="line">注意：这里面的时间戳定义为T1只是为了看起来清晰，实际上时间戳的值就是我们平时接触到的毫秒级时间戳：1628582473928。</span><br><span class="line"></span><br><span class="line">第二次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c1中的age列，值为28，此时这一列的值会对应的产生一个时间戳 T2</span><br><span class="line"></span><br><span class="line">第三次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c1中的age列，值为29，此时这一列的值会对应的产生一个时间戳 T3</span><br><span class="line"></span><br><span class="line">第四次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c2中的car列，值为有车，此时这一列的值会对应的产生一个时间戳 T4</span><br><span class="line"></span><br><span class="line">第五次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c1中的age列，值为30，此时这一列的值会对应的产生一个时间戳 T5</span><br><span class="line"></span><br><span class="line">第六次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c2中的house列，值为有房，此时这一列的值会对应的产生一个时间戳 T6</span><br><span class="line"></span><br><span class="line">第七次向HBase表中添加数据，指定RowKey 为隔壁老王，指定列族c2中的car列，值为没车(老王把车卖了)，此时这一列的值会对应的产生一个时间戳 T7</span><br><span class="line">经过这7步之后，数据就可以达到和图中一样的效果了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HBase是 三维（三个维度） 有序存储的，是指Rowkey，Column key（Column Family和Column）和 TimeStamp 这三个维度是依照ASCII码表排序的。</span><br><span class="line"></span><br><span class="line">先按Rowkey升序排序。Rowkey相同则按Column key升序排序。Rowkey、Column key相同则按Timestamp降序排序</span><br><span class="line"></span><br><span class="line">如下图所示：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211853234.png" alt="image-20230621185309314"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">这个图里面表示对HBase的表t1进行全表扫描，在扫描的时候会返回同一个列的最多2个历史版本数据（VERSIONS&#x3D;&gt;2）。</span><br><span class="line">图中执行scan &#39;t1&#39;,&#123;VERSION&#x3D;&gt;2&#125;（全表扫描） 命令之后，最终返回了3条数据，Rowkey是：stu001,stu002,stu003。</span><br><span class="line">针对第1条数据stu001，它里面一共有3列：age，name、math。列族有2个：info和level。age和name属于info列族，math属于level列族。</span><br><span class="line">这里的info:age显示了两次是因为age字段存储了2个历史版本的数据。</span><br><span class="line">最终从这个图里面是可以看出来HBase的三维有序存储特性的。</span><br><span class="line">首先按照Rowkey（stu001,stu002,stu003）升序排序，相同Rowkey（stu001）内按照Column key（info:age,info:name,level:math）升序排序，针对相同的Column key（info:age），则按照数据对应的Timestamp（1800690940131,1800690940039）降序排序。</span><br></pre></td></tr></table></figure><h2 id="2-快速上手使用HBase"><a href="#2-快速上手使用HBase" class="headerlink" title="2 快速上手使用HBase"></a>2 快速上手使用HBase</h2><h3 id="HBase安装部署"><a href="#HBase安装部署" class="headerlink" title="HBase安装部署"></a>HBase安装部署</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HBase需要依赖于Hadoop（HDFS）和Zookeeper服务</span><br><span class="line">Hadoop我们前面已经学习过了，Zookeeper的安装部署步骤在Kafka课程中已经讲过，所以在这就直接使用了。</span><br><span class="line">HBase支持伪分布集群和分布式集群</span><br><span class="line">在具体安装HBase集群之前，我们需要先确认JDK的版本和Hadoop的版本</span><br><span class="line">HBase与JDK版本对应关系如下：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211859661.png" alt="image-20230621185906640"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HBase与Hadoop版本对应关系如下：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211859080.png" alt="image-20230621185935961"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">咱们本套课程中JDK使用的是1.8版本，HBase的所有版本都是支持的。</span><br><span class="line">Hadoop版本我们使用的是3.2.0，由图中内容可知，我们只能选择HBase2.2.x或者HBase-2.3.x</span><br><span class="line">一般不建议选最新的那个版本，所以在这里我们选择HBase2.2.7版本。</span><br><span class="line"></span><br><span class="line">HBase所有版本的下载地址：</span><br><span class="line">https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hbase&#x2F;</span><br><span class="line"></span><br><span class="line">HBase2.2.7版本的下载地址：</span><br><span class="line">https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hbase&#x2F;2.2.7&#x2F;hbase-2.2.7-bin.tar.gz</span><br><span class="line"></span><br><span class="line">最终下载好的HBase安装包是这个：hbase-2.2.7-bin.tar.gz</span><br></pre></td></tr></table></figure><h4 id="分布式集群"><a href="#分布式集群" class="headerlink" title="分布式集群"></a>分布式集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在这里就直接演示分布式集群的安装步骤了，伪分布集群和分布式集群的安装基本上没有多少区别。</span><br><span class="line"></span><br><span class="line">HBase集群也是支持主从架构的，在这计划使用bigdata01、02、03这三台机器。</span><br><span class="line">建议把HBase的从节点和Hadoop集群的从节点部署在相同的机器上面，这样可以最大化利用数据本地化的特性。</span><br><span class="line">所以最终的节点规划如下：</span><br><span class="line">bigdata01  HMaster(HBase的主节点，主节点可以支持多个，实现HA)</span><br><span class="line">bigdata02  HRegionserver(HBase的从节点)</span><br><span class="line">bigdata03  HRegionserver(HBase的从节点)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">下面开始安装部署：</span><br><span class="line">bigdata01、02、03这三台机器的基础环境是OK的，并且上面已经运行了一套Hadoop的一主两从的集群。</span><br><span class="line"></span><br><span class="line">1：首先在bigdata01上进行操作，将HBase安装包上传到bigdata01的&#x2F;data&#x2F;soft目录中</span><br><span class="line">[root@bigdata01 soft]# ll </span><br><span class="line">-rw-r--r--. 1 root root 220469021 Oct 31  2020 hbase-2.2.7-bin.tar.gz</span><br><span class="line"></span><br><span class="line">2：解压</span><br><span class="line">[root@bigdata01 soft]# tar -zxvf hbase-2.2.7-bin.tar.gz </span><br><span class="line"></span><br><span class="line">3：修改配置文件</span><br><span class="line">首先修改hbase-env.sh，在文件末尾直接添加以下配置即可</span><br><span class="line">[root@bigdata01 soft]# cd hbase-2.2.7&#x2F;conf</span><br><span class="line">[root@bigdata01 conf]# vi hbase-env.sh</span><br><span class="line">....</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;jdk1.8</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;hadoop-3.2.0</span><br><span class="line">export HBASE_MANAGES_ZK&#x3D;false</span><br><span class="line">export HBASE_LOG_DIR&#x3D;&#x2F;data&#x2F;hbase&#x2F;logs</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">接下来修改hbase-site.xml</span><br><span class="line">hbase-site.xml中默认有3个配置参数，主要修改里面hbase.cluster.distributed和hbase.tmp.dir的值。</span><br><span class="line">[root@bigdata01 conf]# vi hbase-site.xml </span><br><span class="line">&lt;!--是否为分布式模式部署，true表示分布式部署--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!-- 本地文件系统tmp目录--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;data&#x2F;hbase&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!-- 这个参数的值默认不变即可，默认就是false。在分布式情况下, 一定设置为false --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">前面这几个已有的参数修改完毕以后，还需要向hbase-site.xml中添加下面这些参数</span><br><span class="line">[root@bigdata01 conf]# vi hbase-site.xml </span><br><span class="line">.......</span><br><span class="line">&lt;!--设置HBase表数据，也就是HBase数据在hdfs上的存储根目录--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!--zookeeper集群的URL配置，多个host中间用逗号隔开--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.quorum&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;bigdata01,bigdata02,bigdata03&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!--HBase在zookeeper上数据的根目录znode节点--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;zookeeper.znode.parent&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;hbase&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;!--设置zookeeper通信端口，不配置也可以，zookeeper默认就是2181--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;2181&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">最后修改regionservers文件，在里面添加HBase从节点的主机名或者ip</span><br><span class="line">[root@bigdata01 conf]# vi regionservers</span><br><span class="line">bigdata02</span><br><span class="line">bigdata03</span><br><span class="line"></span><br><span class="line">注意：如果是使用一台机器安装HBase伪分布集群，只需要在regionservers文件中配置那一台机器的主机名即可。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">4：将bigdata01中修改完配置的HBase目录远程拷贝到bigdata02和bigdata03上</span><br><span class="line">[root@bigdata01 soft]# scp -rq hbase-2.2.7 bigdata02:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line">[root@bigdata01 soft]# scp -rq hbase-2.2.7 bigdata03:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line"></span><br><span class="line">5：启动HBase集群</span><br><span class="line">注意：在启动HBase集群之前一定要确保Hadoop集群和Zookeeper集群已经正常启动了。</span><br><span class="line"></span><br><span class="line">先启动Hadoop集群</span><br><span class="line">[root@bigdata01 hadoop-3.2.0]# sbin&#x2F;start-all.sh</span><br><span class="line"></span><br><span class="line">再启动Zookeeper集群</span><br><span class="line">注意：Zookeeper伪分布和集群的安装部署步骤在Kafka课程中。</span><br><span class="line">地址为：https:&#x2F;&#x2F;class.imooc.com&#x2F;course&#x2F;1695</span><br><span class="line">[root@bigdata01 apache-zookeeper-3.5.8-bin]# bin&#x2F;zkServer.sh start</span><br><span class="line">[root@bigdata02 apache-zookeeper-3.5.8-bin]# bin&#x2F;zkServer.sh start</span><br><span class="line">[root@bigdata03 apache-zookeeper-3.5.8-bin]# bin&#x2F;zkServer.sh start</span><br><span class="line"></span><br><span class="line">最后在bigdata01上启动HBase集群</span><br><span class="line">[root@bigdata01 hbase-2.2.7]# bin&#x2F;start-hbase.sh </span><br><span class="line"></span><br><span class="line">6：验证集群</span><br><span class="line">在bigdata01上执行jps命令，会发现多了一个HMaster进程，这个就是HBase集群主节点中的进程</span><br><span class="line">[root@bigdata01 hbase-2.2.7]# jps</span><br><span class="line">3826 NameNode</span><br><span class="line">5528 QuorumPeerMain</span><br><span class="line">5736 HMaster</span><br><span class="line">4093 SecondaryNameNode</span><br><span class="line">4334 ResourceManager</span><br><span class="line"></span><br><span class="line">然后在bigdata02上执行jps命令，会发现多了一个HRegionServer进程，这个就是HBase集群从节点中的进程</span><br><span class="line">[root@bigdata02 ~]# jps</span><br><span class="line">2631 QuorumPeerMain</span><br><span class="line">2249 NodeManager</span><br><span class="line">2139 DataNode</span><br><span class="line">2715 HRegionServer</span><br><span class="line"></span><br><span class="line">然后在bigdata03上执行jps命令，会发现多了一个HRegionServer进程，这个就是HBase集群从节点中的进程</span><br><span class="line">[root@bigdata03 ~]# jps</span><br><span class="line">2625 QuorumPeerMain</span><br><span class="line">2250 NodeManager</span><br><span class="line">2140 DataNode</span><br><span class="line">2702 HRegionServer</span><br><span class="line"></span><br><span class="line">如果发现HMaster进程和HRegionServer进程都在，说明HBase集群正常启动了</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306211908502.png" alt="image-20230621190830287"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HBase提供的有web界面，可以通过浏览器确认集群是否正常启动，端口默认是16010</span><br><span class="line">http:&#x2F;&#x2F;bigdata01:16010&#x2F;</span><br><span class="line"></span><br><span class="line">7：停止HBase集群</span><br><span class="line">[root@bigdata01 hbase-2.2.7]# bin&#x2F;stop-hbase.sh</span><br><span class="line"></span><br><span class="line">注意：在停止集群进程的时候，要先停HBase集群进程，再停止Zookeeper集群和Hadoop集群，否则HBase停止程序会一直卡住不动，这种情况就需要使用kill命令强制杀进程了。</span><br></pre></td></tr></table></figure><h3 id="HBase常用Shell命令"><a href="#HBase常用Shell命令" class="headerlink" title="HBase常用Shell命令"></a>HBase常用Shell命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HBase集群启动之后，下面我们来操作一下HBase</span><br><span class="line">HBase的使用在工作中主要分为两种形式</span><br><span class="line"></span><br><span class="line">-在开发和调试阶段，我们会通过HBase自带的shell命令行去操作，可以执行创建表，添加数据，修改数据之类的操作，比较方便</span><br><span class="line">-在程序上线运行阶段，需要通过代码来操作HBase，HBase提供的有JavaAPI可以使用</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在这里我们先看一下HBase中常用的一些shell命令</span><br><span class="line"></span><br><span class="line">在这里可以把HBase中的命令总结为三种</span><br><span class="line"></span><br><span class="line">-基础命令</span><br><span class="line">-DDL命令</span><br><span class="line">-增删改查命令</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">如何进入HBase的shell命令行？</span><br><span class="line">执行hbase shell命令即可</span><br><span class="line"></span><br><span class="line">[root@bigdata01 hbase-2.2.7]# bin&#x2F;hbase shell</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:&#x2F;data&#x2F;soft&#x2F;hadoop-3.2.0&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F;slf4j-log4j12-1.7.25.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:&#x2F;data&#x2F;soft&#x2F;hbase-2.2.7&#x2F;lib&#x2F;client-facing-thirdparty&#x2F;slf4j-log4j12-1.7.25.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http:&#x2F;&#x2F;www.slf4j.org&#x2F;codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</span><br><span class="line">HBase Shell</span><br><span class="line">Use &quot;help&quot; to get list of supported commands.</span><br><span class="line">Use &quot;exit&quot; to quit this interactive shell.</span><br><span class="line">For Reference, please visit: http:&#x2F;&#x2F;hbase.apache.org&#x2F;2.0&#x2F;book.html#shell</span><br><span class="line">Version 2.2.7, r0fc18a9056e5eb3a80fdbde916865607946c5195, 2021年 04月 11日 星期日 19:24:57 CST</span><br><span class="line">Took 0.0021 seconds                                                 </span><br><span class="line">hbase(main):001:0&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">为了后期方便操作HBase，建议在PATH中配置一下HBASE_HOME</span><br><span class="line"></span><br><span class="line">[root@bigdata01 hbase-2.2.7]# vi &#x2F;etc&#x2F;profile</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;jdk1.8</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;hadoop-3.2.0</span><br><span class="line">export HBASE_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;hbase-2.2.7</span><br><span class="line">export PATH&#x3D;.:$JAVA_HOME&#x2F;bin:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin:$HBASE</span><br><span class="line">_HOME&#x2F;bin:$PATH</span><br><span class="line">[root@bigdata01 hbase-2.2.7]# source &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line">此时就可以直接在任何目录下执行hbase shell命令了。</span><br><span class="line"></span><br><span class="line">注意：如果命令输入错误，使用键盘上的退格键（backspace）可能会无法删除命令，此时需要确认SecureCRT中的这2个配置。</span><br><span class="line"></span><br><span class="line">1.终端类型选择Linux</span><br><span class="line"></span><br><span class="line">2.选中Backspace发送delete</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306212241300.png" alt="image-20230621224114770"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306212241859.png" alt></p><h4 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">命令解释</span><br><span class="line">status查看集群状态</span><br><span class="line">version查看当前版本</span><br><span class="line">whoami查看当前用户</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; status</span><br><span class="line">1 active master, 0 backup masters, 2 servers, 0 dead, 1.0000 average load</span><br><span class="line">Took 0.9864 seconds                                                   </span><br><span class="line">hbase(main):002:0&gt; version</span><br><span class="line">2.2.7, r0fc18a9056e5eb3a80fdbde916865607946c5195, 2021年 04月 11日 星期日 19:24:57 CST</span><br><span class="line">Took 0.0002 seconds                                                   </span><br><span class="line">hbase(main):003:0&gt; whoami</span><br><span class="line">root (auth:SIMPLE)</span><br><span class="line">    groups: root</span><br><span class="line">Took 0.0085 seconds</span><br></pre></td></tr></table></figure><h4 id="DDL命令"><a href="#DDL命令" class="headerlink" title="DDL命令"></a>DDL命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">命令解释</span><br><span class="line">create创建表</span><br><span class="line">list列出所有表</span><br><span class="line">disable &#x2F; is_disabled禁用表&#x2F;验证表是否被禁用</span><br><span class="line">enable &#x2F; is_enabled启用表&#x2F;验证表是否已启用</span><br><span class="line">desc查看表的详细信息</span><br><span class="line">alter修改表结构</span><br><span class="line">exists验证表是否存在</span><br><span class="line">drop &#x2F; truncate删除表&#x2F;清空表(删除重建)</span><br></pre></td></tr></table></figure><h5 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令：create ‘表名’,‘列族1’,‘列族2’,&#39;列族N’</span><br><span class="line"></span><br><span class="line">注意：单引号不能少，只能使用单引号，不能使用双引号。</span><br><span class="line"></span><br><span class="line">例子：create &#39;student&#39;,&#39;info&#39;,&#39;level&#39;</span><br><span class="line">解释：创建了一张名为student的表，表中有两个列族，分别是info和level。create后面的第一个参数是表名，后面的都是列族的名称</span><br><span class="line"></span><br><span class="line">注意：创建表时不能指定列，只能指定列族。</span><br></pre></td></tr></table></figure><h5 id="列出所有表"><a href="#列出所有表" class="headerlink" title="列出所有表"></a>列出所有表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):005:0&gt; list</span><br><span class="line">TABLE                                                                 </span><br><span class="line">student                                                               </span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0300 seconds                                                   </span><br><span class="line">&#x3D;&gt; [&quot;student&quot;]</span><br></pre></td></tr></table></figure><h5 id="禁用表-验证表是否被禁用"><a href="#禁用表-验证表是否被禁用" class="headerlink" title="禁用表/验证表是否被禁用"></a>禁用表/验证表是否被禁用</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):006:0&gt; disable &#39;student&#39;</span><br><span class="line">Took 1.1489 seconds </span><br><span class="line"></span><br><span class="line">验证表是否被禁用</span><br><span class="line">命令：is_disabled &#39;表名’</span><br><span class="line">解释：返回true表示此表被禁用，此时这个表不能被操作，因为表中的数据是存在Region中的，当Region中的数据达到一定量级的时候会进行分裂，产生多个Region，多个Region会分到其它节点上面。这个时候，数据是不能被操作的，所以会有disabled这个状态。</span><br><span class="line"></span><br><span class="line">hbase(main):008:0&gt; is_disabled &#39;student&#39;</span><br><span class="line">true                                                                  </span><br><span class="line">Took 0.0145 seconds                                                   </span><br><span class="line">&#x3D;&gt; 1</span><br></pre></td></tr></table></figure><h5 id="启用表-验证表是否已启用"><a href="#启用表-验证表是否已启用" class="headerlink" title="启用表/验证表是否已启用"></a>启用表/验证表是否已启用</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">启用表</span><br><span class="line">命令：enable &#39;表名’</span><br><span class="line">解释：当表被手工禁用之后，想要恢复使用，需要启动表</span><br><span class="line"></span><br><span class="line">hbase(main):009:0&gt; enable &#39;student&#39;</span><br><span class="line">Took 0.8177 seconds </span><br><span class="line"></span><br><span class="line">验证表是否已启用</span><br><span class="line">命令：is_enabled &#39;表名’</span><br><span class="line">解释：返回true表示表已启用，默认情况下，创建的新表都是启动状态。</span><br><span class="line"></span><br><span class="line">hbase(main):010:0&gt; is_enabled &#39;student&#39;</span><br><span class="line">true                                                                  </span><br><span class="line">Took 0.0212 seconds                                                   </span><br><span class="line">&#x3D;&gt; true</span><br></pre></td></tr></table></figure><h5 id="查看表的详细信息"><a href="#查看表的详细信息" class="headerlink" title="查看表的详细信息"></a>查看表的详细信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">命令：desc ‘表名’ 或者 desc ‘表名’</span><br><span class="line"></span><br><span class="line">hbase(main):013:0&gt; desc &#39;student&#39;</span><br><span class="line">Table student is ENABLED                                              </span><br><span class="line">student                                                               </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;info&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NE</span><br><span class="line">W_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DA</span><br><span class="line">TA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER</span><br><span class="line">&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;</span><br><span class="line">, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_</span><br><span class="line">ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;</span><br><span class="line">&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                 </span><br><span class="line"></span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;level&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, N</span><br><span class="line">EW_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_D</span><br><span class="line">ATA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVE</span><br><span class="line">R&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW</span><br><span class="line">&#39;, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS</span><br><span class="line">_ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION </span><br><span class="line">&#x3D;&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                </span><br><span class="line"></span><br><span class="line">2 row(s)</span><br><span class="line"></span><br><span class="line">QUOTAS                                                                </span><br><span class="line">0 row(s)</span><br><span class="line">Took 0.0815 seconds</span><br></pre></td></tr></table></figure><h5 id="修改表结构"><a href="#修改表结构" class="headerlink" title="修改表结构"></a>修改表结构</h5><h6 id="修改列族"><a href="#修改列族" class="headerlink" title="修改列族"></a>修改列族</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">使用alter命令可以完成更改列族参数信息、增加列族、删除列族以及更改表等操作，在这里主要演示一下增加列族、修改列族和删除列族</span><br><span class="line">1：修改列族</span><br><span class="line">修改列族的参数信息，例如：修改列族的版本</span><br><span class="line">通过desc命令可以看到student表中列族的版本个数：</span><br><span class="line">NAME &#x3D;&gt; &#39;info&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;</span><br><span class="line">NAME &#x3D;&gt; &#39;level&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;</span><br><span class="line">这里显示的这两个列族版本个数都是1，说明这两个列族中的所有列的值只能保存最新的1份数据，如果想要保存level列族中所有列的最近3个数据历史版本，可以这样操作:</span><br><span class="line"></span><br><span class="line">hbase(main):014:0&gt; alter &#39;student&#39;,&#123;NAME&#x3D;&gt;&#39;level&#39;,VERSIONS&#x3D;&gt;&#39;3&#39;&#125;</span><br><span class="line">Updating all regions with the new schema...</span><br><span class="line">1&#x2F;1 regions updated.</span><br><span class="line">Done.</span><br><span class="line">Took 2.5768 seconds </span><br><span class="line"></span><br><span class="line">此时查看一下student表中列族的信息，发现level这个列族的VERSIONS参数的值变成了3</span><br><span class="line"></span><br><span class="line">hbase(main):015:0&gt; desc &#39;student&#39;</span><br><span class="line">Table student is ENABLED                                              </span><br><span class="line">student                                                               </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;info&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NE</span><br><span class="line">W_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DA</span><br><span class="line">TA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER</span><br><span class="line">&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;</span><br><span class="line">, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_</span><br><span class="line">ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;</span><br><span class="line">&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                 </span><br><span class="line"></span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;level&#39;, VERSIONS &#x3D;&gt; &#39;3&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, N</span><br><span class="line">EW_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_D</span><br><span class="line">ATA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVE</span><br><span class="line">R&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW</span><br><span class="line">&#39;, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS</span><br><span class="line">_ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION </span><br><span class="line">&#x3D;&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                </span><br><span class="line"></span><br><span class="line">2 row(s)</span><br><span class="line"></span><br><span class="line">QUOTAS                                                                </span><br><span class="line">0 row(s)</span><br><span class="line">Took 0.0590 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line">-修改已存在数据的列族的属性时，HBase需要对列族里所有的数据进行修改，如果数据量很大，则修改可能要消耗很长时间。</span><br><span class="line">-这里的版本个数是和列族绑定的，不是和某一个列绑定的。</span><br></pre></td></tr></table></figure><h6 id="增加列族"><a href="#增加列族" class="headerlink" title="增加列族"></a>增加列族</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">2：增加列族</span><br><span class="line">在已存在的表的基础之上增加列族，在这我们向student表中增加一个列族：about</span><br><span class="line">hbase(main):016:0&gt; alter &#39;student&#39;,&#39;about&#39;</span><br><span class="line">Updating all regions with the new schema...</span><br><span class="line">1&#x2F;1 regions updated.</span><br><span class="line">Done.</span><br><span class="line">Took 2.3725 seconds </span><br><span class="line"></span><br><span class="line">此时查看student表中的列族信息，发现有3个列族了</span><br><span class="line">hbase(main):018:0&gt; desc &#39;student&#39;</span><br><span class="line">Table student is ENABLED                                              </span><br><span class="line">student                                                               </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;about&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, N</span><br><span class="line">EW_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_D</span><br><span class="line">ATA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVE</span><br><span class="line">R&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW</span><br><span class="line">&#39;, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS</span><br><span class="line">_ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION </span><br><span class="line">&#x3D;&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                </span><br><span class="line"></span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;info&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NE</span><br><span class="line">W_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DA</span><br><span class="line">TA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER</span><br><span class="line">&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;</span><br><span class="line">, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_</span><br><span class="line">ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;</span><br><span class="line">&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                 </span><br><span class="line"></span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;level&#39;, VERSIONS &#x3D;&gt; &#39;3&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, N</span><br><span class="line">EW_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_D</span><br><span class="line">ATA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVE</span><br><span class="line">R&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW</span><br><span class="line">&#39;, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS</span><br><span class="line">_ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION </span><br><span class="line">&#x3D;&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                </span><br><span class="line"></span><br><span class="line">3 row(s)</span><br><span class="line"></span><br><span class="line">QUOTAS                                                                </span><br><span class="line">0 row(s)</span><br><span class="line">Took 0.0712 seconds</span><br></pre></td></tr></table></figure><h6 id="删除列族"><a href="#删除列族" class="headerlink" title="删除列族"></a>删除列族</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">3：删除列族</span><br><span class="line">删除表中已有的列族，在这我们删除student中的about这个列族</span><br><span class="line">hbase(main):020:0&gt; alter &#39;student&#39;,&#123;NAME&#x3D;&gt;&#39;about&#39;,METHOD&#x3D;&gt;&#39;delete&#39;&#125;</span><br><span class="line">Updating all regions with the new schema...</span><br><span class="line">1&#x2F;1 regions updated.</span><br><span class="line">Done.</span><br><span class="line">Took 2.3361 seconds </span><br><span class="line"></span><br><span class="line">此时再查看student中的列族信息，会发现就只有2个了</span><br><span class="line">hbase(main):021:0&gt; desc &#39;student&#39;</span><br><span class="line">Table student is ENABLED                                              </span><br><span class="line">student                                                               </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                           </span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;info&#39;, VERSIONS &#x3D;&gt; &#39;1&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, NE</span><br><span class="line">W_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_DA</span><br><span class="line">TA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVER</span><br><span class="line">&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW&#39;</span><br><span class="line">, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS_</span><br><span class="line">ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION &#x3D;</span><br><span class="line">&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                 </span><br><span class="line"></span><br><span class="line">&#123;NAME &#x3D;&gt; &#39;level&#39;, VERSIONS &#x3D;&gt; &#39;3&#39;, EVICT_BLOCKS_ON_CLOSE &#x3D;&gt; &#39;false&#39;, N</span><br><span class="line">EW_VERSION_BEHAVIOR &#x3D;&gt; &#39;false&#39;, KEEP_DELETED_CELLS &#x3D;&gt; &#39;FALSE&#39;, CACHE_D</span><br><span class="line">ATA_ON_WRITE &#x3D;&gt; &#39;false&#39;, DATA_BLOCK_ENCODING &#x3D;&gt; &#39;NONE&#39;, TTL &#x3D;&gt; &#39;FOREVE</span><br><span class="line">R&#39;, MIN_VERSIONS &#x3D;&gt; &#39;0&#39;, REPLICATION_SCOPE &#x3D;&gt; &#39;0&#39;, BLOOMFILTER &#x3D;&gt; &#39;ROW</span><br><span class="line">&#39;, CACHE_INDEX_ON_WRITE &#x3D;&gt; &#39;false&#39;, IN_MEMORY &#x3D;&gt; &#39;false&#39;, CACHE_BLOOMS</span><br><span class="line">_ON_WRITE &#x3D;&gt; &#39;false&#39;, PREFETCH_BLOCKS_ON_OPEN &#x3D;&gt; &#39;false&#39;, COMPRESSION </span><br><span class="line">&#x3D;&gt; &#39;NONE&#39;, BLOCKCACHE &#x3D;&gt; &#39;true&#39;, BLOCKSIZE &#x3D;&gt; &#39;65536&#39;&#125;                </span><br><span class="line"></span><br><span class="line">2 row(s)</span><br><span class="line"></span><br><span class="line">QUOTAS                                                                </span><br><span class="line">0 row(s)</span><br><span class="line">Took 0.1049 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：HBase 中的表至少要包含一个列族，因此当表中只有一个列族时，无法将其删除。</span><br></pre></td></tr></table></figure><h6 id="验证表是否存在"><a href="#验证表是否存在" class="headerlink" title="验证表是否存在"></a>验证表是否存在</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">命令：exists &#39;表名’</span><br><span class="line">解释：表存在返回true，否则返回false</span><br><span class="line"></span><br><span class="line">hbase(main):030:0&gt; exists &#39;student&#39;</span><br><span class="line">Table student does exist                                              </span><br><span class="line">Took 0.0066 seconds                                                   </span><br><span class="line">&#x3D;&gt; true</span><br><span class="line">hbase(main):031:0&gt; exists &#39;aaaa&#39;</span><br><span class="line">Table aaaa does not exist                                             </span><br><span class="line">Took 0.0112 seconds                                                   </span><br><span class="line">&#x3D;&gt; false</span><br></pre></td></tr></table></figure><h6 id="删除表-清空表-删除重建"><a href="#删除表-清空表-删除重建" class="headerlink" title="删除表/清空表(删除重建)"></a>删除表/清空表(删除重建)</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">先创建一个表t1，包含1个列族info</span><br><span class="line">hbase(main):032:0&gt; create &#39;t1&#39;,&#39;info&#39;</span><br><span class="line">Created table t1</span><br><span class="line">Took 1.2597 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t1</span><br><span class="line"></span><br><span class="line">1：删除表</span><br><span class="line">命令：drop ‘表名’</span><br><span class="line">hbase(main):033:0&gt; drop &#39;t1&#39;</span><br><span class="line"></span><br><span class="line">ERROR: Table t1 is enabled. Disable it first.</span><br><span class="line"></span><br><span class="line">For usage try &#39;help &quot;drop&quot;&#39;</span><br><span class="line"></span><br><span class="line">Took 0.0142 seconds </span><br><span class="line"></span><br><span class="line">注意：这里提示删除表失败了，提示的是想要删除表，需要先禁用表。</span><br><span class="line">所以在这先禁用此表</span><br><span class="line">hbase(main):034:0&gt; disable &#39;t1&#39;</span><br><span class="line">Took 0.7576 seconds                       </span><br><span class="line"></span><br><span class="line">重新删除表，此时删除成功了。</span><br><span class="line">hbase(main):035:0&gt; drop &#39;t1&#39;</span><br></pre></td></tr></table></figure><h6 id="清空表"><a href="#清空表" class="headerlink" title="清空表"></a>清空表</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">清空表其实包含了两步，删除+重建</span><br><span class="line">命令：truncate ‘表名’</span><br><span class="line"></span><br><span class="line">先创建表t2，包含1个列族info</span><br><span class="line">hbase(main):037:0&gt; create &#39;t2&#39;,&#39;info&#39;</span><br><span class="line">Created table t2</span><br><span class="line">Took 1.2576 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - t2</span><br><span class="line"></span><br><span class="line">清空此表</span><br><span class="line">hbase(main):038:0&gt; truncate &#39;t2&#39;</span><br><span class="line">Truncating &#39;t2&#39; table (it may take a while):</span><br><span class="line">Disabling table...</span><br><span class="line">Truncating table...</span><br><span class="line">Took 3.0259 seconds   </span><br><span class="line"></span><br><span class="line">注意：在清空表的时候，会自动先禁用表。</span><br></pre></td></tr></table></figure><h4 id="增删改查命令-DML"><a href="#增删改查命令-DML" class="headerlink" title="增删改查命令(DML)"></a>增删改查命令(DML)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">命令解释</span><br><span class="line">put添加数据&#x2F;修改数据</span><br><span class="line">get查看数据</span><br><span class="line">count查看表中数据总条数</span><br><span class="line">scan扫描表中的数据</span><br><span class="line">delete &#x2F; deleteall删除数据</span><br></pre></td></tr></table></figure><h5 id="添加数据-修改数据"><a href="#添加数据-修改数据" class="headerlink" title="添加数据/修改数据"></a>添加数据/修改数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HBase中没有insert方法，它也属于key-value类型的NoSQL数据库，类似于HashMap这种数据结构，所以它提供了put方法添加数据</span><br><span class="line">命令：put ‘表名’,‘Rowkey’,‘列族:列’,&#39;value’</span><br><span class="line">添加2条数据，rowkey分别为：jack和tom</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; put &#39;student&#39;,&#39;jack&#39;,&#39;info:sex&#39;,&#39;man&#39;</span><br><span class="line">Took 0.8415 seconds                                                   </span><br><span class="line">hbase(main):002:0&gt; put &#39;student&#39;,&#39;jack&#39;,&#39;info:age&#39;,&#39;22&#39;</span><br><span class="line">Took 0.0295 seconds                                                   </span><br><span class="line">hbase(main):003:0&gt; put &#39;student&#39;,&#39;jack&#39;,&#39;level:class&#39;,&#39;A&#39;</span><br><span class="line">Took 0.0300 seconds                                                   </span><br><span class="line">hbase(main):004:0&gt; put &#39;student&#39;,&#39;tom&#39;,&#39;info:sex&#39;,&#39;woman&#39;</span><br><span class="line">Took 0.0286 seconds                                                   </span><br><span class="line">hbase(main):005:0&gt; put &#39;student&#39;,&#39;tom&#39;,&#39;info:age&#39;,&#39;20&#39;</span><br><span class="line">Took 0.0275 seconds                                                   </span><br><span class="line">hbase(main):006:0&gt; put &#39;student&#39;,&#39;tom&#39;,&#39;level:class&#39;,&#39;B&#39;</span><br><span class="line">Took 0.0228 seconds </span><br><span class="line"></span><br><span class="line">HBase中没有修改方法，所以重复执行put就是修改操作了。</span><br><span class="line">所以put操作在执行的时候，如果指定的数据已经存在，则更新，否则就新增。</span><br></pre></td></tr></table></figure><h5 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">在查看数据的时候有这么几种用法</span><br><span class="line">命令：get ‘表名’,&#39;Rowkey’</span><br><span class="line">命令：get ‘表名’,‘Rowkey’,&#39;列族’</span><br><span class="line">命令：get ‘表名’,‘Rowkey’,‘列族:列’</span><br><span class="line"></span><br><span class="line">查询student中rowkey等于jack的所有列族中的数据</span><br><span class="line"></span><br><span class="line">hbase(main):007:0&gt; get &#39;student&#39;,&#39;jack&#39;</span><br><span class="line">COLUMN             CELL                                               </span><br><span class="line"> info:age          timestamp&#x3D;1776767046323, value&#x3D;22                  </span><br><span class="line"> info:sex          timestamp&#x3D;1776767042049, value&#x3D;man                 </span><br><span class="line"> level:class       timestamp&#x3D;1776767049721, value&#x3D;A                   </span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0800 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">查询student中rowkey等于jack的info列族中的age列的数据</span><br><span class="line"></span><br><span class="line">hbase(main):009:0&gt; get &#39;student&#39;,&#39;jack&#39;,&#39;info:age&#39;</span><br><span class="line">COLUMN             CELL                                               </span><br><span class="line"> info:age          timestamp&#x3D;1776767046323, value&#x3D;22                  </span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0332 seconds</span><br></pre></td></tr></table></figure><h5 id="查看表中数据总条数"><a href="#查看表中数据总条数" class="headerlink" title="查看表中数据总条数"></a>查看表中数据总条数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命令：count ‘表名’</span><br><span class="line"></span><br><span class="line">统计指定表中的数据总数</span><br><span class="line"></span><br><span class="line">hbase(main):010:0&gt; count &#39;student&#39;</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.1515 seconds                                                   </span><br><span class="line">&#x3D;&gt; 2</span><br></pre></td></tr></table></figure><h5 id="扫描表中的数据"><a href="#扫描表中的数据" class="headerlink" title="扫描表中的数据"></a>扫描表中的数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">命令：scan &#39;表名’</span><br><span class="line">扫描表中的所有数据</span><br><span class="line"></span><br><span class="line">hbase(main):011:0&gt; scan &#39;student&#39;</span><br><span class="line">ROW                COLUMN+CELL                                        </span><br><span class="line"> jack              column&#x3D;info:age, timestamp&#x3D;1776767046323, value&#x3D;22 </span><br><span class="line"> jack              column&#x3D;info:sex, timestamp&#x3D;1776767042049, value&#x3D;man</span><br><span class="line"> jack              column&#x3D;level:class, timestamp&#x3D;1776767049721, value&#x3D;</span><br><span class="line">                   A                                                  </span><br><span class="line"> tom               column&#x3D;info:age, timestamp&#x3D;1776767056816, value&#x3D;20 </span><br><span class="line"> tom               column&#x3D;info:sex, timestamp&#x3D;1776767053359, value&#x3D;wom</span><br><span class="line">                   an                                                 </span><br><span class="line"> tom               column&#x3D;level:class, timestamp&#x3D;1776767060140, value&#x3D;</span><br><span class="line">                   B                                                  </span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0791 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan后面可以添加过滤条件，扫描满足条件的数据，后面再分析</span><br></pre></td></tr></table></figure><h5 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delete有这么几种用法：</span><br><span class="line">命令：delete ‘表名’,‘Rowkey’,&#39;列族:列’</span><br><span class="line">命令：delete ‘表名’,‘Rowkey’,‘列族:列’,时间戳</span><br><span class="line"></span><br><span class="line">注意：delete 操作并不会马上删除数据，只会将对应的数据打上删除标记，只有在HBase底层合并数据时，数据才会被真正删除。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">删除指定Rowkey中指定列族中指定列的数据</span><br><span class="line">hbase(main):017:0&gt; delete &#39;student&#39;,&#39;jack&#39;,&#39;info:age&#39;</span><br><span class="line">Took 0.0161 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">删除指定Rowkey中指定列族中指定列中时间戳小于2的数据</span><br><span class="line">hbase(main):018:0&gt; delete &#39;student&#39;,&#39;jack&#39;,&#39;info:age&#39;,2</span><br><span class="line">Took 0.0180 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：delete 命令不能跨列族操作，如果需要删除表中的某一行数据，则需要使用 deleteall 命令，此时不需要指定列族和列的名称</span><br><span class="line"></span><br><span class="line">hbase(main):019:0&gt; deleteall &#39;student&#39;,&#39;jack&#39;</span><br><span class="line">Took 0.0182 seconds</span><br></pre></td></tr></table></figure><h3 id="HBase的namespace-命名空间"><a href="#HBase的namespace-命名空间" class="headerlink" title="HBase的namespace(命名空间)"></a>HBase的namespace(命名空间)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HBase的命名空间相当于MySQL中的Database</span><br><span class="line">HBase默认有2个命名空间：分别是hbase和default</span><br><span class="line">其中hbase存放系统表，default是存放用户表</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">使用list_namespace命令可以查看所有的命名空间，我们创建的表默认在default这个命名空间里面</span><br><span class="line"></span><br><span class="line">hbase(main):023:0&gt; list_namespace</span><br><span class="line">NAMESPACE                                                             </span><br><span class="line">default                                                               </span><br><span class="line">hbase                                                                 </span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.4732 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">可以选择创建一个新的namespace</span><br><span class="line"></span><br><span class="line">hbase(main):029:0&gt; create_namespace &#39;n1&#39;</span><br><span class="line">Took 0.3233 seconds                                                   </span><br><span class="line">hbase(main):030:0&gt; list_namespace</span><br><span class="line">NAMESPACE                                                             </span><br><span class="line">default                                                               </span><br><span class="line">hbase                                                                 </span><br><span class="line">n1                                                                    </span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.0163 seconds</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在创建表的时候可以选择创建到n1这个namespace中，如何实现呢？</span><br><span class="line">使用这种格式即可：&#39;命名空间名称:表名&#39;</span><br><span class="line">针对default这个命名空间，在使用的时候可以省略不写</span><br><span class="line"></span><br><span class="line">hbase(main):031:0&gt; create &#39;n1:t1&#39;,&#39;info&#39;,&#39;level&#39;</span><br><span class="line">Created table n1:t1</span><br><span class="line">Took 2.3100 seconds                                                   </span><br><span class="line">&#x3D;&gt; Hbase::Table - n1:t1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">此时使用list查看所有的表</span><br><span class="line"></span><br><span class="line">hbase(main):032:0&gt; list</span><br><span class="line">TABLE                                                                 </span><br><span class="line">student                                                               </span><br><span class="line">t2                                                                    </span><br><span class="line">n1:t1                                                                 </span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.0083 seconds                                                   </span><br><span class="line">&#x3D;&gt; [&quot;student&quot;, &quot;t2&quot;, &quot;n1:t1&quot;]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">如果只想查看n1这个命名空间中的表，如何实现呢？</span><br><span class="line">可以使用命令list_namespace_tables</span><br><span class="line"></span><br><span class="line">hbase(main):033:0&gt; list_namespace_tables &#39;n1&#39;</span><br><span class="line">TABLE                                                                 </span><br><span class="line">t1                                                                    </span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0099 seconds                                                   </span><br><span class="line">&#x3D;&gt; [&quot;t1&quot;]</span><br></pre></td></tr></table></figure><h3 id="HBase-JavaAPI的使用"><a href="#HBase-JavaAPI的使用" class="headerlink" title="HBase JavaAPI的使用"></a>HBase JavaAPI的使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">创建maven项目：db_hbase</span><br><span class="line">由于需要操作HBase，所以需要在pom.xml中添加hbase-client依赖</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hbase&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hbase-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.2.7&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">以及日志相关配置</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.7.10&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">在resources目录中添加log4j.properties文件，文件内容如下：</span><br><span class="line">log4j.rootLogger&#x3D;info,stdout</span><br><span class="line"></span><br><span class="line">log4j.appender.stdout &#x3D; org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.stdout.Target &#x3D; System.out</span><br><span class="line">log4j.appender.stdout.layout&#x3D;org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern&#x3D;%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%t] [%c] [%p] - %m%n</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在src&#x2F;main&#x2F;java目录中创建package：com.imooc.hbase</span><br><span class="line">创建类：HBaseOp</span><br></pre></td></tr></table></figure><h4 id="对表中的数据进行增删改查-DML"><a href="#对表中的数据进行增删改查-DML" class="headerlink" title="对表中的数据进行增删改查(DML)"></a>对表中的数据进行增删改查(DML)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">首先需要获取HBase数据库连接</span><br><span class="line">代码如下：</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;获取配置</span><br><span class="line">Configuration conf &#x3D; HBaseConfiguration.create();</span><br><span class="line">&#x2F;&#x2F;指定HBase使用的zk的地址，多个用逗号隔开</span><br><span class="line">conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;bigdata01:2181,bigdata02:2181,bigdata03:2181&quot;);</span><br><span class="line">&#x2F;&#x2F;指定HBase在hdfs上的根目录</span><br><span class="line">conf.set(&quot;hbase.rootdir&quot;,&quot;hdfs:&#x2F;&#x2F;bigdata01:9000&#x2F;hbase&quot;);</span><br><span class="line">&#x2F;&#x2F;创建HBase连接，负责对HBase中数据的一些增删改查(DML操作)</span><br><span class="line">Connection conn &#x3D; ConnectionFactory.createConnection(conf);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：想要在哪台机器上执行代码操作HBase，一定要在这台机器上配置HBase集群所有节点的主机名和IP的映射关系</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">因为我们在连接HBase集群的时候在代码中指定的是zookeeper集群的地址信息，通过Zookeeper去查找HBase，HBase会在zookeeper里面存储自己的地址信息，存储的是主机名。</span><br><span class="line">所以一定要在执行HBase代码的机器上配置HBase集群所有节点的主机名和IP的映射关系。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">注意：代码在windows中执行的时候会提示缺少winutils.exe</span><br><span class="line"></span><br><span class="line">[WARN] - Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.</span><br><span class="line"></span><br><span class="line">这个警告信息不影响代码执行，在windows中执行会有这个提示，属于正常，把代码打包提交到集群上执行的时候就不会提示这个了，所以不用处理即可。</span><br></pre></td></tr></table></figure><h5 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;获取Table对象，指定要操作的表名，表需要提前创建好</span><br><span class="line">Table table &#x3D; conn.getTable(TableName.valueOf(&quot;student&quot;));</span><br><span class="line">&#x2F;&#x2F;指定Rowkey，返回put对象</span><br><span class="line">Put put &#x3D; new Put(Bytes.toBytes(&quot;laowang&quot;));</span><br><span class="line">&#x2F;&#x2F;向put对象中指定列族、列、值</span><br><span class="line">&#x2F;&#x2F;put &#39;student&#39;,&#39;laowang&#39;,&#39;info:age&#39;,&#39;18&#39;</span><br><span class="line">put.addColumn(Bytes.toBytes(&quot;info&quot;),Bytes.toBytes(&quot;age&quot;),Bytes.toBytes(&quot;18&quot;));</span><br><span class="line">&#x2F;&#x2F;put &#39;student&#39;,&#39;laowang&#39;,&#39;info:sex&#39;,&#39;man&#39;</span><br><span class="line">put.addColumn(Bytes.toBytes(&quot;info&quot;),Bytes.toBytes(&quot;sex&quot;),Bytes.toBytes(&quot;man&quot;));</span><br><span class="line">&#x2F;&#x2F;put &#39;student&#39;,&#39;laowang&#39;,&#39;level:class&#39;,&#39;A&#39;</span><br><span class="line">put.addColumn(Bytes.toBytes(&quot;level&quot;),Bytes.toBytes(&quot;class&quot;),Bytes.toBytes(&quot;A&quot;));</span><br><span class="line">&#x2F;&#x2F;向表中添加数据</span><br><span class="line">table.put(put);</span><br><span class="line">&#x2F;&#x2F;关闭table连接</span><br><span class="line">table.close();</span><br></pre></td></tr></table></figure><h5 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;获取Table对象，指定要操作的表名，表需要提前创建好</span><br><span class="line">Table table &#x3D; conn.getTable(TableName.valueOf(&quot;student&quot;));</span><br><span class="line">&#x2F;&#x2F;指定Rowkey，返回Get对象</span><br><span class="line">Get get &#x3D; new Get(Bytes.toBytes(&quot;laowang&quot;));</span><br><span class="line">&#x2F;&#x2F;【可选】可以在这里指定要查询指定Rowkey数据哪些列族中的列</span><br><span class="line">&#x2F;&#x2F; 如果不指定，默认查询指定Rowkey所有列的内容</span><br><span class="line">&#x2F;&#x2F;get.addColumn(Bytes.toBytes(&quot;info&quot;),Bytes.toBytes(&quot;age&quot;));</span><br><span class="line">&#x2F;&#x2F;get.addColumn(Bytes.toBytes(&quot;info&quot;),Bytes.toBytes(&quot;sex&quot;));</span><br><span class="line"></span><br><span class="line">Result result &#x3D; table.get(get);</span><br><span class="line">&#x2F;&#x2F;如果不清楚HBase中到底有哪些列族和列，可以使用listCells()获取所有cell(单元格)，cell对应的是某一个列的数据</span><br><span class="line">List&lt;Cell&gt; cells &#x3D; result.listCells();</span><br><span class="line">for (Cell cell: cells) &#123;</span><br><span class="line">    &#x2F;&#x2F;注意：下面获取的信息都是字节类型的，可以通过new String(bytes)转为字符串</span><br><span class="line">    &#x2F;&#x2F;列族</span><br><span class="line">    byte[] famaily_bytes &#x3D; CellUtil.cloneFamily(cell);</span><br><span class="line">    &#x2F;&#x2F;列</span><br><span class="line">    byte[] column_bytes &#x3D; CellUtil.cloneQualifier(cell);</span><br><span class="line">    &#x2F;&#x2F;值</span><br><span class="line">    byte[] value_bytes &#x3D; CellUtil.cloneValue(cell);</span><br><span class="line">    System.out.println(&quot;列族：&quot;+new String(famaily_bytes)+&quot;,列：&quot;+new String(column_bytes)+&quot;,值：&quot;+new String(value_bytes));</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;);</span><br><span class="line">&#x2F;&#x2F;如果明确知道HBase中有哪些列族和列，可以使用getValue(family, qualifier)直接获取指定列族中指定列的数据</span><br><span class="line">byte[] age_bytes &#x3D; result.getValue(Bytes.toBytes(&quot;info&quot;),Bytes.toBytes(&quot;age&quot;));</span><br><span class="line">System.out.println(&quot;age列的值：&quot;+new String(age_bytes));</span><br><span class="line">&#x2F;&#x2F;关闭table连接</span><br><span class="line">table.close();</span><br></pre></td></tr></table></figure><h5 id="查询多版本数据"><a href="#查询多版本数据" class="headerlink" title="查询多版本数据"></a>查询多版本数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;获取Table对象，指定要操作的表名，表需要提前创建好</span><br><span class="line">Table table &#x3D; conn.getTable(TableName.valueOf(&quot;student&quot;));</span><br><span class="line">&#x2F;&#x2F;指定Rowkey，返回Get对象</span><br><span class="line">Get get &#x3D; new Get(Bytes.toBytes(&quot;laowang&quot;));</span><br><span class="line">&#x2F;&#x2F;读取cell中的所有历史版本数据，不设置此配置的时候默认只读取最新版本的数据</span><br><span class="line">&#x2F;&#x2F;可以通过get.readVersions(2)来指定获取多少个历史版本的数据</span><br><span class="line">get.readAllVersions();</span><br><span class="line"></span><br><span class="line">Result result &#x3D; table.get(get);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;获取指定列族中指定列的所有历史版本数据，前提是要设置get.readAllVersions()或者get.readVersions(2)，否则只会获取最新数据</span><br><span class="line">List&lt;Cell&gt; columnCells &#x3D; result.getColumnCells(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;age&quot;));</span><br><span class="line">for (Cell cell :columnCells) &#123;</span><br><span class="line">    byte[] value_bytes &#x3D; CellUtil.cloneValue(cell);</span><br><span class="line">    long timestamp &#x3D; cell.getTimestamp();</span><br><span class="line">    System.out.println(&quot;值为：&quot;+new String(value_bytes)+&quot;,时间戳：&quot;+timestamp);</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;关闭table连接</span><br><span class="line">table.close();</span><br></pre></td></tr></table></figure><h5 id="删除数据-1"><a href="#删除数据-1" class="headerlink" title="删除数据"></a>删除数据</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;获取Table对象，指定要操作的表名，表需要提前创建好</span><br><span class="line">Table table &#x3D; conn.getTable(TableName.valueOf(&quot;student&quot;));</span><br><span class="line">&#x2F;&#x2F;指定Rowkey，返回Delete对象</span><br><span class="line">Delete delete &#x3D; new Delete(Bytes.toBytes(&quot;laowang&quot;));</span><br><span class="line">&#x2F;&#x2F;【可选】可以在这里指定要删除指定Rowkey数据哪些列族中的列</span><br><span class="line">&#x2F;&#x2F;delete.addColumn(Bytes.toBytes(&quot;info&quot;),Bytes.toBytes(&quot;age&quot;));</span><br><span class="line"></span><br><span class="line">table.delete(delete);</span><br><span class="line">&#x2F;&#x2F;关闭table连接</span><br><span class="line">table.close();</span><br></pre></td></tr></table></figure><h4 id="创建和删除表-DDL"><a href="#创建和删除表-DDL" class="headerlink" title="创建和删除表(DDL)"></a>创建和删除表(DDL)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">想要操作表，也就是执行DDL操作，需要获取管理员权限，通过HBase获取</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;获取管理权限，负责对HBase中的表进行操作(DDL操作)</span><br><span class="line">Admin admin &#x3D; conn.getAdmin();</span><br></pre></td></tr></table></figure><h5 id="创建表-1"><a href="#创建表-1" class="headerlink" title="创建表"></a>创建表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;指定列族信息</span><br><span class="line">ColumnFamilyDescriptor familyDesc1 &#x3D; ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(&quot;info&quot;))</span><br><span class="line">        &#x2F;&#x2F;在这里可以给列族设置一些属性</span><br><span class="line">        .setMaxVersions(3)&#x2F;&#x2F;指定最多存储多少个历史版本数据</span><br><span class="line">        .build();</span><br><span class="line">ColumnFamilyDescriptor familyDesc2 &#x3D; ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(&quot;level&quot;))</span><br><span class="line">        &#x2F;&#x2F;在这里可以给列族设置一些属性</span><br><span class="line">        .setMaxVersions(2)&#x2F;&#x2F;指定最多存储多少个历史版本数据</span><br><span class="line">        .build();</span><br><span class="line">ArrayList&lt;ColumnFamilyDescriptor&gt; familyList &#x3D; new ArrayList&lt;ColumnFamilyDescriptor&gt;();</span><br><span class="line">familyList.add(familyDesc1);</span><br><span class="line">familyList.add(familyDesc2);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;获取TableDescriptor对象</span><br><span class="line">TableDescriptor desc &#x3D; TableDescriptorBuilder.newBuilder(TableName.valueOf(&quot;test&quot;))&#x2F;&#x2F;指定表名</span><br><span class="line">        .setColumnFamilies(familyList)&#x2F;&#x2F;指定列族</span><br><span class="line">        .build();</span><br><span class="line">&#x2F;&#x2F;创建表</span><br><span class="line">admin.createTable(desc);</span><br></pre></td></tr></table></figure><h5 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;删除表，先禁用表</span><br><span class="line">admin.disableTable(TableName.valueOf(&quot;test&quot;));</span><br><span class="line">admin.deleteTable(TableName.valueOf(&quot;test&quot;));</span><br></pre></td></tr></table></figure><h4 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最后对代码进行抽取，便于查看，完整代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.hbase;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 操作HBase</span></span><br><span class="line"><span class="comment"> * 表：创建、删除</span></span><br><span class="line"><span class="comment"> * 数据：增、删、改、查</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseOp</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//获取HBase数据库连接</span></span><br><span class="line">        Connection conn = getConn();</span><br><span class="line">        <span class="comment">//添加数据</span></span><br><span class="line">        <span class="comment">//put(conn);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//查询数据</span></span><br><span class="line">        <span class="comment">//get(conn);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 查询多版本的数据</span></span><br><span class="line"><span class="comment">         * 当列的值有多个历史版本的时候</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 修改列族info的最大历史版本存储数量</span></span><br><span class="line"><span class="comment">         * alter 'student',&#123;NAME=&gt;'info',VERSIONS=&gt;3&#125;</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 然后再执行下面命令，向列族info中的age列中添加几次数据，实现多历史版本数据存储</span></span><br><span class="line"><span class="comment">         * put 'student','laowang','info:age','19'</span></span><br><span class="line"><span class="comment">         * put 'student','laowang','info:age','20'</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//getMoreVersion(conn);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//修改数据--同添加数据</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//删除数据</span></span><br><span class="line">        <span class="comment">//delete(conn);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//==============================分割线======================</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取管理权限，负责对HBase中的表进行操作（DDL操作）</span></span><br><span class="line">        Admin admin = conn.getAdmin();</span><br><span class="line">        <span class="comment">//创建表</span></span><br><span class="line">        <span class="comment">//createTable(admin);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//删除表</span></span><br><span class="line">        <span class="comment">//deleteTable(admin);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭admin连接</span></span><br><span class="line">        admin.close();</span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        conn.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> admin</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteTable</span><span class="params">(Admin admin)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//删除表，先禁用表</span></span><br><span class="line">        admin.disableTable(TableName.valueOf(<span class="string">"test"</span>));</span><br><span class="line">        admin.deleteTable(TableName.valueOf(<span class="string">"test"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> admin</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(Admin admin)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//指定列族信息</span></span><br><span class="line">        ColumnFamilyDescriptor familyDesc1 = ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(<span class="string">"info"</span>))</span><br><span class="line">                <span class="comment">//在这里可以给列族设置一些属性</span></span><br><span class="line">                .setMaxVersions(<span class="number">3</span>)<span class="comment">//指定最多存储多少个历史版本数据</span></span><br><span class="line">                .build();</span><br><span class="line">        ColumnFamilyDescriptor familyDesc2 = ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(<span class="string">"level"</span>))</span><br><span class="line">                <span class="comment">//在这里可以给列族设置一些属性</span></span><br><span class="line">                .setMaxVersions(<span class="number">2</span>)<span class="comment">//指定最多存储多少个历史版本数据</span></span><br><span class="line">                .build();</span><br><span class="line">        ArrayList&lt;ColumnFamilyDescriptor&gt; familyList = <span class="keyword">new</span> ArrayList&lt;ColumnFamilyDescriptor&gt;();</span><br><span class="line">        familyList.add(familyDesc1);</span><br><span class="line">        familyList.add(familyDesc2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取TableDescriptor对象</span></span><br><span class="line">        TableDescriptor desc = TableDescriptorBuilder.newBuilder(TableName.valueOf(<span class="string">"test"</span>))<span class="comment">//指定表名</span></span><br><span class="line">                .setColumnFamilies(familyList)<span class="comment">//指定列族</span></span><br><span class="line">                .build();</span><br><span class="line">        <span class="comment">//创建表</span></span><br><span class="line">        admin.createTable(desc);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//获取Table，指定要操作的表名，表需要提前创建好</span></span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(<span class="string">"student"</span>));</span><br><span class="line">        <span class="comment">//指定Rowkey，返回Delete对象</span></span><br><span class="line">        Delete delete = <span class="keyword">new</span> Delete(Bytes.toBytes(<span class="string">"laowang"</span>));</span><br><span class="line">        <span class="comment">//【可选】可以在这里指定要删除指定Rowkey数据哪些列族中的列</span></span><br><span class="line">        <span class="comment">//delete.addColumn(Bytes.toBytes("info"),Bytes.toBytes("age"));</span></span><br><span class="line"></span><br><span class="line">        table.delete(delete);</span><br><span class="line">        <span class="comment">//关闭table连接</span></span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询多版本的数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getMoreVersion</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//获取Table，指定要操作的表名，表需要提前创建好</span></span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(<span class="string">"student"</span>));</span><br><span class="line">        <span class="comment">//指定Rowkey，返回Get对象</span></span><br><span class="line">        Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string">"laowang"</span>));</span><br><span class="line">        <span class="comment">//读取cell中的所有历史版本数据，不设置此配置的时候默认只读取最新版本的数据</span></span><br><span class="line">        <span class="comment">//可以通过get.readVersions(2)来指定获取多少个历史版本的数据</span></span><br><span class="line">        get.readAllVersions();</span><br><span class="line"></span><br><span class="line">        Result result = table.get(get);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取指定列族中指定列的所有历史版本数据，前提是要设置get.readAllVersions()或者get.readVersions(2)，否则只会获取最新数据</span></span><br><span class="line">        List&lt;Cell&gt; columnCells = result.getColumnCells(Bytes.toBytes(<span class="string">"info"</span>), Bytes.toBytes(<span class="string">"age"</span>));</span><br><span class="line">        <span class="keyword">for</span> (Cell cell: columnCells) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] value_bytes = CellUtil.cloneValue(cell);</span><br><span class="line">            <span class="keyword">long</span> timestamp = cell.getTimestamp();</span><br><span class="line">            System.out.println(<span class="string">"值为："</span>+<span class="keyword">new</span> String(value_bytes)+<span class="string">",时间戳："</span>+timestamp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//关闭table连接</span></span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//获取Table，指定要操作的表名，表需要提前创建好</span></span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(<span class="string">"student"</span>));</span><br><span class="line">        <span class="comment">//指定Rowkey，返回Get对象</span></span><br><span class="line">        Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string">"laowang"</span>));</span><br><span class="line">        <span class="comment">//【可选】可以在这里指定要查询指定Rowkey数据哪些列族中的列</span></span><br><span class="line">        <span class="comment">//如果不指定，默认查询指定Rowkey所有列的内容</span></span><br><span class="line">        get.addColumn(Bytes.toBytes(<span class="string">"info"</span>), Bytes.toBytes(<span class="string">"age"</span>));</span><br><span class="line">        get.addColumn(Bytes.toBytes(<span class="string">"info"</span>), Bytes.toBytes(<span class="string">"sex"</span>));</span><br><span class="line"></span><br><span class="line">        Result result = table.get(get);</span><br><span class="line">        <span class="comment">//如果不清楚HBase中到底有哪些列族和列，可以使用listCells()获取所有cell（单元格），cell对应的是某一列的数据</span></span><br><span class="line">        List&lt;Cell&gt; cells = result.listCells();</span><br><span class="line">        <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line">            <span class="comment">//注意：下面获取的信息都是字节类型的，可以通过new String(bytes)转为字符串</span></span><br><span class="line">            <span class="comment">//列族</span></span><br><span class="line">            <span class="keyword">byte</span>[] famaily_bytes = CellUtil.cloneFamily(cell);</span><br><span class="line">            <span class="comment">//列</span></span><br><span class="line">            <span class="keyword">byte</span>[] column_bytes = CellUtil.cloneQualifier(cell);</span><br><span class="line">            <span class="comment">//值</span></span><br><span class="line">            <span class="keyword">byte</span>[] value_bytes = CellUtil.cloneValue(cell);</span><br><span class="line">            System.out.println(<span class="string">"列族："</span>+<span class="keyword">new</span> String(famaily_bytes)+<span class="string">",列："</span>+<span class="keyword">new</span> String(column_bytes)+<span class="string">",值："</span>+<span class="keyword">new</span> String(value_bytes));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"=============================================="</span>);</span><br><span class="line">        <span class="comment">//如果明确知道HBase中有哪些列族和列，可以使用getValue(family,qualifier)直接获取指定列族中指定列的数据</span></span><br><span class="line">        <span class="keyword">byte</span>[] age_bytes = result.getValue(Bytes.toBytes(<span class="string">"info"</span>), Bytes.toBytes(<span class="string">"age"</span>));</span><br><span class="line">        System.out.println(<span class="string">"age列的值："</span>+<span class="keyword">new</span> String(age_bytes));</span><br><span class="line">        <span class="comment">//关闭table连接</span></span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> conn</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//获取Table，指定要操作的表名，表需要提前创建好</span></span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(<span class="string">"student"</span>));</span><br><span class="line">        <span class="comment">//指定Rowkey，返回put对象</span></span><br><span class="line">        Put put = <span class="keyword">new</span> Put(Bytes.toBytes(<span class="string">"laowang"</span>));</span><br><span class="line">        <span class="comment">//向put对象中指定列族、列、值</span></span><br><span class="line">        <span class="comment">//put 'student','laowang','info:age','18'</span></span><br><span class="line">        put.addColumn(Bytes.toBytes(<span class="string">"info"</span>), Bytes.toBytes(<span class="string">"age"</span>), Bytes.toBytes(<span class="string">"18"</span>));</span><br><span class="line">        <span class="comment">//put 'student','laowang','info:sex','man'</span></span><br><span class="line">        put.addColumn(Bytes.toBytes(<span class="string">"info"</span>), Bytes.toBytes(<span class="string">"sex"</span>), Bytes.toBytes(<span class="string">"man"</span>));</span><br><span class="line">        <span class="comment">//put 'student','laowang','level:class','A'</span></span><br><span class="line">        put.addColumn(Bytes.toBytes(<span class="string">"level"</span>), Bytes.toBytes(<span class="string">"class"</span>), Bytes.toBytes(<span class="string">"A"</span>));</span><br><span class="line">        <span class="comment">//向表中添加数据</span></span><br><span class="line">        table.put(put);</span><br><span class="line">        <span class="comment">//关闭table连接</span></span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取连接</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Connection <span class="title">getConn</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//获取配置</span></span><br><span class="line">        Configuration conf = HBaseConfiguration.create();</span><br><span class="line">        <span class="comment">//指定HBase使用的zk的地址，多个用逗号隔开</span></span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"bigdata01:2181,bigdata02:2181,bigdata03:2181"</span>);</span><br><span class="line">        <span class="comment">//指定HBase在hdfs上的根目录</span></span><br><span class="line">        conf.set(<span class="string">"hbase.rootdir"</span>, <span class="string">"hdfs://bigdata01:9000/hbase"</span>);</span><br><span class="line">        <span class="comment">//创建HBase连接，负责对HBase中的数据的一些增删改查（DML操作）</span></span><br><span class="line">        <span class="keyword">return</span> ConnectionFactory.createConnection(conf);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="HBase" scheme="http://tianyong.fun/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-ES+HBase实现仿百度搜索引擎-2</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-ES+HBase%E5%AE%9E%E7%8E%B0%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-2.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-ES+HBase%E5%AE%9E%E7%8E%B0%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-2.html</id>
    <published>2023-06-02T10:03:09.000Z</published>
    <updated>2023-06-18T15:50:02.799Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="ES-HBase实现仿百度搜索引擎-2"><a href="#ES-HBase实现仿百度搜索引擎-2" class="headerlink" title="ES+HBase实现仿百度搜索引擎-2"></a>ES+HBase实现仿百度搜索引擎-2</h1><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Elasticsearch" scheme="http://tianyong.fun/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第十七周-</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AD%E5%91%A8-Flink1.15%E4%B9%8BFlink%20SQL%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%201.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AD%E5%91%A8-Flink1.15%E4%B9%8BFlink%20SQL%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%201.html</id>
    <published>2023-06-02T10:03:09.000Z</published>
    <updated>2023-06-02T10:03:09.649Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第十七周-</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AD%E5%91%A8-Flink1.15%E4%B9%8BFlink%20SQL%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%202.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AD%E5%91%A8-Flink1.15%E4%B9%8BFlink%20SQL%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%202.html</id>
    <published>2023-06-02T10:03:09.000Z</published>
    <updated>2023-06-02T10:03:09.649Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-全文检索引擎Elasticsearch-1</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8EElasticsearch-1.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8EElasticsearch-1.html</id>
    <published>2023-06-02T10:03:09.000Z</published>
    <updated>2023-06-19T08:22:05.020Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="全文检索引擎Elasticsearch-1"><a href="#全文检索引擎Elasticsearch-1" class="headerlink" title="全文检索引擎Elasticsearch-1"></a>全文检索引擎Elasticsearch-1</h1><h2 id="1-快速了解Elasticsearch"><a href="#1-快速了解Elasticsearch" class="headerlink" title="1 快速了解Elasticsearch"></a>1 快速了解Elasticsearch</h2><h3 id="为什么要学Elasticsearch？"><a href="#为什么要学Elasticsearch？" class="headerlink" title="为什么要学Elasticsearch？"></a>为什么要学Elasticsearch？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">针对海量数据计算分析，前面我们学习了MapReduce、Hive、Spark、Flink这些计算引擎和分析工具，但是它们侧重的都是对数据的清洗、聚合之类的需求。</span><br><span class="line">如果想要在海量数据里面快速查询出一批满足条件的数据，这些计算引擎都需要生成一个任务，提交到集群中去执行，这样中间消耗的时间就长了。</span><br><span class="line"></span><br><span class="line">并且针对多条件组合查询需求，这些计算引擎在查询的时候基本上都要实现全表扫描了，这样查询效率也是比较低的。</span><br><span class="line"></span><br><span class="line">所以，为了解决海量数据下的快速检索，以及多条件组合查询需求，Elasticsearch就应运而生了。</span><br></pre></td></tr></table></figure><h3 id="Elasticsearch简介"><a href="#Elasticsearch简介" class="headerlink" title="Elasticsearch简介"></a>Elasticsearch简介</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Elasticsearch是一个分布式的全文检索引擎，它是对lucene的功能做了封装，能够达到实时搜索，稳定，可靠，快速等特点。</span><br><span class="line">如果大家对Lucene有所了解的话，那么针对Elasticsearch其实就好理解了。</span><br></pre></td></tr></table></figure><h3 id="常见的全文检索引擎"><a href="#常见的全文检索引擎" class="headerlink" title="常见的全文检索引擎"></a>常见的全文检索引擎</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Lucene</span><br><span class="line">Lucene是Java家族中最为出名的一个开源搜索引擎，在Java世界中属于标准的全文检索程序，它提供了完整的查询引擎和索引引擎。</span><br><span class="line">但是它也存在一些缺点</span><br><span class="line">1：不支持分布式，无法扩展，海量数据下会存在瓶颈。</span><br><span class="line">2：提供的都是低级API，使用繁琐。</span><br><span class="line">3：没有提供web界面，不便于管理。</span><br><span class="line"></span><br><span class="line">Solr</span><br><span class="line">Solr是一个用java开发的独立的企业级搜索应用服务器，它是基于Lucene的。</span><br><span class="line">它解决了Lucene的一些痛点，提供了web界面，以及高级API接口。</span><br><span class="line">并且从Solr4.0版本开始，Solr开始支持分布式，称之为Solrcloud。</span><br><span class="line"></span><br><span class="line">Elasticsearch</span><br><span class="line">Elasticsearch是一个采用Java语言开发的，基于Lucene的开源、分布式的搜索引擎,能够实现实时搜索。</span><br><span class="line">它最重要的一个特点是天生支持分布式，可以这样说，Elasticsearch就是为了分布式而生的。</span><br><span class="line">它对外提供REST API接口，便于使用，通过外部插件实现web界面支持，便于管理集群。</span><br></pre></td></tr></table></figure><h3 id="Solr-vs-Elasticsearch"><a href="#Solr-vs-Elasticsearch" class="headerlink" title="Solr vs Elasticsearch"></a>Solr vs Elasticsearch</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Elasticsearch一般我们会简称为ES。</span><br><span class="line"></span><br><span class="line">从这里可以看出来，Solr和ES的功能基本是类似的，那在工作中该如何选择呢？</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111104774.png" alt="image-20230611110351736"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Solr从2007年就出现了，在传统企业中应用的还是比较广泛的，并且在2013年的时候，Solr推出了4.0版本，提供了Solrcloud，开始正式支持分布式集群。</span><br><span class="line">ES在2014年的时候才正式推出1.0版本，所以它的出现要比Solr晚很多年。</span><br><span class="line">但是ES从一开始就是为了解决海量数据下的全文检索，所以在分布式集群相关特性层面，ES会优于Solrcloud。</span><br><span class="line">建议：</span><br><span class="line"></span><br><span class="line">如果之前公司里面已经深度使用了Solr，现在为了解决海量数据检索问题，建议优先考虑使用Solrcloud。</span><br><span class="line">如果之前没有使用过Solr，那么在海量数据的场景下，建议优先考虑使用ES。</span><br></pre></td></tr></table></figure><h3 id="MySQL-VS-Elasticsearch"><a href="#MySQL-VS-Elasticsearch" class="headerlink" title="MySQL VS Elasticsearch"></a>MySQL VS Elasticsearch</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">为了便于理解ES，在这里我们拿MySQL和ES做一个对比分析：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111106927.png" alt="image-20230611110616238"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line">1： MySQL中有Database（数据库）的概念，对应的在ES中有Index（索引库）的概念。</span><br><span class="line">2：MySQL中有Table（表）的概念，对应的在ES中有Type（类型）的概念，不过需要注意，ES在1.x~5.x版本中是正常支持Type的，每一个Index下面可以有多个Type。</span><br><span class="line"></span><br><span class="line">从6.0版本开始，每一个Index中只支持1个Type，属于过渡阶段。</span><br><span class="line">从7.0版本开始，取消了Type，也就意味着每一个Index中存储的数据类型可以认为都是同一种，不再区分类型了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">为何要取消Type？</span><br><span class="line"></span><br><span class="line">主要还是基于性能方面的考虑。</span><br><span class="line">因为ES设计初期，是直接参考了关系型数据库的设计模型，存在了Type（表）的概念。</span><br><span class="line">但是，ES的搜索引擎是基于Lucene的，这种基因决定了Type是多余的。</span><br><span class="line">在关系型数据库中Table是独立的，但是在ES中同一个Index中不同Type的数据在底层是存储在同一个Lucene的索引文件中的。</span><br><span class="line">如果在同一个Index中的不同Type中都有一个id字段，那么ES会认为这两个id字段是同一个字段，你必须在不同的Type中给这个id字段定义相同的字段类型，否则，不同Type中的相同字段名称就会在处理的时候出现冲突，导致Lucene处理效率下降。</span><br><span class="line">除此之外，在同一个Index的不同Type下，存储字段个数不一样的数据，会导致存储中出现稀疏数据，影响Lucene压缩文档的能力，最终导致ES查询效率降低。</span><br><span class="line"></span><br><span class="line">3：MySQL中有Row（行）的概念，表示一条数据，在ES中对应的有Document（文档）。</span><br><span class="line">4：MySQL中有Column（列）的概念，表示一条数据中的某个列，在ES中对应的有Field（字段）。</span><br></pre></td></tr></table></figure><h3 id="Elasticsearch核心概念"><a href="#Elasticsearch核心概念" class="headerlink" title="Elasticsearch核心概念"></a>Elasticsearch核心概念</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111111465.png" alt="image-20230611111149099"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ES中几个比较核心的概念：</span><br><span class="line">Cluster：集群</span><br><span class="line">Shard：分片</span><br><span class="line">Replica：副本</span><br><span class="line">Recovery：数据恢复</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">接下来具体分析一下这几个概念：</span><br><span class="line"></span><br><span class="line">Cluster</span><br><span class="line">代表ES集群，集群中有多个节点，其中有一个为主节点，这个主节点是通过选举产生的。</span><br><span class="line"></span><br><span class="line">主从节点是对于集群内部来说的，ES的一个核心特性就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看ES集群，在逻辑上是一个整体，我们与任何一个节点的通信和与整个ES集群通信是等价的。</span><br><span class="line"></span><br><span class="line">主节点的职责是负责管理集群状态，包括管理分片的状态和副本的状态，以及节点的发现和删除。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Shard</span><br><span class="line">代表索引库分片，ES集群可以把一个索引库分成多个分片。</span><br><span class="line"></span><br><span class="line">这样的好处是可以把一个大的索引库水平拆分成多个分片，分布到不同的节点上，构成分布式搜索，进而提高性能和吞吐量。</span><br><span class="line"></span><br><span class="line">注意：分片的数量只能在创建索引库的时候指定，索引库创建后不能更改。</span><br><span class="line"></span><br><span class="line">默认情况下一个索引库有1个分片。</span><br><span class="line"></span><br><span class="line">每个分片中最多存储2,147,483,519条数据，其实就是Integer.MAX_VALUE-128。</span><br><span class="line">因为每一个ES的分片底层对应的都是Lucene索引文件，单个Lucene索引文件最多存储Integer.MAX_VALUE-128个文档（数据）。</span><br><span class="line"></span><br><span class="line">注意：在ES7.0版本之前，每一个索引库默认是有5个分片的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Replica</span><br><span class="line">代表分片的副本，ES集群可以给分片设置副本。</span><br><span class="line"></span><br><span class="line">副本的第一个作用是提高系统的容错性，当某个分片损坏或丢失时可以从副本中恢复。第二个作用是提高ES的查询效率，ES会自动对搜索请求进行负载均衡。</span><br><span class="line"></span><br><span class="line">注意：分片的副本数量可以随时修改。</span><br><span class="line">默认情况下，每一个索引库只有1个主分片和1个副本分片（前提是ES集群有2个及以上节点，如果ES集群只有1个节点，那么索引库就只有1个主分片，不会产生副本分片，因为主分片和副本分片在一个节点里面是没有意义的）。</span><br><span class="line">为了保证数据安全，以及提高查询效率，建议副本数量设置为2或者3。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Recovery</span><br><span class="line">代表数据恢复或者数据重新分布。</span><br><span class="line"></span><br><span class="line">ES集群在有节点加入或退出时会根据机器的负载对分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。</span><br></pre></td></tr></table></figure><h2 id="2-快速上手使用Elasticsearch"><a href="#2-快速上手使用Elasticsearch" class="headerlink" title="2 快速上手使用Elasticsearch"></a>2 快速上手使用Elasticsearch</h2><h3 id="ES安装部署"><a href="#ES安装部署" class="headerlink" title="ES安装部署"></a>ES安装部署</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ES支持单机和集群，在使用层面是完全一样的。</span><br><span class="line">首先下载ES的安装包，目前ES最新版本是7.x，在这使用7.13.4版本。</span><br><span class="line"></span><br><span class="line">下载地址：</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;cn&#x2F;downloads&#x2F;past-releases#elasticsearch</span><br><span class="line">选择ES的对应版本。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111120893.png" alt="image-20230611112053604"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111121533.png" alt="image-20230611112108886"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：目前ES中自带的有open JDK，不用单独安装部署Oracle JDK。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111123514.png" alt="image-20230611112339787"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在具体安装集群之前，先来分析一下ES中的核心配置文件：</span><br><span class="line">在ES_HOME的config目录下有一个elasticsearch.yml配置文件，这个文件是一个yaml格式的文件。</span><br><span class="line">elasticsearch.yml文件内容如下：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; Elasticsearch Configuration &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">#</span><br><span class="line"># NOTE: Elasticsearch comes with reasonable defaults for most settings.</span><br><span class="line">#       Before you set out to tweak and tune the configuration, make sure you</span><br><span class="line">#       understand what are you trying to accomplish and the consequences.</span><br><span class="line">#</span><br><span class="line"># The primary way of configuring a node is via this file. This template lists</span><br><span class="line"># the most important settings you may want to configure for a production cluster.</span><br><span class="line">#</span><br><span class="line"># Please consult the documentation for further information on configuration options:</span><br><span class="line"># https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;index.html</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- Cluster -----------------------------------</span><br><span class="line">#</span><br><span class="line"># Use a descriptive name for your cluster:</span><br><span class="line"># 集群名称，默认是elasticsearch，如果想要将多个ES实例组成一个集群，那么它们的cluster.name必须一致</span><br><span class="line">#cluster.name: my-application</span><br><span class="line">#</span><br><span class="line"># ------------------------------------ Node ------------------------------------</span><br><span class="line">#</span><br><span class="line"># Use a descriptive name for the node:</span><br><span class="line"># 节点名称，可以手工指定，默认也会自动生成</span><br><span class="line">#node.name: node-1</span><br><span class="line">#</span><br><span class="line"># Add custom attributes to the node:</span><br><span class="line"># 给节点指定一些自定义的参数信息</span><br><span class="line">#node.attr.rack: r1</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- Paths ------------------------------------</span><br><span class="line">#</span><br><span class="line"># Path to directory where to store the data (separate multiple locations by comma):</span><br><span class="line"># 可以指定ES的数据存储目录，默认存储在ES_HOME&#x2F;data目录下</span><br><span class="line">#path.data: &#x2F;path&#x2F;to&#x2F;data</span><br><span class="line">#</span><br><span class="line"># Path to log files:</span><br><span class="line"># 可以指定ES的日志存储目录，默认存储在ES_HOME&#x2F;logs目录下</span><br><span class="line">#path.logs: &#x2F;path&#x2F;to&#x2F;logs</span><br><span class="line">#</span><br><span class="line"># ----------------------------------- Memory -----------------------------------</span><br><span class="line">#</span><br><span class="line"># Lock the memory on startup:</span><br><span class="line"># 锁定物理内存地址，防止ES内存被交换出去,也就是避免ES使用swap交换分区中的内存</span><br><span class="line">#bootstrap.memory_lock: true</span><br><span class="line"># 确保ES_HEAP_SIZE参数设置为系统可用内存的一半左右</span><br><span class="line"># Make sure that the heap size is set to about half the memory available</span><br><span class="line"># on the system and that the owner of the process is allowed to use this</span><br><span class="line"># limit.</span><br><span class="line"># 当系统进行内存交换的时候，会导致ES的性能变的很差</span><br><span class="line"># Elasticsearch performs poorly when the system is swapping the memory.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- Network -----------------------------------</span><br><span class="line">#</span><br><span class="line"># By default Elasticsearch is only accessible on localhost. Set a different</span><br><span class="line"># address here to expose this node on the network:</span><br><span class="line"># 为ES设置绑定的IP，默认是127.0.0.1，也就是默认只能通过127.0.0.1 或者localhost才能访问</span><br><span class="line"># ES 1.x版本默认绑定的是0.0.0.0，但是从ES 2.x版本之后默认绑定的是127.0.0.1</span><br><span class="line">#network.host: 192.168.0.1</span><br><span class="line">#</span><br><span class="line"># By default Elasticsearch listens for HTTP traffic on the first free port it</span><br><span class="line"># finds starting at 9200. Set a specific HTTP port here:</span><br><span class="line"># 为ES服务设置监听的端口，默认是9200</span><br><span class="line"># 如果想要在一台机器上启动多个ES实例，需要修改此处的端口号</span><br><span class="line">#http.port: 9200</span><br><span class="line">#</span><br><span class="line"># For more information, consult the network module documentation.</span><br><span class="line">#</span><br><span class="line"># --------------------------------- Discovery ----------------------------------</span><br><span class="line"># </span><br><span class="line"># Pass an initial list of hosts to perform discovery when this node is started:</span><br><span class="line"># The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</span><br><span class="line"># </span><br><span class="line"># 当启动新节点时，通过这个ip列表进行节点发现，组建集群</span><br><span class="line"># 默认ip列表：</span><br><span class="line"># 127.0.0.1，表示ipv4的本地回环地址。</span><br><span class="line">#[::1]，表示ipv6的本地回环地址。</span><br><span class="line"># 在ES 1.x中默认使用的是组播(multicast)协议，默认会自动发现同一网段的ES节点组建集群。</span><br><span class="line"># 从ES 2.x开始默认使用的是单播(unicast)协议，想要组建集群的话就需要在这指定要发现的节点信息了。</span><br><span class="line"># </span><br><span class="line"># 指定想要组装成一个ES集群的多个节点信息</span><br><span class="line">#discovery.seed_hosts: [&quot;host1&quot;, &quot;host2&quot;]</span><br><span class="line">#</span><br><span class="line"># Bootstrap the cluster using an initial set of master-eligible nodes:</span><br><span class="line"># 初始化一批具备成为主节点资格的节点【在选择主节点的时候会优先在这一批列表中进行选择】</span><br><span class="line">#cluster.initial_master_nodes: [&quot;node-1&quot;, &quot;node-2&quot;]</span><br><span class="line">#</span><br><span class="line"># For more information, consult the discovery and cluster formation module documentation.</span><br><span class="line">#</span><br><span class="line"># ---------------------------------- Various -----------------------------------</span><br><span class="line">#</span><br><span class="line"># Require explicit names when deleting indices:</span><br><span class="line"># 禁止使用通配符或_all删除索引, 必须使用名称或别名才能删除该索引。</span><br><span class="line">#action.destructive_requires_name: true</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这段配置的意思是，让Elasticsearch请求JVM锁定堆内存，防止内存被操作系统交换到磁盘上¹²。这样可以提高Elasticsearch 的性能和稳定性，因为垃圾回收时不会触及已经交换出去的内存页¹。如果启用了bootstrap.memory_lock设置，那么JVM会预留它需要的任何内存⁴。如果要使用这个设置，还需要在操作系统或Docker容器中配置相应的ulimit或sysctl参数²³。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">您可以在一台机器上搭建多个ElasticSearch节点来组成一个集群。首先，您需要在机器上安装JDK环境，然后从官网下载ElasticSearch并解压。接着，您需要修改配置文件&#96;elasticsearch.yml&#96;，设置集群名称、节点名称、网络主机、HTTP端口等信息。此外，您还需要修改Linux系统设置，放行主节点端口，并创建ES用户来启动ES的多个节点。最后，您可以使用&#96;curl&#96;命令来查看ES节点的状态 ¹。</span><br></pre></td></tr></table></figure><h4 id="ES单机"><a href="#ES单机" class="headerlink" title="ES单机"></a>ES单机</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1：将ES的安装包上传到bigdata01的&#x2F;data&#x2F;soft目录下</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2：在Linux中添加一个普通用户：es。</span><br><span class="line">因为ES目前不支持root用户启动。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# useradd -d &#x2F;home&#x2F;es -m es</span><br><span class="line">[root@bigdata01 soft]# passwd es</span><br><span class="line">Changing password for user es.</span><br><span class="line">New password: bigdata1234</span><br><span class="line">Retype new password: bigdata1234</span><br><span class="line">passwd: all authentication tokens updated successfully.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">3：修改Linux中最大文件描述符以及最大虚拟内存的参数</span><br><span class="line">因为ES对Linux的最大文件描述符以及最大虚拟内存有一定要求，所以需要修改，否则ES无法正常启动。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# vi &#x2F;etc&#x2F;security&#x2F;limits.conf </span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line">[root@bigdata01 soft]# vi &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">vm.max_map_count&#x3D;262144</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">4：重启Linux系统。</span><br><span class="line">前面修改的参数需要重启系统才会生效。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# reboot -h now</span><br><span class="line"></span><br><span class="line">5：解压ES安装包。</span><br><span class="line">[root@bigdata01 soft]# tar -zxvf elasticsearch-7.13.4-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">6：配置ES_JAVA_HOME环境变量，指向ES中内置的JDK。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# vi &#x2F;etc&#x2F;profile</span><br><span class="line">......</span><br><span class="line">export ES_JAVA_HOME&#x3D;&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;jdk</span><br><span class="line">......</span><br><span class="line">[root@bigdata01 soft]# source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">7：修改elasticsearch-7.13.4目录的权限</span><br><span class="line">因为前面是使用root用户解压的，elasticsearch-7.13.4目录下的文件es用户是没有权限的。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# chmod 777 -R &#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">8：切换到es用户</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# su es</span><br><span class="line"></span><br><span class="line">9：修改elasticsearch.yml配置文件内容</span><br><span class="line">主要修改network.host、discovery.seed_hosts这两个参数。</span><br><span class="line"></span><br><span class="line">注意：yaml文件的格式，参数和值之间需要有一个空格。</span><br><span class="line"></span><br><span class="line">例如：network.host: bigdata01</span><br><span class="line">bigdata01前面必须要有一个空格，否则会报错。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[es@bigdata01 soft]$ cd elasticsearch-7.13.4</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ vi config&#x2F;elasticsearch.yml </span><br><span class="line">......</span><br><span class="line">network.host: bigdata01</span><br><span class="line">discovery.seed_hosts: [&quot;bigdata01&quot;]</span><br><span class="line">......</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">10：启动ES服务【前台启动】</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ bin&#x2F;elasticsearch</span><br><span class="line"></span><br><span class="line">按ctrl+c停止服务。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">11：启动ES服务【后台启动】</span><br><span class="line">在实际工作中需要将ES放在后台运行。</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ bin&#x2F;elasticsearch -d</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">12：验证ES服务。</span><br><span class="line">通过jps命令验证进程是否存在。</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ jps</span><br><span class="line">1849 Elasticsearch</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">通过web界面验证服务是否可以正常访问，端口为9200。</span><br><span class="line">http:&#x2F;&#x2F;bigdata01:9200&#x2F;</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111139441.png" alt="image-20230611113938806"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：需要关闭防火墙。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">13：停止ES服务。</span><br><span class="line">使用kill命令停止。</span><br><span class="line"></span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ jps</span><br><span class="line">1849 Elasticsearch</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ kill</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">14：日志排查方式。</span><br><span class="line">如果发现ES服务启动有问题，需要查看ES的日志。</span><br><span class="line">ES的相关日志都在ES_HOME的logs目录下，ES服务的核心日志在elasticsearch.log日志文件中。</span><br></pre></td></tr></table></figure><h4 id="ES集群"><a href="#ES集群" class="headerlink" title="ES集群"></a>ES集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ES集群规划：</span><br><span class="line">bigdata01</span><br><span class="line">bigdata02</span><br><span class="line">bigdata03</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1：在bigdata01、bigdata02、bigdata03中创建普通用户：es。</span><br><span class="line">具体创建步骤参考ES单机中的操作。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# useradd -d &#x2F;home&#x2F;es -m es</span><br><span class="line">[root@bigdata01 soft]# passwd es</span><br><span class="line">Changing password for user es.</span><br><span class="line">New password: bigdata1234</span><br><span class="line">Retype new password: bigdata1234</span><br><span class="line">passwd: all authentication tokens updated successfully.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">useradd es和useradd -d &#x2F;home&#x2F;es -m es的区别是，前者会创建一个名为es的用户，但不会指定或创建它的家目录，后者会创建一个名为es的用户，并指定它的家目录为&#x2F;home&#x2F;es，并且使用-m选项来创建这个目录¹。如果你想修改一个已经存在的用户的家目录，你可以使用usermod -d命令¹。</span><br><span class="line"></span><br><span class="line">不一定。useradd es的默认家目录取决于&#x2F;etc&#x2F;default&#x2F;useradd文件中的HOME参数³。如果没有指定或修改这个参数，那么默认家目录就是&#x2F;home&#x2F;es⁴。但是，如果你没有使用-m或--create-home选项，那么useradd es不会创建这个家目录⁵。你需要手动创建或者使用usermod -m -d命令来移动已有的内容到新的家目录¹。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2：在bigdata01、bigdata02、bigdata03中修改Linux中最大文件描述符以及最大虚拟内存的参数。</span><br><span class="line">具体修改步骤参考ES单机中的操作。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# vi &#x2F;etc&#x2F;security&#x2F;limits.conf </span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line">[root@bigdata01 soft]# vi &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">vm.max_map_count&#x3D;262144</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">3：重启bigdata01、bigdata02、bigdata03，让前面修改的参数生效。</span><br><span class="line">具体操作步骤参考ES单机中的操作。</span><br><span class="line">4：在bigdata01、bigdata02、bigdata03中配置ES_JAVA_HOME环境变量，指向ES中内置的JDK。</span><br><span class="line">具体配置步骤参考ES单机中的操作。</span><br><span class="line">5：在bigdata01中重新解压ES的安装包以及修改目录权限</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# tar -zxvf elasticsearch-7.13.4-linux-x86_64.tar.gz</span><br><span class="line">[root@bigdata01 soft]# chmod 777 -R &#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">6：修改elasticsearch.yml配置文件</span><br><span class="line">主要修改network.host、discovery.seed_hosts和cluster.initial_master_nodes这三个参数。</span><br><span class="line"></span><br><span class="line">7：将bigdata01中修改好配置的elasticsearch-7.13.4目录远程拷贝到bigdata02和bigdata03。</span><br><span class="line">[root@bigdata01 soft]# scp -rq elasticsearch-7.13.4 bigdata02:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line">[root@bigdata01 soft]# scp -rq elasticsearch-7.13.4 bigdata03:&#x2F;data&#x2F;soft&#x2F;</span><br><span class="line"></span><br><span class="line">8：分别修改bigdata02和bigdata03中ES的elasticsearch.yml配置文件。</span><br><span class="line">修改bigdata02中的elasticsearch.yml配置文件，主要修改network.host参数的值为当前节点主机名。</span><br><span class="line">[root@bigdata02 elasticsearch-7.13.4]# vi config&#x2F;elasticsearch.yml </span><br><span class="line">......</span><br><span class="line">network.host: bigdata02</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">修改bigdata03中的elasticsearch.yml配置文件，主要修改network.host参数的值为当前节点主机名。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">9：在bigdata01、bigdata02、bigdata03中分别启动ES。</span><br><span class="line">在bigdata01上启动。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# su es</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ bin&#x2F;elasticsearch -d</span><br><span class="line"></span><br><span class="line">在bigdata02上启动。</span><br><span class="line">在bigdata03上启动。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">10：验证集群中的进程。</span><br><span class="line">分别在bigdata01、bigdata02、bigdata03中验证进程是否存在。</span><br><span class="line"></span><br><span class="line">11：验证这几个节点是否组成一个集群。</span><br><span class="line">通过ES的REST API可以很方便的查看集群中的节点信息。</span><br><span class="line">http:&#x2F;&#x2F;bigdata01:9200&#x2F;_nodes&#x2F;_all?pretty</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111207382.png" alt="image-20230611120738840"></p><h3 id="ES集群监控管理工具-cerebro"><a href="#ES集群监控管理工具-cerebro" class="headerlink" title="ES集群监控管理工具-cerebro"></a>ES集群监控管理工具-cerebro</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">为了便于我们管理监控ES集群，推荐使用cerebro这个工具。</span><br><span class="line">1：首先到github上下载cerebro的安装包。</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;lmenezes&#x2F;cerebro&#x2F;releases</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111208875.png" alt="image-20230611120816538"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2：将下载好的cerebro-0.9.4.zip安装包上传到bigdata01的&#x2F;data&#x2F;soft目录中并且解压。</span><br><span class="line"></span><br><span class="line">注意：cerebro部署在任意节点上都可以，只要能和ES集群通信即可。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# ll cerebro-0.9.4.zip </span><br><span class="line">-rw-r--r--. 1 root root 57251010 Sep 11  2021 cerebro-0.9.4.zip</span><br><span class="line">[root@bigdata01 soft]# unzip cerebro-0.9.4.zip</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">3：启动cerebro。</span><br><span class="line">将cerebro放在后台启动。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 cerebro-0.9.4]# nohup bin&#x2F;cerebro 2&gt;&amp;1 &gt;&#x2F;dev&#x2F;null &amp;</span><br><span class="line"></span><br><span class="line">这段命令是在Linux系统中运行的。它的意思是在后台运行&#96;cerebro&#96;程序，即使您退出终端，该程序也会继续运行。&#96;nohup&#96;命令用于在后台运行程序，&#96;2&gt;&amp;1 &gt;&#x2F;dev&#x2F;null&#96;表示将标准错误输出重定向到标准输出，并将标准输出重定向到&#96;&#x2F;dev&#x2F;null&#96;，即丢弃所有输出信息。最后的&#96;&amp;&#96;表示在后台运行该命令。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">注意：默认cerebro监听的端口是9000，如果出现端口冲突，需要修改cerebro监控的端口</span><br><span class="line"></span><br><span class="line">在启动cerebro的时候可以通过http.port参数指定端口号，如下命令：</span><br><span class="line">bin&#x2F;cerebro -Dhttp.port&#x3D;1234</span><br><span class="line"></span><br><span class="line">默认通过9000端口可以访问cerebro的web界面。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111210790.png" alt="image-20230611121030491"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4：使用cerebro。</span><br><span class="line">在Node address中输入ES集群任意一个节点的连接信息即可。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111211165.png" alt="image-20230611121101515"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">5：使用cerebro监控管理ES集群。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111211190.png" alt="image-20230611121121089"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">注意：集群有三种状态，green、yellow、red。</span><br><span class="line"></span><br><span class="line">green：表示集群处于健康状态，可以正常使用。</span><br><span class="line">yellow：表示集群处于风险状态，可以正常使用，可能是分片的副本个数不完整。例如：分片的副本数为2，但是现在分片的副本只有1份。</span><br><span class="line">red：表示集群处于故障状态，无法正常使用，可能是集群分片不完整。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">6：cerebro的所有功能。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111212741.png" alt="image-20230611121226272"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">6.1：查看节点信息</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111212780.png" alt="image-20230611121253312"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6.2：rest功能。</span><br><span class="line">便于在页面中操作REST API接口</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111213303.png" alt="image-20230611121329984"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6.3：更多功能。</span><br><span class="line">包括创建索引、集群参数、别名、分词功能、索引模板等。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111214032.png" alt="image-20230611121359073"></p><h3 id="ES的基本操作"><a href="#ES的基本操作" class="headerlink" title="ES的基本操作"></a>ES的基本操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">针对ES的操作，官方提供了很多种操作方式。</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;index.html</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111214584.png" alt="image-20230611121434249"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在实际工作中使用ES的时候，如果想屏蔽语言的差异，建议使用REST API，这种兼容性比较好，但是个人感觉有的操作使用起来比较麻烦，需要拼接组装各种数据字符串。</span><br><span class="line"></span><br><span class="line">针对Java程序员而言，还有一种选择是使用Java API，这种方式相对于REST API而言，代码量会大一些，但是代码层面看起来是比较清晰的。</span><br><span class="line"></span><br><span class="line">下面在操作ES的时候，分别使用一下这两种方式。</span><br></pre></td></tr></table></figure><h4 id="使用REST-API的方式操作ES"><a href="#使用REST-API的方式操作ES" class="headerlink" title="使用REST API的方式操作ES"></a>使用REST API的方式操作ES</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">如果想要在Linux命令行中使用REST API操作ES，需要借助于CURL工具。</span><br><span class="line">CURL是利用URL语法在命令行下工作的开源文件传输工具，使用CURL可以简单实现常见的get&#x2F;post请求。</span><br><span class="line"></span><br><span class="line">curl后面通过-X参数指定请求类型，通过-d指定要传递的参数。</span><br></pre></td></tr></table></figure><h5 id="索引库的操作（创建、删除）"><a href="#索引库的操作（创建、删除）" class="headerlink" title="索引库的操作（创建、删除）"></a>索引库的操作（创建、删除）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">HTTP协议中除了GET和POST请求之外，还有其他几种请求类型，包括：</span><br><span class="line"></span><br><span class="line">- **HEAD**：与GET类似，但只返回HTTP头部信息，不返回实体内容。</span><br><span class="line">- **PUT**：用于上传资源到服务器，通常用于更新资源。</span><br><span class="line">- **DELETE**：用于删除服务器上的资源。</span><br><span class="line">- **OPTIONS**：用于查询服务器支持的HTTP方法。</span><br><span class="line">- **TRACE**：用于追踪请求-响应的传输路径。</span><br><span class="line">- **CONNECT**：用于建立网络隧道，通常用于SSL加密。</span><br><span class="line">- **GET**：用于从服务器获取数据。它将请求参数附加在URL后面，通过查询字符串传递给服务器。GET请求应该只用于获取数据，不应该用于产生副作用。</span><br><span class="line">- **POST**：用于向服务器提交数据。它将请求参数放在HTTP请求体中，可以传输大量数据。POST请求通常用于提交表单或上传文件。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">创建索引库：</span><br><span class="line">curl -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;&#39;</span><br><span class="line">这里使用PUT或者POST都可以。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl  -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;&#39;</span><br><span class="line">&#123;&quot;acknowledged&quot;:true,&quot;shards_acknowledged&quot;:true,&quot;index&quot;:&quot;test&quot;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：索引库名称必须要全部小写，不能以_、 -、 +开头，也不能包含逗号。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 soft]# curl  -XDELETE &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;&#39;</span><br><span class="line">&#123;&quot;acknowledged&quot;:true&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：索引库可以提前创建，也可以在后期添加数据的时候直接指定一个不存在的索引库，ES默认会自动创建这个索引库。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">手工创建索引库和自动创建索引库的区别就是，手工创建可以自定义索引库的分片数量。</span><br><span class="line">下面创建一个具有3个分片的索引库。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;&#39; -d&#39;&#123;&quot;settings&quot;:&#123;&quot;index.number_of_shards&quot;:3&#125;&#125;&#39;</span><br><span class="line">&#123;&quot;acknowledged&quot;:true,&quot;shards_acknowledged&quot;:true,&quot;index&quot;:&quot;test&quot;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-H参数用于在curl命令中设置HTTP请求头。在这个例子中，-H &quot;Content-Type: application&#x2F;json&quot;表示设置HTTP请求头的Content-Type字段为application&#x2F;json，即告诉服务器请求体中的数据是JSON格式。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111223294.png" alt="image-20230611122310001"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">其中实线的框表示是主分片，虚线框是副本分片。</span><br><span class="line">索引分片编号是从0开始的，并且索引分片在物理层面是存在的，可以到集群中查看一下，从界面中也看到test索引库的1号和2号分片是在bigdata01节点上的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">到bigdata01节点中看一下，ES中的所有数据都在ES的数据存储目录中，默认是在ES_HOME下的data目录里面：</span><br><span class="line">[root@bigdata01 1IQ2r-vqRxSsicd8BzWPtg]# pwd</span><br><span class="line">&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;data&#x2F;nodes&#x2F;0&#x2F;indices&#x2F;1IQ2r-vqRxSsicd8BzWPtg</span><br><span class="line">[root@bigdata01 1IQ2r-vqRxSsicd8BzWPtg]# ll</span><br><span class="line">total 0</span><br><span class="line">drwxrwxr-x. 5 es es 49 Feb 26 18:01 1</span><br><span class="line">drwxrwxr-x. 5 es es 49 Feb 26 18:01 2</span><br><span class="line">drwxrwxr-x. 2 es es 24 Feb 26 18:01 _state</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这里面的1IQ2r-vqRxSsicd8BzWPtg表示的是索引库的UUID。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111225755.png" alt="image-20230611122533512"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111225521.png" alt="image-20230611122545144"></p><h5 id="索引的操作（增、删、改、查）"><a href="#索引的操作（增、删、改、查）" class="headerlink" title="索引的操作（增、删、改、查）"></a>索引的操作（增、删、改、查）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">添加索引</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1&#39; -d &#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:20&#125;&#39;</span><br><span class="line">&#123;&quot;_index&quot;:&quot;emp&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:0,&quot;_primary_term&quot;:1&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line"></span><br><span class="line">1.这里emp索引库是不存在的，在使用的时候ES会自动创建，只不过索引分片数量默认是1。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111230257.png" alt="image-20230611123003969"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2.为了兼容之前的API，虽然ES现在取消了Type，但是API中Type的位置还是预留出来了，官方建议统一使用_doc 。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：在添加索引的时候，如果没有指定数据的ID，那么ES会自动生成一个随机的唯一ID。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#39; -d &#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:30&#125;&#39; </span><br><span class="line">&#123;&quot;_index&quot;:&quot;emp&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;EFND8aMBpApLBooiIWda&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:1,&quot;_primary_term&quot;:1&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">查询索引：</span><br><span class="line">查看id&#x3D;1的索引数据。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;emp&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;_seq_no&quot; : 0,</span><br><span class="line">  &quot;_primary_term&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;name&quot; : &quot;tom&quot;,</span><br><span class="line">    &quot;age&quot; : 20</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">只获取部分字段内容。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1?_source&#x3D;name&amp;pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;emp&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;_seq_no&quot; : 0,</span><br><span class="line">  &quot;_primary_term&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;name&quot; : &quot;tom&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@bigdata01 soft]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1?_source&#x3D;name,age&amp;pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;emp&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;_seq_no&quot; : 0,</span><br><span class="line">  &quot;_primary_term&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;name&quot; : &quot;tom&quot;,</span><br><span class="line">    &quot;age&quot; : 20</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">查询指定索引库中所有数据。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 2,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 1,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 2,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 1.0,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;emp&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;name&quot; : &quot;tom&quot;,</span><br><span class="line">          &quot;age&quot; : 20</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;emp&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;EVPO8aMBpApLBooib2e7&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;name&quot; : &quot;jack&quot;,</span><br><span class="line">          &quot;age&quot; : 30</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：针对这种查询操作，可以在浏览器里面执行，或者在cerebo中查询都是可以的，看起来更加清晰。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">在这里扩展一个知识点，使用RestAPI执行query查询。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#x2F;_search?pretty&#39; -d&#39;&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;address&quot;:&quot;bj&quot;&#125;&#125;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 5,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 1,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 1,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 0.2876821,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;stuinfo&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 0.2876821,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;sex&quot; : &quot;man&quot;,</span><br><span class="line">          &quot;name&quot; : &quot;zs&quot;,</span><br><span class="line">          &quot;age&quot; : 20</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="更新索引"><a href="#更新索引" class="headerlink" title="更新索引"></a>更新索引</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">可以分为全部更新和局部更新</span><br><span class="line">全部更新：同添加索引，如果指定id的索引数据（文档）已经存在，则执行更新操作。</span><br><span class="line"></span><br><span class="line">注意：执行更新操作的时候，ES首先将旧的文标记为删除状态，然后添加新的文档</span><br><span class="line"></span><br><span class="line">旧的文档不会立即消失，但是你也无法访问，ES会在你继续添加更多数据的时候在后台清理已经标记为删除状态的文档。</span><br><span class="line"></span><br><span class="line">局部更新：可以添加新字段或者更新已有字段，必须使用POST请求。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 soft]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1&#x2F;_update&#39; -d &#39;&#123;&quot;doc&quot;:&#123;&quot;age&quot;:25&#125;&#125;&#39;</span><br><span class="line">&#123;&quot;_index&quot;:&quot;emp&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:2,&quot;result&quot;:&quot;updated&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:2,&quot;_primary_term&quot;:1&#125;</span><br></pre></td></tr></table></figure><h5 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">删除id&#x3D;1的索引数据。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -XDELETE &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1&#39;</span><br><span class="line">&#123;&quot;_index&quot;:&quot;emp&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:3,&quot;result&quot;:&quot;deleted&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:3,&quot;_primary_term&quot;:1&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 soft]# curl -XDELETE &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_doc&#x2F;1&#39;</span><br><span class="line">&#123;&quot;_index&quot;:&quot;emp&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:4,&quot;result&quot;:&quot;not_found&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:4,&quot;_primary_term&quot;:1&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如果索引数据（文档）存在，ES返回的数据中，result属性值为deleted，_version（版本）属性的值+1。</span><br><span class="line"></span><br><span class="line">如果索引数据不存在，ES返回的数据中，result属性值为not_found，但是_version属性的值依然会+1，这属于ES的版本控制系统，它保证了我们在多个节点间的不同操作的顺序都被正确标记了。</span><br><span class="line">对于索引数据的每次写操作，无论是index，update还是delete，ES都会将_version增加 1。该增加是原子的，并且保证在操作成功返回时会发生。</span><br><span class="line"></span><br><span class="line">注意：删除一条索引数据（文档）也不会立即生效，它只是被标记成已删除状态。ES将会在你之后添加更多索引数据的时候才会在后台清理标记为删除状态的内容。</span><br></pre></td></tr></table></figure><h5 id="Bulk批量操作"><a href="#Bulk批量操作" class="headerlink" title="Bulk批量操作"></a>Bulk批量操作</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Bulk API可以帮助我们同时执行多个请求，提高效率。</span><br><span class="line">格式：</span><br><span class="line">&#123; action: &#123; metadata &#125;&#125;</span><br><span class="line">&#123; request body &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">action：index&#x2F;create&#x2F;update&#x2F;delete</span><br><span class="line">metadata：_index,_type,_id</span><br><span class="line">request body：_source(删除操作不需要) </span><br><span class="line"></span><br><span class="line">create和index的区别：如果数据存在，使用create操作失败，会提示文档已经存在，使用index则可以成功执行(相当于更新操作)。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">下面来看一个案例，假设在MySQL中有一批数据，首先需要从MySQL中把数据读取出来，然后将数据转化为Bulk需要的数据格式。</span><br><span class="line"></span><br><span class="line">在这直接手工生成Bulk需要的数据格式。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 elasticsearch-7.13.4]# vi request </span><br><span class="line">&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;field1&quot; : &quot;value1&quot; &#125;</span><br><span class="line"></span><br><span class="line">&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;field1&quot; : &quot;value1&quot; &#125;</span><br><span class="line"></span><br><span class="line">&#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;</span><br><span class="line"></span><br><span class="line">&#123; &quot;create&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;field1&quot; : &quot;value1&quot; &#125;</span><br><span class="line"></span><br><span class="line">&#123; &quot;update&quot; : &#123;&quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;,&quot;_id&quot; : &quot;1&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;doc&quot; : &#123;&quot;field2&quot; : &quot;value2&quot;&#125; &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">执行Bulk API</span><br><span class="line"></span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# curl -H &quot;Content-Type: application&#x2F;json&quot;  -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_doc&#x2F;_bulk&#39; --data-binary @request</span><br><span class="line">&#123;&quot;took&quot;:167,&quot;errors&quot;:false,&quot;items&quot;:[&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;test&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:0,&quot;_primary_term&quot;:1,&quot;status&quot;:201&#125;&#125;,&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;test&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:0,&quot;_primary_term&quot;:1,&quot;status&quot;:201&#125;&#125;,&#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;test&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_version&quot;:2,&quot;result&quot;:&quot;deleted&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:1,&quot;_primary_term&quot;:1,&quot;status&quot;:200&#125;&#125;,&#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;test&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;3&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:2,&quot;_primary_term&quot;:1,&quot;status&quot;:201&#125;&#125;,&#123;&quot;update&quot;:&#123;&quot;_index&quot;:&quot;test&quot;,&quot;_type&quot;:&quot;_doc&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_version&quot;:2,&quot;result&quot;:&quot;updated&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:2,&quot;failed&quot;:0&#125;,&quot;_seq_no&quot;:1,&quot;_primary_term&quot;:1,&quot;status&quot;:200&#125;&#125;]&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 elasticsearch-7.13.4]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 6,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 3,</span><br><span class="line">    &quot;successful&quot; : 3,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 2,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 1.0,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;test&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;, </span><br><span class="line">        &quot;_id&quot; : &quot;3&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;field1&quot; : &quot;value1&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;test&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;field1&quot; : &quot;value1&quot;,</span><br><span class="line">          &quot;field2&quot; : &quot;value2&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Bulk一次最大可以处理多少数据量？</span><br><span class="line"></span><br><span class="line">Bulk会把将要处理的数据加载到内存中，所以数据量是有限制的，最佳的数据量不是一个确定的数值，它取决于集群硬件，文档大小、文档复杂性，索引以及ES集群的负载。</span><br><span class="line"></span><br><span class="line">一般建议是1000-5000个文档，如果文档很大，可以适当减少，文档总大小建议是5-15MB，默认不能超过100M。</span><br><span class="line">如果想要修改最大限制大小，可以在ES的配置文件中修改http.max_content_length: 100mb，但是不建议，因为太大的话Bulk操作也会慢。</span><br></pre></td></tr></table></figure><h4 id="使用Java-API的方式操作ES"><a href="#使用Java-API的方式操作ES" class="headerlink" title="使用Java API的方式操作ES"></a>使用Java API的方式操作ES</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">针对Java API，目前ES提供了两个Java REST Client版本:</span><br><span class="line"></span><br><span class="line">1.Java Low Level REST Client：</span><br><span class="line">低级别的REST客户端，通过HTTP与集群交互，用户需自己组装请求JSON串，以及解析响应JSON串。兼容所有Elasticsearch版本。</span><br><span class="line">这种方式其实就相当于使用Java对前面讲的REST API做了一层简单的封装，前面我们是使用的CURL这个工具执行的，现在是使用Java代码模拟执行HTTP请求了。</span><br><span class="line"></span><br><span class="line">2.Java High Level REST Client：</span><br><span class="line">高级别的REST客户端，基于低级别的REST客户端进行了封装，增加了组装请求JSON串、解析响应JSON串等相关API，开发代码使用的ES版本需要和集群中的ES版本一致，否则会有版本冲突问题。</span><br><span class="line">这种方式是从ES 6.0版本开始加入的，目的是以Java面向对象的方式进行请求、响应处理。</span><br><span class="line">高级别的REST客户端会兼容高版本的ES集群，例如：使用ES7.0版本开发的代码可以和任何7.x版本的ES集群交互。</span><br><span class="line">如果ES集群后期升级到了8.x版本，那么也要升级之前基于ES 7.0版本开发的代码。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如果考虑到代码后期的兼容性，建议使用Java Low Level REST Client。</span><br><span class="line">如果考虑到易用性，建议使用Java High Level REST Client。</span><br><span class="line">在这我们使用Java High Level REST Client。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">创建maven项目：db_elasticsearch</span><br><span class="line">创建包：com.imooc.es</span><br><span class="line">在pom.xml文件中添加ES的依赖和日志的依赖。</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch.client&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;version&gt;7.13.4&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.logging.log4j&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;log4j-core&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.14.1&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">在resources目录下添加log4j2.properties。</span><br><span class="line"></span><br><span class="line">appender.console.type &#x3D; Console</span><br><span class="line">appender.console.name &#x3D; console</span><br><span class="line">appender.console.layout.type &#x3D; PatternLayout</span><br><span class="line">appender.console.layout.pattern &#x3D; [%d&#123;ISO8601&#125;][%-5p][%-25c] %marker%m%n</span><br><span class="line"></span><br><span class="line">rootLogger.level &#x3D; info</span><br><span class="line">rootLogger.appenderRef.console.ref &#x3D; console</span><br></pre></td></tr></table></figure><h5 id="索引库的操作（创建、删除）-1"><a href="#索引库的操作（创建、删除）-1" class="headerlink" title="索引库的操作（创建、删除）"></a>索引库的操作（创建、删除）</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.es;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.indices.CreateIndexRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.common.settings.Settings;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 针对ES中索引库的操作</span></span><br><span class="line"><span class="comment"> * 1：创建索引库</span></span><br><span class="line"><span class="comment"> * 2：删除索引库</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsIndexOp</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata02"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata03"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建索引库</span></span><br><span class="line">        <span class="comment">//createIndex(client);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//删除索引库</span></span><br><span class="line">        <span class="comment">//deleteIndex(client);</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteIndex</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        DeleteIndexRequest deleteRequest = <span class="keyword">new</span> DeleteIndexRequest(<span class="string">"java_test"</span>);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.indices().delete(deleteRequest, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createIndex</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        CreateIndexRequest createRequest = <span class="keyword">new</span> CreateIndexRequest(<span class="string">"java_test"</span>);</span><br><span class="line">        <span class="comment">//指定索引库的配置信息</span></span><br><span class="line">        createRequest.settings(Settings.builder()</span><br><span class="line">                .put(<span class="string">"index.number_of_shards"</span>, <span class="number">3</span>)<span class="comment">//指定分片个数</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.indices().create(createRequest, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">执行代码的时候会有一个警告信息，提示ES集群没有开启权限校验机制，其实在企业中只要在运维层面控制好了ES集群IP和端口的访问其实就足够了。</span><br></pre></td></tr></table></figure><h5 id="索引的操作（增、删、改、查、Bulk批量操作）"><a href="#索引的操作（增、删、改、查、Bulk批量操作）" class="headerlink" title="索引的操作（增、删、改、查、Bulk批量操作）"></a>索引的操作（增、删、改、查、Bulk批量操作）</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.es;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.apache.logging.log4j.LogManager;</span><br><span class="line"><span class="keyword">import</span> org.apache.logging.log4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.bulk.BulkItemResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.bulk.BulkRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.bulk.BulkResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.delete.DeleteRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.get.GetRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.get.GetResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.index.IndexRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.update.UpdateRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.common.Strings;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.common.xcontent.XContentType;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.fetch.subphase.FetchSourceContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 针对ES中索引数据的操作</span></span><br><span class="line"><span class="comment"> * 增删改查</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsDataOp</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger logger = LogManager.getLogger(EsDataOp<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata02"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata03"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建索引</span></span><br><span class="line">        <span class="comment">//addIndexByJson(client);</span></span><br><span class="line">        <span class="comment">//addIndexByMap(client);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//查询索引</span></span><br><span class="line">        <span class="comment">//getIndex(client);</span></span><br><span class="line">        <span class="comment">//getIndexByFiled(client);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//更新索引</span></span><br><span class="line">        <span class="comment">//注意：可以使用创建索引直接完整更新已存在的数据</span></span><br><span class="line">        <span class="comment">//updateIndexByPart(client);//局部更新</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//删除索引</span></span><br><span class="line">        <span class="comment">//deleteIndex(client);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//Bulk批量操作</span></span><br><span class="line">        <span class="comment">//bulkIndex(client);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bulkIndex</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        BulkRequest request = <span class="keyword">new</span> BulkRequest();</span><br><span class="line">        request.add(<span class="keyword">new</span> IndexRequest(<span class="string">"emp"</span>).id(<span class="string">"20"</span>)</span><br><span class="line">                .source(XContentType.JSON,<span class="string">"field1"</span>, <span class="string">"value1"</span>,<span class="string">"field2"</span>,<span class="string">"value2"</span>));</span><br><span class="line">        request.add(<span class="keyword">new</span> DeleteRequest(<span class="string">"emp"</span>, <span class="string">"10"</span>));<span class="comment">//id为10的数据不存在，但是执行删除是不会报错的</span></span><br><span class="line">        request.add(<span class="keyword">new</span> UpdateRequest(<span class="string">"emp"</span>, <span class="string">"11"</span>)</span><br><span class="line">                .doc(XContentType.JSON,<span class="string">"age"</span>, <span class="number">19</span>));</span><br><span class="line">        request.add(<span class="keyword">new</span> UpdateRequest(<span class="string">"emp"</span>, <span class="string">"12"</span>)<span class="comment">//id为12的数据不存在，这一条命令在执行的时候会失败</span></span><br><span class="line">                .doc(XContentType.JSON,<span class="string">"age"</span>, <span class="number">19</span>));</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        BulkResponse bulkResponse = client.bulk(request, RequestOptions.DEFAULT);</span><br><span class="line">        <span class="comment">//如果Bulk中的个别语句出错不会导致整个Bulk执行失败，所以可以在这里判断一下是否有返回执行失败的信息</span></span><br><span class="line">        <span class="keyword">for</span> (BulkItemResponse bulkItemResponse : bulkResponse) &#123;</span><br><span class="line">            <span class="keyword">if</span> (bulkItemResponse.isFailed()) &#123;</span><br><span class="line">                BulkItemResponse.Failure failure = bulkItemResponse.getFailure();</span><br><span class="line">                logger.error(<span class="string">"Bulk中出现了异常："</span>+failure);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteIndex</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        DeleteRequest request = <span class="keyword">new</span> DeleteRequest(<span class="string">"emp"</span>, <span class="string">"10"</span>);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.delete(request, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">updateIndexByPart</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        UpdateRequest request = <span class="keyword">new</span> UpdateRequest(<span class="string">"emp"</span>, <span class="string">"10"</span>);</span><br><span class="line">        String jsonString = <span class="string">"&#123;\"age\":23&#125;"</span>;</span><br><span class="line">        request.doc(jsonString, XContentType.JSON);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.update(request, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getIndexByFiled</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        GetRequest request = <span class="keyword">new</span> GetRequest(<span class="string">"emp"</span>, <span class="string">"10"</span>);</span><br><span class="line">        <span class="comment">//只查询部分字段</span></span><br><span class="line">        String[] includes = <span class="keyword">new</span> String[]&#123;<span class="string">"name"</span>&#125;;<span class="comment">//指定包含哪些字段</span></span><br><span class="line">        String[] excludes = Strings.EMPTY_ARRAY;<span class="comment">//指定多滤掉哪些字段</span></span><br><span class="line">        FetchSourceContext fetchSourceContext = <span class="keyword">new</span> FetchSourceContext(<span class="keyword">true</span>, includes, excludes);</span><br><span class="line">        request.fetchSourceContext(fetchSourceContext);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        GetResponse response = client.get(request, RequestOptions.DEFAULT);</span><br><span class="line">        <span class="comment">//通过response获取index、id、文档详细内容（source）</span></span><br><span class="line">        String index = response.getIndex();</span><br><span class="line">        String id = response.getId();</span><br><span class="line">        <span class="keyword">if</span>(response.isExists())&#123;<span class="comment">//如果没有查询到文档数据，则isExists返回false</span></span><br><span class="line">            <span class="comment">//获取json字符串格式的文档结果</span></span><br><span class="line">            String sourceAsString = response.getSourceAsString();</span><br><span class="line">            System.out.println(sourceAsString);</span><br><span class="line">            <span class="comment">//获取map格式的文档结果</span></span><br><span class="line">            Map&lt;String, Object&gt; sourceAsMap = response.getSourceAsMap();</span><br><span class="line">            System.out.println(sourceAsMap);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            logger.warn(<span class="string">"没有查询到索引库&#123;&#125;中id为&#123;&#125;的文档!"</span>,index,id);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getIndex</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        GetRequest request = <span class="keyword">new</span> GetRequest(<span class="string">"emp"</span>, <span class="string">"10"</span>);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        GetResponse response = client.get(request, RequestOptions.DEFAULT);</span><br><span class="line">        <span class="comment">//通过response获取index、id、文档详细内容（source）</span></span><br><span class="line">        String index = response.getIndex();</span><br><span class="line">        String id = response.getId();</span><br><span class="line">        <span class="keyword">if</span>(response.isExists())&#123;<span class="comment">//如果没有查询到文档数据，则isExists返回false</span></span><br><span class="line">            <span class="comment">//获取json字符串格式的文档结果</span></span><br><span class="line">            String sourceAsString = response.getSourceAsString();</span><br><span class="line">            System.out.println(sourceAsString);</span><br><span class="line">            <span class="comment">//获取map格式的文档结果</span></span><br><span class="line">            Map&lt;String, Object&gt; sourceAsMap = response.getSourceAsMap();</span><br><span class="line">            System.out.println(sourceAsMap);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            logger.warn(<span class="string">"没有查询到索引库&#123;&#125;中id为&#123;&#125;的文档!"</span>,index,id);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addIndexByMap</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        IndexRequest request = <span class="keyword">new</span> IndexRequest(<span class="string">"emp"</span>);</span><br><span class="line">        request.id(<span class="string">"11"</span>);</span><br><span class="line">        HashMap&lt;String, Object&gt; jsonMap = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">        jsonMap.put(<span class="string">"name"</span>, <span class="string">"tom"</span>);</span><br><span class="line">        jsonMap.put(<span class="string">"age"</span>, <span class="number">17</span>);</span><br><span class="line">        request.source(jsonMap);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.index(request, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addIndexByJson</span><span class="params">(RestHighLevelClient client)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        IndexRequest request = <span class="keyword">new</span> IndexRequest(<span class="string">"emp"</span>);</span><br><span class="line">        request.id(<span class="string">"10"</span>);</span><br><span class="line">        String jsonString = <span class="string">"&#123;"</span> +</span><br><span class="line">                <span class="string">"\"name\":\"jessic\","</span> +</span><br><span class="line">                <span class="string">"\"age\":20"</span> +</span><br><span class="line">                <span class="string">"&#125;"</span>;</span><br><span class="line">        request.source(jsonString, XContentType.JSON);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.index(request, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Elasticsearch" scheme="http://tianyong.fun/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-ES+HBase实现仿百度搜索引擎-1</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-ES+HBase%E5%AE%9E%E7%8E%B0%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-1.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-ES+HBase%E5%AE%9E%E7%8E%B0%E4%BB%BF%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-1.html</id>
    <published>2023-06-02T10:03:09.000Z</published>
    <updated>2023-06-18T15:49:58.252Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="ES-HBase实现仿百度搜索引擎-1"><a href="#ES-HBase实现仿百度搜索引擎-1" class="headerlink" title="ES+HBase实现仿百度搜索引擎-1"></a>ES+HBase实现仿百度搜索引擎-1</h1><h2 id="1-企业中快速复杂查询痛点分析"><a href="#1-企业中快速复杂查询痛点分析" class="headerlink" title="1 企业中快速复杂查询痛点分析"></a>1 企业中快速复杂查询痛点分析</h2><h3 id="大数据领域海量数据存储现状"><a href="#大数据领域海量数据存储现状" class="headerlink" title="大数据领域海量数据存储现状"></a>大数据领域海量数据存储现状</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">首先来分析一下目前大数据领域中的一些数据存储系统：HDFS、HBase、Kudu</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120911703.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-HDFS：是一个分布式文件系统，适合文本类型数据存储，不支持修改删除，适合一次写入，多次读取的场景。借助于Hive可以实现基于SQL的海量数据分析。HDFS在实际工作中是最常见的。</span><br><span class="line"></span><br><span class="line">-HBase：是一个NoSQL类型的数据库，支持海量数据的增删改查，基于Rowkey查询效率高，针对普通字段查询效率非常低。HBase不支持传统的SQL语法，不适合做数据分析。在企业中的应用场景有限，仅适用于有修改删除需求的场景。</span><br><span class="line"></span><br><span class="line">-Kudu：介于HDFS和HBase之间，专门为了应对快速变化的数据进行快速的分析，既支持增删改查，也支持基于SQL的海量数据分析。它定位于OLAP和少量的OLTP场景，如果有大量的随机查询，还是建议使用HBase最为合适。Kudu没有HDFS批处理速度快，也没有HBase随机读写能力强，所以它属于一个折中的方案，应用场景也是有限的。</span><br></pre></td></tr></table></figure><h3 id="大数据领域常见的SQL分析引擎"><a href="#大数据领域常见的SQL分析引擎" class="headerlink" title="大数据领域常见的SQL分析引擎"></a>大数据领域常见的SQL分析引擎</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">目前大数据领域常见的SQL分析引擎有以下这些：Hive、Impala、Kylin。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120911441.png" alt="image-20230612091102908"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Hive：Hive是一个支持SQL的数据查询引擎，适合通过SQL对HDFS中的海量文本数据进行分析，不适合单条数据的随机查询，因为每一次查询底层都需要执行MapReduce任务，单条数据查询效率比较低。</span><br><span class="line"></span><br><span class="line">Impala：Impala是类似于Hive的一个SQL查询引擎，由于Hive底层需要走MapReduce，效率较低，所以Impala自己实现了底层的计算引擎，充分利用了内存的优势，计算性能可以达到Hive的几十倍。虽然性能提高了，但是Impala也不适合快速复杂查询，因为每次查询还是需要加载表中的所有数据，然后过滤出满足条件的数据。</span><br><span class="line"></span><br><span class="line">Kylin：kylin是一个可以支持海量数据亚秒级查询的引擎，它最核心的思想就是预聚合，kylin中可以提前创建一些Cube，其实就是一些数据聚合规则，可以在每天凌晨的时候对数据按照指定的规则进行聚合，这样后期在使用的时候，就可以直接查询聚合之后的数据，提高查询效率，所以Kylin适合一些查询条件固定的需求，不适合灵活多变的查询需求。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">目前大数据领域中这几个数据分析引擎都是不擅长快速复杂查询的，因为他们侧重的其实都是数据分析，而不是快速复杂查询。</span><br><span class="line"></span><br><span class="line">想要实现海量数据的快速复杂查询，其实最常见的解决方案是利用全文检索引擎，因为全文检索引擎工具会对数据分词建立索引，可以支持快速复杂查询。</span><br></pre></td></tr></table></figure><h3 id="目前常见的全文检索引擎"><a href="#目前常见的全文检索引擎" class="headerlink" title="目前常见的全文检索引擎"></a>目前常见的全文检索引擎</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">目前常见的全文检索引擎主要是这几个：Lucene、Solr、Elasticsearch</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120912169.png" alt="image-20230612091235678"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lucene：Lucene是Java家族中最为出名的一个开源搜索引擎，缺点是使用起来比较繁琐，并且不支持分布式，无法应用在海量数据场景下。</span><br><span class="line"></span><br><span class="line">Solr：Solr是对Lucene进行了封装，并且提供了界面操作，使用起来更加友好，从solr4.0版本开始支持分布式，也就是支持集群架构。</span><br><span class="line"></span><br><span class="line">Elasticsearch：Elasticsearch也是对Lucene进行了封装，它从一开始就支持分布式，专门为大数据而生，所以在大数据领域使用的还是比较多的。</span><br></pre></td></tr></table></figure><h3 id="海量数据存储-快速复杂查询需求"><a href="#海量数据存储-快速复杂查询需求" class="headerlink" title="海量数据存储+快速复杂查询需求"></a>海量数据存储+快速复杂查询需求</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">假设现在遇到一个需求，企业里面有一套爬虫程序，每天都会到互联网上抓取海量的文章数据，针对这些文章数据：</span><br><span class="line">1：首先要实现海量文章数据存储，支持数据更新需求</span><br><span class="line">2：还需要提供针对文章数据的快速复杂查询</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120916581.png" alt="image-20230612091639190"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在这里能不能直接使用Elasticsearch实现海量数据存储和快速复杂查询呢？</span><br><span class="line">Elasticsearch最擅长的是快速复杂查询，虽然它支持分布式，也可以存储海量数据，但是这并不是它最擅长的功能，因为数据存储多了之后肯定会影响ES的性能。</span><br><span class="line"></span><br><span class="line">所以单纯使用Elasticsearch来实现这个需求是不太合适的。</span><br><span class="line"></span><br><span class="line">那针对海量数据存储可以考虑HDFS、HBase、Kudu这几个存储系统，首先要把HDFS排除掉，因为HDFS不支持更新操作，剩下的是HBase和Kudu，这两个都支持更新操作，但是Kudu随机查询性能是不如HBase的，所以针对存储这块考虑使用HBase。</span><br><span class="line"></span><br><span class="line">单纯使用HBase也是无法满足需求的，HBase只有根据Rowkey查询效率才高，根据其他字段查询效率是比较差的。</span><br></pre></td></tr></table></figure><h3 id="海量数据存储-快速复杂查询的解决方案"><a href="#海量数据存储-快速复杂查询的解决方案" class="headerlink" title="海量数据存储+快速复杂查询的解决方案"></a>海量数据存储+快速复杂查询的解决方案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">所以这个需求只使用一个技术组件是无法完美解决的，最好的解决方案是将HBase和Elasticsearch整合到一起，利用HBase适合海量数据存储、基于Rowkey查询效率高的特性，以及Elasticsearch适合快速复杂查询的特性。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120918935.png" alt="image-20230612091806749"></p><h2 id="2-仿百度搜索引擎项目架构设计"><a href="#2-仿百度搜索引擎项目架构设计" class="headerlink" title="2 仿百度搜索引擎项目架构设计"></a>2 仿百度搜索引擎项目架构设计</h2><h3 id="项目概览"><a href="#项目概览" class="headerlink" title="项目概览"></a>项目概览</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">首先看一下项目最终的界面效果</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120919094.png" alt="image-20230612091858736"></p><h3 id="项目整体架构流程"><a href="#项目整体架构流程" class="headerlink" title="项目整体架构流程"></a>项目整体架构流程</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120920136.png" alt="image-20230612092004096"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1：项目的数据来源可以是通过爬虫到互联网上采集的数据，也可以是企业数据库中的内部数据</span><br><span class="line">2：根据数据的来源不同，使用不同的程序将数据入库到HBase，实现海量数据存储</span><br><span class="line">3：针对HBase中的数据在ES中建立索引。</span><br><span class="line">4：在数据展现模块中提供仿百度搜索功能。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">注意：并不是把HBase中数据的完整内容全部在ES中建立索引，只需要将检索用到的那些字段在ES中建立索引即可。例如：HBase存储的原始数据有20个字段，在ES可能只需要存储5个字段即可，具体的存储细节在后面会详细分析。</span><br></pre></td></tr></table></figure><h3 id="ES和HBase数据同步的三种方案"><a href="#ES和HBase数据同步的三种方案" class="headerlink" title="ES和HBase数据同步的三种方案"></a>ES和HBase数据同步的三种方案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">针对此项目，有一个核心功能点，如何在ES中同步对HBase中的数据建立索引？</span><br><span class="line">大致有下面这几种方案：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120927744.png" alt="image-20230612092710497"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1：方案1，在将原始数据入库HBase的时候，同时在ES中对数据建立索引，此时可以把入库HBase和ES的代码放在一个事务中，保证HBase和ES的数据一致性。</span><br><span class="line">这种方案的优点是操作方便，缺点是入库HBase和ES的代码绑定到一起了，耦合性太高，如果遇到ES出现故障，会导致入库HBase的操作也会失败，或者是ES集群压力过大的时候，会导致数据入库HBase的效率降低。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120927645.png" alt="image-20230612092739473"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2：方案2，在将原始数据入库HBase的时候，通过HBase中的协处理器实现数据同步，让协处理器监听HBase中的新增和删除操作，在协处理器内部操作ES，实现对数据建立索引的功能。</span><br><span class="line">HBase中的协处理器其实类似于MySQL中的触发器。</span><br><span class="line">这种方案的优点是通过协处理器可以很方便的获取到HBase中新增和变化的数据，如果入库HBase的程序是之前已经开发好的，此时不需要对之前的代码进行任何改动，影响程度比较低。缺点是过于依赖HBase了，如果后期涉及到HBase集群版本升级，无法保证协处理器功能的可用性。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120928386.png" alt="image-20230612092821245"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">3：方案3，在将原始数据入库HBase的时候，同时在Redis中使用list数据类型模拟一个队列，存储数据的Rowkey。此时将入库HBase和Redis的操作放在一个事务里面，保证数据的一致性。然后再通过另外一个同步程序，从Redis的list队列中读取Rowkey，根据Rowkey到HBase中获取数据的详细信息，在ES中建立索引，将HBase中数据的Rowkey作为ES中数据的ID。</span><br><span class="line">在这个方案里面是将入库HBase和在ES中建立索引这两个功能解耦了，借助于中间层的Redis实现的。</span><br><span class="line">这种方案的缺点是把入库HBase和Redis的功能耦合在一起了，但是Redis是轻量级的，出现问题的概率是比较低的，对性能损耗也不高，所以是可以接受的。</span><br><span class="line">此时就算ES出现问题，只需要在同步程序内部实现正常的异常处理即可，将建立索引失败数据的Rowkey重新添加到Redis的list列表里面即可，不会导致HBase和ES数据不一致的问题。</span><br><span class="line"></span><br><span class="line">其实第2种方案和第3种方案都可以使用，个人推荐使用第3种方案，可控性高一些，在项目中也会使用第3种方案实现。</span><br></pre></td></tr></table></figure><h3 id="项目整体执行流程"><a href="#项目整体执行流程" class="headerlink" title="项目整体执行流程"></a>项目整体执行流程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">接下来分析一下项目底层细节流程</span><br><span class="line">如下图所示</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120931503.png" alt="image-20230612093116446"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1：通过入库程序向HBase中入库数据，同时在Redis中存储数据的Rowkey。</span><br><span class="line">2：从Redis中获取数据的Rowkey，根据Rowkey到HBase中查询数据的详细信息，然后在ES中建立索引。</span><br><span class="line">此时我们的海量数据已经存储到HBase中，并且将需要查询的字段在ES中建立索引了。</span><br><span class="line">3：用户向ES发送查询请求</span><br><span class="line">4：ES返回符合条件的数据的ID，其实就是HBase中数据的Rowkey。在这里也可以根据需求额外再返回一些字段信息都是可以的。</span><br><span class="line">5：当用户想要查看数据完整详细信息的时候，需要根据Rowkey到HBase中查询</span><br><span class="line">6：HBase会给用户返回Rowkey对应数据的详细信息。</span><br></pre></td></tr></table></figure><h2 id="3-ES高级特性扩展"><a href="#3-ES高级特性扩展" class="headerlink" title="3 ES高级特性扩展"></a>3 ES高级特性扩展</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在具体开发项目之前，先来了解一下ES中的几个特性：</span><br></pre></td></tr></table></figure><h3 id="ES中的-source字段"><a href="#ES中的-source字段" class="headerlink" title="ES中的_source字段"></a>ES中的_source字段</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306120936278.png" alt="image-20230612093604097"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在ES中包含一个特殊的字段：_source</span><br><span class="line">当我们在ES中对数据建立索引的时候，在ES底层其实会存储两份数据，一份是原始文档的内容，还有一份是对原始文档分词产生的倒排索引内容。</span><br><span class="line"></span><br><span class="line">其中原始文档内容会存储到_source这个字段里面，咱们前面在学习JavaAPI操作ES的时候，通过search查询的结果数据，最终在解析的时候其实就是从_source字段中解析的。</span><br><span class="line"></span><br><span class="line">_source字段中默认会包含原始文档中所有字段的内容。</span><br></pre></td></tr></table></figure><h3 id="ES中字段的index和store特性"><a href="#ES中字段的index和store特性" class="headerlink" title="ES中字段的index和store特性"></a>ES中字段的index和store特性</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">我们在向ES中添加数据的时候，ES底层针对每个字段其实还会涉及到index和store这两个属性：</span><br><span class="line"></span><br><span class="line">index：表示是否在ES中建立索引，默认为true。</span><br><span class="line">store：表示是否在ES中存储，默认为false。</span><br><span class="line"></span><br><span class="line">这里的store属性其实是Lucene中的语法，表示是否存储字段内容，ES对它做了优化，默认会使用_source字段存储原始文档所有字段的内容，这样可以提高数据解析性能，所以这里的store属性其实就不需要设置了，它的默认值就是false，表示不存储。</span><br><span class="line"></span><br><span class="line">注意：如果这里的store也设置为true，此时ES会重复存储对应字段的内容。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">下面来看一个例子：</span><br><span class="line">假设我要向ES中添加一批学生数据，包括姓名、年龄、性别、家庭住址这些字段。</span><br><span class="line">针对这批数据，我的需求是需要根据学生的姓名、家庭住址进行查询，最终在返回结果数据的时候，只需要把学生的姓名、年龄、性别返回过来即可，不需要返回家庭住址。</span><br><span class="line"></span><br><span class="line">针对这个需求而言</span><br><span class="line">1：需要根据学生的姓名、家庭住址进行查询，所以这两个字段必须在ES中建立索引，否则无法根据姓名和家庭住址进行查询。</span><br><span class="line">2：还需要在返回结果数据的时候把学生的姓名、年龄、性别返回过来，那也就意味着姓名、年龄、性别字段需要在ES中进行存储，否则ES是无法返回这些字段内容的。</span><br><span class="line">所以针对这个需求总结一下：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">是否建立索引是否存储</span><br><span class="line">姓名是是</span><br><span class="line">年龄否是</span><br><span class="line">性别否是</span><br><span class="line">家庭住址   是   否</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">判断一个字段是否需要建立索引，唯一的依据就是是否需要根据这个字段进行查询，如果需要，则建立索引，否则不建立索引。</span><br><span class="line">判断一个字段是否需要存储，唯一的依据就是是否需要从ES中获取这个字段的值，如果需要，则存储，否则不存储。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：在实际工作中，针对某个字段来说，需要建立索引，但是不需要存储，这种场景也是存在的，因为某一些字段内容如果比较大，并且没有必要从ES中返回，其实就没必要在ES中存储了，否则会额外占用ES的存储空间，也会影响ES的查询效率。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">由于默认情况下_source字段会存储所有字段的内容，所以需要在_source字段中过滤掉不需要存储的字段。</span><br><span class="line">在mapping中设置:&quot;_source&quot;:&#123;&quot;excludes&quot;:[&quot;address&quot;]&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">针对这个案例，创建一个索引库：stuinfo</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~] curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#39; -d&#39;&#123;&quot;mappings&quot;:&#123;&quot;_source&quot;:&#123;&quot;excludes&quot;:[&quot;address&quot;]&#125;,&quot;properties&quot;:&#123;&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;index&quot;:true&#125;,&quot;age&quot;:&#123;&quot;type&quot;:&quot;integer&quot;,&quot;index&quot;:false&#125;,&quot;sex&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;index&quot;:false&#125;,&quot;address&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;index&quot;:true&#125;&#125;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">查询mappings信息。</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;stuinfo&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;_source&quot; : &#123;</span><br><span class="line">        &quot;excludes&quot; : [</span><br><span class="line">          &quot;address&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;address&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;integer&quot;,</span><br><span class="line">          &quot;index&quot; : false</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;sex&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;index&quot; : false</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">向索引库中添加一条数据</span><br><span class="line">curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#x2F;_doc&#x2F;1&#39; -d &#39;&#123;&quot;name&quot;:&quot;zs&quot;,&quot;age&quot;:20,&quot;sex&quot;:&quot;man&quot;,&quot;address&quot;:&quot;bj&quot;&#125;&#39;</span><br><span class="line"></span><br><span class="line">查看这条数据，验证一下效果。</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#x2F;_search?pretty&#39; </span><br><span class="line">&#123;</span><br><span class="line"> ......</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;sex&quot; : &quot;man&quot;,</span><br><span class="line">    &quot;name&quot; : &quot;zs&quot;,</span><br><span class="line">    &quot;age&quot; : 20</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">发现返回的_source字段中确实没有address字段的内容了。</span><br><span class="line"></span><br><span class="line">但是此时我们还是可以根据address进行查询的，因为倒排索引中有这个字段的内容。</span><br><span class="line">在这里扩展一个知识点，使用RestAPI执行query查询。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121015221.png" alt="image-20230612101521802"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">根据address可以查询到数据，说明address的index属性生效了</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#x2F;_search?pretty&#39; -d&#39;&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;address&quot;:&quot;bj&quot;&#125;&#125;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 5,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 1,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 1,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 0.2876821,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;stuinfo&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 0.2876821,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;sex&quot; : &quot;man&quot;,</span><br><span class="line">          &quot;name&quot; : &quot;zs&quot;,</span><br><span class="line">          &quot;age&quot; : 20</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果我们使用sex字段进行查询，会看到报错信息，因为sex字段没有建立索引是无法作为查询字段的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stuinfo&#x2F;_search?pretty&#39; -d&#39;&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;sex&quot;:&quot;man&quot;&#125;&#125;&#125;&#39;    </span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;query_shard_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;failed to create query: Cannot search on field [sex] since it is not indexed.&quot;,</span><br><span class="line">        &quot;index_uuid&quot; : &quot;sPuh_JJNSYW33Oie4KSRcg&quot;,</span><br><span class="line">        &quot;index&quot; : &quot;stuinfo&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;search_phase_execution_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;all shards failed&quot;,</span><br><span class="line">    &quot;phase&quot; : &quot;query&quot;,</span><br><span class="line">    &quot;grouped&quot; : true,</span><br><span class="line">    &quot;failed_shards&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;shard&quot; : 0,</span><br><span class="line">        &quot;index&quot; : &quot;stuinfo&quot;,</span><br><span class="line">        &quot;node&quot; : &quot;_6ff1IjTTGm3jZ_edi6-KA&quot;,</span><br><span class="line">        &quot;reason&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;query_shard_exception&quot;,</span><br><span class="line">          &quot;reason&quot; : &quot;failed to create query: Cannot search on field [sex] since it is not indexed.&quot;,</span><br><span class="line">          &quot;index_uuid&quot; : &quot;sPuh_JJNSYW33Oie4KSRcg&quot;,</span><br><span class="line">          &quot;index&quot; : &quot;stuinfo&quot;,</span><br><span class="line">          &quot;caused_by&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;illegal_argument_exception&quot;,</span><br><span class="line">            &quot;reason&quot; : &quot;Cannot search on field [sex] since it is not indexed.&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 400</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-开发仿百度搜索引擎项目"><a href="#4-开发仿百度搜索引擎项目" class="headerlink" title="4 开发仿百度搜索引擎项目"></a>4 开发仿百度搜索引擎项目</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这个搜索引擎项目主要涉及到数据采集、数据存储、建立索引和数据展现环节。</span><br><span class="line">针对一个搜索引擎项目而言，它的数据基本上都是来源于互联网上的公开数据，想要获取这些数据就需要使用爬虫工具了，目前市面上有一些爬虫产品，但是在使用的时候基本上都需要二次开发，所以企业里面都会有专门的爬虫工程师负责这个工作。</span><br><span class="line">我们在开发这个搜索引擎项目的时候就不再针对爬虫数据采集模块进行扩展了，到时候我会提供一个数据接口，大家通过接口可以直接获取到一些互联网上的公开数据。</span><br><span class="line">数据大致格式是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121050949.png" alt="image-20230612105000321"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">我们在开发这个搜索引擎项目的时候会重点实现数据存储、建立索引这两个环节。</span><br><span class="line"></span><br><span class="line">大致的开发步骤是这样的：</span><br><span class="line">1：调用接口获取数据导入HBase和Redis(存储Rowkey)。</span><br><span class="line">2：通过ES对HBase中的数据建立索引。</span><br><span class="line">3：对接Web项目，提供页面检索功能。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在具体开发项目之前，我们首先分析一下项目中的数据和具体的查询要求，这样就知道ES中索引库的mapping应该如何设计了。</span><br><span class="line">在这个搜索引擎项目中，我们需要对爬虫采集到的文章数据在ES中建立索引。</span><br><span class="line"></span><br><span class="line">由于文章数据的核心内容主要在标题、描述和正文这3个字段中，所以在查询的时候需要用到这3个字段。</span><br><span class="line">那ES在返回满足条件的数据的时候，都需要返回哪些字段呢？</span><br><span class="line">参考一下百度的结果列表界面，可以发现，百度的列表页面会显示标题、描述和作者信息。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121052050.png" alt="image-20230612105219912"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">那针对我们这里的文章数据，还有一个时间字段，其实也可以显示在列表页面中，具体显示哪些字段，可以根据工作中的具体需求来定。</span><br><span class="line">在这里我们希望在列表页面显示的是文章的标题、作者、描述、时间这4个字段。</span><br><span class="line">针对文章的ID，在这里直接作为ES中数据的ID，ES中的ID是必须要存储和建立索引的。</span><br><span class="line">所以最终总结一下是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121053192.png" alt="image-20230612105345979"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">文章ID：需要建立索引，并且存储，这是ES中ID字段必须要具备的特性。</span><br><span class="line">标题：因为查询的时候会用到，所以需要建立索引，并且在返回结果列表信息的时候需要直接从ES中返回，所以需要存储。</span><br><span class="line">作者：查询用不到，所以不需要建立索引，但是需要在返回结果列表信息的时候一块返回，所以需要存储。</span><br><span class="line">描述：查询会用到，返回的结果列表信息中也有这个字段内容，所以需要建立索引，并且存储。</span><br><span class="line">正文：因为查询的时候会用到，所以需要建立索引，但是在返回结果列表信息的时候不需要返回这个字段，所以不需要存储。其实还有一点很重要的原因是因为这个字段内容太长了，如果在ES中存储，会额外占用很多的存储空间，最终会影响ES的性能。</span><br><span class="line">时间：查询用不到，所以不需要建立索引，但是需要在返回结果列表信息的时候一块返回，所以需要存储。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来手工指定一下索引库的settings和mapping参数。</span><br><span class="line">由于这里的字段比较多，最好把settings和mapping信息写到一个文件中，使用起来比较方便。</span><br><span class="line">创建一个文件：article.json，内容如下：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">        &quot;settings&quot;:&#123;</span><br><span class="line">                &quot;number_of_shards&quot;:5,</span><br><span class="line">                &quot;number_of_replicas&quot;:1</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;mappings&quot;:&#123;</span><br><span class="line">&quot;dynamic&quot;:&quot;strict&quot;,</span><br><span class="line">&quot;_source&quot;:&#123;&quot;excludes&quot;:[&quot;content&quot;]&#125;,</span><br><span class="line">&quot;properties&quot;:&#123;</span><br><span class="line">&quot;title&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,</span><br><span class="line">&quot;author&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;index&quot;:false&#125;,</span><br><span class="line">&quot;describe&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,</span><br><span class="line">&quot;content&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot;&#125;,</span><br><span class="line">&quot;time&quot;:&#123;&quot;type&quot;:&quot;date&quot;,&quot;index&quot;:false,&quot;format&quot;:&quot;yyyy-MM-dd HH:mm:ss&quot;&#125;</span><br><span class="line">&#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line">dynamic参数有4个选项值(后期ES中如果用于建立索引的字段多了一些未知字段的场景)：</span><br><span class="line"></span><br><span class="line">true是默认的，表示开启动态映射(自动识别)</span><br><span class="line">false表示忽略没有定义的字段</span><br><span class="line">strict表示遇到未知字段时抛出异常</span><br><span class="line">runtime表示遇到未知字段时将它作为运行时字段，运行时字段是在ES7.11版本中增加的，运行时字段不会被索引，但是可以从_source中获取运行时字段内容，所以runtime可以适合公共字段已知，并且想兼容未知扩展字段的场景。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121321626.png" alt="image-20230612132118974"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dynamic具体选择哪个参数，就需要根据需求来定了，在这里不希望在ES中保存未知字段，所以使用strict。</span><br><span class="line"></span><br><span class="line">将article.json上传到&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4目录下</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# ll article.json </span><br><span class="line">-rw-r--r--. 1 root root 534 Apr  2 17:44 article.json</span><br></pre></td></tr></table></figure><h3 id="调用接口获取数据导入HBase和Redis"><a href="#调用接口获取数据导入HBase和Redis" class="headerlink" title="调用接口获取数据导入HBase和Redis"></a>调用接口获取数据导入HBase和Redis</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在Idea中直接打开已有项目：db_fullsearch，里面有一个web_fullsearch子model项目。</span><br><span class="line">接着再创建一个子Model项目：data_manager</span><br><span class="line">在子Model项目data_manager的pom.xml中添加此项目需要用到的依赖。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;slf4j-api&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.httpcomponents&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;httpclient&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.hbase&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;hbase-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.elasticsearch.client&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;redis.clients&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;jedis&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;&#x2F;dependencies&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在子Model项目data_manager中添加log4j.properties配置文件。</span><br><span class="line">log4j.rootLogger&#x3D;info,stdout</span><br><span class="line"></span><br><span class="line">log4j.appender.stdout &#x3D; org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.stdout.Target &#x3D; System.out</span><br><span class="line">log4j.appender.stdout.layout&#x3D;org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern&#x3D;[%p] %m%n</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在子Model项目data_manager中创建package：com.imooc.core和com.imooc.utils</span><br><span class="line">在com.imooc.utils包中引入工具类：HttpUtil、RedisUtil、HBaseUtil（开发）。</span><br><span class="line">接着在com.imooc.core中创建类：DataImport，负责实现数据导入到HBase和Redis。</span><br><span class="line">HBaseUtil代码如下：</span><br></pre></td></tr></table></figure><h4 id="com-imooc-utils"><a href="#com-imooc-utils" class="headerlink" title="com.imooc.utils"></a>com.imooc.utils</h4><h5 id="HBaseUtil"><a href="#HBaseUtil" class="headerlink" title="HBaseUtil"></a>HBaseUtil</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.sun.org.apache.bcel.internal.generic.TABLESWITCH;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * HBase工具类</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseUtil</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">HBaseUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Connection conn = getConn();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Connection <span class="title">getConn</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//获取hbase链接</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定hbase使用的zk地址</span></span><br><span class="line">        <span class="comment">//注意：需要在执行hbase hava代码的机器上配置zk和hbase集群的主机名和ip的映射关系</span></span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>,<span class="string">"bigdata01:2181"</span>);</span><br><span class="line">        <span class="comment">//指定hbase在hdfs上的根目录</span></span><br><span class="line">        conf.set(<span class="string">"hbase.rootdir"</span>,<span class="string">"hdfs://bigdata01:9000/hbase"</span>);</span><br><span class="line">        <span class="comment">//创建HBase数据库链接</span></span><br><span class="line">        Connection co = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            co = ConnectionFactory.createConnection(conf);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            System.out.println(<span class="string">"获取链接失败："</span>+e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> co;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对外提供的方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cfs</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String tableName,String... cfs)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Admin admin = conn.getAdmin();</span><br><span class="line">        ArrayList&lt;ColumnFamilyDescriptor&gt; cfArr = <span class="keyword">new</span> ArrayList&lt;ColumnFamilyDescriptor&gt;();</span><br><span class="line">        <span class="keyword">for</span> (String cf : cfs) &#123;</span><br><span class="line">            ColumnFamilyDescriptor cfDesc = ColumnFamilyDescriptorBuilder</span><br><span class="line">                    .newBuilder(Bytes.toBytes(cf))</span><br><span class="line">                    .build();</span><br><span class="line">            cfArr.add(cfDesc);</span><br><span class="line">        &#125;</span><br><span class="line">        TableDescriptor tableDesc = TableDescriptorBuilder</span><br><span class="line">                .newBuilder(TableName.valueOf(tableName))</span><br><span class="line">                .setColumnFamilies(cfArr)</span><br><span class="line">                .build();</span><br><span class="line">        admin.createTable(tableDesc);</span><br><span class="line">        admin.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加一个单元格(列)的数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> rowKey</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> columnFamily</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> column</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put2HBaseCell</span><span class="params">(String tableName,String rowKey,String columnFamily,String column,String value)</span><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Put put = <span class="keyword">new</span> Put(Bytes.toBytes(rowKey));</span><br><span class="line">        put.addColumn(Bytes.toBytes(columnFamily),Bytes.toBytes(column),Bytes.toBytes(value));</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 向hbase中添加一批数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put2HBaseList</span><span class="params">(String tableName, List&lt;Put&gt; list)</span><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        table.put(list);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">把这个构造方法私有化的意义是为了防止外部类创建RedisUtil的实例对象。这样可以保证RedisUtil是一个单例类，只有一个实例存在。这样可以节省内存空间，避免多个实例之间的同步问题，提高性能。😊</span><br><span class="line"></span><br><span class="line">已收到消息. 把这个构造方法私有化的意义是为了防止外部类创建RedisUtil的实例对象。这样可以保证RedisUtil是一个单例类，只有一个实例存在。这样可以节省内存空间，避免多个实例之间的同步问题，提高性能。😊</span><br></pre></td></tr></table></figure><h5 id="RedisUtil"><a href="#RedisUtil" class="headerlink" title="RedisUtil"></a>RedisUtil</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPoolConfig;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 基于Redis连接池提取Redis工具类</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisUtil</span> </span>&#123;</span><br><span class="line">    <span class="comment">//私有化构造函数，禁止new</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">RedisUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> JedisPool jedisPool = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Jedis <span class="title">getJedis</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(jedisPool==<span class="keyword">null</span>)&#123;</span><br><span class="line">            JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">            poolConfig.setMaxIdle(<span class="number">10</span>);</span><br><span class="line">            poolConfig.setMaxTotal(<span class="number">100</span>);</span><br><span class="line">            poolConfig.setMaxWaitMillis(<span class="number">2000</span>);</span><br><span class="line">            poolConfig.setTestOnBorrow(<span class="keyword">true</span>);</span><br><span class="line">            jedisPool = <span class="keyword">new</span> JedisPool(poolConfig, <span class="string">"192.168.182.103"</span>, <span class="number">6379</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> jedisPool.getResource();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向连接池返回连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">returnResource</span><span class="params">(Jedis jedis)</span></span>&#123;</span><br><span class="line">        jedis.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="com-imooc-core"><a href="#com-imooc-core" class="headerlink" title="com.imooc.core"></a>com.imooc.core</h4><h5 id="DataImport"><a href="#DataImport" class="headerlink" title="DataImport"></a>DataImport</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataImport代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.core;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONArray;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.imooc.utils.HBaseUtil;</span><br><span class="line"><span class="keyword">import</span> com.imooc.utils.HttpUtil;</span><br><span class="line"><span class="keyword">import</span> com.imooc.utils.RedisUtil;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过接口获取文章数据，入库HBase和Redis（Rowkey）</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 注意：HBase建表语句 create 'article','info'</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataImport</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Logger logger = LoggerFactory.getLogger(DataImport<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//通过接口获取文章数据</span></span><br><span class="line">        String dataUrl = <span class="string">"http://data.xuwei.tech/a1/wz1"</span>;</span><br><span class="line">        JSONObject paramObj = <span class="keyword">new</span> JSONObject();</span><br><span class="line">        paramObj.put(<span class="string">"code"</span>,<span class="string">"imooc"</span>);<span class="comment">//校验码</span></span><br><span class="line">        paramObj.put(<span class="string">"num"</span>,<span class="number">100</span>);<span class="comment">//数据条数，默认返回100条，最大支持返回1000条</span></span><br><span class="line">        JSONObject dataObj = HttpUtil.doPost(dataUrl, paramObj);</span><br><span class="line">        <span class="keyword">boolean</span> flag = dataObj.containsKey(<span class="string">"error"</span>);</span><br><span class="line">        <span class="keyword">if</span>(!flag)&#123;</span><br><span class="line">            JSONArray resArr = dataObj.getJSONArray(<span class="string">"data"</span>);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;resArr.size();i++)&#123;</span><br><span class="line">                JSONObject jsonObj = resArr.getJSONObject(i);</span><br><span class="line">                <span class="comment">//System.out.println(jsonObj.toJSONString());</span></span><br><span class="line">                <span class="comment">//文章ID作为HBase的Rowkey和ES的ID</span></span><br><span class="line">                String id = jsonObj.getString(<span class="string">"id"</span>);</span><br><span class="line">                String title = jsonObj.getString(<span class="string">"title"</span>);</span><br><span class="line">                String author = jsonObj.getString(<span class="string">"author"</span>);</span><br><span class="line">                String describe = jsonObj.getString(<span class="string">"describe"</span>);</span><br><span class="line">                String content = jsonObj.getString(<span class="string">"content"</span>);</span><br><span class="line">                String time = jsonObj.getString(<span class="string">"time"</span>);</span><br><span class="line">                Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">try</span>&#123;</span><br><span class="line">                    <span class="comment">//将数据入库到HBase</span></span><br><span class="line">                    String tableName = <span class="string">"article"</span>;</span><br><span class="line">                    String cf = <span class="string">"info"</span>;</span><br><span class="line">                    HBaseUtil.put2HBaseCell(tableName,id,cf,<span class="string">"title"</span>,title);</span><br><span class="line">                    HBaseUtil.put2HBaseCell(tableName,id,cf,<span class="string">"author"</span>,author);</span><br><span class="line">                    HBaseUtil.put2HBaseCell(tableName,id,cf,<span class="string">"describe"</span>,describe);</span><br><span class="line">                    HBaseUtil.put2HBaseCell(tableName,id,cf,<span class="string">"content"</span>,content);</span><br><span class="line">                    HBaseUtil.put2HBaseCell(tableName,id,cf,<span class="string">"time"</span>,time);</span><br><span class="line">                    <span class="comment">//将Rowkey保存到Redis中</span></span><br><span class="line">                    jedis = RedisUtil.getJedis();</span><br><span class="line">                    jedis.lpush(<span class="string">"l_article_ids"</span>,id);</span><br><span class="line">                &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">                    <span class="comment">//注意：由于hbase的put操作属于幂等操作，多次操作，对最终的结果没有影响，所以不需要额外处理</span></span><br><span class="line">                    logger.error(<span class="string">"数据添加失败："</span>+e.getMessage());</span><br><span class="line">                &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">//向连接池返回连接</span></span><br><span class="line">                    <span class="keyword">if</span>(jedis!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                        RedisUtil.returnResource(jedis);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            logger.error(<span class="string">"获取文章数据失败："</span>+dataObj.toJSONString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过ES对HBase中的数据建立索引"><a href="#通过ES对HBase中的数据建立索引" class="headerlink" title="通过ES对HBase中的数据建立索引"></a>通过ES对HBase中的数据建立索引</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在com.imooc.core中创建类：DataIndex，负责实现在ES中对数据建立索引。</span><br><span class="line">在开发DataIndex代码的时候，需要向Es中写入数据，所以最好封装一个EsUtil工具类。</span><br><span class="line">同时需要对HBaseUtil工具类进行完善，增加一个getFromHBase方法，负责从HBase中获取数据</span><br><span class="line"></span><br><span class="line">EsUtil工具类代码如下：</span><br></pre></td></tr></table></figure><h4 id="com-imooc-utils-1"><a href="#com-imooc-utils-1" class="headerlink" title="com.imooc.utils"></a>com.imooc.utils</h4><h5 id="EsUtil"><a href="#EsUtil" class="headerlink" title="EsUtil"></a>EsUtil</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.nio.client.HttpAsyncClientBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.nio.reactor.IOReactorConfig;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.index.IndexRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClientBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ES工具类</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsUtil</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">EsUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> RestHighLevelClient client;</span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        <span class="comment">//注意：高级别客户端其实是对低级别客户端的代码进行了封装，所以连接池使用的是低级别客户端中的连接池</span></span><br><span class="line">        client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>,<span class="number">9200</span>,<span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>,<span class="number">9200</span>,<span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>,<span class="number">9200</span>,<span class="string">"http"</span>))</span><br><span class="line">                        .setHttpClientConfigCallback(<span class="keyword">new</span> RestClientBuilder.HttpClientConfigCallback() &#123;</span><br><span class="line">                            <span class="function"><span class="keyword">public</span> HttpAsyncClientBuilder <span class="title">customizeHttpClient</span><span class="params">(HttpAsyncClientBuilder httpClientBuilder)</span> </span>&#123;</span><br><span class="line">                                <span class="keyword">return</span> httpClientBuilder.setDefaultIOReactorConfig(</span><br><span class="line">                                        IOReactorConfig.custom()</span><br><span class="line">                                                <span class="comment">//设置线程池中线程的数量，默认是1个，建议设置为和客户端机器可用CPU数量一致</span></span><br><span class="line">                                                .setIoThreadCount(<span class="number">1</span>)</span><br><span class="line">                                                .build());</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取客户端</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> RestHighLevelClient <span class="title">getRestClient</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> client;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭客户端</span></span><br><span class="line"><span class="comment">     * 注意：调用高级别客户单的close方法时，会将低级别客户端创建的连接池整个关闭掉，最终导致client无法继续使用</span></span><br><span class="line"><span class="comment">     * 所以正常是用不到这个close方法的，只有在程序结束的时候才需要调用</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">closeRestClient</span><span class="params">()</span><span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 建立索引</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> index</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> map</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addIndex</span><span class="params">(String index, String id, Map&lt;String,String&gt; map)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        IndexRequest request = <span class="keyword">new</span> IndexRequest(index);</span><br><span class="line">        request.id(id);</span><br><span class="line">        request.source(map);</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        client.index(request, RequestOptions.DEFAULT);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="HBaseUtil-1"><a href="#HBaseUtil-1" class="headerlink" title="HBaseUtil"></a>HBaseUtil</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HBaseUtil工具类代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.sun.org.apache.bcel.internal.generic.TABLESWITCH;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * HBase工具类</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseUtil</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">HBaseUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Connection conn = getConn();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Connection <span class="title">getConn</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//获取hbase链接</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//指定hbase使用的zk地址</span></span><br><span class="line">        <span class="comment">//注意：需要在执行hbase hava代码的机器上配置zk和hbase集群的主机名和ip的映射关系</span></span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>,<span class="string">"bigdata01:2181"</span>);</span><br><span class="line">        <span class="comment">//指定hbase在hdfs上的根目录</span></span><br><span class="line">        conf.set(<span class="string">"hbase.rootdir"</span>,<span class="string">"hdfs://bigdata01:9000/hbase"</span>);</span><br><span class="line">        <span class="comment">//创建HBase数据库链接</span></span><br><span class="line">        Connection co = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            co = ConnectionFactory.createConnection(conf);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            System.out.println(<span class="string">"获取链接失败："</span>+e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> co;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对外提供的方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> conn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cfs</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String tableName,String... cfs)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Admin admin = conn.getAdmin();</span><br><span class="line">        ArrayList&lt;ColumnFamilyDescriptor&gt; cfArr = <span class="keyword">new</span> ArrayList&lt;ColumnFamilyDescriptor&gt;();</span><br><span class="line">        <span class="keyword">for</span> (String cf : cfs) &#123;</span><br><span class="line">            ColumnFamilyDescriptor cfDesc = ColumnFamilyDescriptorBuilder</span><br><span class="line">                    .newBuilder(Bytes.toBytes(cf))</span><br><span class="line">                    .build();</span><br><span class="line">            cfArr.add(cfDesc);</span><br><span class="line">        &#125;</span><br><span class="line">        TableDescriptor tableDesc = TableDescriptorBuilder</span><br><span class="line">                .newBuilder(TableName.valueOf(tableName))</span><br><span class="line">                .setColumnFamilies(cfArr)</span><br><span class="line">                .build();</span><br><span class="line">        admin.createTable(tableDesc);</span><br><span class="line">        admin.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加一个单元格(列)的数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> rowKey</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> columnFamily</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> column</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put2HBaseCell</span><span class="params">(String tableName,String rowKey,String columnFamily,String column,String value)</span><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Put put = <span class="keyword">new</span> Put(Bytes.toBytes(rowKey));</span><br><span class="line">        put.addColumn(Bytes.toBytes(columnFamily),Bytes.toBytes(column),Bytes.toBytes(value));</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 向hbase中添加一批数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put2HBaseList</span><span class="params">(String tableName, List&lt;Put&gt; list)</span><span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        table.put(list);</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据Rowkey获取数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> rowKey</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String,String&gt; <span class="title">getFromHBase</span><span class="params">(String tableName,String rowKey)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Get get = <span class="keyword">new</span> Get(Bytes.toBytes(rowKey));</span><br><span class="line">        Result result = table.get(get);</span><br><span class="line">        List&lt;Cell&gt; cells = result.listCells();</span><br><span class="line">        HashMap&lt;String, String&gt; resMap = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">        <span class="keyword">for</span> (Cell cell: cells) &#123;</span><br><span class="line">            <span class="comment">//列</span></span><br><span class="line">            <span class="keyword">byte</span>[] column_bytes = CellUtil.cloneQualifier(cell);</span><br><span class="line">            <span class="comment">//值</span></span><br><span class="line">            <span class="keyword">byte</span>[] value_bytes = CellUtil.cloneValue(cell);</span><br><span class="line">            resMap.put(<span class="keyword">new</span> String(column_bytes),<span class="keyword">new</span> String(value_bytes));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="com-imooc-core-1"><a href="#com-imooc-core-1" class="headerlink" title="com.imooc.core"></a>com.imooc.core</h4><h5 id="DataIndex"><a href="#DataIndex" class="headerlink" title="DataIndex"></a>DataIndex</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataIndex代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.core;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.imooc.utils.EsUtil;</span><br><span class="line"><span class="keyword">import</span> com.imooc.utils.HBaseUtil;</span><br><span class="line"><span class="keyword">import</span> com.imooc.utils.RedisUtil;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在ES中对HBase中的数据建立索引</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataIndex</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Logger logger = LoggerFactory.getLogger(DataIndex<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        List&lt;String&gt; rowKeyList = <span class="keyword">null</span>;</span><br><span class="line">        Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1：首先从Redis的列表中获取Rowkey</span></span><br><span class="line">            jedis = RedisUtil.getJedis();</span><br><span class="line">            <span class="comment">//brpop如果获取到了数据，返回的list里面有两列，第一列是key的名称，第二列是具体的数据</span></span><br><span class="line">            rowKeyList = jedis.brpop(<span class="number">3</span>, <span class="string">"l_article_ids"</span>);</span><br><span class="line">            <span class="keyword">while</span> (rowKeyList != <span class="keyword">null</span>) &#123;</span><br><span class="line">                String rowKey = rowKeyList.get(<span class="number">1</span>);</span><br><span class="line">                <span class="comment">//2：根据Rowkey到HBase中获取数据的详细信息</span></span><br><span class="line">                Map&lt;String, String&gt; map = HBaseUtil.getFromHBase(<span class="string">"article"</span>, rowKey);</span><br><span class="line">                <span class="comment">//3：在ES中对数据建立索引</span></span><br><span class="line">                EsUtil.addIndex(<span class="string">"article"</span>,rowKey,map);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//循环从Redis的列表中获取Rowkey</span></span><br><span class="line">                rowKeyList = jedis.brpop(<span class="number">3</span>, <span class="string">"l_article_ids"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            logger.error(<span class="string">"数据建立索引失败："</span>+e.getMessage());</span><br><span class="line">            <span class="comment">//在这里可以考虑把获取出来的rowKey再push到Redis中，这样可以保证数据不丢</span></span><br><span class="line">            <span class="keyword">if</span>(rowKeyList!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                jedis.rpush(<span class="string">"l_article_ids"</span>,rowKeyList.get(<span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//向连接池返回连接</span></span><br><span class="line">            <span class="keyword">if</span>(jedis!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                RedisUtil.returnResource(jedis);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//注意：确认ES连接不再使用了再关闭连接(当知识运行一次，就可以要下面的代码；如果要一直运行()相当于try外层再加一个while(True)，然后后面运行完了sleep一会)，就要慎重考虑下面的代码该如何编写)，否则会导致client无法继续使用</span></span><br><span class="line">            <span class="keyword">try</span>&#123;</span><br><span class="line">                EsUtil.closeRestClient();</span><br><span class="line">            &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">                logger.error(<span class="string">"ES连接关闭失败："</span>+e.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="对接Web项目，提供页面检索功能"><a href="#对接Web项目，提供页面检索功能" class="headerlink" title="对接Web项目，提供页面检索功能"></a>对接Web项目，提供页面检索功能</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">完善web_fullsearch项目中和大数据相关的代码。</span><br><span class="line">最核心的代码就是EsUtil中的search方法：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 全文检索功能</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> index</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> start</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> row</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, Object&gt; <span class="title">search</span><span class="params">(String key, String index, <span class="keyword">int</span> start, <span class="keyword">int</span> row)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest();</span><br><span class="line"><span class="comment">//指定索引库，支持指定一个或者多个，也支持通配符</span></span><br><span class="line">searchRequest.indices(index);</span><br><span class="line"></span><br><span class="line"><span class="comment">//指定searchType</span></span><br><span class="line">searchRequest.searchType(SearchType.DFS_QUERY_THEN_FETCH);</span><br><span class="line"></span><br><span class="line"><span class="comment">//组装查询条件</span></span><br><span class="line">SearchSourceBuilder searchSourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line"><span class="comment">//如果传递了搜索参数，则拼接查询条件</span></span><br><span class="line"><span class="keyword">if</span>(StringUtils.isNotBlank(key))&#123;</span><br><span class="line">searchSourceBuilder.query(QueryBuilders.multiMatchQuery(key,<span class="string">"title"</span>,<span class="string">"describe"</span>,<span class="string">"content"</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//分页</span></span><br><span class="line">searchSourceBuilder.from(start);</span><br><span class="line">searchSourceBuilder.size(row);</span><br><span class="line"></span><br><span class="line"><span class="comment">//高亮</span></span><br><span class="line"><span class="comment">//设置高亮字段</span></span><br><span class="line">HighlightBuilder highlightBuilder =  <span class="keyword">new</span> HighlightBuilder()</span><br><span class="line">.field(<span class="string">"title"</span>)</span><br><span class="line">.field(<span class="string">"describe"</span>);<span class="comment">//支持多个高亮字段</span></span><br><span class="line"><span class="comment">//设置高亮字段的前缀和后缀内容</span></span><br><span class="line">highlightBuilder.preTags(<span class="string">"&lt;font color='red'&gt;"</span>);</span><br><span class="line">highlightBuilder.postTags(<span class="string">"&lt;/font&gt;"</span>);</span><br><span class="line">searchSourceBuilder.highlighter(highlightBuilder);</span><br><span class="line"></span><br><span class="line"><span class="comment">//指定查询条件</span></span><br><span class="line">searchRequest.source(searchSourceBuilder);</span><br><span class="line"></span><br><span class="line"><span class="comment">//执行查询操作</span></span><br><span class="line">SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line"><span class="comment">//存储返回给页面的数据</span></span><br><span class="line">Map&lt;String, Object&gt; map = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line"><span class="comment">//获取查询返回的结果</span></span><br><span class="line">SearchHits hits = searchResponse.getHits();</span><br><span class="line"><span class="comment">//获取数据总量</span></span><br><span class="line"><span class="keyword">long</span> numHits = hits.getTotalHits().value;</span><br><span class="line">map.put(<span class="string">"count"</span>,numHits);</span><br><span class="line">ArrayList&lt;Article&gt; arrayList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="comment">//获取具体内容</span></span><br><span class="line">SearchHit[] searchHits = hits.getHits();</span><br><span class="line"><span class="comment">//迭代解析具体内容</span></span><br><span class="line"><span class="keyword">for</span> (SearchHit hit: searchHits) &#123;</span><br><span class="line">Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();</span><br><span class="line">String id = hit.getId();</span><br><span class="line">String title = sourceAsMap.get(<span class="string">"title"</span>).toString();</span><br><span class="line">String author = sourceAsMap.get(<span class="string">"author"</span>).toString();</span><br><span class="line">String describe = sourceAsMap.get(<span class="string">"describe"</span>).toString();</span><br><span class="line">String time = sourceAsMap.get(<span class="string">"time"</span>).toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取高亮字段内容</span></span><br><span class="line">Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();</span><br><span class="line"><span class="comment">//获取title字段的高亮内容</span></span><br><span class="line">HighlightField highlightField = highlightFields.get(<span class="string">"title"</span>);</span><br><span class="line"><span class="keyword">if</span>(highlightField!=<span class="keyword">null</span>)&#123;</span><br><span class="line">Text[] fragments = highlightField.getFragments();</span><br><span class="line">title = <span class="string">""</span>;</span><br><span class="line"><span class="keyword">for</span> (Text text : fragments) &#123;</span><br><span class="line">title += text;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//获取describe字段的高亮内容</span></span><br><span class="line">HighlightField highlightField2 = highlightFields.get(<span class="string">"describe"</span>);</span><br><span class="line"><span class="keyword">if</span>(highlightField2!=<span class="keyword">null</span>)&#123;</span><br><span class="line">Text[] fragments = highlightField2.fragments();</span><br><span class="line">describe = <span class="string">""</span>;</span><br><span class="line"><span class="keyword">for</span> (Text text : fragments) &#123;</span><br><span class="line">describe += text;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//把文章信息封装到Article对象中</span></span><br><span class="line">Article article = <span class="keyword">new</span> Article();</span><br><span class="line">article.setId(id);</span><br><span class="line">article.setTitle(title);</span><br><span class="line">article.setAuthor(author);</span><br><span class="line">article.setDescribe(describe);</span><br><span class="line">article.setTime(time);</span><br><span class="line"><span class="comment">//最后再把拼装好的article添加到list对象汇总</span></span><br><span class="line">arrayList.add(article);</span><br><span class="line">&#125;</span><br><span class="line">map.put(<span class="string">"dataList"</span>,arrayList);</span><br><span class="line"><span class="keyword">return</span> map;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="从0-1运行项目"><a href="#从0-1运行项目" class="headerlink" title="从0~1运行项目"></a>从0~1运行项目</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">首先要确保Hadoop、Zookeeper、HBase、Redis、Elasticsearch这些服务都是正常的。</span><br><span class="line">1：首先在HBase中创建表：article</span><br><span class="line">hbase(main):001:0&gt; create &#39;article&#39;,&#39;info&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">2：在ES中创建索引库：article，通过article.json文件指定索引库的settings和mapping。</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;article&#39; -d @article.json</span><br><span class="line"></span><br><span class="line">确认一下索引库article的mapping信息：</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;article&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;article&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;dynamic&quot; : &quot;strict&quot;,</span><br><span class="line">      &quot;_source&quot; : &#123;</span><br><span class="line">        &quot;excludes&quot; : [</span><br><span class="line">          &quot;content&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;author&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;index&quot; : false</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot; : &quot;ik_max_word&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;describe&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot; : &quot;ik_max_word&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;time&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;date&quot;,</span><br><span class="line">          &quot;index&quot; : false,</span><br><span class="line">          &quot;format&quot; : &quot;yyyy-MM-dd HH:mm:ss&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;title&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot; : &quot;ik_max_word&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：需要确认ES集群中已经集成了ik分词器，否则这里执行会报错。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">3：在本地执行data_manager项目中的DataImport代码，将数据导入到HBase和Redis。</span><br><span class="line">修改项目中用到的HBaseUtil和RedisUtil工具类中的节点信息。</span><br><span class="line"></span><br><span class="line">注意：DataImport代码执行需要消耗一段时间。</span><br><span class="line"></span><br><span class="line">到HBase中验证数据：</span><br><span class="line">hbase(main):003:0&gt; count &#39;article&#39;</span><br><span class="line">100 row(s)</span><br><span class="line">Took 0.2357 seconds                                                   </span><br><span class="line">&#x3D;&gt; 100</span><br><span class="line"></span><br><span class="line">到Redis中验证数据：</span><br><span class="line">[root@bigdata04 redis-5.0.9]# redis-cli </span><br><span class="line">127.0.0.1:6379&gt; lrange l_article_ids 0 -1</span><br><span class="line">  1) &quot;0e52f3fb-50a7-43e6-ba1a-8f862464436e&quot;</span><br><span class="line">  2) &quot;0e0fbb25-421c-4419-9ccc-bbfcd7bc783f&quot;</span><br><span class="line">  3) &quot;0e0cbf00-d63c-4c1f-aa2e-9f96a5826029&quot;</span><br><span class="line">  4) &quot;0ddaccc1-af4c-47b1-b526-5a32b2d68aa5&quot;</span><br><span class="line">  5) &quot;0db74ee1-6243-4c3e-ba01-2eacba76188d&quot;</span><br><span class="line">  6) &quot;0d9eae28-b614-4347-9126-ad0ee7519ef1&quot;</span><br><span class="line">  7) &quot;0d7bd4de-159e-46ef-a75c-5d88de612def&quot;</span><br><span class="line">  8) &quot;0d5aeec8-3aa4-4fa5-b7eb-1ba0d0f2d715&quot;</span><br><span class="line">  9) &quot;0d286033-dcad-4514-85e1-2ae052ff531c&quot;</span><br><span class="line"> 10) &quot;0d239fca-c524-47ab-be9a-05133ea57a4f&quot;</span><br><span class="line"> 11) &quot;0d20beb1-a5c5-4638-99c5-9f69084b44c8&quot;</span><br><span class="line"> 12) &quot;0cd0ece6-9d61-4fda-bbcd-a9d9f0d7ff70&quot;</span><br><span class="line"> 13) &quot;0cc57b16-fbe6-488e-b080-dab0f0a71930&quot;</span><br><span class="line"> 14) &quot;0cb28936-e83f-46e9-8d36-70ae77018fdf&quot;</span><br><span class="line"> 15) &quot;0c85c890-57de-40cb-b7f6-8615eb1896fe&quot;</span><br><span class="line"> 16) &quot;0c30950e-8fb0-4212-ae13-e8e659515ff3&quot;</span><br><span class="line"> 17) &quot;0c2c9dca-b0db-42bc-aa6c-ad180501169d&quot;</span><br><span class="line"> 18) &quot;0bfdef9f-8ba9-4c2d-95e4-74284cf07500&quot;</span><br><span class="line"> 19) &quot;0bf5aef2-9ac4-4550-80f5-be862a04deba&quot;</span><br><span class="line"> 20) &quot;0be8351d-dd82-4e43-92c7-cb8819421b25&quot;</span><br><span class="line"> 21) &quot;0bbc79e8-9ab1-44c1-beec-ef2b22c48cfe&quot;</span><br><span class="line"> 22) &quot;0baf900c-2812-4bdf-8188-962ac9d17f23&quot;</span><br><span class="line"> 23) &quot;0ba2b80b-0b43-4916-9d04-8d67aa4e95b2&quot;</span><br><span class="line"> 24) &quot;0b672fc3-0737-467b-b32c-b888de1eaab6&quot;</span><br><span class="line"> 25) &quot;0b3dc9c2-96b6-4340-8af3-e07c8bac0ba8&quot;</span><br><span class="line"> 26) &quot;0b0161f5-d1d4-4109-8f12-a4b47dbff0e5&quot;</span><br><span class="line"> 27) &quot;0a088500-f708-470a-bda1-9e5a714c0b81&quot;</span><br><span class="line"> 28) &quot;09e8bd66-17e0-4e28-b804-a67df7312f90&quot;</span><br><span class="line"> 29) &quot;09d6e535-4f39-45ba-9857-c6ab01fe8823&quot;</span><br><span class="line"> 30) &quot;09a76b9e-030c-465b-8c80-b88fe5bbac16&quot;</span><br><span class="line"> 31) &quot;09a09479-56c1-4fd3-8893-3e4d307951b9&quot;</span><br><span class="line"> 32) &quot;09193761-e549-48ee-86fb-89295094f1e4&quot;</span><br><span class="line"> 33) &quot;090b766d-9f8e-4cb9-9a5f-b8c3373a9eb6&quot;</span><br><span class="line"> 34) &quot;09089c93-9848-4244-9eff-9034d434865b&quot;</span><br><span class="line"> 35) &quot;09036b9f-8b67-4275-837a-b884c8945a31&quot;</span><br><span class="line"> 36) &quot;08d8762e-dc47-49f5-ad14-de52f7fbb04e&quot;</span><br><span class="line"> 37) &quot;08839fde-1984-4739-bac2-f854989cdc6c&quot;</span><br><span class="line"> 38) &quot;0872be3a-2545-4a98-ba33-6ec148999130&quot;</span><br><span class="line"> 39) &quot;0862af37-2047-470d-a8b8-c57740a0df8b&quot;</span><br><span class="line"> 40) &quot;085f3acc-1f92-4dd2-b516-d0991b660680&quot;</span><br><span class="line"> 41) &quot;08210f1a-f553-4d3c-a09f-420dc8e6fe8c&quot;</span><br><span class="line"> 42) &quot;080639ea-ee70-47ff-b7d1-de75eb1e1196&quot;</span><br><span class="line"> 43) &quot;07ef53b0-9179-416e-bf8b-7720079fc87a&quot;</span><br><span class="line"> 44) &quot;07d79c1d-ceaa-4cd0-a3be-96186037b0c1&quot;</span><br><span class="line"> 45) &quot;07b71e20-a4b3-4f9d-b7c6-6db163cbabd1&quot;</span><br><span class="line"> 46) &quot;07928b77-a31e-4646-aff0-79ab61f8b605&quot;</span><br><span class="line"> 47) &quot;076077f1-8324-4ef3-9e8f-66c806644db6&quot;</span><br><span class="line"> 48) &quot;074a36a1-c7b4-4d1a-b8a1-3a01d0c1a2ec&quot;</span><br><span class="line"> 49) &quot;0734a9d3-4aa6-4206-aa12-9e26e67f0ef2&quot;</span><br><span class="line"> 50) &quot;072b6883-3258-4cff-8e90-77d4f011acfe&quot;</span><br><span class="line"> 51) &quot;06d75712-1fac-4a19-927f-f4c13ceba899&quot;</span><br><span class="line"> 52) &quot;06d498d1-97cd-4384-8ec1-82e9a1e0070b&quot;</span><br><span class="line"> 53) &quot;06beaece-c734-4eba-bcf7-64a9e43d6c55&quot;</span><br><span class="line"> 54) &quot;0682b625-f247-4c70-a628-4919946ff588&quot;</span><br><span class="line"> 55) &quot;0659a1c3-2f34-4342-827b-7c867a3394e3&quot;</span><br><span class="line"> 56) &quot;0647046c-2129-4c16-83f9-7857e9da6e2c&quot;</span><br><span class="line"> 57) &quot;0643961e-74ea-46d2-8da8-02309c6cc489&quot;</span><br><span class="line"> 58) &quot;061776ad-5742-4fcc-b997-9a25f5b6a4e0&quot;</span><br><span class="line"> 59) &quot;05ec598f-4b02-448f-88b6-f17f3891bd3f&quot;</span><br><span class="line"> 60) &quot;058ca914-aa70-4cf5-b69f-852e03729b52&quot;</span><br><span class="line"> 61) &quot;0504f099-995c-475d-97e8-f4d691673cbb&quot;</span><br><span class="line"> 62) &quot;04fce8dc-e27c-4f1c-bb4c-34597fad1810&quot;</span><br><span class="line"> 63) &quot;04b00310-c09a-44e2-9895-1fd22cd14148&quot;</span><br><span class="line"> 64) &quot;04997210-1552-4dcb-b13d-16e79ced1320&quot;</span><br><span class="line"> 65) &quot;04943196-717d-4594-bc83-a76189187c2e&quot;</span><br><span class="line"> 66) &quot;04940647-ff85-497d-b2fd-44f43600a569&quot;</span><br><span class="line"> 67) &quot;04755a1e-32b2-42b7-933e-405c8143eb8f&quot;</span><br><span class="line"> 68) &quot;047139c9-c351-4275-83be-c96b8105811b&quot;</span><br><span class="line"> 69) &quot;0451dbce-f8da-4862-b563-bee0bc5abdc6&quot;</span><br><span class="line"> 70) &quot;042bed42-fbb9-4c51-a424-089f579697e0&quot;</span><br><span class="line"> 71) &quot;03f3a775-6736-4ffb-bda0-b6e3ae215394&quot;</span><br><span class="line"> 72) &quot;03dde3c0-300f-4431-9f58-82dc3869020a&quot;</span><br><span class="line"> 73) &quot;03dd67bf-9044-4c00-a34d-c480d221afdb&quot;</span><br><span class="line"> 74) &quot;03b79d39-ddcb-48b2-8cdf-bd480041018d&quot;</span><br><span class="line"> 75) &quot;039b6212-3760-4261-a3ad-66427ca3ece2&quot;</span><br><span class="line"> 76) &quot;034e7e37-0e9a-49d0-86f7-f74956ad9c1c&quot;</span><br><span class="line"> 77) &quot;032f6cc9-0ec8-4014-a37c-ee233afad174&quot;</span><br><span class="line"> 78) &quot;02ce202c-4b37-4e21-b8c6-241323daaf4f&quot;</span><br><span class="line"> 79) &quot;02c32611-8f4c-44cc-85e6-9aabe50c5deb&quot;</span><br><span class="line"> 80) &quot;02617a09-af48-4885-9193-e36c73e1cc93&quot;</span><br><span class="line"> 81) &quot;022ec4b4-9061-489e-9c1f-d702187d9173&quot;</span><br><span class="line"> 82) &quot;022bfe1c-c04a-4dfd-83d1-545a2fa37d62&quot;</span><br><span class="line"> 83) &quot;0221116d-1140-4161-976e-780166b409ee&quot;</span><br><span class="line"> 84) &quot;0211f787-5122-4b95-90b2-36a60da5072c&quot;</span><br><span class="line"> 85) &quot;01f80b6f-ef70-4cf3-af3c-0c39cc1ca6df&quot;</span><br><span class="line"> 86) &quot;01ae3dff-19bf-4dfe-a417-f00c5cbee89e&quot;</span><br><span class="line"> 87) &quot;017b4fc5-a5b4-40f4-a22c-c0585dce1b8c&quot;</span><br><span class="line"> 88) &quot;0157ba2a-e6ea-4272-8257-be4d07278f41&quot;</span><br><span class="line"> 89) &quot;01476c80-aa75-46ed-b912-cad708cfb6da&quot;</span><br><span class="line"> 90) &quot;0125e066-aeb7-4053-ab85-e358076a23b0&quot;</span><br><span class="line"> 91) &quot;00ded12e-3974-46ff-b425-a1f4202d5380&quot;</span><br><span class="line"> 92) &quot;00b5546f-04a5-4d98-80b2-dbf2254f8f81&quot;</span><br><span class="line"> 93) &quot;0087283d-3773-4788-a86e-3a3a425d2240&quot;</span><br><span class="line"> 94) &quot;005dc64e-0134-43d8-b9bf-b3390e59ab12&quot;</span><br><span class="line"> 95) &quot;004ecf75-54b9-4aa7-a3ff-7ee2e0907f85&quot;</span><br><span class="line"> 96) &quot;004a2fb2-1547-4c63-8bfb-abfe812681aa&quot;</span><br><span class="line"> 97) &quot;0025b235-f4cd-45e4-90c3-46acbb3165fb&quot;</span><br><span class="line"> 98) &quot;001b046c-f1c9-457d-a8b7-cd157bc5d889&quot;</span><br><span class="line"> 99) &quot;00119d1d-b587-478f-86c0-ceb4f15c5cf7&quot;</span><br><span class="line">100) &quot;00093f78-11c7-43e1-abed-86c735252155&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">4：在本地执行data_manager项目中的DataIndex代码，在ES中建立索引。</span><br><span class="line"></span><br><span class="line">注意：需要修改项目中用到的EsUtil工具类中的节点信息。</span><br><span class="line"></span><br><span class="line">到ES中验证数据：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;article&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 393,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 5,</span><br><span class="line">    &quot;successful&quot; : 5,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 100,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 1.0,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;article&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;01476c80-aa75-46ed-b912-cad708cfb6da&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;author&quot; : &quot;腾讯新闻&quot;,</span><br><span class="line">          &quot;describe&quot; : &quot;　　浙江在线11月11日讯由于感情纠葛，阿松(化名)的婚外恋女友一怒之下抄起剪刀，几乎剪断了他的整根“命根子”。所幸医生及时抢救，周密施术，才保住了他的“男儿身”。昨天，正在义乌进行康复治疗的阿松，回想起前几天的经历，依旧百感交集。　　“小三”怒剪命根只因疑其不忠　　三十多岁的阿松是重庆人，在义乌工作，妻子女儿也都在义乌。　　阿松还有一个婚外恋女友，是在一家工厂里认识的，两个人相恋已经有一年多了。女友30多岁，也有自己的家庭。　　阿松说，最近一段时间，女友屡屡怀疑阿松“不忠”，据说是听到了一些传言。　　十几天前，被妒忌之火冲昏头脑的女友，居然想到了断其“命根”的“教训”办法。当时是下午3点多，&quot;,</span><br><span class="line">          &quot;time&quot; : &quot;2021-10-17 11:13:19&quot;,</span><br><span class="line">          &quot;title&quot; : &quot;“小三”怀疑男友不忠怒剪其“命根”&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;article&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;01f80b6f-ef70-4cf3-af3c-0c39cc1ca6df&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;author&quot; : &quot;腾讯新闻&quot;,</span><br><span class="line">          &quot;describe&quot; : &quot;　　　　两岸几十年的隔阂已经使共同的汉语言演变出一些差异。图为在台湾书店里的内地游客。　　　　台湾中华语文研习所董事长何景贤，手捧两种版本的《两岸现代汉语常用词典》。　　中新网11月11日电教育部语言文字应用管理司司长王登峰在接受香港《文汇报》访问时表示，两岸合编《中华大辞典》主要将以民间方式进行，届时将推出简体字括注繁体字以及繁体字括注简体字两个版本。另有消息人士透露，预计该项目将于年底启动。　　第五届两岸经贸文化论坛共同建议7月份曾就两岸合编《中华大辞典》达成初步意向。王登峰表示，大陆方面已经作好充分的准备工作，将主要以1996年两岸合编的《两岸现代汉语常用词典》为工作基础。两岸有关部门达&quot;,</span><br><span class="line">          &quot;time&quot; : &quot;2021-10-17 11:13:19&quot;,</span><br><span class="line">          &quot;title&quot; : &quot;两岸将合编中华大辞典收集新词汇(组图)&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">......</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">重点关注_source字段中是否包含content字段，如果包含此字段内容说明前面的mapping配置有问题，如果不包含此字段内容说明是正确的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">5：对web_fullsearch项目打包并运行。</span><br><span class="line">web_fullsearch项目是一个Javaweb项目，所以需要打war包，最终在Web容器中运行，在这里我们使用Tomcat这个web容器。</span><br><span class="line">打war包。</span><br><span class="line"></span><br><span class="line">D:\IdeaProjects\db_fullsearch\web_fullsearch&gt;mvn clean package -DskipTests</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 24.974s</span><br><span class="line">[INFO] Final Memory: 35M&#x2F;348M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">使用之前在学习ES课程的时候在bigdata04上部署的tomcat，将war包上传到tomcat的webapps目录下：</span><br><span class="line">[root@bigdata04 apache-tomcat-8.0.52]# cd webapps&#x2F;</span><br><span class="line">[root@bigdata04 webapps]# ll</span><br><span class="line">total 84888</span><br><span class="line">drwxr-xr-x. 14 root root     4096 Mar 16 20:37 docs</span><br><span class="line">drwxr-xr-x.  6 root root       83 Mar 16 20:37 examples</span><br><span class="line">drwxr-xr-x.  5 root root       87 Mar 16 20:37 host-manager</span><br><span class="line">drwxr-xr-x.  5 root root      103 Mar 16 20:37 manager</span><br><span class="line">drwxr-xr-x.  3 root root     4096 Mar 16 20:45 ROOT</span><br><span class="line">-rw-r--r--.  1 root root 86913853 Oct 17  2021 web_fullsearch.war</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">启动tomcat：</span><br><span class="line">[root@bigdata04 apache-tomcat-8.0.52]# bin&#x2F;startup.sh </span><br><span class="line"></span><br><span class="line">访问项目：</span><br><span class="line">http:&#x2F;&#x2F;bigdata04:8080&#x2F;web_fullsearch&#x2F;article</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121511613.png" alt="image-20230612151125293"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6：验证搜索功能。</span><br><span class="line">确认分页、高亮、查询文章明细数据等功能是否正常。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121511028.png" alt="image-20230612151144676"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306121512497.png" alt="image-20230612151156591"></p><h2 id="5-项目中遇到的典型问题"><a href="#5-项目中遇到的典型问题" class="headerlink" title="5 项目中遇到的典型问题"></a>5 项目中遇到的典型问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">单索引库查询效率降低的问题</span><br><span class="line"></span><br><span class="line">爬虫程序每天都会到互联网上采集新的文章数据，如果项目运行了半年、1年，所有的数据都存储到ES的一个索引库里面，这样会导致查询效率降低。</span><br><span class="line">可以考虑按周或者按月创建索引库，通过索引库别名关联最近半年内的索引库，实现默认查询最近半年内的数据。</span><br><span class="line">索引库的命名可以按照一定的规律，假设是按月建立索引库，则索引库的名称大致是这样的：</span><br><span class="line">article_202201</span><br><span class="line">article_202202</span><br><span class="line">article_202203</span><br><span class="line">......</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如果确实需要查询历史以来所有的数据，在查询的时候可以通过索引库通配符实现所有数据查询，使用这个索引库通配符即可：article_*，这样可以查询所有以article_开头的索引库。</span><br><span class="line"></span><br><span class="line">类似于百度这样，提供一个高级搜索选项，在里面进行一些个性化高级设置。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306141139433.png" alt="image-20230614113918727"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306141139401.png" alt="image-20230614113936078"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">自定义词库导致的历史数据查询异常问题</span><br><span class="line"></span><br><span class="line">当项目运行了一段时间以后，需要在自定义词库中新增一些词语，但是这个新增的词语只会针对后续新增的索引数据生效，对之前的索引数据是不生效的。</span><br><span class="line">针对之前的历史数据根据新增的词语进行查询，可能还是查不出来结果，这属于正常现象。</span><br><span class="line"></span><br><span class="line">如果想要实现新增的自定义词语在历史数据中可以查询出来数据，只有一个办法，就是重建索引，这个工作量就有点大了，所以一般情况下也不需要针对历史数据额外处理，知道有这个现象就行了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ES和HBase数据一致性问题</span><br><span class="line"></span><br><span class="line">针对这个问题，可以分析一下ES和HBase数据同步的三种方案，每种方案的优缺点。</span><br><span class="line">详细分析见第2章《ES和HBase数据同步的三种方案》小节。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">针对这个项目能不能只用ES？</span><br><span class="line"></span><br><span class="line">Elasticsearch最擅长的是快速复杂查询，虽然它支持分布式，也可以存储海量数据，但是这并不是它最擅长的功能，因为数据存储多了之后肯定会影响ES的性能，所以需要引入HBase实现海量数据存储，在ES中主要维护查询需要用到的字段。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ES和HBase中存储的数据有什么区别？</span><br><span class="line"></span><br><span class="line">可以详细分析一下ES中的mapping设计，重点分析文章的正文(content)字段。</span><br><span class="line">正文字段只需要在HBase中存储，不需要在ES中存储，但是需要在ES中建立索引，因为在查询的时候需要根据这个字段进行查询。</span><br><span class="line">详细解释见第4章内容。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306141142525.png" alt="image-20230614114230255"></p><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Elasticsearch" scheme="http://tianyong.fun/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-全文检索引擎Elasticsearch-2</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8EElasticsearch-2.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8EElasticsearch-2.html</id>
    <published>2023-06-02T10:03:09.000Z</published>
    <updated>2023-06-19T10:51:55.179Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="全文检索引擎Elasticsearch-2"><a href="#全文检索引擎Elasticsearch-2" class="headerlink" title="全文检索引擎Elasticsearch-2"></a>全文检索引擎Elasticsearch-2</h1><h2 id="3-Elasticsearch分词详解"><a href="#3-Elasticsearch分词详解" class="headerlink" title="3 Elasticsearch分词详解"></a>3 Elasticsearch分词详解</h2><h3 id="ES分词介绍"><a href="#ES分词介绍" class="headerlink" title="ES分词介绍"></a>ES分词介绍</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ES中在添加数据，也就是创建索引的时候，会先对数据进行分词。</span><br><span class="line">在查询索引数据的时候，也会先根据查询的关键字进行分词。</span><br><span class="line">所以在ES中分词这个过程是非常重要的，涉及到查询的效率和准确度。</span><br><span class="line"></span><br><span class="line">假设有一条数据，数据中有一个字段是titile，这个字段的值为LexCorp BFG-9000。</span><br><span class="line">我们想要把这条数据在ES中创建索引，方便后期检索。</span><br><span class="line"></span><br><span class="line">创建索引和查询索引的大致流程是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111457924.png" alt="image-20230611145714539"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">图中左侧是创建索引的过程：</span><br><span class="line">首先对数据进行空白字符分割，将LexCorp BFG-9000切分为LexCorp和BFG-9000。</span><br><span class="line">然后进行单词切割，将LexCorp切分为Lex和Corp，BFG-9000切分为BFG和9000。</span><br><span class="line">最后执行小写转换操作，将英文单词全部转换为小写。</span><br><span class="line"></span><br><span class="line">图中右侧是查询索引的过程：</span><br><span class="line">后期想要查询LexCorp BFG-9000这条数据，但是具体的内容记不清了，大致想起来了一些关键词Lex corp bfg9000。</span><br><span class="line">接下来就根据这些关键词进行查询，</span><br><span class="line">首先还是对数据进行空白符分割，将Lex corp bfg9000切分为Lex、corp 和bfg9000。</span><br><span class="line">然后进行单词切割，Lex和corp不变，将bfg9000切分为bfg和9000。</span><br><span class="line">最后执行小写转换操作，将英文单词全部转换为小写。</span><br><span class="line">这样其实在检索的时候就可以忽略英文大小写了，因为前面在创建索引的时候也会对英文进行小写转换。</span><br><span class="line"></span><br><span class="line">到这可以发现，使用Lex corp bfg9000是可以查找到LexCorp BFG-9000这条数据的，因为在经过空白符分割、单词切割、小写转换之后，这两条数据是一样的，其实只要能有一个单词是匹配的，就可以把这条数据查找出来。</span><br><span class="line"></span><br><span class="line">了解了这个流程之后，我们以后在搜索引擎里面搜索一些内容的时候其实就知道要怎么快速高效的检索内容了，只需要输入一些关键词，中间最好用空格隔开，针对英文字符不用纠结大小写了。</span><br><span class="line"></span><br><span class="line">这些数据在ES中分词之后，其实在底层会产生倒排索引，注意了，倒排索引是ES能够提供快速检索能力的核心，下面来看一下这个倒排索引</span><br></pre></td></tr></table></figure><h3 id="倒排索引介绍"><a href="#倒排索引介绍" class="headerlink" title="倒排索引介绍"></a>倒排索引介绍</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">假设有一批数据，数据中有两个字段，文档编号和文档内容。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111501138.png" alt="image-20230611150131888"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">针对这一批数据，在ES中创建索引之后，最终产生的倒排索引内容大致是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111501077.png" alt="image-20230611150153996"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">解释：</span><br><span class="line"></span><br><span class="line">单词ID：记录每个单词的单词编号。</span><br><span class="line">单词：对应的单词。</span><br><span class="line">文档频率：代表文档集合中有多少个文档包含某个单词。</span><br><span class="line">倒排列表：包含单词ID及其它必要信息。</span><br><span class="line">DocId：单词出现的文档id。</span><br><span class="line">TF：单词在某个文档中出现的次数。</span><br><span class="line">POS：单词在文档中出现的位置。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">以单词 加盟 为例，其单词编号为6，文档频率为3，代表整个文档集合中有3个文档包含这个单词，对应的倒排列表为&#123;(2;1;&lt;4&gt;),(3;1;&lt;7&gt;),(5;1;&lt;5&gt;)&#125;，含义是在文档2，3，5中出现过这个单词，在每个文档中都只出现过1次，单词 加盟 在第一个文档的POS（位置）是4，即文档的第四个单词是 加盟 ，其它的类似。</span><br><span class="line">这个倒排索引已经是一个非常完备的索引系统，实际搜索系统的索引结构基本如此。</span><br></pre></td></tr></table></figure><h3 id="分词器的作用"><a href="#分词器的作用" class="headerlink" title="分词器的作用"></a>分词器的作用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">前面分析了ES在创建索引和查询索引的时候都需要进行分词，分词需要用到分词器。下面来具体分析一下分词器的作用：</span><br><span class="line"></span><br><span class="line">分词器的作用是把一段文本中的词按照一定规则进行切分。</span><br><span class="line"></span><br><span class="line">分词器对应的是Analyzer类，这是一个抽象类，切分词的具体规则是由子类实现的。</span><br><span class="line">也就是说不同的分词器分词的规则是不同的！</span><br><span class="line"></span><br><span class="line">所以对于不同的语言，要用不同的分词器。</span><br><span class="line">在创建索引时会用到分词器，在搜索时也会用到分词器，这两个地方要使用同一个分词器，否则可能会搜索不出结果。</span><br></pre></td></tr></table></figure><h4 id="分词器的工作流程"><a href="#分词器的工作流程" class="headerlink" title="分词器的工作流程"></a>分词器的工作流程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">分词器的工作流程一般是这样的：</span><br><span class="line"></span><br><span class="line">1.切分关键词，把关键的、核心的单词切出来。</span><br><span class="line">2.去除停用词。</span><br><span class="line">3.对于英文单词，把所有字母转为小写（搜索时不区分大小写）</span><br><span class="line"></span><br><span class="line">针对停用词下面来详细分析一下：</span><br></pre></td></tr></table></figure><h5 id="停用词"><a href="#停用词" class="headerlink" title="停用词"></a>停用词</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">有些词在文本中出现的频率非常高，但是对文本所携带的信息基本不产生影响。</span><br><span class="line">例如：</span><br><span class="line">英文停用词：a、an、the、of等</span><br><span class="line">中文停用词：的、了、着、是、标点符号等</span><br><span class="line"></span><br><span class="line">文本经过分词之后，停用词通常被过滤掉，不会被进行索引。</span><br><span class="line">在检索的时候，用户的查询中如果含有停用词，检索系统也会将其过滤掉（因为用户输入的查询字符串也要进行分词处理）。</span><br><span class="line">排除停用词可以加快建立索引的速度，减小索引库文件的大小，并且还可以提高查询的准确度。</span><br><span class="line">如果不去除停用词，可能会存在这个情况：</span><br><span class="line">假设有一批文章数据，基本上每篇文章里面都有的这个词，那我在检索的时候只要输入了的这个词，那么所有文章都认为是满足条件的数据，但是这样是没有意义的。</span><br><span class="line"></span><br><span class="line">常见的英文停用词汇总：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">a</span><br><span class="line">about</span><br><span class="line">above</span><br><span class="line">after</span><br><span class="line">again</span><br><span class="line">against</span><br><span class="line">all</span><br><span class="line">am</span><br><span class="line">an</span><br><span class="line">and</span><br><span class="line">any</span><br><span class="line">are</span><br><span class="line">aren&#39;t</span><br><span class="line">as</span><br><span class="line">at</span><br><span class="line">be</span><br><span class="line">because</span><br><span class="line">been</span><br><span class="line">before</span><br><span class="line">being</span><br><span class="line">below</span><br><span class="line">between</span><br><span class="line">both</span><br><span class="line">but</span><br><span class="line">by</span><br><span class="line">can&#39;t</span><br><span class="line">cannot</span><br><span class="line">could</span><br><span class="line">couldn&#39;t</span><br><span class="line">did</span><br><span class="line">didn&#39;t</span><br><span class="line">do</span><br><span class="line">does</span><br><span class="line">doesn&#39;t</span><br><span class="line">doing</span><br><span class="line">don&#39;t</span><br><span class="line">down</span><br><span class="line">during</span><br><span class="line">each</span><br><span class="line">few</span><br><span class="line">for</span><br><span class="line">from</span><br><span class="line">further</span><br><span class="line">had</span><br><span class="line">hadn&#39;t</span><br><span class="line">has</span><br><span class="line">hasn&#39;t</span><br><span class="line">have</span><br><span class="line">haven&#39;t</span><br><span class="line">having</span><br><span class="line">he</span><br><span class="line">he&#39;d</span><br><span class="line">he&#39;ll</span><br><span class="line">he&#39;s</span><br><span class="line">her</span><br><span class="line">here</span><br><span class="line">here&#39;s</span><br><span class="line">hers</span><br><span class="line">herself</span><br><span class="line">him</span><br><span class="line">himself</span><br><span class="line">his</span><br><span class="line">how</span><br><span class="line">how&#39;s</span><br><span class="line">i</span><br><span class="line">i&#39;d</span><br><span class="line">i&#39;ll</span><br><span class="line">i&#39;m</span><br><span class="line">i&#39;ve</span><br><span class="line">if</span><br><span class="line">in</span><br><span class="line">into</span><br><span class="line">is</span><br><span class="line">isn&#39;t</span><br><span class="line">it</span><br><span class="line">it&#39;s</span><br><span class="line">its</span><br><span class="line">itself</span><br><span class="line">let&#39;s</span><br><span class="line">me</span><br><span class="line">more</span><br><span class="line">most</span><br><span class="line">mustn&#39;t</span><br><span class="line">my</span><br><span class="line">myself</span><br><span class="line">no</span><br><span class="line">nor</span><br><span class="line">not</span><br><span class="line">of</span><br><span class="line">off</span><br><span class="line">on</span><br><span class="line">once</span><br><span class="line">only</span><br><span class="line">or</span><br><span class="line">other</span><br><span class="line">ought</span><br><span class="line">our</span><br><span class="line">ours</span><br><span class="line">ourselves</span><br><span class="line">out</span><br><span class="line">over</span><br><span class="line">own</span><br><span class="line">same</span><br><span class="line">shan&#39;t</span><br><span class="line">she</span><br><span class="line">she&#39;d</span><br><span class="line">she&#39;ll</span><br><span class="line">she&#39;s</span><br><span class="line">should</span><br><span class="line">shouldn&#39;t</span><br><span class="line">so</span><br><span class="line">some</span><br><span class="line">such</span><br><span class="line">than</span><br><span class="line">that</span><br><span class="line">that&#39;s</span><br><span class="line">the</span><br><span class="line">their</span><br><span class="line">theirs</span><br><span class="line">them</span><br><span class="line">themselves</span><br><span class="line">then</span><br><span class="line">there</span><br><span class="line">there&#39;s</span><br><span class="line">these</span><br><span class="line">they</span><br><span class="line">they&#39;d</span><br><span class="line">they&#39;ll</span><br><span class="line">they&#39;re</span><br><span class="line">they&#39;ve</span><br><span class="line">this</span><br><span class="line">those</span><br><span class="line">through</span><br><span class="line">to</span><br><span class="line">too</span><br><span class="line">under</span><br><span class="line">until</span><br><span class="line">up</span><br><span class="line">very</span><br><span class="line">was</span><br><span class="line">wasn&#39;t</span><br><span class="line">we</span><br><span class="line">we&#39;d</span><br><span class="line">we&#39;ll</span><br><span class="line">we&#39;re</span><br><span class="line">we&#39;ve</span><br><span class="line">were</span><br><span class="line">weren&#39;t</span><br><span class="line">what</span><br><span class="line">what&#39;s</span><br><span class="line">when</span><br><span class="line">when&#39;s</span><br><span class="line">where</span><br><span class="line">where&#39;s</span><br><span class="line">which</span><br><span class="line">while</span><br><span class="line">who</span><br><span class="line">who&#39;s</span><br><span class="line">whom</span><br><span class="line">why</span><br><span class="line">why&#39;s</span><br><span class="line">with</span><br><span class="line">won&#39;t</span><br><span class="line">would</span><br><span class="line">wouldn&#39;t</span><br><span class="line">you</span><br><span class="line">you&#39;d</span><br><span class="line">you&#39;ll</span><br><span class="line">you&#39;re</span><br><span class="line">you&#39;ve</span><br><span class="line">your</span><br><span class="line">yours</span><br><span class="line">yourself</span><br><span class="line">yourselves</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">常见的中文停用词汇总：</span><br><span class="line"></span><br><span class="line">的</span><br><span class="line">一</span><br><span class="line">不</span><br><span class="line">在</span><br><span class="line">人</span><br><span class="line">有</span><br><span class="line">是</span><br><span class="line">为</span><br><span class="line">以</span><br><span class="line">于</span><br><span class="line">上</span><br><span class="line">他</span><br><span class="line">而</span><br><span class="line">后</span><br><span class="line">之</span><br><span class="line">来</span><br><span class="line">及</span><br><span class="line">了</span><br><span class="line">因</span><br><span class="line">下</span><br><span class="line">可</span><br><span class="line">到</span><br><span class="line">由</span><br><span class="line">这</span><br><span class="line">与</span><br><span class="line">也</span><br><span class="line">此</span><br><span class="line">但</span><br><span class="line">并</span><br><span class="line">个</span><br><span class="line">其</span><br><span class="line">已</span><br><span class="line">无</span><br><span class="line">小</span><br><span class="line">我</span><br><span class="line">们</span><br><span class="line">起</span><br><span class="line">最</span><br><span class="line">再</span><br><span class="line">今</span><br><span class="line">去</span><br><span class="line">好</span><br><span class="line">只</span><br><span class="line">又</span><br><span class="line">或</span><br><span class="line">很</span><br><span class="line">亦</span><br><span class="line">某</span><br><span class="line">把</span><br><span class="line">那</span><br><span class="line">你</span><br><span class="line">乃</span><br><span class="line">它</span><br><span class="line">吧</span><br><span class="line">被</span><br><span class="line">比</span><br><span class="line">别</span><br><span class="line">趁</span><br><span class="line">当</span><br><span class="line">从</span><br><span class="line">到</span><br><span class="line">得</span><br><span class="line">打</span><br><span class="line">凡</span><br><span class="line">儿</span><br><span class="line">尔</span><br><span class="line">该</span><br><span class="line">各</span><br><span class="line">给</span><br><span class="line">跟</span><br><span class="line">和</span><br><span class="line">何</span><br><span class="line">还</span><br><span class="line">即</span><br><span class="line">几</span><br><span class="line">既</span><br><span class="line">看</span><br><span class="line">据</span><br><span class="line">距</span><br><span class="line">靠</span><br><span class="line">啦</span><br><span class="line">了</span><br><span class="line">另</span><br><span class="line">么</span><br><span class="line">每</span><br><span class="line">们</span><br><span class="line">嘛</span><br><span class="line">拿</span><br><span class="line">哪</span><br><span class="line">那</span><br><span class="line">您</span><br><span class="line">凭</span><br><span class="line">且</span><br><span class="line">却</span><br><span class="line">让</span><br><span class="line">仍</span><br><span class="line">啥</span><br><span class="line">如</span><br><span class="line">若</span><br><span class="line">使</span><br><span class="line">谁</span><br><span class="line">虽</span><br><span class="line">随</span><br><span class="line">同</span><br><span class="line">所</span><br><span class="line">她</span><br><span class="line">哇</span><br><span class="line">嗡</span><br><span class="line">往</span><br><span class="line">哪</span><br><span class="line">些</span><br><span class="line">向</span><br><span class="line">沿</span><br><span class="line">哟</span><br><span class="line">用</span><br><span class="line">于</span><br><span class="line">咱</span><br><span class="line">则</span><br><span class="line">怎</span><br><span class="line">曾</span><br><span class="line">至</span><br><span class="line">致</span><br><span class="line">着</span><br><span class="line">诸</span><br><span class="line">自</span><br></pre></td></tr></table></figure><h5 id="中文分词方式"><a href="#中文分词方式" class="headerlink" title="中文分词方式"></a>中文分词方式</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">针对中文而言，在分词的时候有多种分词规则：</span><br><span class="line">常见的有单字分词、二分法分词、词库分词等</span><br><span class="line">单字分词：&quot;我&quot;、&quot;们&quot;、&quot;是&quot;、&quot;中&quot;、&quot;国&quot;、&quot;人&quot;</span><br><span class="line">二分法分词：&quot;我们&quot;、&quot;们是&quot;、&quot;是中&quot;、&quot;中国&quot;、&quot;国人&quot;。</span><br><span class="line">词库分词：按照某种算法构造词，然后去匹配已建好的词库集合，如果匹配到就切分出来成为词语。</span><br><span class="line"></span><br><span class="line">从这里面可以看出来，其实最理想的中文分词方式是词库分词。</span><br></pre></td></tr></table></figure><h5 id="常见的中文分词器"><a href="#常见的中文分词器" class="headerlink" title="常见的中文分词器"></a>常见的中文分词器</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">针对前面分析的几种中文分词方式，对应的有一些已经实现好的中分分词器。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111510363.png" alt="image-20230611151020118"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在词库分词方式领域里面，最经典的就是IK分词器，你懂得！</span><br></pre></td></tr></table></figure><h4 id="ES中文分词插件-es-ik"><a href="#ES中文分词插件-es-ik" class="headerlink" title="ES中文分词插件(es-ik)"></a>ES中文分词插件(es-ik)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在中文数据检索场景中，为了提供更好的检索效果，需要在ES中集成中文分词器，因为ES默认是按照英文的分词规则进行分词的，基本上可以认为是单字分词，对中文分词效果不理想。</span><br><span class="line">ES之前是没有提供中文分词器的，现在官方也提供了一些，但是在中文分词领域，IK分词器是不可撼动的，所以在这里我们主要讲一下如何在ES中集成IK这个中文分词器。</span><br><span class="line">首先下载es-ik插件，需要到github上下载。</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;medcl&#x2F;elasticsearch-analysis-ik</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111515484.png" alt="image-20230611151532296"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111515497.png" alt="image-20230611151550453"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">最终的下载地址为：</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;medcl&#x2F;elasticsearch-analysis-ik&#x2F;releases&#x2F;download&#x2F;v7.13.4&#x2F;elasticsearch-analysis-ik-7.13.4.zip</span><br><span class="line"></span><br><span class="line">注意：在ES中安装IK插件的时候，需要在ES集群的所有节点中都安装。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1：将下载好的elasticsearch-analysis-ik-7.13.4.zip上传到bigdata01的&#x2F;data&#x2F;soft&#x2F; elasticsearch-7.13.4目录中。</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# ll elasticsearch-analysis-ik-7.13.4.zip </span><br><span class="line">-rw-r--r--. 1 root root 4504502 Sep  3  2021 elasticsearch-analysis-ik-7.13.4.zip</span><br><span class="line"></span><br><span class="line">2：将elasticsearch-analysis-ik-7.13.4.zip远程拷贝到bigdata02和bigdata03上。</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# scp -rq elasticsearch-analysis-ik-7.13.4.zip  bigdata02:&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# scp -rq elasticsearch-analysis-ik-7.13.4.zip  bigdata03:&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3：在bigdata01节点离线安装IK插件。</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# bin&#x2F;elasticsearch-plugin install file:&#x2F;&#x2F;&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;elasticsearch-analysis-ik-7.13.4.zip</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">注意：在安装的过程中会有警告信息提示需要输入y确认继续向下执行。</span><br><span class="line"></span><br><span class="line">最后看到如下内容就表示安装成功了。</span><br><span class="line">-&gt; Installed analysis-ik</span><br><span class="line">-&gt; Please restart Elasticsearch to activate any plugins installed</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">config目录下面的analysis-ik里面存储的是ik的配置文件信息。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# cd config&#x2F;</span><br><span class="line">[root@bigdata01 config]# ll analysis-ik&#x2F;</span><br><span class="line">total 8260</span><br><span class="line">-rwxrwxrwx. 1 root root 5225922 Feb 27 20:57 extra_main.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   63188 Feb 27 20:57 extra_single_word.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   63188 Feb 27 20:57 extra_single_word_full.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   10855 Feb 27 20:57 extra_single_word_low_freq.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     156 Feb 27 20:57 extra_stopword.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     625 Feb 27 20:57 IKAnalyzer.cfg.xml</span><br><span class="line">-rwxrwxrwx. 1 root root 3058510 Feb 27 20:57 main.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     123 Feb 27 20:57 preposition.dic</span><br><span class="line">-rwxrwxrwx. 1 root root    1824 Feb 27 20:57 quantifier.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     164 Feb 27 20:57 stopword.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     192 Feb 27 20:57 suffix.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     752 Feb 27 20:57 surname.dic</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plugins目录下面的analysis-ik里面存储的是ik的核心jar包。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# cd plugins&#x2F;</span><br><span class="line">[root@bigdata01 plugins]# ll analysis-ik&#x2F;</span><br><span class="line">total 1428</span><br><span class="line">-rwxrwxrwx. 1 root root 263965 Feb 27 20:56 commons-codec-1.9.jar</span><br><span class="line">-rwxrwxrwx. 1 root root  61829 Feb 27 20:56 commons-logging-1.2.jar</span><br><span class="line">-rwxrwxrwx. 1 root root  54626 Feb 27 20:56 elasticsearch-analysis-ik-7.13.4.jar</span><br><span class="line">-rwxrwxrwx. 1 root root 736658 Feb 27 20:56 httpclient-4.5.2.jar</span><br><span class="line">-rwxrwxrwx. 1 root root 326724 Feb 27 20:56 httpcore-4.4.4.jar</span><br><span class="line">-rwxrwxrwx. 1 root root   1807 Feb 27 20:56 plugin-descriptor.properties</span><br><span class="line">-rwxrwxrwx. 1 root root    125 Feb 27 20:56 plugin-security.policy</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">4：在bigdata02节点离线安装IK插件。</span><br><span class="line"></span><br><span class="line">5：在bigdata03节点离线安装IK插件。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">6：如果集群正在运行，则需要停止集群。</span><br><span class="line">在bigdata01上停止。</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# jps</span><br><span class="line">1680 Elasticsearch</span><br><span class="line">2047 Jps</span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# kill 1680</span><br><span class="line"></span><br><span class="line">在bigdata02上停止。</span><br><span class="line"></span><br><span class="line">在bigdata03上停止。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">7：修改elasticsearch-7.13.4的plugins目录下analysis-ik子目录的权限。</span><br><span class="line">直接修改elasticsearch-7.13.4目录的权限即可。</span><br><span class="line">在bigdata01上执行。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 elasticsearch-7.13.4]# cd ..</span><br><span class="line">[root@bigdata01 soft]# chmod -R 777 elasticsearch-7.13.4</span><br><span class="line"></span><br><span class="line">在bigdata02上执行。</span><br><span class="line">在bigdata03上执行。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">8：重新启动ES集群。</span><br><span class="line">在bigdata01上执行。</span><br><span class="line">[root@bigdata01 soft]# su es</span><br><span class="line">[es@bigdata01 soft]$ cd &#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ bin&#x2F;elasticsearch -d</span><br><span class="line"></span><br><span class="line">在bigdata02上执行。</span><br><span class="line">在bigdata03上执行。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">9：验证IK的分词效果。</span><br><span class="line">首先使用默认分词器测试中文分词效果。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;我们是中国人&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;我&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 1,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;们&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 1,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;是&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 3,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;中&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;国&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 4,</span><br><span class="line">      &quot;end_offset&quot; : 5,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 4</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;人&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 5,</span><br><span class="line">      &quot;end_offset&quot; : 6,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 5</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">然后使用IK分词器测试中文分词效果。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 soft]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;我们是中国人&quot;,&quot;tokenizer&quot;:&quot;ik_max_word&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;我们&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;是&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 3,</span><br><span class="line">      &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;中国人&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 6,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;中国&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 5,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;国人&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 4,</span><br><span class="line">      &quot;end_offset&quot; : 6,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 4</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在这里我们发现分出来的单词里面有一个是，这个单词其实可以认为是一个停用词，在分词的时候是不需要切分出来的。</span><br><span class="line">在这被切分出来了，那也就意味着在进行停用词过滤的时候没有过滤掉。</span><br><span class="line"></span><br><span class="line">针对ik这个词库而言，它的停用词词库里面都有哪些单词呢？</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 elasticsearch-7.13.4]# cd config&#x2F;analysis-ik&#x2F;</span><br><span class="line">[root@bigdata01 analysis-ik]# ll</span><br><span class="line">total 8260</span><br><span class="line">-rwxrwxrwx. 1 root root 5225922 Feb 27 20:57 extra_main.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   63188 Feb 27 20:57 extra_single_word.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   63188 Feb 27 20:57 extra_single_word_full.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   10855 Feb 27 20:57 extra_single_word_low_freq.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     156 Feb 27 20:57 extra_stopword.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     625 Feb 27 20:57 IKAnalyzer.cfg.xml</span><br><span class="line">-rwxrwxrwx. 1 root root 3058510 Feb 27 20:57 main.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     123 Feb 27 20:57 preposition.dic</span><br><span class="line">-rwxrwxrwx. 1 root root    1824 Feb 27 20:57 quantifier.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     164 Feb 27 20:57 stopword.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     192 Feb 27 20:57 suffix.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     752 Feb 27 20:57 surname.dic</span><br><span class="line">[root@bigdata01 analysis-ik]# more stopword.dic </span><br><span class="line">a</span><br><span class="line">an</span><br><span class="line">and</span><br><span class="line">are</span><br><span class="line">as</span><br><span class="line">at</span><br><span class="line">be</span><br><span class="line">but</span><br><span class="line">by</span><br><span class="line">for</span><br><span class="line">if</span><br><span class="line">in</span><br><span class="line">into</span><br><span class="line">is</span><br><span class="line">it</span><br><span class="line">no</span><br><span class="line">not</span><br><span class="line">of</span><br><span class="line">on</span><br><span class="line">or</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ik的停用词词库是stopword.dic这个文件，这个文件里面目前都是一些英文停用词。</span><br><span class="line">我们可以手工在这个文件中把中文停用词添加进去，先添加 是 这个停用词。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 analysis-ik]# vi stopword.dic </span><br><span class="line">.....</span><br><span class="line">是</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">然后把这个文件的改动同步到集群中的所有节点上。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 analysis-ik]# scp -rq stopword.dic bigdata02:&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;config&#x2F;analysis-ik&#x2F;</span><br><span class="line">[root@bigdata01 analysis-ik]# scp -rq stopword.dic bigdata03:&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;config&#x2F;analysis-ik&#x2F;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">重启集群让配置生效。</span><br><span class="line"></span><br><span class="line">再使用IK分词器测试一下中文分词效果。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 analysis-ik]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;我们是中国人&quot;,&quot;tokenizer&quot;:&quot;ik_max_word&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;我们&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;中国人&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 6,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;中国&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 5,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;国人&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 4,</span><br><span class="line">      &quot;end_offset&quot; : 6,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 3</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此时再查看会发现没有&quot;是&quot; 这个单词了，相当于在过滤停用词的时候把它过滤掉了。</span><br></pre></td></tr></table></figure><h3 id="es-ik添加自定义词库"><a href="#es-ik添加自定义词库" class="headerlink" title="es-ik添加自定义词库"></a>es-ik添加自定义词库</h3><h4 id="自定义词库"><a href="#自定义词库" class="headerlink" title="自定义词库"></a>自定义词库</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">针对一些特殊的词语在分词的时候也需要能够识别。</span><br><span class="line">例如：公司产品的名称或者网络上新流行的词语</span><br><span class="line">假设我们公司开发了一款新产品，命名为：数据大脑，我们希望ES在分词的时候能够把这个产品名称直接识别成一个词语。</span><br><span class="line">现在使用ik分词器测试一下分词效果：</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;数据大脑&quot;,&quot;tokenizer&quot;:&quot;ik_max_word&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;数据&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;大脑&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">结果发现ik分词器会把数据大脑分为 数据 和 大脑这两个单词。</span><br><span class="line">因为这个词语是我们自己造出来的，并不是通用的词语，所以ik分词器识别不出来也属于正常。</span><br><span class="line">想要让IK分词器识别出来，就需要自定义词库了，也就是把我们自己造的词语添加到词库里面，这样在分词的时候就可以识别到了。</span><br><span class="line">下面演示一下如何在IK中自定义词库：</span><br><span class="line">1：首先在ik插件对应的配置文件目录下创建一个自定义词库文件my.dic</span><br><span class="line">首先在bigdata01节点上操作。</span><br><span class="line">切换到es用户，进入到ik插件对应的配置文件目录</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# su es</span><br><span class="line">[es@bigdata01 root]$ cd &#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4</span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ cd config</span><br><span class="line">[es@bigdata01 config]$ cd analysis-ik</span><br><span class="line">[es@bigdata01 analysis-ik]$ ll</span><br><span class="line">total 8260</span><br><span class="line">-rwxrwxrwx. 1 root root 5225922 Feb 27 20:57 extra_main.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   63188 Feb 27 20:57 extra_single_word.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   63188 Feb 27 20:57 extra_single_word_full.dic</span><br><span class="line">-rwxrwxrwx. 1 root root   10855 Feb 27 20:57 extra_single_word_low_freq.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     156 Feb 27 20:57 extra_stopword.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     625 Feb 27 20:57 IKAnalyzer.cfg.xml</span><br><span class="line">-rwxrwxrwx. 1 root root 3058510 Feb 27 20:57 main.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     123 Feb 27 20:57 preposition.dic</span><br><span class="line">-rwxrwxrwx. 1 root root    1824 Feb 27 20:57 quantifier.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     171 Feb 27 21:42 stopword.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     192 Feb 27 20:57 suffix.dic</span><br><span class="line">-rwxrwxrwx. 1 root root     752 Feb 27 20:57 surname.dic</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">创建自定义词库文件my.dic</span><br><span class="line">直接在文件中添加词语即可，每一个词语一行。</span><br><span class="line"></span><br><span class="line">[es@bigdata01 analysis-ik]$ vi my.dic</span><br><span class="line">数据大脑</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">注意：这个my.dic词库文件可以在Linux中直接使用vi命令创建，或者在Windows中创建之后上传到这里。</span><br><span class="line"></span><br><span class="line">-如果是在Linux中直接使用vi命令创建，可以直接使用。</span><br><span class="line">-如果是在Windows中创建的，需要注意文件的编码必须是UTF-8 without BOM 格式【UTF-8 无 BOM格式】</span><br><span class="line"></span><br><span class="line">以Notepad++为例：新版本的Notepad++里面的文件编码有这么几种，需要选择【使用UTF-8编码】，这个就是UTF-8 without BOM 格式。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111535279.png" alt="image-20230611153519003"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">2：修改ik的IKAnalyzer.cfg.xml配置文件</span><br><span class="line">进入到ik插件对应的配置文件目录中，修改IKAnalyzer.cfg.xml配置文件</span><br><span class="line"></span><br><span class="line">[es@bigdata01 analysis-ik]$ vi IKAnalyzer.cfg.xml </span><br><span class="line"></span><br><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;!DOCTYPE properties SYSTEM &quot;http:&#x2F;&#x2F;java.sun.com&#x2F;dtd&#x2F;properties.dtd&quot;&gt;</span><br><span class="line">&lt;properties&gt;</span><br><span class="line">        &lt;comment&gt;IK Analyzer 扩展配置&lt;&#x2F;comment&gt;</span><br><span class="line">        &lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span><br><span class="line">        &lt;entry key&#x3D;&quot;ext_dict&quot;&gt;my.dic&lt;&#x2F;entry&gt;</span><br><span class="line">         &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span><br><span class="line">        &lt;entry key&#x3D;&quot;ext_stopwords&quot;&gt;&lt;&#x2F;entry&gt;</span><br><span class="line">        &lt;!--用户可以在这里配置远程扩展字典 --&gt;</span><br><span class="line">        &lt;!-- &lt;entry key&#x3D;&quot;remote_ext_dict&quot;&gt;words_location&lt;&#x2F;entry&gt; --&gt;</span><br><span class="line">        &lt;!--用户可以在这里配置远程扩展停止词字典--&gt;</span><br><span class="line">        &lt;!-- &lt;entry key&#x3D;&quot;remote_ext_stopwords&quot;&gt;words_location&lt;&#x2F;entry&gt;--&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：需要把my.dic词库文件添加到key&#x3D;&quot;ext_dict&quot;这个entry中，切记不要随意新增entry，随意新增的entry是不被IK识别的，并且entry的名称也不能乱改，否则也不会识别。</span><br><span class="line"></span><br><span class="line">如果需要指定多个自定义词库文件的话需要使用分号;隔开。</span><br><span class="line">例如：&lt;entry key&#x3D;&quot;ext_dict&quot;&gt;my.dic;your.dic&lt;&#x2F;entry&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">3：将修改好的IK配置文件复制到集群中的所有节点中</span><br><span class="line"></span><br><span class="line">注意：如果是多个节点的ES集群，一定要把配置远程拷贝到其他节点。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">先从bigdata01上将my.dic拷贝到bigdata02和bigdata03</span><br><span class="line"></span><br><span class="line">[es@bigdata01 analysis-ik]$ scp -rq my.dic bigdata02:&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;config&#x2F;analysis-ik&#x2F;</span><br><span class="line">The authenticity of host &#39;bigdata02 (192.168.182.101)&#39; can&#39;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:SnzVynyweeRcPIorakoDQRxFhugZp6PNIPV3agX&#x2F;bZM.</span><br><span class="line">ECDSA key fingerprint is MD5:f6:1a:48:78:64:77:89:52:c4:ad:63:82:a5:d5:57:92.</span><br><span class="line">Are you sure you want to continue connecting (yes&#x2F;no)? yes</span><br><span class="line">es@bigdata02&#39;s password: </span><br><span class="line">[es@bigdata01 analysis-ik]$ scp -rq my.dic bigdata03:&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;config&#x2F;analysis-ik&#x2F;</span><br><span class="line">The authenticity of host &#39;bigdata03 (192.168.182.102)&#39; can&#39;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:SnzVynyweeRcPIorakoDQRxFhugZp6PNIPV3agX&#x2F;bZM.</span><br><span class="line">ECDSA key fingerprint is MD5:f6:1a:48:78:64:77:89:52:c4:ad:63:82:a5:d5:57:92.</span><br><span class="line">Are you sure you want to continue connecting (yes&#x2F;no)? yes</span><br><span class="line">es@bigdata03&#39;s password:</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：因为现在使用的是普通用户es，所以在使用scp的时候需要指定目标机器的用户名（如果是root可以省略不写），并且还需要手工输入密码，因为之前是基于root用户做的免密码登录。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">再从bigdata01上将IKAnalyzer.cfg.xml拷贝到bigdata02和bigdata03</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：如果后期想增加自定义停用词库，也需要按照这个思路进行添加，只不过停用词库需要配置到 key&#x3D;&quot;ext_stopwords&quot;这个entry中。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">4：重启ES验证一下自定义词库的分词效果</span><br><span class="line"></span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;数据大脑&quot;,&quot;tokenizer&quot;:&quot;ik_max_word&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;数据大脑&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;数据&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;大脑&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">现在发现数据大脑这个词语可以被识别出来了，说明自定义词库生效了。</span><br></pre></td></tr></table></figure><h4 id="热更新词库"><a href="#热更新词库" class="headerlink" title="热更新词库"></a>热更新词库</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">针对前面分析的自定义词库，后期只要词库内容发生了变动，就需要重启ES才能生效，在实际工作中，频繁重启ES集群不是一个好办法</span><br><span class="line">所以ES提供了热更新词库的解决方案，在不重启ES集群的情况下识别新增的词语，这样就很方便了，也不会对线上业务产生影响。</span><br><span class="line">下面来演示一下热更新词库的使用：</span><br><span class="line">1：在bigdata04上部署HTTP服务</span><br><span class="line">在这使用tomcat作为Web容器，先下载一个tomcat 8.x版本。</span><br><span class="line">tomcat 8.0.52版本下载地址：</span><br><span class="line">https:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;tomcat&#x2F;tomcat-8&#x2F;v8.0.52&#x2F;bin&#x2F;apache-tomcat-8.0.52.tar.gz</span><br><span class="line">上传到bigdata04上的&#x2F;data&#x2F;soft目录里面，并且解压</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata04 soft]# ll apache-tomcat-8.0.52.tar.gz </span><br><span class="line">-rw-r--r--. 1 root root 9435483 Sep 22  2021 apache-tomcat-8.0.52.tar.gz</span><br><span class="line">[root@bigdata04 soft]# tar -zxvf apache-tomcat-8.0.52.tar.gz</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tomcat的ROOT项目中创建一个自定义词库文件hot.dic，在文件中输入一行内容：测试</span><br><span class="line">[root@bigdata04 soft]# cd apache-tomcat-8.0.52</span><br><span class="line">[root@bigdata04 apache-tomcat-8.0.52]# cd webapps&#x2F;ROOT&#x2F;</span><br><span class="line">[root@bigdata04 ROOT]# vi hot.dic</span><br><span class="line">测试</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">启动Tomcat</span><br><span class="line"></span><br><span class="line">[root@bigdata04 ROOT]# cd &#x2F;data&#x2F;soft&#x2F;apache-tomcat-8.0.52</span><br><span class="line">[root@bigdata04 apache-tomcat-8.0.52]# bin&#x2F;startup.sh </span><br><span class="line">Using CATALINA_BASE:   &#x2F;data&#x2F;soft&#x2F;apache-tomcat-8.0.52</span><br><span class="line">Using CATALINA_HOME:   &#x2F;data&#x2F;soft&#x2F;apache-tomcat-8.0.52</span><br><span class="line">Using CATALINA_TMPDIR: &#x2F;data&#x2F;soft&#x2F;apache-tomcat-8.0.52&#x2F;temp</span><br><span class="line">Using JRE_HOME:        &#x2F;data&#x2F;soft&#x2F;jdk1.8</span><br><span class="line">Using CLASSPATH:       &#x2F;data&#x2F;soft&#x2F;apache-tomcat-8.0.52&#x2F;bin&#x2F;bootstrap.jar:&#x2F;data&#x2F;soft&#x2F;apache-tomcat-8.0.52&#x2F;bin&#x2F;tomcat-juli.jar</span><br><span class="line">Tomcat started.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">验证一下hot.dic文件是否可以通过浏览器访问：</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111553223.png" alt="image-20230611155315334"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">注意：页面会显示乱码，这是正常的，不用处理即可。</span><br><span class="line"></span><br><span class="line">2：修改ES集群中ik插件的IKAnalyzer.cfg.xml配置文件</span><br><span class="line">在bigdata01上修改。</span><br><span class="line">在key&#x3D;&quot;remote_ext_dict&quot;这个entry中添加hot.dic的远程访问链接</span><br><span class="line">http:&#x2F;&#x2F;bigdata04:8080&#x2F;hot.dic</span><br><span class="line"></span><br><span class="line">注意：一定要记得去掉key&#x3D;&quot;remote_ext_dict&quot;这个entry外面的注释，否则添加的内容是不生效的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[es@bigdata01 analysis-ik]$ vi IKAnalyzer.cfg.xml </span><br><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;!DOCTYPE properties SYSTEM &quot;http:&#x2F;&#x2F;java.sun.com&#x2F;dtd&#x2F;properties.dtd&quot;&gt;</span><br><span class="line">&lt;properties&gt;</span><br><span class="line">        &lt;comment&gt;IK Analyzer 扩展配置&lt;&#x2F;comment&gt;</span><br><span class="line">        &lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span><br><span class="line">        &lt;entry key&#x3D;&quot;ext_dict&quot;&gt;my.dic&lt;&#x2F;entry&gt;</span><br><span class="line">         &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span><br><span class="line">        &lt;entry key&#x3D;&quot;ext_stopwords&quot;&gt;&lt;&#x2F;entry&gt;</span><br><span class="line">        &lt;!--用户可以在这里配置远程扩展字典 --&gt;</span><br><span class="line">        &lt;entry key&#x3D;&quot;remote_ext_dict&quot;&gt;http:&#x2F;&#x2F;bigdata04:8080&#x2F;hot.dic&lt;&#x2F;entry&gt; </span><br><span class="line">        &lt;!--用户可以在这里配置远程扩展停止词字典--&gt;</span><br><span class="line">        &lt;!-- &lt;entry key&#x3D;&quot;remote_ext_stopwords&quot;&gt;words_location&lt;&#x2F;entry&gt;--&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">3：将修改好的IK配置文件复制到集群中的所有节点中</span><br><span class="line"></span><br><span class="line">4：重启ES集群验证效果。</span><br><span class="line">因为修改了配置，所以需要重启集群。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">验证：</span><br><span class="line">对北京雾霾这个词语进行分词</span><br><span class="line"></span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;北京雾霾&quot;,&quot;tokenizer&quot;:&quot;ik_max_word&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;北京&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;雾&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 3,</span><br><span class="line">      &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;霾&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">正常情况下 北京雾霾 会被分被拆分为多个词语，但是在这我希望ES能够把 北京雾霾 认为是一个完整的词语，又不希望重启ES。</span><br><span class="line">这样就可以修改前面配置的hot.dic文件，在里面增加一个词语：北京雾霾</span><br><span class="line">在bigdata04里面操作，此时可以在Linux中直接编辑文件。</span><br><span class="line"></span><br><span class="line">[root@bigdata04 apache-tomcat-8.0.52]# cd webapps&#x2F;ROOT&#x2F;</span><br><span class="line">[root@bigdata04 ROOT]# vi hot.dic </span><br><span class="line">测试</span><br><span class="line">北京雾霾</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">文件保存之后，在bigdata01上查看ES的日志会看到如下日志信息：</span><br><span class="line">[2027-03-09T18:43:12,700][INFO ][o.w.a.d.Dictionary       ] [bigdata01] start to reload ik dict.</span><br><span class="line">[2027-03-09T18:43:12,701][INFO ][o.w.a.d.Dictionary       ] [bigdata01] try load config from &#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;config&#x2F;analysis-ik&#x2F;IKAnalyzer.cfg.xml</span><br><span class="line">[2027-03-09T18:43:12,929][INFO ][o.w.a.d.Dictionary       ] [bigdata01] [Dict Loading] &#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;config&#x2F;analysis-ik&#x2F;my.dic</span><br><span class="line">[2027-03-09T18:43:12,929][INFO ][o.w.a.d.Dictionary       ] [bigdata01] [Dict Loading] http:&#x2F;&#x2F;bigdata04:8080&#x2F;hot.dic</span><br><span class="line">[2027-03-09T18:43:12,934][INFO ][o.w.a.d.Dictionary       ] [bigdata01] ﻿测试</span><br><span class="line">[2027-03-09T18:43:12,935][INFO ][o.w.a.d.Dictionary       ] [bigdata01] 北京雾霾</span><br><span class="line">[2027-03-09T18:43:12,935][INFO ][o.w.a.d.Dictionary       ] [bigdata01] reload ik dict finished.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">再对北京雾霾这个词语进行分词</span><br><span class="line"></span><br><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;北京雾霾&quot;,&quot;tokenizer&quot;:&quot;ik_max_word&quot;&#125;&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;北京雾霾&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;北京&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;雾&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 3,</span><br><span class="line">      &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;霾&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 3,</span><br><span class="line">      &quot;end_offset&quot; : 4,</span><br><span class="line">      &quot;type&quot; : &quot;CN_CHAR&quot;,</span><br><span class="line">      &quot;position&quot; : 3</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">此时，发现北京雾霾这个词语就可以完整被切分出来了，到这为止，我们就成功实现了热更新自定义词库的功能。</span><br><span class="line"></span><br><span class="line">注意：默认情况下，最多一分钟之内就可以识别到新增的词语。</span><br><span class="line">通过查看es-ik插件的源码可以发现</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;medcl&#x2F;elasticsearch-analysis-ik&#x2F;blob&#x2F;master&#x2F;src&#x2F;main&#x2F;java&#x2F;org&#x2F;wltea&#x2F;analyzer&#x2F;dic&#x2F;Monitor.java</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111559457.png" alt="image-20230611155917849"></p><h2 id="4-Elasticsearch查询详解"><a href="#4-Elasticsearch查询详解" class="headerlink" title="4 Elasticsearch查询详解"></a>4 Elasticsearch查询详解</h2><h3 id="ES-Search查询"><a href="#ES-Search查询" class="headerlink" title="ES Search查询"></a>ES Search查询</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在ES中查询单条数据可以使用Get，想要查询一批满足条件的数据的话，就需要使用Search了。</span><br><span class="line">下面来看一个案例，查询索引库中的所有数据，代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.es;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.SearchHit;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.SearchHits;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Search详解</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsSearchOp</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata02"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata03"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest();</span><br><span class="line">        <span class="comment">//指定索引库，支持指定一个或者多个，也支持通配符，例如：user*</span></span><br><span class="line">        searchRequest.indices(<span class="string">"user"</span>);</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">//过滤条件</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">//执行查询操作</span></span><br><span class="line">        SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取查询返回的结果</span></span><br><span class="line">        SearchHits hits = searchResponse.getHits();</span><br><span class="line">        <span class="comment">//获取数据总量</span></span><br><span class="line">        <span class="keyword">long</span> numHits = hits.getTotalHits().value;</span><br><span class="line">        System.out.println(<span class="string">"数据总数："</span>+numHits);</span><br><span class="line">        <span class="comment">//获取具体内容</span></span><br><span class="line">        SearchHit[] searchHits = hits.getHits();</span><br><span class="line">        <span class="comment">//迭代解析具体内容</span></span><br><span class="line">        <span class="keyword">for</span> (SearchHit hit : searchHits) &#123;</span><br><span class="line">            String sourceAsString = hit.getSourceAsString();</span><br><span class="line">            System.out.println(sourceAsString);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        client.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">在执行代码之前先初始化数据：</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;1&#39; -d &#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:20&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;2&#39; -d &#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:15&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;3&#39; -d &#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:17&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;4&#39; -d &#39;&#123;&quot;name&quot;:&quot;jess&quot;,&quot;age&quot;:19&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;5&#39; -d &#39;&#123;&quot;name&quot;:&quot;mick&quot;,&quot;age&quot;:23&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;6&#39; -d &#39;&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:12&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;7&#39; -d &#39;&#123;&quot;name&quot;:&quot;john&quot;,&quot;age&quot;:28&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;8&#39; -d &#39;&#123;&quot;name&quot;:&quot;jojo&quot;,&quot;age&quot;:30&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;9&#39; -d &#39;&#123;&quot;name&quot;:&quot;bubu&quot;,&quot;age&quot;:16&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;10&#39; -d &#39;&#123;&quot;name&quot;:&quot;pig&quot;,&quot;age&quot;:21&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;11&#39; -d &#39;&#123;&quot;name&quot;:&quot;mary&quot;,&quot;age&quot;:19&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">在IDEA中执行代码，可以看到下面结果：</span><br><span class="line">数据总数：11</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:20&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:15&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:17&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jess&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;mick&quot;,&quot;age&quot;:23&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:12&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;john&quot;,&quot;age&quot;:28&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jojo&quot;,&quot;age&quot;:30&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;bubu&quot;,&quot;age&quot;:16&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;pig&quot;,&quot;age&quot;:21&#125;</span><br><span class="line"></span><br><span class="line">显示数据总数有11条，但是下面的明细内容只有10条，这是因为ES默认只会返回10条数据，如果默认返回所有满足条件的数据，对ES的压力就比较大了。</span><br></pre></td></tr></table></figure><h3 id="searchType详解"><a href="#searchType详解" class="headerlink" title="searchType详解"></a>searchType详解</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ES在查询数据的时候可以指定searchType，也就是搜索类型</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;指定searchType</span><br><span class="line">searchRequest.searchType(SearchType.QUERY_THEN_FETCH);</span><br><span class="line"></span><br><span class="line">searchType之前是可以指定为下面这4种：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111606352.png" alt="image-20230611160600236"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">其中QUERY AND FETCH和DFS QUERY AND FETCH这两种searchType现在已经不支持了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">这4种搜索类型到底有什么区别，下面我们来详细分析一下：</span><br><span class="line"></span><br><span class="line">在具体分析这4种搜索类型的区别之前，我们先分析一下分布式搜索的背景：</span><br><span class="line">ES天生就是为分布式而生的，但分布式有分布式的缺点，比如要搜索某个单词，但是数据却分别在5个分片（Shard)上面，这5个分片可能在5台主机上面。因为全文搜索天生就要排序（按照匹配度进行排名）,但数据却在5个分片上，如何得到最后正确的排序呢？ES是这样做的，大概分两步。</span><br><span class="line">第1步：ES客户端将会同时向5个分片发起搜索请求。</span><br><span class="line">第2步：这5个分片基于本分片的内容独立完成搜索，然后将符合条件的结果全部返回。</span><br><span class="line">大致流程如下图所示：</span><br></pre></td></tr></table></figure><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111613627.png" alt="image-20230611161344874" style="zoom: 50%;"><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111614039.png" alt="image-20230611161408321" style="zoom:50%;"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">然而这其中有两个问题。</span><br><span class="line">第一：数量问题。比如，用户需要搜索&quot;衣服&quot;，要求返回符合条件的前10条。但在5个分片中，可能都存储着衣服相关的数据。所以ES会向这5个分片都发出查询请求，并且要求每个分片都返回符合条件的10条记录。这种情况，ES中5个分片最多会收到10*5&#x3D;50条记录，这样返回给用户的结果数量会多于用户请求的数量。</span><br><span class="line">第二：排名问题。上面说的搜索，每个分片计算符合条件的前10条数据都是基于自己分片的数据进行打分计算的。计算分值使用的词频和文档频率等信息都是基于自己分片的数据进行的，而ES进行整体排名是基于每个分片计算后的分值进行排序的(相当于打分依据就不一样，最终对这些数据统一排名的时候就不准确了)，这就可能会导致排名不准确的问题。如果我们想更精确的控制排序，应该先将计算排序和排名相关的信息（词频和文档频率等打分依据）从5个分片收集上来，进行统一计算，然后使用整体的词频和文档频率为每个分片中的数据进行打分，这样打分依据就一样了。</span><br><span class="line"></span><br><span class="line">再举个例子解释一下【排名问题】：</span><br><span class="line">假设某学校有一班和二班两个班级。</span><br><span class="line">期末考试之后，学校要给全校前十名学员发奖金。</span><br><span class="line">但是一班和二班考试的时候使用的不是一套试卷。</span><br><span class="line">一班：使用的是A卷【A卷偏容易】</span><br><span class="line">二班：使用的是B卷【B卷偏难】</span><br><span class="line">结果就是一班的最高分是100分，最低分是80分。</span><br><span class="line">二班的最高分是70分，最低分是30分。</span><br><span class="line"></span><br><span class="line">这样全校前十名就都是一班的学员了。这显然是不合理的。</span><br><span class="line">因为一班和二班的试卷难易程度不一样，也就是打分依据不一样，所以不能放在一块排名，这个就解释了刚才的排名问题。</span><br><span class="line">如果想要保证排名准确的话，需要保证一班和二班使用的试卷内容一样。</span><br><span class="line">可以这样做，把A卷和B卷的内容组合到一块，作为C卷。</span><br><span class="line">一班和二班考试都使用C卷，这样他们的打分依据就一样了，最终再根据所有学员的成绩排名求前十名就准确合理了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这两个问题，ES也没有什么较好的解决方法，最终把选择的权利交给用户，方法就是在搜索的时候指定searchType。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">1.QUERY AND FETCH(淘汰)</span><br><span class="line">向索引的所有分片都发出查询请求，各分片返回的时候把元素文档（document）和计算后的排名信息一起返回。</span><br><span class="line">这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去分片查询一次。但是各个分片返回的结果的数量之和可能是用户要求的数据量的N倍。</span><br><span class="line">优点：</span><br><span class="line">只需要查询一次</span><br><span class="line">缺点：</span><br><span class="line">返回的数据量不准确，可能返回(N*分片数量)的数据</span><br><span class="line">并且数据排名也不准确</span><br><span class="line"></span><br><span class="line">2.QUERY THEN FETCH（ES默认的搜索方式）</span><br><span class="line">如果你搜索时，没有指定搜索方式，就是使用的这种搜索方式。这种搜索方式，大概分两个步骤，</span><br><span class="line">第一步，先向所有的分片发出请求，各分片只返回文档id(注意，不包括文档document)和排名相关的信息(也就是文档对应的分值)，然后按照各分片返回的文档的分数进行重新排序和排名，取前size个文档。</span><br><span class="line">第二步，根据文档id去相关的分片取文档。这种方式返回的文档数量与用户要求的数量是相等的。</span><br><span class="line">优点：</span><br><span class="line">返回的数据量是准确的</span><br><span class="line">缺点：</span><br><span class="line">性能一般，</span><br><span class="line">并且数据排名不准确</span><br><span class="line"></span><br><span class="line">3.DFS QUERY AND FETCH(淘汰)</span><br><span class="line">这种方式比第一种方式多了一个DFS步骤，有这一步，可以更精确控制搜索打分和排名。</span><br><span class="line">也就是在进行查询之前，先对所有分片发送请求，把所有分片中的词频和文档频率等打分依据全部汇总到一块，再执行后面的操作、</span><br><span class="line">优点：</span><br><span class="line">数据排名准确</span><br><span class="line">缺点：</span><br><span class="line">性能一般</span><br><span class="line">返回的数据量不准确，可能返回(N*分片数量)的数据</span><br><span class="line"></span><br><span class="line">4.DFS QUERY THEN FETCH</span><br><span class="line">比第2种方式多了一个DFS步骤。</span><br><span class="line">也就是在进行查询之前，先对所有分片发送请求，把所有分片中的词频和文档频率等打分依据全部汇总到一块，再执行后面的操作、</span><br><span class="line">优点：</span><br><span class="line">返回的数据量是准确的</span><br><span class="line">数据排名准确</span><br><span class="line">缺点：</span><br><span class="line">性能最差【这个最差只是表示在这四种查询方式中性能最慢，也不至于不能忍受，如果对查询性能要求不是非常高，而对查询准确度要求比较高的时候可以考虑这个】</span><br></pre></td></tr></table></figure><h3 id="DFS是一个什么样的过程？"><a href="#DFS是一个什么样的过程？" class="headerlink" title="DFS是一个什么样的过程？"></a>DFS是一个什么样的过程？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DFS其实就是在进行真正的查询之前，先把各个分片的词频率和文档频率收集一下，然后进行词搜索的时候，各分片依据全局的词频率和文档频率进行搜索和排名。显然如果使用DFS_QUERY_THEN_FETCH这种查询方式，效率是最低的，因为一个搜索，可能要请求3次分片。但使用DFS方法，搜索精度是最高的。</span><br><span class="line"></span><br><span class="line">总结一下，从性能考虑QUERY_AND_FETCH是最快的，DFS_QUERY_THEN_FETCH是最慢的。从搜索的准确度来说，DFS要比非DFS的准确度更高。</span><br><span class="line"></span><br><span class="line">目前官方舍弃了QUERY AND FETCH和DFS QUERY AND FETCH这两种类型，保留了QUERY THEN FETCH和DFS QUERY THEN FETCH，这两种都是可以保证数据量是准确的。如果对查询的精确度要求没那么高，就使用QUERY THEN FETCH，如果对查询数据的精确度要求非常高，就使用DFS QUERY THEN FETCH。</span><br></pre></td></tr></table></figure><h3 id="ES查询扩展"><a href="#ES查询扩展" class="headerlink" title="ES查询扩展"></a>ES查询扩展</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在查询数据的时候可以在searchRequest中指定一些参数，实现过滤、分页、排序、高亮等功能</span><br></pre></td></tr></table></figure><h4 id="EsSearchOp"><a href="#EsSearchOp" class="headerlink" title="EsSearchOp"></a>EsSearchOp</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.es;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.common.text.Text;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.index.query.Operator;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.index.query.QueryBuilders;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.SearchHit;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.SearchHits;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.builder.SearchSourceBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.fetch.subphase.highlight.HighlightField;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.sort.SortOrder;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Search详解</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsSearchOp</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>,<span class="number">9200</span>,<span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata02"</span>,<span class="number">9200</span>,<span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata03"</span>,<span class="number">9200</span>,<span class="string">"http"</span>)));</span><br><span class="line">        SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest();</span><br><span class="line">        <span class="comment">//指定索引库，支持指定一个或者多个，也支持通配符，例如：user*</span></span><br><span class="line">        searchRequest.indices(<span class="string">"user"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定查询条件</span></span><br><span class="line">        SearchSourceBuilder searchSourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line">        <span class="comment">//查询所有，可以不指定，默认就是查询索引库中的所有数据</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchAllQuery());</span></span><br><span class="line">        <span class="comment">//对指定字段的值进行过滤，注意：在查询数据的时候会对数据进行分词</span></span><br><span class="line">        <span class="comment">//如果指定多个query，后面的query会覆盖前面的query</span></span><br><span class="line">        <span class="comment">//针对字符串类型内容的查询，不支持通配符</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","tom"));</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("age","17"));//针对age的值，这里可以指定字符串或者数字都可以</span></span><br><span class="line">        <span class="comment">//针对字符串类型内容的查询，支持通配符，但是性能较差，可以认为是全表扫描</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.wildcardQuery("name","t*"));</span></span><br><span class="line">        <span class="comment">//区间查询，主要针对数据类型，可以使用from+to 或者gt,gte+lt,lte</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.rangeQuery("age").from(0).to(20));</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.rangeQuery("age").gte(0).lte(20));</span></span><br><span class="line">        <span class="comment">//不限制边界，指定为null即可</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.rangeQuery("age").from(0).to(null));</span></span><br><span class="line">        <span class="comment">//同时指定多个条件，条件之间的关系支持and(must)、or(should)</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.boolQuery().should(QueryBuilders.matchQuery("name","tom")).should(QueryBuilders.matchQuery("age",19)));</span></span><br><span class="line">        <span class="comment">//多条件组合查询的时候，可以设置条件的权重值，将满足高权重值条件的数据排到结果列表的前面</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.boolQuery().should(QueryBuilders.matchQuery("name","tom").boost(1.0f)).should(QueryBuilders.matchQuery("age",19).boost(5.0f)));</span></span><br><span class="line">        <span class="comment">//对多个指定字段的值进行过滤，注意：多个字段的数据类型必须一致，否则会报错，如果查询的字段不存在不会报错</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.multiMatchQuery("tom","name","tag"));</span></span><br><span class="line">        <span class="comment">//这里通过queryStringQuery可以支持Lucene的原生查询语法，更加灵活，注意：AND、OR、TO之类的关键字必须大写</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.queryStringQuery("name:tom AND age:[15 TO 30]"));</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.boolQuery().must(QueryBuilders.matchQuery("name","tom")).must(QueryBuilders.rangeQuery("age").from(15).to(30)));</span></span><br><span class="line">        <span class="comment">//queryStringQuery支持通配符，但是性能也是比较差</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.queryStringQuery("name:t*"));</span></span><br><span class="line">        <span class="comment">//精确查询，查询的时候不分词，针对人名、手机号、主机名、邮箱号码等字段的查询时一般不需要分词</span></span><br><span class="line">        <span class="comment">//初始化一条测试数据name=刘德华，默认情况下在建立索引的时候刘德华 会被切分为刘、德、华这三个词</span></span><br><span class="line">        <span class="comment">//所以这里精确查询是查不出来的，使用matchQuery是可以查出来的</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华"));</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.termQuery("name","刘德华"));</span></span><br><span class="line">        <span class="comment">//正常情况下想要使用termQuery实现精确查询的字段不能进行分词</span></span><br><span class="line">        <span class="comment">//但是有时候会遇到某个字段已经分词建立索引了，后期还想要实现精确查询</span></span><br><span class="line">        <span class="comment">//重新建立索引也不现实，怎么办呢？</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.queryStringQuery("name:\"刘德华\""));</span></span><br><span class="line">        <span class="comment">//matchQuery默认会根据分词的结果进行 or 操作，满足任意一个词语的数据都会查询出来</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华"));</span></span><br><span class="line">        <span class="comment">//如果想要对matchQuery的分词结果实现and操作，可以通过operator进行设置</span></span><br><span class="line">        <span class="comment">//这种方式也可以解决某个字段已经分词建立索引了，后期还想要实现精确查询的问题（间接实现，其实是查询了满足刘、德、华这三个词语的内容）</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华").operator(Operator.AND));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//高亮查询name字段</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","tom"));</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华"));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//分页</span></span><br><span class="line">        <span class="comment">//设置每页的起始位置，默认是0</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.from(0);</span></span><br><span class="line">        <span class="comment">//设置每页的数据量，默认是10</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.size(10);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//排序</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.sort("age", SortOrder.DESC);</span></span><br><span class="line">        <span class="comment">//注意：age字段是数字类型，不需要分词，name字段是字符串类型（Text），默认会被分词，所以不支持排序和聚合操作</span></span><br><span class="line">        <span class="comment">//如果想要根据这些会被分词的字段进行排序或者聚合，需要指定使用他们的keyword类型，这个类型表示不会对数据分词</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.sort("name.keyword",SortOrder.DESC);</span></span><br><span class="line">        <span class="comment">//keyword类型的特性其实也适用于精确查询的场景，可以在matchQuery中指定字段的keyword类型实现精确查询，不管在建立索引的时候有没有被分词都不影响使用</span></span><br><span class="line">        <span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name.keyword","刘德华"));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//高亮</span></span><br><span class="line">        <span class="comment">//设置高亮字段</span></span><br><span class="line">        HighlightBuilder highlightBuilder = <span class="keyword">new</span> HighlightBuilder()</span><br><span class="line">                .field(<span class="string">"name"</span>);<span class="comment">//支持多个高亮字段，使用多个field方法指定即可</span></span><br><span class="line">        <span class="comment">//设置高亮字段的前缀和后缀内容</span></span><br><span class="line">        highlightBuilder.preTags(<span class="string">"&lt;font color='red'&gt;"</span>);</span><br><span class="line">        highlightBuilder.postTags(<span class="string">"&lt;/font&gt;"</span>);</span><br><span class="line">        searchSourceBuilder.highlighter(highlightBuilder);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        searchRequest.source(searchSourceBuilder);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//执行查询操作</span></span><br><span class="line">        SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取查询返回的结果</span></span><br><span class="line">        SearchHits hits = searchResponse.getHits();</span><br><span class="line">        <span class="comment">//获取数据总量</span></span><br><span class="line">        <span class="keyword">long</span> numHits = hits.getTotalHits().value;</span><br><span class="line">        System.out.println(<span class="string">"数据总数："</span>+numHits);</span><br><span class="line">        <span class="comment">//获取具体内容</span></span><br><span class="line">        SearchHit[] searchHits = hits.getHits();</span><br><span class="line">        <span class="comment">//迭代解析具体内容</span></span><br><span class="line">        <span class="keyword">for</span> (SearchHit hit : searchHits) &#123;</span><br><span class="line">            <span class="comment">/*String sourceAsString = hit.getSourceAsString();</span></span><br><span class="line"><span class="comment">            System.out.println(sourceAsString);*/</span></span><br><span class="line">            Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap();</span><br><span class="line">            String name = sourceAsMap.get(<span class="string">"name"</span>).toString();</span><br><span class="line">            <span class="keyword">int</span> age = Integer.parseInt(sourceAsMap.get(<span class="string">"age"</span>).toString());</span><br><span class="line">            <span class="comment">//获取高亮字段内容</span></span><br><span class="line">            Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();</span><br><span class="line">            <span class="comment">//获取name字段的高亮内容</span></span><br><span class="line">            HighlightField highlightField = highlightFields.get(<span class="string">"name"</span>);</span><br><span class="line">            <span class="keyword">if</span>(highlightField!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                Text[] fragments = highlightField.getFragments();</span><br><span class="line">                name = <span class="string">""</span>;</span><br><span class="line">                <span class="keyword">for</span> (Text text: fragments) &#123;</span><br><span class="line">                    name += text;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取最终的结果数据</span></span><br><span class="line">            System.out.println(name+<span class="string">"---"</span>+age);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">首先看一下如何在查询的时候指定过滤条件</span><br><span class="line">核心代码如下：</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//指定查询条件</span></span><br><span class="line">SearchSourceBuilder searchSourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line"><span class="comment">//查询所有，可以不指定，默认就是查询索引库中的所有数据</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.matchAllQuery());</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//对指定字段的值进行过滤，注意：在查询数据的时候会对数据进行分词</span></span><br><span class="line"><span class="comment">//如果指定多个query，后面的query会覆盖前面的query</span></span><br><span class="line"><span class="comment">//针对字符串(数字)类型内容的查询，不支持通配符</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","tom"));</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("age","17"));//针对age的值，这里可以指定字符串或者数字都可以</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//针对字符串类型内容的查询，支持通配符，但是性能较差，可以认为是全表扫描</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.wildcardQuery("name","t*"));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//区间查询，主要针对数据类型，可以使用from+to 或者gt,gte+lt,lte</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.rangeQuery("age").from(0).to(20));</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.rangeQuery("age").gte(0).lte(20));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//不限制边界，指定为null即可</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.rangeQuery("age").from(0).to(null));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//同时指定多个条件，条件之间的关系支持and(must)、or(should)</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.boolQuery().should(QueryBuilders.matchQuery("name","tom")).should(QueryBuilders.matchQuery("age",19)));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//多条件组合查询的时候，可以设置条件的权重值，将满足高权重值条件的数据排到结果列表的前面</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.boolQuery().should(QueryBuilders.matchQuery("name","tom").boost(1.0f)).should(QueryBuilders.matchQuery("age",19).boost(5.0f)));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//对多个指定字段的值进行过滤，注意：多个字段的数据类型必须一致，否则会报错，如果查询的字段不存在不会报错</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.multiMatchQuery("tom","name","tag")); // tag字段不存在</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//这里通过queryStringQuery可以支持Lucene的原生查询语法，更加灵活，注意：AND、OR、TO之类的关键字必须大写</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.queryStringQuery("name:tom AND age:[15 TO 30]"));</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.boolQuery().must(QueryBuilders.matchQuery("name","tom")).must(QueryBuilders.rangeQuery("age").from(15).to(30)));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//queryStringQuery支持通配符，但是性能也是比较差</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.queryStringQuery("name:t*"));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//精确查询(查询时不分词)，查询的时候不分词，针对人名、手机号、主机名、邮箱号码等字段的查询时一般不需要分词</span></span><br><span class="line"><span class="comment">//初始化一条测试数据name=刘德华，默认情况下在建立索引的时候(这是建立索引，还没字段的分词器，还是默认的)刘德华 会被切分为刘、德、华这三个词</span></span><br><span class="line"><span class="comment">//所以这里精确查询是查不出来的，使用matchQuery是可以查出来的</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华"));</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.termQuery("name","刘德华"));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//正常情况下想要使用termQuery实现精确查询的字段不能进行分词</span></span><br><span class="line"><span class="comment">//但是有时候会遇到某个字段已经分词建立索引了，后期还想要实现精确查询</span></span><br><span class="line"><span class="comment">//重新建立索引也不现实，怎么办呢？</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.queryStringQuery("name:\"刘德华\"")); //这里里面是转义字符</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//matchQuery默认会根据分词的结果进行 or 操作，满足任意一个词语的数据都会查询出来</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华"));</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//如果想要对matchQuery的分词结果实现and操作，可以通过operator进行设置</span></span><br><span class="line"><span class="comment">//这种方式也可以解决某个字段已经分词建立索引了，后期还想要实现精确查询的问题（间接实现，其实是查询了满足刘、德、华这三个词语的内容）</span></span><br><span class="line"><span class="comment">//searchSourceBuilder.query(QueryBuilders.matchQuery("name","刘德华").operator(Operator.AND));</span></span><br><span class="line"></span><br><span class="line">searchRequest.source(searchSourceBuilder);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">带权重</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306132345436.png" alt="image-20230613234458201"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用match，还是模糊查询</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306132358298.png" alt="image-20230613235809923"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">termQuery，查不到结果，因为他直接拿“刘德华”去查询，索引库里没有</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306140001201.png" alt="image-20230614000114276"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">利用queryStringQuery实现精准查询</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306140003432.png" alt="image-20230614000332868"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">默认情况下ES会对刘德华这个词语进行分词，效果如下（使用的默认分词器）：</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST  &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_analyze?pretty&#39; -d &#39;&#123;&quot;text&quot;:&quot;刘德华&quot;&#125;&#39;      </span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokens&quot; : [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;刘&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 0,</span><br><span class="line">      &quot;end_offset&quot; : 1,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;德&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 1,</span><br><span class="line">      &quot;end_offset&quot; : 2,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;token&quot; : &quot;华&quot;,</span><br><span class="line">      &quot;start_offset&quot; : 2,</span><br><span class="line">      &quot;end_offset&quot; : 3,</span><br><span class="line">      &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;,</span><br><span class="line">      &quot;position&quot; : 2</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">初始化数据：</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;12&#39; -d &#39;&#123;&quot;name&quot;:&quot;刘德华&quot;,&quot;age&quot;:60&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]$ curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;user&#x2F;_doc&#x2F;13&#39; -d &#39;&#123;&quot;name&quot;:&quot;刘老二&quot;,&quot;age&quot;:20&#125;&#39;</span><br></pre></td></tr></table></figure><h4 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ES每次返回的数据默认最多是10条，可以认为是一页的数据，这个数据量是可以控制的</span><br><span class="line">核心代码如下：</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;分页</span><br><span class="line">&#x2F;&#x2F;设置每页的起始位置，默认是0</span><br><span class="line">&#x2F;&#x2F;searchSourceBuilder.from(0);</span><br><span class="line">&#x2F;&#x2F;设置每页的数据量，默认是10</span><br><span class="line">&#x2F;&#x2F;searchSourceBuilder.size(10);</span><br></pre></td></tr></table></figure><h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">在返回满足条件的结果之前，可以按照指定的要求对数据进行排序，默认是按照搜索条件的匹配度返回数据的。(默认情况下，查询关键字的匹配度越高越靠前)</span><br><span class="line">核心代码如下：</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;排序</span><br><span class="line">&#x2F;&#x2F;按照age字段，倒序排序</span><br><span class="line">&#x2F;&#x2F;searchSourceBuilder.sort(&quot;age&quot;, SortOrder.DESC);</span><br><span class="line">&#x2F;&#x2F;注意：age字段是数字类型，不需要分词，name字段是字符串类型(Text)，默认会被分词，所以不支持排序和聚合操作</span><br><span class="line">&#x2F;&#x2F;如果想要根据这些会被分词的字段进行排序或者聚合，需要指定使用他们的keyword类型，这个类型表示不会对数据分词(ES默认会对字符串类型数据，建立两份索引，一份分词，一份不分词)</span><br><span class="line">&#x2F;&#x2F;searchSourceBuilder.sort(&quot;name.keyword&quot;, SortOrder.DESC);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;keyword类型的特性其实也适用于精确查询的场景，可以在matchQuery中指定字段的keyword类型实现精确查询，不管在建立索引的时候有没有被分词都不影响使用</span><br><span class="line">&#x2F;&#x2F;searchSourceBuilder.query(QueryBuilders.matchQuery(&quot;name.keyword&quot;, &quot;刘德华&quot;));</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">match实现精确查询</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306140026183.png" alt="image-20230614002640823"></p><h4 id="高亮"><a href="#高亮" class="headerlink" title="高亮"></a>高亮</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">针对用户搜索时的关键词，如果匹配到了，最终在页面展现的时候可以标红高亮显示，看起来比较清晰。</span><br><span class="line">设置高亮的核心代码如下：</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;高亮</span><br><span class="line">&#x2F;&#x2F;设置高亮字段</span><br><span class="line">HighlightBuilder highlightBuilder &#x3D; new HighlightBuilder()</span><br><span class="line">        .field(&quot;name&quot;);&#x2F;&#x2F;支持多个高亮字段，使用多个field方法指定即可</span><br><span class="line">&#x2F;&#x2F;设置高亮字段的前缀和后缀内容</span><br><span class="line">highlightBuilder.preTags(&quot;&lt;font color&#x3D;&#39;red&#39;&gt;&quot;);</span><br><span class="line">highlightBuilder.postTags(&quot;&lt;&#x2F;font&gt;&quot;);</span><br><span class="line">searchSourceBuilder.highlighter(highlightBuilder);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">别忘了前面完整代码中，要对高亮字段查询，才会有效果</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306140044744.png" alt="image-20230614004401423"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306140043276.png" alt="image-20230614004343078"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">解析高亮内容的核心代码如下：</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;迭代解析具体内容</span><br><span class="line">for (SearchHit hit : searchHits) &#123;</span><br><span class="line">    &#x2F;*String sourceAsString &#x3D; hit.getSourceAsString();</span><br><span class="line">    System.out.println(sourceAsString);*&#x2F;</span><br><span class="line">    Map&lt;String, Object&gt; sourceAsMap &#x3D; hit.getSourceAsMap();</span><br><span class="line">    String name &#x3D; sourceAsMap.get(&quot;name&quot;).toString();</span><br><span class="line">    int age &#x3D; Integer.parseInt(sourceAsMap.get(&quot;age&quot;).toString());</span><br><span class="line">    &#x2F;&#x2F;获取高亮字段内容</span><br><span class="line">    Map&lt;String, HighlightField&gt; highlightFields &#x3D; hit.getHighlightFields();</span><br><span class="line">    &#x2F;&#x2F;获取name字段的高亮内容</span><br><span class="line">    HighlightField highlightField &#x3D; highlightFields.get(&quot;name&quot;);</span><br><span class="line">    if(highlightField!&#x3D;null)&#123;</span><br><span class="line">        Text[] fragments &#x3D; highlightField.getFragments();</span><br><span class="line">        name &#x3D; &quot;&quot;;</span><br><span class="line">        for (Text text : fragments) &#123;</span><br><span class="line">            name +&#x3D; text;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;获取最终的结果数据</span><br><span class="line">    System.out.println(name+&quot;---&quot;+age);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">注意：必须要设置查询的字段，否则无法实现高亮。</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;高亮查询name字段</span><br><span class="line">searchSourceBuilder.query(QueryBuilders.matchQuery(&quot;name&quot;,&quot;tom&quot;));</span><br><span class="line">searchSourceBuilder.query(QueryBuilders.matchQuery(&quot;name&quot;,&quot;刘德华&quot;));</span><br></pre></td></tr></table></figure><h3 id="评分依据-了解"><a href="#评分依据-了解" class="headerlink" title="评分依据(了解)"></a>评分依据(了解)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ES在返回满足条件的数据的时候，按照搜索条件的匹配度返回数据的，匹配度最高的数据排在最前面，这个匹配度其实就是ES中返回结果中的score字段的值。</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;获取数据的匹配度分值，值越大说明和搜索的关键字匹配度越高</span><br><span class="line">float score &#x3D; hit.getScore();</span><br><span class="line">&#x2F;&#x2F;获取最终的结果数据</span><br><span class="line">System.out.println(name+&quot;---&quot;+age+&quot;---&quot;+score);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">此时，我们搜索name&#x3D;刘华 的数据</span><br><span class="line">searchSourceBuilder.query(QueryBuilders.matchQuery(&quot;name&quot;, &quot;刘华&quot;));</span><br><span class="line"></span><br><span class="line">结果如下：</span><br><span class="line">数据总数：2</span><br><span class="line">&lt;font color&#x3D;&#39;red&#39;&gt;刘&lt;&#x2F;font&gt;德&lt;font color&#x3D;&#39;red&#39;&gt;华&lt;&#x2F;font&gt;---60---2.591636</span><br><span class="line">&lt;font color&#x3D;&#39;red&#39;&gt;刘&lt;&#x2F;font&gt;老二---20---1.0036464</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">可以看到第一条数据的score分值为2.59</span><br><span class="line">第二条数据的score分值为1.00</span><br><span class="line"></span><br><span class="line">score分值具体是如何计算出来的呢？可以通过开启评分依据进行查看详细信息：</span><br><span class="line">首先开启评分依据：</span><br><span class="line">&#x2F;&#x2F;评分依据，true：开启，false：关闭</span><br><span class="line">searchSourceBuilder.explain(true);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">获取评分依据信息：</span><br><span class="line">&#x2F;&#x2F;获取Score的评分依据</span><br><span class="line">Explanation explanation &#x3D; hit.getExplanation();</span><br><span class="line">&#x2F;&#x2F;打印评分依据</span><br><span class="line">if(explanation!&#x3D;null)&#123;</span><br><span class="line">    System.out.println(explanation.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">再执行程序，就可以看到具体的评分依据信息了：</span><br><span class="line">数据总数：2</span><br><span class="line">&lt;font color&#x3D;&#39;red&#39;&gt;刘&lt;&#x2F;font&gt;德&lt;font color&#x3D;&#39;red&#39;&gt;华&lt;&#x2F;font&gt;---60---2.591636</span><br><span class="line">2.591636 &#x3D; sum of:</span><br><span class="line">  1.0036464 &#x3D; weight(name:刘 in 1) [PerFieldSimilarity], result of:</span><br><span class="line">    1.0036464 &#x3D; score(freq&#x3D;1.0), computed as boost * idf * tf from:</span><br><span class="line">      2.2 &#x3D; boost</span><br><span class="line">      1.4552872 &#x3D; idf, computed as log(1 + (N - n + 0.5) &#x2F; (n + 0.5)) from:</span><br><span class="line">        3.0 &#x3D; n, number of documents containing term</span><br><span class="line">        14.0 &#x3D; N, total number of documents with field</span><br><span class="line">      0.3134796 &#x3D; tf, computed as freq &#x2F; (freq + k1 * (1 - b + b * dl &#x2F; avgdl)) from:</span><br><span class="line">        1.0 &#x3D; freq, occurrences of term within document</span><br><span class="line">        1.2 &#x3D; k1, term saturation parameter</span><br><span class="line">        0.75 &#x3D; b, length normalization parameter</span><br><span class="line">        3.0 &#x3D; dl, length of field</span><br><span class="line">        1.4285715 &#x3D; avgdl, average length of field</span><br><span class="line">  1.5879896 &#x3D; weight(name:华 in 1) [PerFieldSimilarity], result of:</span><br><span class="line">    1.5879896 &#x3D; score(freq&#x3D;1.0), computed as boost * idf * tf from:</span><br><span class="line">      2.2 &#x3D; boost</span><br><span class="line">      2.3025851 &#x3D; idf, computed as log(1 + (N - n + 0.5) &#x2F; (n + 0.5)) from:</span><br><span class="line">        1.0 &#x3D; n, number of documents containing term</span><br><span class="line">        14.0 &#x3D; N, total number of documents with field</span><br><span class="line">      0.3134796 &#x3D; tf, computed as freq &#x2F; (freq + k1 * (1 - b + b * dl &#x2F; avgdl)) from:</span><br><span class="line">        1.0 &#x3D; freq, occurrences of term within document</span><br><span class="line">        1.2 &#x3D; k1, term saturation parameter</span><br><span class="line">        0.75 &#x3D; b, length normalization parameter</span><br><span class="line">        3.0 &#x3D; dl, length of field</span><br><span class="line">        1.4285715 &#x3D; avgdl, average length of field</span><br><span class="line"></span><br><span class="line">&lt;font color&#x3D;&#39;red&#39;&gt;刘&lt;&#x2F;font&gt;老二---20---1.0036464</span><br><span class="line">1.0036464 &#x3D; sum of:</span><br><span class="line">  1.0036464 &#x3D; weight(name:刘 in 2) [PerFieldSimilarity], result of:</span><br><span class="line">    1.0036464 &#x3D; score(freq&#x3D;1.0), computed as boost * idf * tf from:</span><br><span class="line">      2.2 &#x3D; boost</span><br><span class="line">      1.4552872 &#x3D; idf, computed as log(1 + (N - n + 0.5) &#x2F; (n + 0.5)) from:</span><br><span class="line">        3.0 &#x3D; n, number of documents containing term</span><br><span class="line">        14.0 &#x3D; N, total number of documents with field</span><br><span class="line">      0.3134796 &#x3D; tf, computed as freq &#x2F; (freq + k1 * (1 - b + b * dl &#x2F; avgdl)) from:</span><br><span class="line">        1.0 &#x3D; freq, occurrences of term within document</span><br><span class="line">        1.2 &#x3D; k1, term saturation parameter</span><br><span class="line">        0.75 &#x3D; b, length normalization parameter</span><br><span class="line">        3.0 &#x3D; dl, length of field</span><br><span class="line">        1.4285715 &#x3D; avgdl, average length of field</span><br></pre></td></tr></table></figure><h3 id="ES中分页的性能问题"><a href="#ES中分页的性能问题" class="headerlink" title="ES中分页的性能问题"></a>ES中分页的性能问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在使用ES实现分页查询的时候，不要一次请求过多或者页码过大的结果，这样会对服务器造成很大的压力，因为它们会在返回前排序。</span><br><span class="line">ES是分布式搜索，所以ES客户端的一个查询请求会发送到索引对应的多个分片中，每个分片都会生成自己的排序结果，最后再进行集中排序，以确保最终结果的正确性。</span><br><span class="line"></span><br><span class="line">我们假设在搜索一个拥有5个主分片的索引，当我们请求第一页数据的时候，每个分片产生自己前10名，然后将它们返回给请求节点，然后这个请求节点会将收到的50条结果重新排序以产生最终的前10名。</span><br><span class="line"></span><br><span class="line">现在想象一下我们如果要获得第1,000页的数据，也就是第10,001到第10,010条数据，每一个分片都会先产生自己的前10,010名，然后请求节点统一处理这50,050条数据，最后再丢弃掉其中的50,040条！</span><br><span class="line">现在我们就明白了，在分布式系统中，大页码请求所消耗的系统资源是呈指数式增长的。这也是为什么网络搜索引擎一般不会提供超过1,000条搜索结果的原因。</span><br><span class="line">例如：百度上的效果。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111650965.png" alt="image-20230611165023568"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当然还有一点原因是后面的搜索结果基本上也不是我们想要的数据了，我们在使用搜索引擎的时候，一般只会看第1页和第2页的数据。</span><br></pre></td></tr></table></figure><h3 id="aggregations聚合统计"><a href="#aggregations聚合统计" class="headerlink" title="aggregations聚合统计"></a>aggregations聚合统计</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ES中可以实现基于字段进行分组聚合的统计</span><br><span class="line">聚合操作支持count()、sum()、avg()、max()、min()等</span><br><span class="line"></span><br><span class="line">下面来看两个案例</span><br></pre></td></tr></table></figure><h4 id="统计相同年龄的学员个数"><a href="#统计相同年龄的学员个数" class="headerlink" title="统计相同年龄的学员个数"></a>统计相同年龄的学员个数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">需求：统计相同年龄的学员个数</span><br><span class="line">数据如下所示：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111657341.png" alt="image-20230611165752222"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">首先在ES中初始化这份数据：</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;2&#39; -d&#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;3&#39; -d&#39;&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;4&#39; -d&#39;&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;5&#39; -d&#39;&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;6&#39; -d&#39;&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.es;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.AggregationBuilders;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.bucket.terms.Terms;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.builder.SearchSourceBuilder;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 聚合统计：统计相同年龄的学员个数</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsAggOp01</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata02"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata03"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)));</span><br><span class="line">        SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest();</span><br><span class="line">        searchRequest.indices(<span class="string">"stu"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定查询条件</span></span><br><span class="line">        SearchSourceBuilder searchSourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line">        <span class="comment">//指定分组信息，默认是执行count聚合</span></span><br><span class="line">        TermsAggregationBuilder aggregation = AggregationBuilders.terms(<span class="string">"age_term"</span>)</span><br><span class="line">                .field(<span class="string">"age"</span>);</span><br><span class="line">        searchSourceBuilder.aggregation(aggregation);</span><br><span class="line"></span><br><span class="line">        searchRequest.source(searchSourceBuilder);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//执行查询操作</span></span><br><span class="line">        SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取分组信息</span></span><br><span class="line">        Terms terms = searchResponse.getAggregations().get(<span class="string">"age_term"</span>);</span><br><span class="line">        List&lt;? extends Terms.Bucket&gt; buckets = terms.getBuckets();</span><br><span class="line">        <span class="keyword">for</span> (Terms.Bucket bucket: buckets) &#123;</span><br><span class="line">            System.out.println(bucket.getKey()+<span class="string">"---"</span>+bucket.getDocCount());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="统计每个学员的总成绩"><a href="#统计每个学员的总成绩" class="headerlink" title="统计每个学员的总成绩"></a>统计每个学员的总成绩</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">需求：统计每个学员的总成绩</span><br><span class="line">数据如下所示：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306111659147.png" alt="image-20230611165858836"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;subject&quot;:&quot;chinese&quot;,&quot;score&quot;:59&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_doc&#x2F;2&#39; -d&#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;subject&quot;:&quot;math&quot;,&quot;score&quot;:89&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_doc&#x2F;3&#39; -d&#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;subject&quot;:&quot;chinese&quot;,&quot;score&quot;:78&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_doc&#x2F;4&#39; -d&#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;subject&quot;:&quot;math&quot;,&quot;score&quot;:85&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_doc&#x2F;5&#39; -d&#39;&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;subject&quot;:&quot;chinese&quot;,&quot;score&quot;:97&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_doc&#x2F;6&#39; -d&#39;&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;subject&quot;:&quot;math&quot;,&quot;score&quot;:68&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.imooc.es;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.search.SearchResponse;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RequestOptions;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestHighLevelClient;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.Aggregation;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.AggregationBuilders;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.bucket.terms.Terms;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.aggregations.metrics.Sum;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.search.builder.SearchSourceBuilder;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 聚合统计：统计每个学员的总成绩</span></span><br><span class="line"><span class="comment"> * Created by xuwei</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EsAggOp02</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">//获取RestClient连接</span></span><br><span class="line">        RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">                RestClient.builder(</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata01"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata02"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                        <span class="keyword">new</span> HttpHost(<span class="string">"bigdata03"</span>, <span class="number">9200</span>, <span class="string">"http"</span>)));</span><br><span class="line">        SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest();</span><br><span class="line">        searchRequest.indices(<span class="string">"score"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定查询条件</span></span><br><span class="line">        SearchSourceBuilder searchSourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line">        <span class="comment">//指定分组和求sum</span></span><br><span class="line">        TermsAggregationBuilder aggregation = AggregationBuilders.terms(<span class="string">"name_term"</span>)</span><br><span class="line">                .field(<span class="string">"name.keyword"</span>)<span class="comment">//指定分组字段，如果是字符串(Text)类型，则需要指定使用keyword类型</span></span><br><span class="line">                .subAggregation(AggregationBuilders.sum(<span class="string">"sum_score"</span>).field(<span class="string">"score"</span>));<span class="comment">//指定求sum,也支持avg、min、max等操作</span></span><br><span class="line">        searchSourceBuilder.aggregation(aggregation);</span><br><span class="line"></span><br><span class="line">        searchRequest.source(searchSourceBuilder);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//执行查询操作</span></span><br><span class="line">        SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取分组信息</span></span><br><span class="line">        Terms terms = searchResponse.getAggregations().get(<span class="string">"name_term"</span>);</span><br><span class="line">        List&lt;? extends Terms.Bucket&gt; buckets = terms.getBuckets();</span><br><span class="line">        <span class="keyword">for</span> (Terms.Bucket bucket: buckets) &#123;</span><br><span class="line">            <span class="comment">//获取sum聚合的结果</span></span><br><span class="line">            Sum sum = bucket.getAggregations().get(<span class="string">"sum_score"</span>);</span><br><span class="line">            System.out.println(bucket.getKey()+<span class="string">"---"</span>+sum.getValue());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭连接</span></span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="aggregations获取所有分组数据"><a href="#aggregations获取所有分组数据" class="headerlink" title="aggregations获取所有分组数据"></a>aggregations获取所有分组数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">默认情况下，ES只会返回10个分组的数据，如果分组之后的结果超过了10组，如何解决？</span><br><span class="line"></span><br><span class="line">可以通过在聚合操作中使用size方法进行设置，获取指定个数的数据组或者获取所有的数据组。</span><br><span class="line">在案例1的基础上再初始化一批测试数据：</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;61&#39; -d&#39;&#123;&quot;name&quot;:&quot;s1&quot;,&quot;age&quot;:31&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;62&#39; -d&#39;&#123;&quot;name&quot;:&quot;s2&quot;,&quot;age&quot;:32&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;63&#39; -d&#39;&#123;&quot;name&quot;:&quot;s3&quot;,&quot;age&quot;:33&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;64&#39; -d&#39;&#123;&quot;name&quot;:&quot;s4&quot;,&quot;age&quot;:34&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;65&#39; -d&#39;&#123;&quot;name&quot;:&quot;s5&quot;,&quot;age&quot;:35&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;66&#39; -d&#39;&#123;&quot;name&quot;:&quot;s6&quot;,&quot;age&quot;:36&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;67&#39; -d&#39;&#123;&quot;name&quot;:&quot;s7&quot;,&quot;age&quot;:37&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;68&#39; -d&#39;&#123;&quot;name&quot;:&quot;s8&quot;,&quot;age&quot;:38&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_doc&#x2F;69&#39; -d&#39;&#123;&quot;name&quot;:&quot;s9&quot;,&quot;age&quot;:39&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">支持案例1的代码，查看返回的分组个数：</span><br><span class="line">18---3</span><br><span class="line">29---2</span><br><span class="line">19---1</span><br><span class="line">31---1</span><br><span class="line">32---1</span><br><span class="line">33---1</span><br><span class="line">34---1</span><br><span class="line">35---1</span><br><span class="line">36---1</span><br><span class="line">37---1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">发现结果中返回的分组个数是10个，没有全部都显示出来，这个其实和分页也没关系，尝试增加分页的代码发现也是无效的：</span><br><span class="line">&#x2F;&#x2F;增加分页参数，注意：分页参数针对分组数据是无效的。</span><br><span class="line">searchSourceBuilder.from(0).size(20);</span><br><span class="line"></span><br><span class="line">执行案例1的代码，结果发现还是10条数据。</span><br><span class="line">18---3</span><br><span class="line">29---2</span><br><span class="line">19---1</span><br><span class="line">31---1</span><br><span class="line">32---1</span><br><span class="line">33---1</span><br><span class="line">34---1</span><br><span class="line">35---1</span><br><span class="line">36---1</span><br><span class="line">37---1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">通过在聚合操作上使用size方法进行设置：</span><br><span class="line">TermsAggregationBuilder aggregation &#x3D; AggregationBuilders.terms(&quot;age_term&quot;)</span><br><span class="line">        .field(&quot;age&quot;)</span><br><span class="line">        .size(20);&#x2F;&#x2F;获取指定分组个数的数据</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">执行案例1的代码：</span><br><span class="line">18---3</span><br><span class="line">29---2</span><br><span class="line">19---1</span><br><span class="line">31---1</span><br><span class="line">32---1</span><br><span class="line">33---1</span><br><span class="line">34---1</span><br><span class="line">35---1</span><br><span class="line">36---1</span><br><span class="line">37---1</span><br><span class="line">38---1</span><br><span class="line">39---1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">此时可以获取到所有分组的数据，因为结果一共有12个分组，在代码中通过size设置最多可以获取到20个分组的数据。</span><br><span class="line"></span><br><span class="line">如果前期不确定到底有多少个分组的数据，还想获取到所有分组的数据，此时可以在size中设置一个Integer的最大值，这样基本上就没什么问题了，但是注意：如果最后的分组个数太多，会给ES造成比较大的压力，所以官方在这做了限制，让用户手工指定获取多少分组的数据。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TermsAggregationBuilder aggregation &#x3D; AggregationBuilders.terms(&quot;age_term&quot;)</span><br><span class="line">        .field(&quot;age&quot;)</span><br><span class="line">        .size(Integer.MAX_VALUE);&#x2F;&#x2F;获取指定分组个数的数据</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：在ES7.x版本之前，想要获取所有的分组数据，只需要在size中指定参数为0即可。现在ES7.x版本不支持这个数值了。</span><br></pre></td></tr></table></figure><h2 id="5-Elasticsearch的高级特性"><a href="#5-Elasticsearch的高级特性" class="headerlink" title="5 Elasticsearch的高级特性"></a>5 Elasticsearch的高级特性</h2><h3 id="ES中的settings"><a href="#ES中的settings" class="headerlink" title="ES中的settings"></a>ES中的settings</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">ES中的settings可以设置索引库的一些配置信息，主要是针对分片数量和副本数量</span><br><span class="line">其中分片数量只能在一开始创建索引库的时候指定，后期不能修改。</span><br><span class="line">副本数量可以随时修改。</span><br><span class="line"></span><br><span class="line">首先查看一下ES中目前已有的索引库的默认settings信息。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;emp&#x2F;_settings?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;emp&quot; : &#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;routing&quot; : &#123;</span><br><span class="line">          &quot;allocation&quot; : &#123;</span><br><span class="line">            &quot;include&quot; : &#123;</span><br><span class="line">              &quot;_tier_preference&quot; : &quot;data_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;emp&quot;,</span><br><span class="line">        &quot;creation_date&quot; : &quot;1803648122805&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;kBpwz6kAQ2eS0uCISVcaew&quot;,</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7130499&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">此时分片和副本数量默认都是1。</span><br><span class="line">尝试手工指定分片和副本数量。</span><br><span class="line">针对不存在的索引，在创建的时候可以同时指定分片(5)和副本(1)数量：</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test1&#x2F;&#39; -d&#39;&#123;&quot;settings&quot;:&#123;&quot;number_of_shards&quot;:5,&quot;number_of_replicas&quot;:1&#125;&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">查看这个索引库的settings信息：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test1&#x2F;_settings?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test1&quot; : &#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;routing&quot; : &#123;</span><br><span class="line">          &quot;allocation&quot; : &#123;</span><br><span class="line">            &quot;include&quot; : &#123;</span><br><span class="line">              &quot;_tier_preference&quot; : &quot;data_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;5&quot;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;test1&quot;,</span><br><span class="line">        &quot;creation_date&quot; : &quot;1804844538706&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;WEUwvKVoRzWfna-KFntdqQ&quot;,</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7130499&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">针对已存在的索引，只能通过settings指定副本信息。</span><br><span class="line">将刚才创建的索引的副本数量修改为0。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test1&#x2F;_settings&#39; -d&#39;&#123;&quot;index&quot;:&#123;&quot;number_of_replicas&quot;:0&#125;&#125;&#39;</span><br><span class="line"></span><br><span class="line">查看这个索引库目前的settings信息：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test1&#x2F;_settings?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test1&quot; : &#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;routing&quot; : &#123;</span><br><span class="line">          &quot;allocation&quot; : &#123;</span><br><span class="line">            &quot;include&quot; : &#123;</span><br><span class="line">              &quot;_tier_preference&quot; : &quot;data_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;5&quot;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;test1&quot;,</span><br><span class="line">        &quot;creation_date&quot; : &quot;1804844538706&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;0&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;WEUwvKVoRzWfna-KFntdqQ&quot;,</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7130499&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ES中的mapping"><a href="#ES中的mapping" class="headerlink" title="ES中的mapping"></a>ES中的mapping</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mapping表示索引库中数据的字段类型信息，类似于MySQL中的表结构信息。</span><br><span class="line"></span><br><span class="line">一般不需要手工指定mapping，因为ES会自动根据数据格式识别它的类型</span><br><span class="line"></span><br><span class="line">如果你需要对某些字段添加特殊属性（例如：指定分词器），就必须手工指定字段的mapping。</span><br><span class="line"></span><br><span class="line">下面先来看一下ES中的常用数据类型：</span><br></pre></td></tr></table></figure><h4 id="ES中的常用数据类型"><a href="#ES中的常用数据类型" class="headerlink" title="ES中的常用数据类型"></a>ES中的常用数据类型</h4><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112219264.png" alt="ES中的常用数据类型"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">字符串：支持text和keyword类型</span><br><span class="line">text类型支持分词，支持模糊、精确查询，但是不支持聚合和排序操作，text类型不限制存储的内容长度，适合大字段存储。</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;7.13&#x2F;text.html</span><br><span class="line"></span><br><span class="line">keyword类型不支持分词，会直接对数据建立索引，支持模糊、精确查询，支持聚合和排序操作。keyword类型最大支持存储内容长度为32766个UTF-8类型的字符,可以通过设置ignore_above参数指定某个字段最大支持的字符长度，超过给定长度后的数据将不被索引，此时就无法通过termQuery精确查询返回结果了。keyword类型适合存储手机号、姓名等不需要分词的数据。</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;7.13&#x2F;keyword.html</span><br><span class="line"></span><br><span class="line">数字：最常用的就是long和double了，整数使用long、小数使用double。当然也支持integer、short、byte、float这些数据类型。</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;7.13&#x2F;number.html</span><br><span class="line"></span><br><span class="line">日期：最常用的就是date类型了，date类型可以支持到毫秒，如果特殊情况下需要精确到纳秒需要使用date_nanos这个类型。</span><br><span class="line">其中date日期类型可以自定义日期格式，通过format参数指定：</span><br><span class="line">&#123;“type”:“date”,“format”:“yyyy-MM-dd”&#125;</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;7.13&#x2F;date.html</span><br><span class="line"></span><br><span class="line">布尔型：支持true或者false。</span><br><span class="line"></span><br><span class="line">二进制：该字段存储编码为Base64字符串的二进制值。如果想要存储图片，可以存储图片地址，或者图片本身，存储图片本身的话就需要获取图片的二进制值进行存储了。</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;7.13&#x2F;binary.html</span><br></pre></td></tr></table></figure><h4 id="查看mapping"><a href="#查看mapping" class="headerlink" title="查看mapping"></a>查看mapping</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">ES中还支持一些其他数据类型，感兴趣的话可以到文档里面看一下：</span><br><span class="line">https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;7.13&#x2F;mapping-types.html</span><br><span class="line"></span><br><span class="line">下面查询一下目前已有的索引库score的mapping信息：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;score&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;score&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;fields&quot; : &#123;</span><br><span class="line">            &quot;keyword&quot; : &#123;</span><br><span class="line">              &quot;type&quot; : &quot;keyword&quot;,</span><br><span class="line">              &quot;ignore_above&quot; : 256</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;score&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;subject&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;fields&quot; : &#123;</span><br><span class="line">            &quot;keyword&quot; : &#123;</span><br><span class="line">              &quot;type&quot; : &quot;keyword&quot;,</span><br><span class="line">              &quot;ignore_above&quot; : 256</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">通过返回的mapping信息可以看到score这个索引库里面有3个字段，name、score和subject。</span><br><span class="line">1：name是text类型，其中还通过fields属性指定了一个keyword类型，表示name字段会按照text类型和keyword类型存储2份。</span><br><span class="line"></span><br><span class="line">针对fields属性的解释官网里面有详细介绍，见下图：</span><br><span class="line">大致意思是说，一个字段可以设置多种数据类型，这样ES会按照多种数据类型的特性对这个字段进行存储和建立索引。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112222083.png" alt="image-20230611222209691"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&quot;ignore_above&quot; : 256，表示keyword类型最大支持的字符串长度是256。</span><br><span class="line">ES默认会把字符串类型的数据同时指定text类型和keyword类型。</span><br><span class="line">想要实现分词检索的时候需要使用text类型，在代码层面直接指定这个name字段就表示使用text类型。</span><br><span class="line">想要实现精确查询的时候需要使用keyword类型，在代码层面指定name.keyword表示使用name的keyword类型。</span><br><span class="line"></span><br><span class="line">其实前面我们在讲排序的时候也用到了这个keyword类型的特性，因为直接指定name字段会使用text类型，text类型不支持排序和聚合，所以使用的是name.keyword。</span><br><span class="line"></span><br><span class="line">2：score是long类型，整数默认会被识别为long类型。</span><br><span class="line">3：subject也是text类型，和name是一样的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：ES 7.x版本之前字符串默认只会被识别为text类型，不会附加一个keyword类型。</span><br></pre></td></tr></table></figure><h4 id="手工创建mapping"><a href="#手工创建mapping" class="headerlink" title="手工创建mapping"></a>手工创建mapping</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">下面我们首先操作一个不存在的索引库的mapping信息：</span><br><span class="line">指定name为text类型(手工指定字符串类型时，就不会再支持keyword类型了)，并且使用ik分词器。</span><br><span class="line">age为integer类型。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test2&#39; -d&#39;&#123;&quot;mappings&quot;:&#123;&quot;properties&quot;:&#123;&quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;,&quot;analyzer&quot;: &quot;ik_max_word&quot;&#125;,&quot;age&quot;:&#123;&quot;type&quot;:&quot;integer&quot;&#125;&#125;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">查看这个索引库的mapping信息。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test2&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test2&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;integer&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot; : &quot;ik_max_word&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="更新mapping"><a href="#更新mapping" class="headerlink" title="更新mapping"></a>更新mapping</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在这个已存在的索引库中增加mapping信息。</span><br><span class="line"></span><br><span class="line">注意：只能新增字段，不能修改已有字段的类型，否则会报错。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test2&#x2F;_mapping&#39; -d&#39;&#123;&quot;properties&quot;:&#123;&quot;age&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;&#125;&#125;&#39;</span><br><span class="line">&#123;&quot;error&quot;:&#123;&quot;root_cause&quot;:[&#123;&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;mapper [age] cannot be changed from type [integer] to [long]&quot;&#125;],&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;mapper [age] cannot be changed from type [integer] to [long]&quot;&#125;,&quot;status&quot;:400&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">可以假设一下，假设支持修改已有字段的类型，之前name是text类型，如果我修改为long类型，这样就会出现矛盾了，所以ES不支持修改已有字段的类型。</span><br><span class="line">在已存在的索引库中增加一个flag字段，类型为boolean类型</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test2&#x2F;_mapping&#39; -d&#39;&#123;&quot;properties&quot;:&#123;&quot;flag&quot;:&#123;&quot;type&quot;:&quot;boolean&quot;&#125;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">查看索引库的最新mapping信息。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test2&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test2&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;integer&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;flag&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;boolean&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot; : &quot;ik_max_word&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ES的偏好查询-分片查询方式"><a href="#ES的偏好查询-分片查询方式" class="headerlink" title="ES的偏好查询(分片查询方式)"></a>ES的偏好查询(分片查询方式)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ES中的索引数据最终都是存储在分片里面的，分片有多个，并且分片还分为主分片和副本分片。</span><br><span class="line"></span><br><span class="line">ES在查询索引库中的数据时，具体是到哪些分片里面查询数据呢？</span><br><span class="line"></span><br><span class="line">在具体分析这个之前，我们先分析一下ES的分布式查询过程：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112228956.png" alt="image-20230611222857840"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">这个表示是一个3个节点的ES集群，集群内有一个索引库，索引库里面有P0和P1两个主分片，这两个主分片分别都有2个副本分片，R0和R1。</span><br><span class="line"></span><br><span class="line">查询过程主要包含三个步骤：</span><br><span class="line"></span><br><span class="line">1.客户端发送一个查询请求到Node 3，Node 3会创建一个空优先队列，主要为了存储结果数据。</span><br><span class="line">2.Node 3将查询请求转发到索引的主分片或副本分片中。每个分片在本地执行查询并将查询到的结果添加到本地的有序优先队列中。</span><br><span class="line">具体这里面Node 3将查询请求转发到索引的哪个分片中，可以是随机的，也可以由我们程序员来控制。默认是randomize across shards：表示随机从分片中取数据。</span><br><span class="line">3.每个分片返回各自优先队列中所有文档的ID和排序值给到Node 3，Node 3合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">注意：当客户端的一个搜索请求被发送到某个节点时，这个节点就变成了协调节点。 这个节点的任务是广播查询请求到所有相关分片，并将它们查询到的结果整合成全局排序后的结果集合，这个结果集合会返回给客户端。</span><br><span class="line">这里面的Node3节点其实就是协调节点。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来具体分析一下如何控制查询请求到分片之间的分发规则：</span><br><span class="line">先创建一个具有5个分片，0个副本的索引库</span><br><span class="line">分片太少不好验证效果。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;&#39; -d&#39;&#123;&quot;settings&quot;:&#123;&quot;number_of_shards&quot;:5,&quot;number_of_replicas&quot;:0&#125;&#125;&#39;</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112239645.png" alt="image-20230611223918180"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在索引库中初始化一批测试数据：</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;_doc&#x2F;2&#39; -d&#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;_doc&#x2F;3&#39; -d&#39;&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;_doc&#x2F;4&#39; -d&#39;&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;_doc&#x2F;5&#39; -d&#39;&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;pre&#x2F;_doc&#x2F;6&#39; -d&#39;&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这些测试数据在索引库的分片中的分布情况是这样的：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112242368.png" alt="image-20230611224210088"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112242380.png" alt="image-20230611224227978"></p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112242573.png" alt="image-20230611224242367"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在代码层面通过preference(...)来设置具体的分片查询方式：</span><br><span class="line">&#x2F;&#x2F;指定分片查询方式</span><br><span class="line">searchRequest.preference();&#x2F;&#x2F;默认随机</span><br></pre></td></tr></table></figure><h4 id="local"><a href="#local" class="headerlink" title="_local"></a>_local</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">表示查询操作会优先在本地节点(协调节点)的分片中查询，没有的话再到其它节点中查询。</span><br><span class="line">这种方式可以提高查询性能，假设一个索引库有5个分片，这5个分片都在Node3节点里面，客户端的查询请求正好也分配到了Node3节点上，这样在查询这5个分片的数据就都在Node3节点上进行查询了，每个分片返回结果数据的时候就不需要跨网络传输数据了，可以节省网络传输的时间。</span><br><span class="line">但是这种方式也会有弊端，如果这个节点在某一时刻接收到的查询请求比较多的时候，会对当前节点造成比较大的压力，因为这些查询请求都会优先查询这个节点上的分片数据。</span><br><span class="line"></span><br><span class="line">searchRequest.preference(&quot;_local&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">此时是可以查到所有数据的。</span><br><span class="line">数据总数：6</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br></pre></td></tr></table></figure><h4 id="only-local"><a href="#only-local" class="headerlink" title="_only_local"></a>_only_local</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">表示查询只会在本地节点的分片中查询。</span><br><span class="line">这种方式只会在查询请求所在的节点上进行查询，查询速度比较快，但是数据可能不完整，因为我们无法保证索引库的分片正好都在这一个节点上。</span><br><span class="line"></span><br><span class="line">searchRequest.preference(&quot;_only_local&quot;);</span><br><span class="line"></span><br><span class="line">数据总数：2</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br><span class="line"></span><br><span class="line">注意：大家在自己本地试验的时候，结果和我的可能不一样，因为请求不一定会分到哪一个节点上面。</span><br></pre></td></tr></table></figure><h4 id="only-nodes"><a href="#only-nodes" class="headerlink" title="_only_nodes"></a>_only_nodes</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">表示只在指定的节点中查询。</span><br><span class="line">可以控制只在指定的节点中查询某一个索引库的分片信息。</span><br><span class="line">但是注意：这里指定的节点列表里面，必须包含指定索引库的所有分片，如果从这些节点列表中获取到的索引库的分片个数不完整，程序会报错。</span><br><span class="line">这种情况适用于在某种特殊情况下，集群中的个别节点压力比较大，短时间内又无法恢复，那么我们在查询的时候可以规避掉这些节点，只选择一些正常的节点进行查询。</span><br><span class="line">前提是索引库的分片有副本，如果没有副本，只有一个主分片，就算主分片的节点压力比较大，那也只能查询这个节点了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在这里面需要指定节点ID，节点ID应该如何获取呢？</span><br><span class="line"></span><br><span class="line">通过ES中针对节点信息的RestAPI可以快速获取：</span><br><span class="line">http:&#x2F;&#x2F;bigdata01:9200&#x2F;_nodes?pretty</span><br><span class="line">返回的信息有点多，建议在浏览器中访问。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112251246.png" alt="image-20230611225100064"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">最终可以获取到三个节点的ID：</span><br><span class="line"></span><br><span class="line">注意：这个节点ID是集群随机生成的一个字符串，所以每个人的集群节点ID都是不一样的。</span><br><span class="line"></span><br><span class="line">目前这个索引库的分片分布在3个节点上</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112253294.png" alt="image-20230611225316854"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">在这里可以指定一个或者多个节点ID，多个节点ID之间使用逗号分割即可</span><br><span class="line">首先指定bigdata01节点的ID</span><br><span class="line"></span><br><span class="line">searchRequest.preference(&quot;_only_nodes:KzjZauWGRt6hJRKTgZ7BcA&quot;);</span><br><span class="line"></span><br><span class="line">注意：执行这个查询会报错，错误提示找不到pre索引库的2号分片的数据，2号分片是在bigdata03节点上</span><br><span class="line">&#123;&quot;error&quot;:&#123;&quot;root_cause&quot;:[&#123;&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;no data nodes with criteria [l7H4B3pdRm6ckBWd7ODS5Q] found for shard: [pre][2]&quot;&#125;],&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;no data nodes with criteria [l7H4B3pdRm6ckBWd7ODS5Q] found for shard: [pre][2]&quot;&#125;,&quot;status&quot;:400&#125;</span><br><span class="line"></span><br><span class="line">再把bigdata03的节点ID添加到里面</span><br><span class="line">searchRequest.preference(&quot;_only_nodes:l7H4B3pdRm6ckBWd7ODS5Q,KzjZauWGRt6hJRKTgZ7BcA&quot;);</span><br><span class="line">执行发现还是会报错，提示找不到pre索引库的3号分片，3号分片是在bigdata02节点上的</span><br><span class="line">&#123;&quot;error&quot;:&#123;&quot;root_cause&quot;:[&#123;&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;no data nodes with criterion [l7H4B3pdRm6ckBWd7ODS5Q,KzjZauWGRt6hJRKTgZ7BcA] found for shard: [pre][3]&quot;&#125;],&quot;type&quot;:&quot;illegal_argument_exception&quot;,&quot;reason&quot;:&quot;no data nodes with criterion [l7H4B3pdRm6ckBWd7ODS5Q,KzjZauWGRt6hJRKTgZ7BcA] found for shard: [pre][3]&quot;&#125;,&quot;status&quot;:400&#125;</span><br><span class="line"></span><br><span class="line">再把bigdata02的节点ID添加到里面</span><br><span class="line">searchRequest.preference(&quot;_only_nodes:l7H4B3pdRm6ckBWd7ODS5Q,KzjZauWGRt6hJRKTgZ7BcA,nS_RptvTQDuRYTplia24WA&quot;);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">此时执行就可以正常执行了：</span><br><span class="line">数据总数：6</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：在ES7.x版本之前，_only_nodes后面可以只指定某一个索引库部分分片所在的节点信息，如果不完整，不会报错，只是返回的数据是不完整的。</span><br></pre></td></tr></table></figure><h4 id="prefer-nodes"><a href="#prefer-nodes" class="headerlink" title="_prefer_nodes"></a>_prefer_nodes</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">表示优先在指定的节点上查询。</span><br><span class="line">优先在指定的节点上查询索引库分片中的数据</span><br><span class="line">如果某个节点比较空闲，尽可能的多在这个节点上查询，减轻集群中其他节点的压力，尽可能实现负载均衡。</span><br><span class="line">这里可以指定一个或者多个节点</span><br><span class="line"></span><br><span class="line">searchRequest.preference(&quot;_prefer_nodes:l7H4B3pdRm6ckBWd7ODS5Q&quot;);</span><br><span class="line"></span><br><span class="line">最终可以查询到完整的结果：</span><br><span class="line">数据总数：6</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br></pre></td></tr></table></figure><h4 id="shards-常用"><a href="#shards-常用" class="headerlink" title="_shards(常用)"></a>_shards(常用)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">表示只查询索引库中指定分片的数据。</span><br><span class="line">在查询的时候可以指定只查询索引库中指定分片中的数据，其实有点类似于Hive中的分区表的特性。</span><br><span class="line">如果我们提前已经知道需要查询的数据都在这个索引库的哪些分片里面，在这里提前指定对应分片编号，这样查询请求就只会到这些分片里面进行查询，这样可以提高查询效率，减轻集群压力。</span><br><span class="line">可以指定一个或者多个分片编号，分片编号是从0开始的。</span><br><span class="line"></span><br><span class="line">searchRequest.preference(&quot;_shards:0,1&quot;);</span><br><span class="line"></span><br><span class="line">最终可以看到这两个分区里面的数据：</span><br><span class="line">数据总数：3</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">那我们如何控制将某一类型的数据添加到指定分片呢？</span><br><span class="line"></span><br><span class="line">不要着急，一会就会讲到。</span><br></pre></td></tr></table></figure><h4 id="custom-string"><a href="#custom-string" class="headerlink" title="custom-string"></a>custom-string</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">自定义一个参数，不能以下划线(_)开头。</span><br><span class="line">有时候我们希望多次查询使用索引库中相同的分片，因为分片会有副本，正常情况下如果不做控制，那么两次查询的时候使用的分片可能会不一样，第一次查询可能使用的是主分片，第二次查询可能使用的是副本分片。</span><br><span class="line"></span><br><span class="line">大家可能会有疑问，不管是主分片，还是副本分片，这些分片里面的数据是完全一样的，就算两次查询使用的不是相同分片又会有什么问题吗？</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">会有问题的！如果searchType使用的是QUERY_THEN_FETCH，此时分片里面的数据在计算打分依据的时候是根据当前节点里面的词频和文档频率，两次查询使用的分片不是同一个，这样就会导致在计算打分依据的时候使用的样本不一致，最终导致两次相同的查询条件返回的结果不一样。</span><br><span class="line">当然了，如果你使用的是DFS_QUERY_THEN_FETCH就不会有这个问题了，但是DFS_QUERY_THEN_FETCH对性能损耗会大一些，所以并不是所有情况下都使用这种searchType。</span><br><span class="line"></span><br><span class="line">通过自定义参数的设置，只要两次查询使用的自定义参数是同一个，这样就可以保证这两次查询使用的分片是一样的，那么这两次查询的结果肯定是一样的。</span><br><span class="line"></span><br><span class="line">注意：自定义参数不能以_开头。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">searchRequest.preference(&quot;abc&quot;);&#x2F;&#x2F;自定义参数</span><br><span class="line"></span><br><span class="line">查询到的结果还是完整的。</span><br><span class="line">数据总数：6</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br></pre></td></tr></table></figure><h3 id="ES中的routing路由功能"><a href="#ES中的routing路由功能" class="headerlink" title="ES中的routing路由功能"></a>ES中的routing路由功能</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ES在添加数据时，会根据id或者routing参数进行hash，得到hash值再与该索引库的分片数量取模，得到的值即为存入的分片编号</span><br><span class="line"></span><br><span class="line">如果多条数据使用相同的routing，那么最终计算出来的分片编号都是一样的，那么这些数据就可以存储到相同的分片里面了。</span><br><span class="line"></span><br><span class="line">后期查询的只需要到指定分片中查询即可，可以显著提高查询性能。</span><br><span class="line"></span><br><span class="line">如果在面试的时候面试官问你如何在ES中实现极速查询，其实就是问这个routing路由功能的。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">下面来演示一下：</span><br><span class="line">创建一个新的索引库，指定5个分片，0个副本。</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;&#39; -d&#39;&#123;&quot;settings&quot;:&#123;&quot;number_of_shards&quot;:5,&quot;number_of_replicas&quot;:0&#125;&#125;&#39;</span><br><span class="line"></span><br><span class="line">初始化数据：</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;_doc&#x2F;1?routing&#x3D;class1&#39; -d&#39;&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;_doc&#x2F;2?routing&#x3D;class1&#39; -d&#39;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;_doc&#x2F;3?routing&#x3D;class1&#39; -d&#39;&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;_doc&#x2F;4?routing&#x3D;class1&#39; -d&#39;&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;_doc&#x2F;5?routing&#x3D;class1&#39; -d&#39;&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;rout&#x2F;_doc&#x2F;6?routing&#x3D;class1&#39; -d&#39;&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">如果是使用的JavaAPI，那么需要通过使用routing函数指定。</span><br><span class="line"></span><br><span class="line">private static void addIndexByJson(RestHighLevelClient client) throws IOException &#123;</span><br><span class="line">    IndexRequest request &#x3D; new IndexRequest(&quot;emp&quot;);</span><br><span class="line">    request.id(&quot;10&quot;);</span><br><span class="line">    String jsonString &#x3D; &quot;&#123;&quot; +</span><br><span class="line">            &quot;\&quot;name\&quot;:\&quot;jessic\&quot;,&quot; +</span><br><span class="line">            &quot;\&quot;age\&quot;:20&quot; +</span><br><span class="line">            &quot;&#125;&quot;;</span><br><span class="line">    request.source(jsonString, XContentType.JSON);</span><br><span class="line">    request.routing(&quot;class1&quot;);</span><br><span class="line">    &#x2F;&#x2F;执行</span><br><span class="line">    client.index(request, RequestOptions.DEFAULT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数据在分片中的分布情况，发现所有数据都在0号分片里面，说明routing参数生效了。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112320577.png" alt="image-20230611232004430"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">通过代码查询的时候，可以通过偏好查询指定只查询0号分片里面的数据。</span><br><span class="line"></span><br><span class="line">SearchRequest searchRequest &#x3D; new SearchRequest();</span><br><span class="line">searchRequest.indices(&quot;rout&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;指定分片查询方式</span><br><span class="line">searchRequest.preference(&quot;_shards:0&quot;);</span><br><span class="line"></span><br><span class="line">这样就可以查看所有的数据：</span><br><span class="line">数据总数：6</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">通过偏好查询中的_shard手工指定分片编号在使用的时候不太友好，需要我们单独维护一份数据和分片之间的关系，比较麻烦。</span><br><span class="line">还有一种比较简单常用的方式是在查询的时候设置相同的路由参数，这样就可以快速查询到使用这个路由参数添加的数据了。</span><br><span class="line">底层其实是会计算这个路由参数对应的分片编号，最终到指定的分片中查询数据。</span><br><span class="line"></span><br><span class="line">SearchRequest searchRequest &#x3D; new SearchRequest();</span><br><span class="line">&#x2F;&#x2F;指定索引库，支持指定一个或者多个，也支持通配符，例如：user*</span><br><span class="line">searchRequest.indices(&quot;rout&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;指定分片查询方式</span><br><span class="line">&#x2F;&#x2F;searchRequest.preference(&quot;_shards:0&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;指定路由参数</span><br><span class="line">searchRequest.routing(&quot;class1&quot;);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">结果如下</span><br><span class="line">数据总数：6</span><br><span class="line">&#123;&quot;name&quot;:&quot;tom&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:29&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;jessica&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dave&quot;,&quot;age&quot;:19&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lilei&quot;,&quot;age&quot;:18&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;lili&quot;,&quot;age&quot;:29&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">我们把routing参数修改一下，改为class2</span><br><span class="line">&#x2F;&#x2F;指定路由参数</span><br><span class="line">searchRequest.routing(&quot;class2&quot;);</span><br><span class="line"></span><br><span class="line">此时结果如下：</span><br><span class="line">数据总数：0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">从这可以看出来，这个routing参数确实生效了。</span><br><span class="line"></span><br><span class="line">注意：routing机制使用不好可能会导致数据倾斜，就是有的分片里面数据很多，有的分片里面数据很少。</span><br></pre></td></tr></table></figure><h3 id="ES的索引库模板-了解"><a href="#ES的索引库模板-了解" class="headerlink" title="ES的索引库模板(了解)"></a>ES的索引库模板(了解)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在实际工作中针对一批大量数据存储的时候需要使用多个索引库，如果手工指定每个索引库的配置信息的话就很麻烦了。</span><br><span class="line">配置信息其实主要就是settings和mapping。</span><br><span class="line">可以通过提前创建一个索引库模板，后期在创建索引库的时候，只要索引库的命名符合一定的要求就可以直接套用模板中的配置。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">下面看一个案例：</span><br><span class="line">首先创建两个索引库模板：</span><br><span class="line">第一个索引库模板：</span><br><span class="line">[root@bigdata01 ~]#curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_template&#x2F;t_1&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;template&quot; : &quot;*&quot;,</span><br><span class="line">    &quot;order&quot; : 0,</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">        &quot;properties&quot;:&#123;</span><br><span class="line">            &quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;&#125;,</span><br><span class="line">            &quot;age&quot;:&#123;&quot;type&quot;:&quot;integer&quot;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">第二个索引库模板：</span><br><span class="line">[root@bigdata01 ~]#curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_template&#x2F;t_2&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;template&quot; : &quot;te*&quot;,</span><br><span class="line">    &quot;order&quot; : 1,</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">        &quot;properties&quot;:&#123;</span><br><span class="line">            &quot;name&quot;:&#123;&quot;type&quot;:&quot;text&quot;&#125;,</span><br><span class="line">            &quot;age&quot;:&#123;&quot;type&quot;:&quot;long&quot;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意：order值大的模板内容会覆盖order值小的。</span><br><span class="line"></span><br><span class="line">第一个索引库模板默认会匹配所有的索引库，第二个索引库模板只会匹配索引库名称以te开头的索引库，通过template属性配置的。</span><br><span class="line">如果我们创建的索引库名称满足第二个就会使用第二个模板，不满足的话才会使用第一个模板。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">下面创建一个索引库，索引库名称为：test10</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl  -XPUT &#39;http:&#x2F;&#x2F;localhost:9200&#x2F;test10&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">查看索引库test10的setting和mapping信息。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test10&#x2F;_settings?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test10&quot; : &#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;routing&quot; : &#123;</span><br><span class="line">          &quot;allocation&quot; : &#123;</span><br><span class="line">            &quot;include&quot; : &#123;</span><br><span class="line">              &quot;_tier_preference&quot; : &quot;data_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;3&quot;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;test10&quot;,</span><br><span class="line">        &quot;creation_date&quot; : &quot;1804935156129&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;iJLdIRwQSpagzEtIu0LDEw&quot;,</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7130499&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;test10&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;test10&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">接下来再创建一个索引库，索引库名称为hello</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl  -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;hello&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;hello&#x2F;_settings?pretty&#39; </span><br><span class="line">&#123;</span><br><span class="line">  &quot;hello&quot; : &#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;routing&quot; : &#123;</span><br><span class="line">          &quot;allocation&quot; : &#123;</span><br><span class="line">            &quot;include&quot; : &#123;</span><br><span class="line">              &quot;_tier_preference&quot; : &quot;data_content&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;2&quot;,</span><br><span class="line">        &quot;provided_name&quot; : &quot;hello&quot;,</span><br><span class="line">        &quot;creation_date&quot; : &quot;1804935301339&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;uuid&quot; : &quot;xkg-XXSQSHKcJ_5nxyTPTQ&quot;,</span><br><span class="line">        &quot;version&quot; : &#123;</span><br><span class="line">          &quot;created&quot; : &quot;7130499&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;hello&#x2F;_mapping?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;hello&quot; : &#123;</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;integer&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">通过结果可以看出来hello这个索引库使用到了第一个索引库模板。</span><br><span class="line"></span><br><span class="line">后期想要查看索引库模板内容可以这样查看：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_template&#x2F;t_*?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;t_1&quot; : &#123;</span><br><span class="line">    &quot;order&quot; : 0,</span><br><span class="line">    &quot;index_patterns&quot; : [</span><br><span class="line">      &quot;*&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;2&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;integer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;aliases&quot; : &#123; &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;t_2&quot; : &#123;</span><br><span class="line">    &quot;order&quot; : 1,</span><br><span class="line">    &quot;index_patterns&quot; : [</span><br><span class="line">      &quot;te*&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;3&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;age&quot; : &#123;</span><br><span class="line">          &quot;type&quot; : &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;aliases&quot; : &#123; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">想要删除索引库模板可以这样做：</span><br><span class="line">[root@bigdata01 ~]# curl -XDELETE &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_template&#x2F;t_2&#39;</span><br></pre></td></tr></table></figure><h3 id="ES的索引库别名-了解"><a href="#ES的索引库别名-了解" class="headerlink" title="ES的索引库别名(了解)"></a>ES的索引库别名(了解)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在工作中使用ES收集应用的运行日志，每个星期创建一个索引库，这样时间长了就会创建很多的索引库，操作和管理的时候很不方便。</span><br><span class="line">由于新增索引数据只会操作当前这个星期的索引库，所以为了使用方便，我们就创建了两个索引库别名：curr_week和last_3_month。</span><br><span class="line"></span><br><span class="line">-curr_week：这个别名指向当前这个星期的索引库，新增数据使用这个索引库别名。</span><br><span class="line">-last_3_month：这个别名指向最近三个月的所有索引库，因为我们的需求是需要查询最近三个月的日志信息。</span><br><span class="line"></span><br><span class="line">后期只需要修改这两个别名和索引库之间的指向关系即可，应用层代码不需要任何改动。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">下面来演示一下这个案例：</span><br><span class="line">假设ES已经收集了一段时间的日志数据，每一星期都会创建一个索引库，所以目前创建了4个索引库：</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;&#39; </span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260308&#x2F;&#39; </span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260315&#x2F;&#39; </span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260322&#x2F;&#39; </span><br><span class="line"></span><br><span class="line">分别向每个索引库里面初始化1条测试数据:</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;log&quot;:&quot;info-&gt;20260301&quot;&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260308&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;log&quot;:&quot;info-&gt;20260308&quot;&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260315&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;log&quot;:&quot;info-&gt;20260315&quot;&#125;&#39;</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260322&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;log&quot;:&quot;info-&gt;20260322&quot;&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">为了使用方便，我们创建了两个索引库别名：curr_week和last_3_month。</span><br><span class="line">curr_week指向最新的索引库：log_20260322</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_aliases&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;log_20260322&quot;, &quot;alias&quot; : &quot;curr_week&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">last_3_month指向之前3个月内的索引库：</span><br><span class="line">可以同时增加多个索引别名。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_aliases&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;log_20260301&quot;, &quot;alias&quot; : &quot;last_3_month&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;log_20260308&quot;, &quot;alias&quot; : &quot;last_3_month&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;log_20260315&quot;, &quot;alias&quot; : &quot;last_3_month&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">以后使用的时候，想要操作当前星期内的数据就使用curr_week这个索引库别名就行了。</span><br><span class="line">查询一下curr_week里面的数据：</span><br><span class="line">这里面就1条数据，和使用索引库log_20260322查询的结果是一样的。</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;curr_week&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 987,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 2,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 1,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 1.0,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;log_20260322&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;log&quot; : &quot;info-&gt;20260322&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">再使用last_3_month查询一下数据：</span><br><span class="line">这里面返回了log_20260301、log_20260308和log_20260315这3个索引库里面的数据。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;last_3_month&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 73,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 6,</span><br><span class="line">    &quot;successful&quot; : 6,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 3,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 1.0,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;log_20260301&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;log&quot; : &quot;info-&gt;20260301&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;log_20260308&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;log&quot; : &quot;info-&gt;20260308&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;log_20260315&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;log&quot; : &quot;info-&gt;20260315&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">过了一个星期之后，又多了一个新的索引库：log_20260329</span><br><span class="line">创建这个索引库并初始化一条数据</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260329&#x2F;&#39; </span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260329&#x2F;_doc&#x2F;1&#39; -d&#39;&#123;&quot;log&quot;:&quot;info-&gt;20260329&quot;&#125;&#39;</span><br><span class="line"></span><br><span class="line">此时就需要修改curr_week别名指向的索引库了，需要先删除之前的关联关系，再增加新的。</span><br><span class="line">删除curr_week和log_20260322之间的关联关系。</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_aliases&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;remove&quot; : &#123; &quot;index&quot; : &quot;log_20260322&quot;, &quot;alias&quot; : &quot;curr_week&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&#39;</span><br><span class="line"></span><br><span class="line">新增curr_week和log_20260329之间的关联关系</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_aliases&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;log_20260329&quot;, &quot;alias&quot; : &quot;curr_week&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&#39;</span><br><span class="line"></span><br><span class="line">此时再查询curr_week中的数据其实就是查询索引库log_20260329里面的数据了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">然后再把索引库log_20260322添加到last_3_month别名中：</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_aliases&#39; -d &#39;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;log_20260322&quot;, &quot;alias&quot; : &quot;last_3_month&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">这些关联别名映射关系和移除别名映射关系的操作需要写个脚本定时执行，这样就可以实现别名自动关联到指定索引库了。</span><br><span class="line"></span><br><span class="line">假设时间长了，我们如果忘记了这个别名下对应的都有哪些索引库，可以使用下面的方法查看一下：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_alias&#x2F;curr_week?pretty&#39;  </span><br><span class="line">&#123;</span><br><span class="line">  &quot;log_20260329&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">      &quot;curr_week&quot; : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_alias&#x2F;last_3_month?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;log_20260315&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">      &quot;last_3_month&quot; : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;log_20260308&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">      &quot;last_3_month&quot; : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;log_20260301&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">      &quot;last_3_month&quot; : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;log_20260322&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">      &quot;last_3_month&quot; : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">如果想知道哪些别名指向了这个索引，可以这样查看：</span><br><span class="line">[root@bigdata01 ~]#  curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;_alias&#x2F;*?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;log_20260301&quot; : &#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">      &quot;last_3_month&quot; : &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">注意：针对3个月以前的索引基本上就很少再使用了，为了减少对ES服务器的性能损耗（主要是内存的损耗），建议把这些长时间不使用的索引库close掉，close之后这个索引库里面的索引数据就不支持读写操作了，close并不会删除索引库里面的数据，后期想要重新读写这个索引库里面的数据的话，可以通过open把索引库打开。</span><br><span class="line"></span><br><span class="line">将log_20260301索引库close掉：</span><br><span class="line">[root@bigdata01 ~]# curl -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;_close&#39;</span><br><span class="line"></span><br><span class="line">此时再查看这个索引库的数据就查询不到了：</span><br><span class="line">会提示这个索引库已经被close掉了。</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;index_closed_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;closed&quot;,</span><br><span class="line">        &quot;index_uuid&quot; : &quot;VGfSvKVJRjy5h3aCcsveKQ&quot;,</span><br><span class="line">        &quot;index&quot; : &quot;log_20260301&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;index_closed_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;closed&quot;,</span><br><span class="line">    &quot;index_uuid&quot; : &quot;VGfSvKVJRjy5h3aCcsveKQ&quot;,</span><br><span class="line">    &quot;index&quot; : &quot;log_20260301&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 400</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">注意：这些close之后的索引库需要从索引库别名中移除掉，否则会导致无法使用从索引库别名查询数据，因为这个索引库别名中映射的有已经close掉的索引库。</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;last_3_month&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;index_closed_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;closed&quot;,</span><br><span class="line">        &quot;index_uuid&quot; : &quot;VGfSvKVJRjy5h3aCcsveKQ&quot;,</span><br><span class="line">        &quot;index&quot; : &quot;log_20260301&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;index_closed_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;closed&quot;,</span><br><span class="line">    &quot;index_uuid&quot; : &quot;VGfSvKVJRjy5h3aCcsveKQ&quot;,</span><br><span class="line">    &quot;index&quot; : &quot;log_20260301&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 400</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">接下来将log_20260301索引库重新open（打开）。</span><br><span class="line">[root@bigdata01 ~]# curl -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;_open&#39;</span><br><span class="line"></span><br><span class="line">索引库open之后就可以查询了</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;log_20260301&#x2F;_search?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 5,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 2,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">      &quot;value&quot; : 1,</span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : 1.0,</span><br><span class="line">    &quot;hits&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot; : &quot;log_20260301&quot;,</span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">        &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">        &quot;_score&quot; : 1.0,</span><br><span class="line">        &quot;_source&quot; : &#123;</span><br><span class="line">          &quot;log&quot; : &quot;info-&gt;20260301&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">索引库别名也可以正常使用了</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">索引库close掉之后，虽然对ES服务器没有性能损耗了，但是对ES集群的磁盘占用还是存在的，所以可以根据需求，将一年以前的索引库彻底删除掉。</span><br></pre></td></tr></table></figure><h3 id="ES-SQL"><a href="#ES-SQL" class="headerlink" title="ES SQL"></a>ES SQL</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">针对ES中的结构化数据，使用SQL实现聚合统计会很方便，可以减少很多工作量。</span><br><span class="line"></span><br><span class="line">ES SQL支持常见的SQL语法，包括分组、排序、函数等，但是目前不支持JOIN。</span><br><span class="line"></span><br><span class="line">在使用的时候可以使用SQL命令行、RestAPI、JDBC、ODBC等方式操作。</span><br><span class="line">本地测试的时候使用SQL命令行更加方便。</span><br><span class="line">想要实现跨语言调用使用RestAPI更加方便。</span><br><span class="line">Java程序员使用JDBC方式更方便。</span><br></pre></td></tr></table></figure><h4 id="ES-SQL命令行下的使用"><a href="#ES-SQL命令行下的使用" class="headerlink" title="ES SQL命令行下的使用"></a>ES SQL命令行下的使用</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[es@bigdata01 elasticsearch-7.13.4]$ bin&#x2F;elasticsearch-sql-cli http:&#x2F;&#x2F;bigdata01:9200</span><br><span class="line">sql&gt; select * from user;</span><br><span class="line">      age      |     name      </span><br><span class="line">---------------+---------------</span><br><span class="line">20             |tom            </span><br><span class="line">15             |tom            </span><br><span class="line">17             |jack           </span><br><span class="line">19             |jess           </span><br><span class="line">23             |mick           </span><br><span class="line">12             |lili           </span><br><span class="line">28             |john           </span><br><span class="line">30             |jojo           </span><br><span class="line">16             |bubu           </span><br><span class="line">21             |pig            </span><br><span class="line">19             |mary           </span><br><span class="line">60             |刘德华            </span><br><span class="line">20             |刘老二</span><br><span class="line">sql&gt; select * from user where age &gt; 20;</span><br><span class="line">      age      |     name      </span><br><span class="line">---------------+---------------</span><br><span class="line">23             |mick           </span><br><span class="line">28             |john           </span><br><span class="line">30             |jojo           </span><br><span class="line">21             |pig            </span><br><span class="line">60             |刘德华</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">如果想要实现模糊查询，使用sql中的like是否可行？</span><br><span class="line">sql&gt; select * from user where name like &#39;刘华&#39;;                     </span><br><span class="line">      age      |     name      </span><br><span class="line">---------------+---------------</span><br><span class="line">sql&gt; select * from user where name like &#39;刘%&#39;;  </span><br><span class="line">      age      |     name      </span><br><span class="line">---------------+---------------</span><br><span class="line">60             |刘德华            </span><br><span class="line">20             |刘老二</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">like这种方式其实就是普通的查询了，无法实现分词查询。</span><br><span class="line">想要实现分词查询，需要使用match。</span><br><span class="line"></span><br><span class="line">sql&gt; select * from user where match(name,&#39;刘华&#39;);       </span><br><span class="line">      age      |     name      </span><br><span class="line">---------------+---------------</span><br><span class="line">60             |刘德华            </span><br><span class="line">20             |刘老二</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">退出ES SQL命令行，需要输入exit；</span><br></pre></td></tr></table></figure><h4 id="RestAPI下ES-SQL的使用。"><a href="#RestAPI下ES-SQL的使用。" class="headerlink" title="RestAPI下ES SQL的使用。"></a>RestAPI下ES SQL的使用。</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">查询user索引库中的数据，根据age倒序排序，获取前5条数据。</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_sql?format&#x3D;txt&#39; -d&#39;</span><br><span class="line">&#123;</span><br><span class="line">&quot;query&quot;:&quot;select * from user order by age desc limit 5&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br><span class="line">      age      |     name      </span><br><span class="line">---------------+---------------</span><br><span class="line">60             |刘德华            </span><br><span class="line">30             |jojo           </span><br><span class="line">28             |john           </span><br><span class="line">23             |mick           </span><br><span class="line">21             |pig</span><br></pre></td></tr></table></figure><h4 id="JDBC操作ES-SQL"><a href="#JDBC操作ES-SQL" class="headerlink" title="JDBC操作ES SQL"></a>JDBC操作ES SQL</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">首先添加ES sql-jdbc的依赖。</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.elasticsearch.plugin&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;x-pack-sql-jdbc&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;7.13.4&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">package com.imooc.es;</span><br><span class="line"></span><br><span class="line">import java.sql.Connection;</span><br><span class="line">import java.sql.DriverManager;</span><br><span class="line">import java.sql.ResultSet;</span><br><span class="line">import java.sql.Statement;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * JDBC操作ES SQL</span><br><span class="line"> * Created by xuwei</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class EsJdbcOp &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        &#x2F;&#x2F;指定jdbcUrl</span><br><span class="line">        String jdbcUrl &#x3D; &quot;jdbc:es:&#x2F;&#x2F;http:&#x2F;&#x2F;bigdata01:9200&#x2F;?timezone&#x3D;UTC+8&quot;;</span><br><span class="line">        Properties properties &#x3D; new Properties();</span><br><span class="line">        &#x2F;&#x2F;获取JDBC连接</span><br><span class="line">        Connection conn &#x3D; DriverManager.getConnection(jdbcUrl, properties);</span><br><span class="line">        Statement stmt &#x3D; conn.createStatement();</span><br><span class="line">        ResultSet results &#x3D; stmt.executeQuery(&quot;select name,age from user order by age desc limit 5&quot;);</span><br><span class="line">        while (results.next())&#123;</span><br><span class="line">            String name &#x3D; results.getString(1);</span><br><span class="line">            int age &#x3D; results.getInt(2);</span><br><span class="line">            System.out.println(name+&quot;--&quot;+age);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;关闭连接</span><br><span class="line">        stmt.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：jdbc这种方式目前无法免费使用，需要购买授权。</span><br><span class="line"></span><br><span class="line">Exception in thread &quot;main&quot; java.sql.SQLInvalidAuthorizationSpecException: current license is non-compliant for [jdbc]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">所以在工作中常用的是RestAPI这种方式。</span><br></pre></td></tr></table></figure><h3 id="ES优化策略"><a href="#ES优化策略" class="headerlink" title="ES优化策略"></a>ES优化策略</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">1.ES中Too many open files的问题。</span><br><span class="line"></span><br><span class="line">ES中的索引数据都是存储在磁盘文件中的，每一条数据在底层都会产生一份索引片段文件</span><br><span class="line">这些索引数据默认的存储目录是在ES安装目录下的data目录里面。</span><br><span class="line"></span><br><span class="line">[es@bigdata01 index]$ pwd</span><br><span class="line">&#x2F;data&#x2F;soft&#x2F;elasticsearch-7.13.4&#x2F;data&#x2F;nodes&#x2F;0&#x2F;indices&#x2F;28q_rMHAR4GJBImzb40woA&#x2F;0&#x2F;index</span><br><span class="line">[es@bigdata01 index]$ ll</span><br><span class="line">total 52</span><br><span class="line">-rw-rw-r--. 1 es es  479 Mar 12 15:21 _0.cfe</span><br><span class="line">-rw-rw-r--. 1 es es 3302 Mar 12 15:21 _0.cfs</span><br><span class="line">-rw-rw-r--. 1 es es  363 Mar 12 15:21 _0.si</span><br><span class="line">-rw-rw-r--. 1 es es  479 Mar 12 15:21 _1.cfe</span><br><span class="line">-rw-rw-r--. 1 es es 2996 Mar 12 15:21 _1.cfs</span><br><span class="line">-rw-rw-r--. 1 es es  363 Mar 12 15:21 _1.si</span><br><span class="line">-rw-rw-r--. 1 es es  923 Mar 12 16:28 _2_1.fnm</span><br><span class="line">-rw-rw-r--. 1 es es  103 Mar 12 16:28 _2_1_Lucene80_0.dvd</span><br><span class="line">-rw-rw-r--. 1 es es  160 Mar 12 16:28 _2_1_Lucene80_0.dvm</span><br><span class="line">-rw-rw-r--. 1 es es  479 Mar 12 16:28 _2.cfe</span><br><span class="line">-rw-rw-r--. 1 es es 3718 Mar 12 16:28 _2.cfs</span><br><span class="line">-rw-rw-r--. 1 es es  363 Mar 12 16:28 _2.si</span><br><span class="line">-rw-rw-r--. 1 es es  533 Mar 12 16:33 segments_4</span><br><span class="line">-rw-rw-r--. 1 es es    0 Mar 12 15:21 write.lock</span><br><span class="line"></span><br><span class="line">注意：路径中的28q_rMHAR4GJBImzb40woA表示是索引库的UUID。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306112348016.png" alt="image-20230611234857593"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ES在查询索引库里面数据的时候需要读取所有的索引片段，如果索引库中数据量比较多，那么ES在查询的时候就需要读取很多索引片段文件，此时可能就会达到Linux系统的极限，因为Linux会限制系统内最大文件打开数。</span><br><span class="line">这个最大文件打开数的的配置在安装ES集群的时候我们已经修改过了：</span><br><span class="line">主要就是这些参数：</span><br><span class="line">[root@bigdata01 soft]# vi &#x2F;etc&#x2F;security&#x2F;limits.conf </span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line"></span><br><span class="line">理论上来说，不管我们将最大文件打开数修改为多大，在使用的时候都有可能会出问题，因为ES中的数据是越来越多的，那如何解决？</span><br><span class="line">其实也不用过于担心，因为ES中默认会有一个自动的索引片段合并机制，这样可以保证ES中不会产生过多的索引片段。</span><br><span class="line">只要是单个索引片段文件小于5G的，在自动索引片段合并机制触发的时候都会进行合并。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">2.索引合并优化，清除标记为删除状态的索引数据。</span><br><span class="line"></span><br><span class="line">咱们前面分析过，ES中的删除并不是真正的删除，只是会给数据标记一个删除状态，索引片段在合并的时候，是会把索引片段中标记为删除的数据真正删掉，这样也是可以提高性能的，因为标记为删除状态的数据是会参与查询的，只不过会被过滤掉。</span><br><span class="line"></span><br><span class="line">索引片段合并除了可以避免产生Too many open files这个问题，其实它也是可以显著提升查询性能的，因为我们读取一个中等大小的文件肯定是比读取很多个小文件效率更高的</span><br><span class="line"></span><br><span class="line">除了等待自动的索引片段合并，也可以手工执行索引片段合并操作，但是要注意：索引片段合并操作是比较消耗系统IO资源的，不要在业务高峰期执行，也没必要频繁调用，可以每天凌晨执行一次。</span><br><span class="line"></span><br><span class="line">[root@bigdata01 ~]# curl -XPOST &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;stu&#x2F;_forcemerge&#39;</span><br><span class="line">合并之后会的索引片段就变成了这样，这些文件其实属于一个索引片段，都是以_3开头的：</span><br><span class="line">[es@bigdata01 index]$ ll</span><br><span class="line">total 72</span><br><span class="line">-rw-rw-r--. 1 es es 158 Mar 14 15:47 _3.fdm</span><br><span class="line">-rw-rw-r--. 1 es es 527 Mar 14 15:47 _3.fdt</span><br><span class="line">-rw-rw-r--. 1 es es  64 Mar 14 15:47 _3.fdx</span><br><span class="line">-rw-rw-r--. 1 es es 922 Mar 14 15:47 _3.fnm</span><br><span class="line">-rw-rw-r--. 1 es es 202 Mar 14 15:47 _3.kdd</span><br><span class="line">-rw-rw-r--. 1 es es  69 Mar 14 15:47 _3.kdi</span><br><span class="line">-rw-rw-r--. 1 es es 200 Mar 14 15:47 _3.kdm</span><br><span class="line">-rw-rw-r--. 1 es es 159 Mar 14 15:47 _3_Lucene80_0.dvd</span><br><span class="line">-rw-rw-r--. 1 es es 855 Mar 14 15:47 _3_Lucene80_0.dvm</span><br><span class="line">-rw-rw-r--. 1 es es  78 Mar 14 15:47 _3_Lucene84_0.doc</span><br><span class="line">-rw-rw-r--. 1 es es  92 Mar 14 15:47 _3_Lucene84_0.pos</span><br><span class="line">-rw-rw-r--. 1 es es 305 Mar 14 15:47 _3_Lucene84_0.tim</span><br><span class="line">-rw-rw-r--. 1 es es  74 Mar 14 15:47 _3_Lucene84_0.tip</span><br><span class="line">-rw-rw-r--. 1 es es 261 Mar 14 15:47 _3_Lucene84_0.tmd</span><br><span class="line">-rw-rw-r--. 1 es es  59 Mar 14 15:47 _3.nvd</span><br><span class="line">-rw-rw-r--. 1 es es 103 Mar 14 15:47 _3.nvm</span><br><span class="line">-rw-rw-r--. 1 es es 575 Mar 14 15:47 _3.si</span><br><span class="line">-rw-rw-r--. 1 es es 316 Mar 14 15:47 segments_5</span><br><span class="line">-rw-rw-r--. 1 es es   0 Mar 12 15:21 write.lock</span><br><span class="line"></span><br><span class="line">如果一个索引库中的数据已经非常多了，手工执行索引片段合并操作可能会产生一些非常大的索引片段（超过5G的），如果继续向这个索引库里面写入新的数据，那么ES的自动索引片段合并机制就不会再考虑这些非常大的索引片段了（超过5G的），这样会导致索引库中保留了非常大的索引片段，从而降低搜索性能。</span><br><span class="line"></span><br><span class="line">这种问题该如何解决呢？往下面继续看！</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">3.分片和副本个数调整</span><br><span class="line"></span><br><span class="line">分片多的话，可以提升建立索引的能力，单个索引库，建议使用5-20个分片比较合适。</span><br><span class="line">分片数过少或过多，都会降低检索效率。</span><br><span class="line">分片数过多会导致检索时打开比较多的文件，另外也会导致多台服务器之间的通讯。</span><br><span class="line">而分片数过少会导致单个分片索引过大，所以检索速度也会慢。</span><br><span class="line">建议单个分片存储20G左右的索引数据【最高也不要超过50G，否则性能会很差】</span><br><span class="line">所以，大致有一个公式：分片数量&#x3D;数据总量&#x2F;20G</span><br><span class="line"></span><br><span class="line">当数据规模超过单个索引库最大存储能力的时候，只需要新建一个索引库即可，所以ES中的海量数据存储能力是需要依靠多个索引库的，这样就可以解决前面所说的索引库中单个索引片段过大的问题。</span><br><span class="line"></span><br><span class="line">副本多的话，理论上来说可以提升检索的能力，但是如果设置很多副本的话也会对服务器造成额外的压力，因为主分片需要给所有副本分片同步数据，所以建议最多设置1-2个副本即可。</span><br><span class="line"></span><br><span class="line">注意：从ES7.x版本开始，集群中每个节点默认支持最多1000个了片，这块主要是考虑到单个节点的性能问题，如果集群内每个节点的性能都比较强，当然也是支持修改的。</span><br><span class="line"></span><br><span class="line">先查看一下现在集群默认的参数配置：</span><br><span class="line">现在里面的参数都是空的。</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_cluster&#x2F;settings?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;persistent&quot; : &#123; &#125;,</span><br><span class="line">  &quot;transient&quot; : &#123; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">修改节点支持的最大分片数量</span><br><span class="line">[root@bigdata01 ~]# curl -H &quot;Content-Type: application&#x2F;json&quot; -XPUT &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_cluster&#x2F;settings&#39;  -d &#39;&#123; &quot;persistent&quot;: &#123; &quot;cluster.max_shards_per_node&quot;: &quot;10000&quot; &#125; &#125;&#39;</span><br><span class="line"></span><br><span class="line">重新查询集群最新的参数配置：</span><br><span class="line">[root@bigdata01 ~]# curl -XGET &#39;http:&#x2F;&#x2F;bigdata01:9200&#x2F;_cluster&#x2F;settings?pretty&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;persistent&quot; : &#123;</span><br><span class="line">    &quot;cluster&quot; : &#123;</span><br><span class="line">      &quot;max_shards_per_node&quot; : &quot;10000&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;transient&quot; : &#123; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">4.初始化数据时，建议将副本数设置为0。</span><br><span class="line"></span><br><span class="line">如果是在项目初期，ES集群刚安装好，需要向里面批量初始化大量数据，此时建议将副本数设置为0，这样是可以显著提高入库效率的。</span><br><span class="line">如果有副本的话，在批量初始化数据的同时，索引库的主分片还需要负责向副本分片同步数据，这样会影响数据的入库性能。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5. 针对不使用的index，建议close，减少性能损耗。</span><br><span class="line">具体的操作方式在前面讲索引库别名的时候已经讲过了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">6.调整ES的JVM内存大小，单个ES实例最大不超过32G。</span><br><span class="line"></span><br><span class="line">单个ES实例官方建议最大使用32G内存，如果超过这个内存ES也使用不了，这样会造成资源浪费。</span><br><span class="line">所以在前期申请ES集群机器的时候，建议单机内存在32G左右即可。</span><br><span class="line">如果由于历史遗留问题导致每台机器的内存都很大，假设是128G的，如果在这台机器上只部署一个ES实例，会造成内存资源浪费，此时有一种取巧的方式，在同一台机器上部署多个ES实例，只需要让这台机器中的每个ES实例监听不同的端口就行了。</span><br><span class="line">这样这个128G内存的机器理论上至少可以部署4个ES实例。</span><br><span class="line">但是这样会存在一个弊端，如果后期这台机器出现了故障，那么ES集群会同时丢失4个节点，可能会丢数据，所以还是尽量避免这种情况。</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Elasticsearch" scheme="http://tianyong.fun/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第十七周-Flink极速上手篇-Flink新版本1.12以上-3</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1-12%E4%BB%A5%E4%B8%8A-3.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E4%B8%83%E5%91%A8-Flink%E6%9E%81%E9%80%9F%E4%B8%8A%E6%89%8B%E7%AF%87-Flink%E6%96%B0%E7%89%88%E6%9C%AC1-12%E4%BB%A5%E4%B8%8A-3.html</id>
    <published>2023-06-02T09:40:07.000Z</published>
    <updated>2023-06-02T10:01:55.124Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="Flink新版本1-12以上-3"><a href="#Flink新版本1-12以上-3" class="headerlink" title="Flink新版本1.12以上-3"></a>Flink新版本1.12以上-3</h1><h2 id="Checkpoint与State剖析"><a href="#Checkpoint与State剖析" class="headerlink" title="Checkpoint与State剖析"></a>Checkpoint与State剖析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">前面我们已经掌握了Checkpoint和State使用，下面我们来从底层原理层面深度分析一下Checkpoint和State的细节流程。</span><br><span class="line"></span><br><span class="line">首先是checkpoint的生成过程</span><br></pre></td></tr></table></figure><h3 id="Checkpoint的生成过程"><a href="#Checkpoint的生成过程" class="headerlink" title="Checkpoint的生成过程"></a>Checkpoint的生成过程</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021740884.png" alt="image-20230602174046655"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">我们先整体看一下这个图：</span><br><span class="line"></span><br><span class="line">首先看图中左边的内容，这块内容表示是输入数据流中的数据以及对应的偏移量。</span><br><span class="line">其中里面的send、follow是具体的数据，下面的1、2、3、4、5、6是数据对应的偏移量。</span><br><span class="line">这个输入数据流表示是直播间内用户产生的实时行为数据，send表示送礼，follow表示关注</span><br><span class="line">在这里我们需要对这些用户行为数据实时统计，统计出每种行为出现的总次数。</span><br><span class="line"></span><br><span class="line">中间的[send ,4]表示目前消费者消费到的那条数据及对应的偏移量，这个信息会存储在基于内存的状态中。</span><br><span class="line"></span><br><span class="line">右边的[count(send), 3]、[count(follow) ,1],这些是实时汇总的结果，这些数据也会存储在基于内存的状态中。</span><br><span class="line"></span><br><span class="line">Flink触发执行Checkpoint之后会把内存中存储的状态数据写入到下面的持久化存储中。</span><br><span class="line"></span><br><span class="line">下面我们来详细看一下checkpoint的执行流程。</span><br><span class="line">1：当消费到[send，4]这条数据时，正好达到了checkpoint的执行时机，此时JobManager中的checkpoint coordinator会触发checkpoint开始执行。</span><br><span class="line">此时状态中存储的消费偏移量是4</span><br><span class="line"></span><br><span class="line">2-1：checkpoint真正开始执行的时候，他会先把状态中维护的消费偏移量写入到持久化存储中。</span><br><span class="line"></span><br><span class="line">2-2：写入结束后，DataSource组件会把状态的存储路径信息反馈给JobManager中的checkpoint coordinator。</span><br><span class="line"></span><br><span class="line">3-1、3-2、4-1、4-2：接着后面算子中的状态数据：[count(send), 3]、[count(follow) ,1]也会进行同样的步骤</span><br><span class="line"></span><br><span class="line">5：等所有的算子都完成了状态数据的持久化存储，也就是说 checkpoint coordinator 收集到了所有任务反馈给他的状态存储路径，这个时候就认为这一次的checkpoint真正执行成功了，最后他会向持久化存储中再备份一个 checkpoint metadata元数据文件，那么本次整个checkpoint流程就完成了。如果中间有任何一个阶段不成功，那么本次checkpoint就宣告失败。</span><br><span class="line"></span><br><span class="line">当达到下一次checkpoint执行时机的时候，会继续重复前面的执行流程。</span><br><span class="line"></span><br><span class="line">这就是checkpoint的生成过程。</span><br></pre></td></tr></table></figure><h3 id="Checkpoint的恢复过程"><a href="#Checkpoint的恢复过程" class="headerlink" title="Checkpoint的恢复过程"></a>Checkpoint的恢复过程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">下面我们来分析一下Checkpoint的恢复过程。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021745635.png" alt="image-20230602174549554"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">继续接着前面的业务流程，前面我们在消费完第4条数据的时候触发了一次checkpoint。</span><br><span class="line">checkpoint执行结束后，紧接着消费者开始消费第5条数据，当把第5条数据follow消费出来之后，在计算的时候由于资源问题导致出现了故障，此时任务异常结束了。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021746680.png" alt="image-20230602174608348"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">任务结束后，Flink尝试重启任务，并恢复数据到之前的状态。</span><br><span class="line">在最开始重启任务的时候，任务中基于内存的状态都是空的。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021746670.png" alt="image-20230602174632536"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当任务重新启动之后，会根据指定的快照数据进行恢复，此时上一次在快照时保存的偏移量4、[count(send), 3]、[count(follow) ,1]这些数据对应的都恢复到了正确的位置。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021746394.png" alt="image-20230602174650649"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">恢复成功之后，任务会基于之前的偏移量4继续往后面消费，所以又把[follow，5]这条数据消费出来了。</span><br><span class="line">此时算子中计算的结果，count(follow)就变成了2。</span><br><span class="line">这就是正常的数据处理流程了。</span><br></pre></td></tr></table></figure><h3 id="Checkpoint-Barrier"><a href="#Checkpoint-Barrier" class="headerlink" title="Checkpoint Barrier"></a>Checkpoint Barrier</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">在Checkpoint执行过程中，还有一个重要的角色，Barrier。</span><br><span class="line">可以将Barrier认为是一个标记或者说是一条特殊的数据。</span><br><span class="line"></span><br><span class="line">Flink任务在每次触发Checkpoint的时候都会由JobManager的Checkpoint Coordinator向Source端插入一个Barrier。</span><br><span class="line"></span><br><span class="line">Barrier中包含有一个Checkpoint ID，用于标识它属于哪一个Checkpoint。</span><br><span class="line"></span><br><span class="line">Barrier中的Checkpoint ID是严格单调递增的(自增ID)。</span><br><span class="line">看下面这个图</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021747611.png" alt="image-20230602174724039"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">图里面的A\B\C\D这些属于数据流中的正常数据。</span><br><span class="line">其中1和2是checkpoint ID，这是特殊的Barrier标记数据。</span><br><span class="line">每次触发checkpoint的时候，JobManager的Checkpoint Coordinator都会向数据流中插入一个Barrier。</span><br><span class="line"></span><br><span class="line">这个Barrier标记在源码中对应的类是CheckpointBarrier</span><br><span class="line">可以大致看一下他的代码：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class CheckpointBarrier extends RuntimeEvent &#123;</span><br><span class="line"></span><br><span class="line">    private final long id;</span><br><span class="line">    private final long timestamp;</span><br><span class="line">    private final CheckpointOptions checkpointOptions;</span><br><span class="line"></span><br><span class="line">    public CheckpointBarrier(long id, long timestamp, CheckpointOptions checkpointOptions) &#123;</span><br><span class="line">        this.id &#x3D; id;</span><br><span class="line">        this.timestamp &#x3D; timestamp;</span><br><span class="line">        this.checkpointOptions &#x3D; checkNotNull(checkpointOptions);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">从这可以看出来他里面除了包含一个自增的id字段，还有一个时间戳字段，以及保存checkpoint参数的字段。</span><br><span class="line"></span><br><span class="line">Barrier中的Checkpoint ID其实就是之前我们在任务界面中查看Checkpoint相关信息时显示的那个ID。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021748333.png" alt="image-20230602174822221"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Checkpoint在执行的时候，Source在接收到Barrier，会把Barrier广播发送到下游算子，当下游算子A接收到了所有输入数据流的Barrier时，意味着算子A已经处理完了截止到当前Checkpoint的数据。</span><br><span class="line"></span><br><span class="line">然后算子A就可以执行Checkpoint，并将Barrier广播发送至下游算子。</span><br><span class="line"></span><br><span class="line">Barrier的最大作用是用于算子各个子任务之间对齐检查点，Barrier对齐之后才会保存状态数据，最终保持一致性语义。</span><br><span class="line"></span><br><span class="line">怎么理解呢？</span><br><span class="line"></span><br><span class="line">看下面这个图：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202306021748577.png" alt="image-20230602174840536"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Source会把Barrier广播发送到下游算子A。</span><br><span class="line"></span><br><span class="line">Source的并行度为2，所以Source的每个子任务都会给下游的算子广播发送Barrier。</span><br><span class="line"></span><br><span class="line">算子A在这里也产生了2个子任务，对应的是算子A-1和算子A-2，每个子任务负责处理一部分数据</span><br><span class="line"></span><br><span class="line">在这里Source-1这个子任务会给下游的算子A-1和算子A-2分别发送Barrier。</span><br><span class="line"></span><br><span class="line">Source-2这个子任务也会给下游的算子A-1和算子A-2分别发送Barrier。</span><br><span class="line"></span><br><span class="line">当算子A-1收到Source-1和Source-2这两个子任务发给他的Barrier标记时，他才会真正执行checkpoint，因为这个时候才实现了Barrier对齐，也就意味着这个子任务把本次checkpoint之前需要处理的数据都处理完了，这个时候执行checkpoint操作，才能保证数据的一致性。</span><br><span class="line"></span><br><span class="line">算子A-2也是这样的。</span><br></pre></td></tr></table></figure><h4 id="Kafka-Flink-Kafka实现端到端一致性"><a href="#Kafka-Flink-Kafka实现端到端一致性" class="headerlink" title="Kafka+Flink+Kafka实现端到端一致性"></a>Kafka+Flink+Kafka实现端到端一致性</h4><h3 id="Flink-Kafka相关源码分析"><a href="#Flink-Kafka相关源码分析" class="headerlink" title="Flink-Kafka相关源码分析"></a>Flink-Kafka相关源码分析</h3><h2 id="Kafka连接器新API的使用"><a href="#Kafka连接器新API的使用" class="headerlink" title="Kafka连接器新API的使用"></a>Kafka连接器新API的使用</h2><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>找工作知识复习</title>
    <link href="http://tianyong.fun/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0.html"/>
    <id>http://tianyong.fun/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0.html</id>
    <published>2023-05-25T08:59:41.000Z</published>
    <updated>2023-05-27T17:14:09.354Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="找工作知识复习"><a href="#找工作知识复习" class="headerlink" title="找工作知识复习"></a>找工作知识复习</h1><h2 id="直播平台三度关系推荐"><a href="#直播平台三度关系推荐" class="headerlink" title="直播平台三度关系推荐"></a>直播平台三度关系推荐</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.技术选型：</span><br><span class="line">数据采集聚合</span><br><span class="line">数据分发</span><br><span class="line">数据存储</span><br><span class="line">数据计算</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2.整体架构</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3.Neo4j安装，概念，创建节点和关系，查找，更新，索引，批量导入</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4.数据来源分析，模拟产生</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">5.zookeeper,kafka启动-&gt;创建topic-&gt;数据分发-&gt;数据落盘</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">6.第二个任务：实时维护粉丝关注</span><br></pre></td></tr></table></figure><h2 id="Java常识"><a href="#Java常识" class="headerlink" title="Java常识"></a>Java常识</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">继承-&gt;extends-&gt;protected-&gt;super-&gt;构造函数第一行应该是父类的某个构造函数，否则默认父类无参数构造函数-&gt;限制继承final和sealed、permits-&gt;覆写和重载-&gt;多态-&gt;向上转型</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">抽象方法-&gt;抽象类-&gt;继承抽象类时必须覆写(否则还是抽象类)-&gt;可以有实例字段和方法</span><br><span class="line"></span><br><span class="line">接口-&gt;interface-&gt;implements-&gt;一个类可以继承多个接口-&gt;一个接口可以extends一个接口-&gt;不能有实例字段(可以有静态字段，且要有final修饰)和方法-&gt;可以有default方法</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">静态字段static-&gt;静态方法</span><br></pre></td></tr></table></figure><h2 id="IDEA常识"><a href="#IDEA常识" class="headerlink" title="IDEA常识"></a>IDEA常识</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">内存设置：</span><br><span class="line">一个全局内存设置，一个为单独程序设置运行时的内存</span><br></pre></td></tr></table></figure><h2 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h2><pre><code></code></pre><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第十八周 直播平台三度关系推荐v2.0-4</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AB%E5%91%A8-%E7%9B%B4%E6%92%AD%E5%B9%B3%E5%8F%B0%E4%B8%89%E5%BA%A6%E5%85%B3%E7%B3%BB%E6%8E%A8%E8%8D%90v2-0-4.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AB%E5%91%A8-%E7%9B%B4%E6%92%AD%E5%B9%B3%E5%8F%B0%E4%B8%89%E5%BA%A6%E5%85%B3%E7%B3%BB%E6%8E%A8%E8%8D%90v2-0-4.html</id>
    <published>2023-05-17T07:34:44.000Z</published>
    <updated>2023-05-17T07:39:42.425Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第十八周-直播平台三度关系推荐v2-0-4"><a href="#第十八周-直播平台三度关系推荐v2-0-4" class="headerlink" title="第十八周 直播平台三度关系推荐v2.0-4"></a>第十八周 直播平台三度关系推荐v2.0-4</h1><h2 id="数据加工总线之SparkSQL计算引擎开发"><a href="#数据加工总线之SparkSQL计算引擎开发" class="headerlink" title="数据加工总线之SparkSQL计算引擎开发"></a>数据加工总线之SparkSQL计算引擎开发</h2><h3 id="核心功能点梳理"><a href="#核心功能点梳理" class="headerlink" title="核心功能点梳理"></a>核心功能点梳理</h3><h3 id="开发基于SparkSQL的计算引擎"><a href="#开发基于SparkSQL的计算引擎" class="headerlink" title="开发基于SparkSQL的计算引擎"></a>开发基于SparkSQL的计算引擎</h3><h2 id="数据加工总线之FlinkSQL计算引擎开发"><a href="#数据加工总线之FlinkSQL计算引擎开发" class="headerlink" title="数据加工总线之FlinkSQL计算引擎开发"></a>数据加工总线之FlinkSQL计算引擎开发</h2><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="直播平台三度关系推荐v2.0" scheme="http://tianyong.fun/tags/%E7%9B%B4%E6%92%AD%E5%B9%B3%E5%8F%B0%E4%B8%89%E5%BA%A6%E5%85%B3%E7%B3%BB%E6%8E%A8%E8%8D%90v2-0/"/>
    
  </entry>
  
  <entry>
    <title>大数据开发工程师-第十八周 直播平台三度关系推荐v2.0-3</title>
    <link href="http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AB%E5%91%A8-%E7%9B%B4%E6%92%AD%E5%B9%B3%E5%8F%B0%E4%B8%89%E5%BA%A6%E5%85%B3%E7%B3%BB%E6%8E%A8%E8%8D%90v2-0-3.html"/>
    <id>http://tianyong.fun/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88-%E7%AC%AC%E5%8D%81%E5%85%AB%E5%91%A8-%E7%9B%B4%E6%92%AD%E5%B9%B3%E5%8F%B0%E4%B8%89%E5%BA%A6%E5%85%B3%E7%B3%BB%E6%8E%A8%E8%8D%90v2-0-3.html</id>
    <published>2023-05-03T09:35:36.000Z</published>
    <updated>2023-05-17T07:39:38.772Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr><script type="text/javascript" src="/js/src/bai.js"></script><h1 id="第十八周-直播平台三度关系推荐v2-0-3"><a href="#第十八周-直播平台三度关系推荐v2-0-3" class="headerlink" title="第十八周 直播平台三度关系推荐v2.0-3"></a>第十八周 直播平台三度关系推荐v2.0-3</h1><h2 id="数据中台的前世今生"><a href="#数据中台的前世今生" class="headerlink" title="数据中台的前世今生"></a>数据中台的前世今生</h2><h3 id="什么是中台"><a href="#什么是中台" class="headerlink" title="什么是中台"></a>什么是中台</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">中台是2019年开始火起来的一个概念，它最早是由阿里在2015年提出的“大中台，小前台”战略中延伸出来的概念，灵感来源于一家芬兰的小公司Supercell——一家仅有300名员工，却接连推出爆款游戏，是全球最会赚钱的明星游戏公司。2015年年中,马云带领阿里巴巴集团高管,拜访了位于芬兰赫尔辛基的这家移动游戏公司，这家看似很小的公司，设置了一个强大的技术平台，来支持众多的小团队进行游戏研发。这样一来，他们就可以专心创新，不用担心基础却又至关重要的技术支撑问题。恰恰是这家小公司，开创了中台的“玩法”，并将其运用到了极致。</span><br><span class="line">下面我们举个例子，通过IT行业的发展来进一步理解什么是中台？为什么要出现中台？</span><br></pre></td></tr></table></figure><p>传统IT时代</p><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305162119743.png" alt="image-20230516211621053"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在传统IT时代，无论项目如何复杂，都可以分为 前台 和 后台 两部分，简单明了。</span><br><span class="line">每一个业务线负责维护自己的前台和后台</span><br><span class="line">这里的前台不仅仅包含前端页面，还包含提供的各种服务</span><br><span class="line">后台指的是底层的服务，例如我们提取的一些工具服务</span><br><span class="line">在当时，项目的发展相对稳定，并不需要像互联网时代那么快速的去迭代和试错，所以这种架构没有什么问题。</span><br></pre></td></tr></table></figure><h4 id="传统IT时代存在的问题"><a href="#传统IT时代存在的问题" class="headerlink" title="传统IT时代存在的问题"></a>传统IT时代存在的问题</h4><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305162119728.png" alt="image-20230516211851281"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">发展到现在这个时代，传统的前台+后台这种架构是存在一些问题的，每一个产品线之间都会有一些重复的内容，例如这里面的用户模块和支付模块，每一个产品线都需要，如果每一个产品线都是自己开发自己的，这样就会有三套用户模块和支付模块，对于集团公司而言，这就叫重复造轮子。如果后期又增加了新的产品线，还要重新再开发用户模块和支付模块。</span><br><span class="line"></span><br><span class="line">所以说为了提高开发效率，我们有必要抽取出一个中间组织，为所有的产品线提供一些公共资源，这个中间组织就是中台。</span><br><span class="line"></span><br><span class="line">下面来看一个引入了中台之后的案例。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305162122689.png" alt="image-20230516212224583"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">本来是各个部门都建立了自己的数据采集，数仓，数据模型等内容，重复开发，浪费成本。各个部门的数据也没有打通，数据很难产生很大的价值。</span><br><span class="line">引入了中台之后，构建了统一的数据采集、统一的数据资产中心、统一的数据建模、分析与挖掘、统一的数据服务，最终向各部门统一提供数据支撑。</span><br></pre></td></tr></table></figure><h4 id="阿里”大中台小前台架构-”"><a href="#阿里”大中台小前台架构-”" class="headerlink" title="阿里”大中台小前台架构 ”"></a>阿里”大中台小前台架构 ”</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接下来这个是阿里的大中台 小前台架构</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305162125389.png" alt="image-20230516212502449"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">阿里许多产品线的共通业务经过下沉，形成了中台的各种业务中心，为各大业务线提供支持。</span><br><span class="line">这样前台应用就会更加灵活，想要构建一个新的前台应用也是比较快速容易的。</span><br></pre></td></tr></table></figure><h4 id="中台架构主要解决的问题"><a href="#中台架构主要解决的问题" class="headerlink" title="中台架构主要解决的问题"></a>中台架构主要解决的问题</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">下面我们来总结一下中台这种架构主要解决的问题。</span><br><span class="line"></span><br><span class="line">信息获取成本高，之前是每一个产品线都需要单独维护自己的数据，成本比较高。</span><br><span class="line">服务具有不确定性，通过中台可以以不变应万变</span><br><span class="line">互联互通成本高，不同产品线的数据想要打通成本过高。</span><br><span class="line">低水平重复建设，不同产品线需要重复建设相同的模块。</span><br><span class="line">通过中台，可以很好的解决这些问题。</span><br></pre></td></tr></table></figure><h4 id="中台的延伸"><a href="#中台的延伸" class="headerlink" title="中台的延伸"></a>中台的延伸</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">中台是一个大而全的概念，基于中台延伸出了多个方向</span><br><span class="line">技术中台</span><br><span class="line">移动中台</span><br><span class="line">业务中台</span><br><span class="line">数据中台</span><br><span class="line">研发中台</span><br><span class="line">组织中台</span><br><span class="line">等等…</span><br><span class="line"></span><br><span class="line">在这里我们可以把中台理解为航空母舰，这些中台都是基于这个航空母舰延伸出来的</span><br><span class="line"></span><br><span class="line">技术中台提供了技术支撑能力，帮助我们解决了基础设施，分布式数据库等底层技术问题，为前台特种兵提供了精良的武器装备。</span><br><span class="line"></span><br><span class="line">移动中台提供了战场一线火力支援能力，帮助我们提供更加个性化的服务，增强用户体验，为战场提供了陆军支援能力，随机应变，所向披靡。</span><br><span class="line">注意：这里的移动中台并不是说这个中台会移动，这里的移动表示的是移动端的意思，就是手机端。</span><br><span class="line"></span><br><span class="line">业务中台提供重用服务，例如用户中心，订单中心之类的开箱即用可重用能力，为战场提供了强大的后台炮火支援能力，随叫随到，威力强大。</span><br><span class="line"></span><br><span class="line">数据中台提供了数据分析能力，帮助我们从数据中学习改进，调整方向，为战场提供了强大及时的雷达监测能力，帮助我们掌控战场。</span><br><span class="line"></span><br><span class="line">研发中台提供了技术实践支撑能力，帮助我们快速搭建项目，管理进度，测试，持续集成，持续交付，是前台特种兵的训练基地及快速送达战场的机动运输部队。</span><br><span class="line"></span><br><span class="line">组织中台为我们的项目提供投资管理、风险管理、资源调度等，是战场的指挥部，战争的大脑，指挥前线，调度后方。</span><br></pre></td></tr></table></figure><h4 id="阿里中台技术栈全景"><a href="#阿里中台技术栈全景" class="headerlink" title="阿里中台技术栈全景"></a>阿里中台技术栈全景</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接下来我们来看一下阿里的中台技术栈全景</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305162133313.png" alt="image-20230516213309367"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">最下面是一些基础设施和基础中间件</span><br><span class="line">上层是业务中台和数据中台</span><br><span class="line">其中业务中台里面是以业务进行区分，抽取出来的一些公共组件，例如：会员中心，商品中心，交易中心、订单中心、支付中心、评价中心</span><br><span class="line">后期如果新增的产品线需要用到这些功能的时候可以从业务总台中直接开箱即用，提高效率。</span><br><span class="line">数据中台中包含大数据计算服务(包含离线和实时)、大数据开发套件(这里面包含的是一些小工具)、画像分析、数据可视化、数仓规则、数据服务等，可以实现数据的一站式接入和使用。</span><br><span class="line">移动中台包含了很多移动端的公共组件和功能。</span><br><span class="line">基于这些中台就可以快速为上层这些应用提供各种支持了。</span><br></pre></td></tr></table></figure><h3 id="什么是数据中台"><a href="#什么是数据中台" class="headerlink" title="什么是数据中台"></a>什么是数据中台</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">前面我们讲了什么是中台，中台其实是一个统称，基于中台也延伸出了很多分支。</span><br><span class="line">每一个分支深究起来都有很多内容，不过目前来说，在这些中台的分支里面，数据中台是最为火热的，因为数据是可以直接为企业决策提供支持，可以直接产生价值的。</span><br><span class="line"></span><br><span class="line">下面我们就来具体分析一下什么是数据中台</span><br><span class="line">针对数据中台的定义业内目前有很多种说法，没有官方的定义，不同的人有不同的理解。</span><br><span class="line"></span><br><span class="line">通俗来讲数据中台是指利用大数据技术，对海量数据统一进行采集、计算、存储，并且对外提供数据服务。</span><br><span class="line">数据中台的主要作用在于将企业内部所有数据统一处理形成标准化数据，挖掘出对企业最有价值的数据，构建企业数据资产库，对内对外提供一致的，高可用的大数据服务。</span><br><span class="line"></span><br><span class="line">正式一点来说，可以这样理解</span><br><span class="line">数据中台是一套可持续 ”让企业的数据用起来 ” 的机制</span><br><span class="line">通过数据中台把数据变为一种服务能力，既能提升决策水平，又能直接支撑企业业务</span><br><span class="line">数据中台不仅仅是技术，也不仅仅是产品，而是一套完整的让数据用起来的机制。</span><br><span class="line">数据中台不是单纯的技术叠加，不是一个技术化的大数据平台，二者有本质区别。</span><br><span class="line">大数据平台更关心技术层面的事情，包括研发效率，平台的大数据处理能力，针对的往往是技术人员</span><br><span class="line">而数据中台的核心是数据服务能力，数据中台不仅面向技术人员，更需要面向多个部门的业务人员。</span><br></pre></td></tr></table></figure><h3 id="数据中台的演进过程"><a href="#数据中台的演进过程" class="headerlink" title="数据中台的演进过程"></a>数据中台的演进过程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">数据中台并不是直接就有的，也是根据时代的发展，企业的需求，一步一步演进出来的。</span><br><span class="line">下面我们就来看一下数据中台的演进过程。</span><br><span class="line"></span><br><span class="line">1：最开始是 数据库阶段，主要是OLTP（联机事务处理）的需求；</span><br><span class="line">以淘宝为例，最开始淘宝还只是一个简单的网站，淘宝的整个结构就是前端的一些页面，加上后端的数据库，只是个简单的OLTP系统，主要就是交易的事务处理。</span><br><span class="line"></span><br><span class="line">这个阶段，互联网黄页才刚刚出现，数据来源大部分还是传统商业的ERP&#x2F;CRM的结构化数据，数据量并不大，也就是GB的级别。简单的数据库就能满足需求。</span><br><span class="line"></span><br><span class="line">随着淘宝用户超过100万，分析需求的比重就越来越大。淘宝需要知道它的交易来自于哪些地区，来自于哪些人，谁在买淘宝的东西等等，于是，就进入了数据处理的第二个阶段：数据仓库阶段。</span><br><span class="line"></span><br><span class="line">2：数据仓库阶段，OLAP（联机分析处理）成为主要需求；</span><br><span class="line">OLTP和OLAP对数据存储和计算的需求是不一样的，OLTP处理的是结构化的交易数据，而OLAP对应的是互联网数据，而互联网里面数据量最大的是日志，90%以上的数据都是用户点击之类的非结构化的日志数据，而且数据量已经达到了TB的级别。</span><br><span class="line"></span><br><span class="line">针对分析需求，就诞生了数据仓库，数据仓库主要解决大量数据的存储和计算需求，也就是把非结构化的数据转化成结构化数据，存储下来。</span><br><span class="line"></span><br><span class="line">这个阶段，数据仓库支持的主要就是BI和报表需求。</span><br><span class="line"></span><br><span class="line">随着数据量越来越大，从TB进入了PB级别，原来的技术架构越来越不能支持海量数据处理，这时候就进入了第三个阶段：数据平台阶段。</span><br><span class="line"></span><br><span class="line">3：数据平台阶段，主要解决BI和报表需求的技术问题；</span><br><span class="line">这个阶段解决的还是BI和报表需求，但是主要是在解决底层的技术问题，也就是数据库架构设计的问题。</span><br><span class="line"></span><br><span class="line">这在数据库技术领域被概括为「Shared Everything、Shared Nothing、或Shared Disk」，说的就是数据库架构设计本身的不同技术思路之争。</span><br><span class="line"></span><br><span class="line">Shared Everything一般是针对单个主机，完全透明共享CPU&#x2F;MEMORY&#x2F;IO，并行处理能力是最差的，典型的代表SQLServer。</span><br><span class="line"></span><br><span class="line">Shared Disk的代表是Oracle RAC，用户访问RAC就像访问一个数据库，但是这背后是一个集群，RAC来保证这个集群的数据一致性。</span><br><span class="line"></span><br><span class="line">问题在于Oracle RAC(实时应用集群)是基于IOE架构的（使用IBM的小型机、Oracle数据库、EMC存储设备）。在海量数据处理上，IOE架构有天然的限制，不适合未来的发展。</span><br><span class="line"></span><br><span class="line">Shared Nothing的代表就是Hadoop。Hadoop的并行处理和扩展能力更好。</span><br><span class="line"></span><br><span class="line">Hadoop的好处是如果要增加数据处理的能力和容量，只需要增加服务器就好，成本不高，在海量数据处理和大规模并行处理上有很大优势。</span><br><span class="line"></span><br><span class="line">综上所述，第三阶段就是，建立Shared Nothing的海量数据处理平台来解决数据存储成本增长过快的问题。</span><br><span class="line"></span><br><span class="line">4：数据中台阶段，通过系统来对接OLTP（事务处理）和OLAP（报表分析）的需求，强调数据业务化的能力。</span><br><span class="line">这个阶段的特征是数据量呈现指数级增长，从PB迈向了EB级别，未来会到什么量级，谁也说不清楚。</span><br><span class="line"></span><br><span class="line">主要是因为，2015年之后，IOT（物联网）发展起来，带动了视频、图像、声音数据的增长，未来90%的数据可能都来自于视频、图像、声音这些非结构化数据，这些数据需要视觉计算技术、图像解析引擎+视频解析引擎+音频解析引擎来转换成结构化数据。5G技术的发展，可能会进一步放大视频、图像、声音数据的重要性。</span><br><span class="line"></span><br><span class="line">线下要想和线上一样，通过数据来改善业务，就要和线上一样能做到行为可监测，数据可收集，这是前提。线下最大量的就是视频、图像、声音数据，而这些数据靠人来手工收集，肯定是不靠谱的，依靠IOT（物联网）技术和算法的进步，最终会通过智能端来自动化获取数据。</span><br><span class="line"></span><br><span class="line">要使用这些数据，光有视觉算法和智能端也不行，要有云来存储和处理这些数据，以及打通其它领域的数据。</span><br><span class="line"></span><br><span class="line">目前的数据中台，最底层的数据平台还是偏技术的，是中台技术方案的其中一个组件，主要解决数据存储和计算的问题；在往上面就是一层数据服务层，数据服务层通过服务化API能够把数据和前台的业务层对接；数据中台里面都是系统去做对接，通过智能算法，能把前台的分析需求和交易需求去做对接，最终赋能业务。</span><br></pre></td></tr></table></figure><h3 id="数据中台-VS-数据仓库"><a href="#数据中台-VS-数据仓库" class="headerlink" title="数据中台 VS 数据仓库"></a>数据中台 VS 数据仓库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">数据仓库主要支持管理决策和业务分析</span><br><span class="line">数据中台是将数据服务化之后提供给业务系统，目的是将数据能力渗透到各个业务环节，不限于决策分析类场景</span><br><span class="line">数据中台建设包含数据体系建设，也就是数据中台包含数据仓库的完整内容</span><br><span class="line">所以说数据仓库阶段的成果是可以转化到数据中台阶段的，并不会全部推倒重做。</span><br></pre></td></tr></table></figure><h3 id="数据中台需要具备的四大能力"><a href="#数据中台需要具备的四大能力" class="headerlink" title="数据中台需要具备的四大能力"></a>数据中台需要具备的四大能力</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">根据我们前面对数据中台的分析，总结起来，数据中台需要具备以下能力：</span><br><span class="line">1：数据汇聚整合</span><br><span class="line">随着业务的发展，企业内部往往有多个信息部门和数据中心，大量系统、功能和应用重复建设，存在巨大的数据资源、计算资源和人力资源的浪费，同时组织壁垒也会导致数据孤岛的出现，使得内外部数据难以全局规划，数据中台需要对数据进行整合和完善。</span><br><span class="line"></span><br><span class="line">2：数据提纯加工</span><br><span class="line">数据就像石油，需要经过提纯加工才能使用，这个过程就是数据资产化。</span><br><span class="line">数据中台必须联通全域数据，通过统一的数据标准和质量体系，建设提纯加工后的标准数据资产体系，以满足企业业务对数据的需求。</span><br><span class="line"></span><br><span class="line">3：数据服务可视化</span><br><span class="line">为了尽快让数据用起来，数据中台必须提供快捷，快速的数据服务能力，让相关人员能够迅速开发数据应用，支持数据资产场景化能力的快速输出，以响应客户的动态需求。</span><br><span class="line"></span><br><span class="line">4：数据价值变现</span><br><span class="line">数据中台通过打通企业数据，提供以前单个部门无法提供的数据服务能力，以实现数据的更大价值变现。</span><br></pre></td></tr></table></figure><h2 id="数据中台架构"><a href="#数据中台架构" class="headerlink" title="数据中台架构"></a>数据中台架构</h2><h3 id="数据中台总体架构图"><a href="#数据中台总体架构图" class="headerlink" title="数据中台总体架构图"></a>数据中台总体架构图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">前面我们通过理论层面对数据中台有了一定的了解，下面我们通过架构层面来详细看一下数据中台的设计</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171109254.png" alt="image-20230517110950057"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">数据中台是位于底层存储计算平台与上层的数据应用之间的一整套体系。</span><br><span class="line">数据中台屏蔽掉底层存储平台的计算技术复杂性，降低对技术人才的需求，让数据的使用成本更低。</span><br><span class="line">通过数据中台的数据汇聚、数据开发模块建立企业数据资产。</span><br><span class="line">通过数据体系对数据进行分层存储</span><br><span class="line">通过资产管理、数据服务，把数据资产变为数据服务能力，服务于企业业务。</span><br><span class="line">数据安全管理、数据运营体系，保障数据中台可以长期健康、持续运转。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">数据汇聚</span><br><span class="line">数据汇聚是数据中台数据接入的入口，数据中台本身不产生数据，所有的数据来自于业务系统，数据库、日志、文件等，这些数据分散在不同的网络环境和存储平台中，难以利用，很难产生业务价值，所以需要统一汇聚。</span><br><span class="line"></span><br><span class="line">数据开发</span><br><span class="line">数据开发是一整套数据加工以及处理的工具，因为通过数据汇聚模块汇聚到中台的数据没有经过处理，基本是按照数据的原始状态堆砌在一起的，这样业务是很难直接使用的。所以需要通过数据开发模块实现对数据的加工处理，形成有价值的数据，提供给业务部门使用。</span><br><span class="line"></span><br><span class="line">数据体系</span><br><span class="line">通过数据汇聚、数据开发，中台就具备了构建数仓平台的基本能力，这一块其实就是将采集过来的各种数据按照数仓的标准进行建设。</span><br><span class="line"></span><br><span class="line">数据资产管理</span><br><span class="line">通过数仓建立起来的数据资产比较偏向于技术，业务人员比较难理解，资产管理是以业务人员更好理解的方式，把数据资产展现给企业的业务人员。</span><br><span class="line"></span><br><span class="line">数据服务体系</span><br><span class="line">数据服务体系就是把数据变为一种服务能力，通过数据服务让数据参与到业务，激活整个数据中台，数据服务体系是数据中台存在的价值所在。</span><br><span class="line"></span><br><span class="line">数据运营体系</span><br><span class="line">是数据中台得以健康、持续运转的基础</span><br><span class="line"></span><br><span class="line">数据安全管理</span><br><span class="line">是为了保证数据中台中的数据安全。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这是一个典型的数据中台总体架构设计。</span><br></pre></td></tr></table></figure><h3 id="数据中台-四字箴言"><a href="#数据中台-四字箴言" class="headerlink" title="数据中台 四字箴言"></a>数据中台 四字箴言</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果大家之前没有工作过的话，可能对数据中台还是不好理解，所以在这我将数据中台的功能总结为四个字：采、存、通、用</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">下面我们来详细分析一下这四字箴言</span><br><span class="line"></span><br><span class="line">采</span><br><span class="line">采：表示采集的意思，就是采集企业中的所有数据。</span><br><span class="line">随着互联网、移动互联网、物联网等技术的兴起，企业的业务形态开始多元化，数据的产生形式也是多样化的，对应的就需要有多种采集形式</span><br><span class="line"></span><br><span class="line">埋点采集、硬件采集、爬虫采集、数据库采集、日志采集</span><br><span class="line"></span><br><span class="line">埋点采集：一般是采集用户行为信息，例如用户在平台上的浏览、点击、停留等行为</span><br><span class="line">硬件采集：指的是物联网数据采集，例如通过无人机传感器来采集空气质量指标</span><br><span class="line">爬虫采集：指的是采集互联网上的公开数据，例如：电商平台竞品价格采集</span><br><span class="line">数据库采集：一般是采集企业内的业务数据，例如：用户交易数据、用户个人信息数据等</span><br><span class="line">日志采集：一般是采集软件运行时产生的日志</span><br><span class="line"></span><br><span class="line">这些是常见的采集形式</span><br><span class="line"></span><br><span class="line">从数据组织形式可以分为：结构化数据、半结构化数据、非结构化数据</span><br><span class="line">结构化数据：数据规则、完整、能够通过二维逻辑来表现的数据，严格遵守数据格式与长度规范，常见的有数据库中的数据、excel中的数据</span><br><span class="line">半结构化数据：数据规则、完整，同样严格遵守数据格式与长度规范，但无法通过二维关系来表现，常见的有JSON、XML等格式的数据</span><br><span class="line">非结构化数据：数据结构不规则或不完整，不方便用二维逻辑表来表现，需要经过复杂的逻辑处理才能提取其中的信息内容，常见的有word文档、图片、视频、音频等数据</span><br><span class="line"></span><br><span class="line">从数据的时效性上来划分，可以分为：离线数据、实时数据</span><br><span class="line">离线数据：主要用于大批量数据的周期性迁移，对时效性要求不高，一般采用分布式批量数据同步的形式，通过连接读取数据，读取数据过程中可以有全量、增量的方式，经过统一处理后写入到目标存储。</span><br><span class="line">实时数据：主要面向低延时的数据应用场景，一般通过实时监控的方式实现，例如通过读取数据库的binlog日志来实现数据库的实时数据采集。</span><br><span class="line"></span><br><span class="line">前面我们针对数据的采集形式、数据的组织形式、数据的时效性进行了分析，那这些数据在采集的时候具体应该使用什么类型的工具呢？</span><br><span class="line"></span><br><span class="line">常见的采集工具有：Flume、FileBeat、Logstash、Sqoop、Canal、DataX等</span><br><span class="line">其中Flume、FileBeat、Logstash适合采集日志数据，这三个组件的特性在前面项目课程中已经详细分析过了，在这不再赘述。</span><br><span class="line">sqoop是在结构化数据和HDFS之间进行批量数据迁移的工具，适合批量采集数据库中的数据，它的主要优势是，在特定场景下，数据交换过程会有很大的性能提升。主要缺点是处理过程定制程度较高，需要在脚本中调整配置参数实现，在用户的一些自定义逻辑和数据同步链路监控方面比较薄弱。</span><br><span class="line">DataX是阿里开源的一套数据采集工具，提供数据采集全链路的流量监控，将作业本身的状态，数据流量，数据速度，执行速度等信息进行展示，提供脏数据探测功能，支持传输过程中对传输报错进行策略化处理。由于它是基于进程内读写直连的方式，高并发数据采集场景下对机器内存要求比较高。不过DataX不支持非结构化数据的采集。</span><br><span class="line"></span><br><span class="line">这些单个工具都无法很好的满足企业复杂的数据采集场景，所以我们需要对已有的采集工具进行二次开发，以可视化配置的方式提供给用户，屏蔽底层工具的复杂性，要支持常见的数据源采集：关系型数据库、NoSQL数据库、MQ、文件系统等，并且支持增量同步、全量同步等方式。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">存</span><br><span class="line">将数据采集过来之后，就需要考虑数据存储了。</span><br><span class="line">在这里我们可以将数据分为两种：静态数据和动态数据</span><br><span class="line">其中静态数据：是以 HDFS 、S3等分布式文件系统作为存储引擎，适用于高吞吐量的离线大数据分析场景。这类存储的局限性是数据无法进行随机的读写。</span><br><span class="line">动态数据：是以 HBase、Cassandra等NoSQL数据库作为存储引擎，适用于大数据随机读写的场景。这类存储的局限性是批量读取吞吐量远不如HDFS，不适合用于批量数据分析的场景。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">通</span><br><span class="line">表示是对数据进行加工计算，构建企业级数据仓库，打通企业中的全域数据。</span><br><span class="line">针对数据的加工计算，可以分为两大块，离线计算和实时计算</span><br><span class="line">离线计算中的代表框架为：MapReduce、Hive、和Spark</span><br><span class="line">实时计算中的代表框架为：Storm、SparkStreaming和Flink，针对实时计算，现在主要是以Flink为主了。</span><br><span class="line">针对这些计算框架，如果每一个计算任务都需要开发代码的话，对使用人员就不友好了，特别是针对一些业务人员，他们不会写代码，只会写SQL，所以这时候我们就需要开发一套基于SQL的一站式开发平台，底层引擎使用Spark和Flink，支持离线数据计算和实时数据计算。</span><br><span class="line">让用户彻底规避掉繁重的底层代码开发工作。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">用</span><br><span class="line">企业全域数据采集、存储，打通之后，就涉及到如何去用了。</span><br><span class="line">这里的”用” 包含很多层面。</span><br><span class="line">首先是包括数据资产管理，也可以称之为数据治理，其中包含数据元标准管理，数据标签管理，数据模型管理、元数据管理、数据质量管理等，保证数据中台里面数据的合理化和规范化，充分发挥数据的价值。</span><br><span class="line">对于数据的拥有者和管理者来说，通过对数据的合理管理和有效应用，能盘活并充分释放数据的巨大价值，但如果不能对数据进行有效管理，数据就用不起来，或者即使用起来也用不好，在这种情况下，堆积如山的无序数据给企业带来的是高昂的成本。</span><br><span class="line"></span><br><span class="line">在使用数据的时候还需要做好数据安全管理，随着大数据技术和应用的快速发展，数据所承载的多维度业务价值已被越来越多的挖掘和应用变现，随之而来的是数据安全和隐私已经成为世界性的关注点，上升到国家战略层面，最近闹得沸沸扬扬的特朗普要禁用国外版的抖音(TikTok)事件，特朗普的理由就是TikTok平台的数据对他们产生了威胁。</span><br><span class="line">所以说数据安全很有必要，整体的数据安全管理体系通过分层建设、分级防护，创造面向数据的安全管理体系系统框架，形成完整的数据安全管理体系。</span><br><span class="line">数据中台的建设，应该始终把数据安全管理放在最重要的位置上，通过设计完备的数据安全管理体系，多方面，多层次保障数据安全。</span><br><span class="line"></span><br><span class="line">最终我们需要把安全、有价值的数据快速方便的提供给上层应用，此时需要通过数据服务对外开放，也就是API接口的形式。</span><br><span class="line">举个例子，水是生命之源，是人们赖以生存和发展的重要物质资源，在日常生活中，可以通过不同的方式使用水，这也给我们的生活带来了巨大便利。</span><br><span class="line">在数据世界中，数据资产就好比日常生活中生命所需的水资源，无处不在且不可或缺。但是如果没有相应的水加工厂，运输管道，人们只能到水库打水喝，这明显会极大影响人们正常的生活和工作。因此，将数据封装成数据服务，以接口形式提供给上层应用，才能极大释放、提升数据资产的价值。</span><br><span class="line"></span><br><span class="line">最后总结一下，数据中台其实可以这样理解，采集企业全域数据，存储起来，通过加工计算打通数据之间的关系，最后以API接口的形式对外提供数据服务。这就是数据中台要做的事情。</span><br></pre></td></tr></table></figure><h2 id="什么样的企业适合建设数据中台"><a href="#什么样的企业适合建设数据中台" class="headerlink" title="什么样的企业适合建设数据中台"></a>什么样的企业适合建设数据中台</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">前面我们分析了什么是数据中台，数据中台的好处，以及数据中台的架构，是不是所有的企业都需要构建数据中台呢？</span><br><span class="line">不是的，下面就来看一下到底什么样的企业适合建设数据中台</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171128064.png" alt="image-20230517112856557"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">看这个案例：</span><br><span class="line">某企业下面有多个科研实体，每个科研实体下面有多个研究中心</span><br><span class="line">类似于一个集团公司，下面有多个子公司，每个子公司里面还有多个产品线。</span><br><span class="line">这种类型的企业业务复杂，有丰富的数据维度和多个业务场景，比较适合建设数据中台。</span><br><span class="line">初创型企业没有必要搭建数据中台，首先要解决的是生存问题，甚至于连数据仓库都没必要搭建，需要等企业走上正轨进入快速发展期的时候才需要构建数据仓库、数据中台。</span><br></pre></td></tr></table></figure><h3 id="数据应用成熟度的四个阶段"><a href="#数据应用成熟度的四个阶段" class="headerlink" title="数据应用成熟度的四个阶段"></a>数据应用成熟度的四个阶段</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">当然了，评价一个企业是否适合建设数据中台，也是有一些量化指标的，可以根据企业中的数据应用成熟度来进行判断，我们可以把企业中数据应用成熟度分为四个阶段</span><br><span class="line"></span><br><span class="line">统计分析</span><br><span class="line">决策支持</span><br><span class="line">数据驱动</span><br><span class="line">运营优化</span><br><span class="line"></span><br><span class="line">针对不同的阶段，从企业战略定位、企业数据形态、数据应用场景、数据应用工具、企业组织架构等多个方面，不同特征维度进行参考判定，也就构成了数据应用成熟度评估模型。</span><br><span class="line">依据这四个阶段的划分标准，企业可以进行数据应用成熟度的自我评测。</span><br><span class="line">数据应用成熟度越高，则代表数据对业务的支撑能力越强，数据应用成熟度越低，则意味着业务对数据的依赖程度越低。</span><br><span class="line"></span><br><span class="line">来看一下具体的评估模型。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171132712.png" alt="image-20230517113246298"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">第一阶段：统计分析阶段</span><br><span class="line">统计分析阶段主要有以下特征</span><br><span class="line">1：在企业战略方面，该阶段的企业战略定位纯粹以业务为驱动，主要以满足企业业务需求，实现业务流程的流程化、自动化为导向。</span><br><span class="line">2：在企业数据形态方面，该阶段的企业可能有少量的业务数据积累，但没有以数据为导向积累数据，数据主要以业务系统依托的关系型数据库进行存储，数据无组织，各业务数据分散存储和管理，数据维度单一，无数据质量管控。</span><br><span class="line">3：在数据应用场景方面，该阶段的数据应用场景只针对业务系统中的关键数据和指标，进行简单的、单一维度的统计分析和管理，辅助业务总结，每次基于业务目标的数据统计都需要定制化开发，如周报、月报等。</span><br><span class="line">4：在数据应用工具方面，该阶段业务报表主要以系统内嵌报表以及Excel报表为主，模式相对单一。</span><br><span class="line">5：在企业组织架构发面，该阶段企业无专门的数据相关部门，主要以IT部门的数据库运维管理和业务部门的数据分析师为主，需要数据报表时，一般用系统中定制的统计报表或者由特定业务部门提供Excel报表。</span><br><span class="line"></span><br><span class="line">如果对数据的应用仅停留在单系统、单维度的统计分析上，只用于对历史业务开展情况进行简单分析，数据并没有发挥出应有的价值，数据只是辅助企业了解业务运转的情况。我们希望能通过数据为业务决策提供支撑，因此就出现了第二阶段</span><br><span class="line"></span><br><span class="line">第二阶段：决策支持阶段</span><br><span class="line">决策支持阶段主要有以下特征</span><br><span class="line">1：在企业战略方面，该阶段，企业开始具备通过数据支撑经营决策的思路，并在考虑通过数据可视化的方式实现数据与业务的融合，以解决业务问题和支撑管理决策。</span><br><span class="line">2：在企业数据形态方面，企业开始注重业务过程中的数据积累，开始对各业务环节的数据进行汇聚、管理、数据维度逐渐丰富。以面向业务主体的指标体系为形式进行数据组织，开始注重数据质量的管控，实施数据质量控制。</span><br><span class="line">3：在数据应用场景方面，该阶段的数据应用场景开始基于数据仓库进行各业务主题的数据收集、管理、分析，为企业管理人员提供决策支持。</span><br><span class="line">4：在数据应用工具方面，开始针对数据收集和管理 建立数据仓库，数据开发工具和专业可视化工具，进行系统化数据收集、管理和分析。</span><br><span class="line">5：在企业组织架构发面，开始出现数据分析师的岗位，可能会设立专门的数据挖掘或商业智能部门来支撑企业进行数据化决策。</span><br><span class="line"></span><br><span class="line">无论是在统计分析阶段还是决策支撑阶段，业务的运转和数据之间依然是相互隔离的。企业对数据的应用都还停留在对部分维度的业务数据进行分析得到结果后，再由人工对业务进行不同程度的干预，最终实现业务优化。而我们希望能够让数据直接驱动业务变得更精准，更有效。最典型的应用场景就是类似于头条、抖音里面的个性化推荐功能，通过数据直接驱动业务的优化。所以就出现了第三阶段</span><br><span class="line"></span><br><span class="line">第三阶段：数据驱动阶段</span><br><span class="line"></span><br><span class="line">数据驱动阶段主要有以下特征</span><br><span class="line">1：在企业战略方面，企业开始将数据作为重要资产和生产资料，通过大数据技术对企业相关数据进行汇聚、打通和分析挖掘，为业务应用提供数据服务，通过数据驱动业务发展。</span><br><span class="line">2：在企业数据形态方面，业务数据积累具备一定规模，对结构化数据、非结构化数据进行处理与应用，根据需求进行数据清洗加工和标准化处理。</span><br><span class="line">3：在数据应用场景方面，该阶段的数据应用场景主要以满足业务需求为主，主要是用数据提升现有业务能力，进行智能化升级。</span><br><span class="line">4：在数据应用工具方面，在该阶段，企业开始通过大数据生态体系中的批计算、流计算等大数据处理技术进行数据汇聚和开发，并最终为现有的业务场景赋能，以驱动业务升级。</span><br><span class="line">5：在企业组织架构发面，在该阶段，企业开始正式设立独立的大数据部门。</span><br><span class="line"></span><br><span class="line">数据驱动阶段，数据其实已经与业务紧密结合，数据在业务运转过程中直接产生价值，但是，由于数据应用都是独立建设的，没有从全局考虑，企业在数据应用的过程中，经常会遇到标准口径不一致，内容重复建设，各业务数据无法融合产生更大的价值，企业数据价值无法被业务快速应用等问题，因此，出现了第四阶段</span><br><span class="line"></span><br><span class="line">第四阶段：运营优化阶段</span><br><span class="line">运营优化阶段主要有以下特征</span><br><span class="line">1：在企业战略方面，该阶段，企业开始建设数据中台，数据中台定位是为企业未来5~10年发展提供数据能力支撑，在DT时代对企业进行智能化升级。</span><br><span class="line">2：在企业数据形态方面，在该阶段，企业数据伴随数据驱动的业务快速发展，数据量快速增长，通过建立企业体系化，标准化的数据采集、存储、实现企业数据的全面资产化。</span><br><span class="line">3：在数据应用场景方面，在该阶段，数据应用通过统一的数据资产体系，提供统一、标准化的数据服务能力，为企业各类快速变化的业务应用提供数据服务支撑。</span><br><span class="line">4：在数据应用工具方面，建立一套体系化的数据汇聚、加工、管理、服务及应用体系，逐渐实现大数据能力工具化，工具平台化，平台智能化。</span><br><span class="line">5：在企业组织架构方面，在该阶段，企业组织架构中开始在管理层设置数据管理委员会来负责数据机制的建设和管理，将数据变为企业的一种独特资产。同时也会成立专门的资产运营部门，保障数据资产应用的合理性和效率，将更多的数据服务消费者引入到数据平台之中。</span><br><span class="line"></span><br><span class="line">这就是数据应用成熟度的四个阶段，目前中大型企业大部分处于从决策支持阶段转向数据驱动阶段，一些一线大型互联网企业正在处于从数据驱动阶段转向运营优化阶段。</span><br><span class="line">目前数据中台正处于快速发展阶段，成熟的大型公司都在开始着手构建数据中台。</span><br></pre></td></tr></table></figure><h3 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">下面有几个小案例，我们来分析一下</span><br><span class="line"></span><br><span class="line">企业A：类似于”万能钥匙 ”之类的工具类APP，随着DAU的增加，需要给用户提供个性化推荐内容</span><br><span class="line">目前比较合适的是启动一个内容推荐类的算法项目，在可预见的将来，看不到更多的数据场景，所以不适合建设数据中台。</span><br><span class="line"></span><br><span class="line">企业B：类似于”百果园 ”之类的连锁店，门店数量比较多，需要用大数据来精细化运营用户和商品</span><br><span class="line">因为具备了一定的门店规模和数据规模，可以实现一些个性化营销推送，商品猜你喜欢等功能，比较适合建设数据中台。</span><br><span class="line"></span><br><span class="line">企业C：类似于”华为 ”这样的多业态集团公司，旗下有多个业务板块，各个业务板块都有自己的数仓和报表</span><br><span class="line"></span><br><span class="line">这种属于多业态集团公司，是最适合建设数据中台的。</span><br></pre></td></tr></table></figure><h2 id="数据中台企业级解决方案"><a href="#数据中台企业级解决方案" class="headerlink" title="数据中台企业级解决方案"></a>数据中台企业级解决方案</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">前面我们对数据中台的理论进行分析，下面我们来看一下，数据中台在一些大型企业中的落地方案</span><br></pre></td></tr></table></figure><h3 id="阿里数据中台"><a href="#阿里数据中台" class="headerlink" title="阿里数据中台"></a>阿里数据中台</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在国内，”中台”的概念是阿里带头喊出来的，所以我们先来看一下阿里的数据中台方案</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171137113.png" alt="image-20230517113733709"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">最底层是计算和存储平台</span><br><span class="line">往上面是垂直数据中心，负责全域数据采集与引入，以需求为驱动，以数据多样性的全域思想为指导，采集与引入全业务、多终端、多形态的数据；</span><br><span class="line">再往上面是公共数据中心，按照基础层、公共中间层、应用层的数据分层架构模式，通过数据指标结构化、规范化的方式实现指标口径统一</span><br><span class="line">再往上面是萃取数据中心，形成以业务核心对象为中心的连接和标签体系，深度萃取数据价值</span><br><span class="line">再往上面是统一主题式服务，通过构建服务元数据中心和数据服务查询引擎，面向业务统一数据出口与数据查询逻辑，屏蔽多数据源与多物理表；</span><br><span class="line">左侧是数据资产管理：通过资产分析、应用、优化、运营等方面实现降低数据管理成本、追踪数据价值。</span><br><span class="line"></span><br><span class="line">最上层的是不同的产品线应用，通过下面的数据中台提供一站式数据服务支撑。</span><br><span class="line"></span><br><span class="line">阿里数据中台有三大核心：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171138752.png" alt="image-20230517113808804"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">OneData（统一数据）：定义数据标准与建模标准，对离线数据、实时数据建立数据资产体系</span><br><span class="line">OneEntity（统一实体）：主数据的管理，实现全域产品体系主数据融合</span><br><span class="line">OneService（统一服务）：统一对外提供API与SDK服务</span><br><span class="line">这就是阿里数据中台的三大核心。其实就是将全域数据统一标准，然后打通，最终统一对外提供数据服务。</span><br></pre></td></tr></table></figure><h3 id="菜鸟数据中台"><a href="#菜鸟数据中台" class="headerlink" title="菜鸟数据中台"></a>菜鸟数据中台</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171138932.png" alt="image-20230517113839690"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">整体技术架构，分三层，底层是基础设施，基础平台，中间是中台，上面是前台。</span><br><span class="line">有些同学可能会有困惑“数据中台和大数据平台”的区别是什么？</span><br><span class="line">图中的基础平台就是我们常说的大数据平台，包含了数据的采集、计算、加工等。</span><br><span class="line">数据中台是构建在整个大数据平台之上的，它是围绕数据运营、分析、应用等场景去做的一套解决方案。</span><br><span class="line"></span><br><span class="line">数据中台分成两块，一个是数据层，一个是服务层。数据层就是我们前面说的“数仓“，这里边包含菜鸟的所有数据，沉淀的数据资产。</span><br><span class="line">再往上是服务层，这里划分成了几个套件，每个套件都是围绕数据使用的一个场景做的解决方案 。</span><br><span class="line"></span><br><span class="line">右侧的东西是数据管理套件，从数据的加工生产到使用，它从全链路的视角把数据给管理起来。</span><br><span class="line"></span><br><span class="line">最上层是前台业务。</span><br></pre></td></tr></table></figure><h3 id="滴滴数据中台"><a href="#滴滴数据中台" class="headerlink" title="滴滴数据中台"></a>滴滴数据中台</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171146305.jpg" alt="图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">最底层是数据架构：数据架构体系包含了当前大数据领域主流的技术</span><br><span class="line"></span><br><span class="line">再往上面是数据研发，数据中间件，实现数据的采集，计算和数据质量监控。</span><br><span class="line"></span><br><span class="line">再往上面是数据资产体系，构建了数据字典和数据图谱，然后通过数据赋能，提供各种自助查询和可视化分析。</span><br><span class="line"></span><br><span class="line">最上层是数据服务层，将数据服务化提供给各个产品使用。</span><br></pre></td></tr></table></figure><h3 id="苏宁数据中台"><a href="#苏宁数据中台" class="headerlink" title="苏宁数据中台"></a>苏宁数据中台</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171145463.jpg" alt="图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">最底层是大数据计算存储引擎</span><br><span class="line">上层是数据开发套件，负责加工计算数据，</span><br><span class="line">然后是数据仓库主题域，构建多维度的数据主题，</span><br><span class="line">接下来是数据治理套件，管理数据模型，保证数据质量。</span><br><span class="line"></span><br><span class="line">再往上层是数据应用引擎，这里面包含了可视化引擎，数据服务引擎，数据分析引擎和画像引擎，通过这几个引擎对外提供数据服务。</span><br><span class="line"></span><br><span class="line">最上层是数据应用层，主要是使用数据的。</span><br></pre></td></tr></table></figure><h3 id="华为云数据中台"><a href="#华为云数据中台" class="headerlink" title="华为云数据中台"></a>华为云数据中台</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171145118.jpg" alt="图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">华为云数据中台在这里可以划分为三块</span><br><span class="line"></span><br><span class="line">第一块是数据建设：其实就是把全域数据采集过来，对数据加工计算，基于各种维度构建数据主题。</span><br><span class="line">第二块是平台建设：这里面抽取出来了一些公共的功能组件，并且提供了数据服务。</span><br><span class="line"></span><br><span class="line">第三块是中台消费场景，这里面会有多种场景依靠数据中台提供数据支撑。</span><br></pre></td></tr></table></figure><h3 id="浙江移动数据中台"><a href="#浙江移动数据中台" class="headerlink" title="浙江移动数据中台"></a>浙江移动数据中台</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171144694.jpg" alt="图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">浙江移动打造的数据中台，是为了实现跨域数据整合并沉淀公共的数据能力，同时提供丰富的数据模型，标准化的数据服务，个性化的开发平台与工具，满足一线数据开放和智慧运营的要求。</span><br><span class="line">这个数据中台架构中主要包含了三块内容</span><br><span class="line">数据模型、数据服务和数据开发。</span><br><span class="line"></span><br><span class="line">数据模型：负责实现数据与数据模型打通。</span><br><span class="line">数据服务：负责封装标准数据服务，对外提供数据查询服务</span><br><span class="line">数据开发：针对各种个性化数据应用开发需求提供技术支持</span><br></pre></td></tr></table></figure><h3 id="某大数据服务商数据中台"><a href="#某大数据服务商数据中台" class="headerlink" title="某大数据服务商数据中台"></a>某大数据服务商数据中台</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171142475.png" alt="image-20230517114238211"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">底层是基础设施和计算层</span><br><span class="line">往上面是数据开发治理模块，里面涉及离线数据开发、实时数据开发和算法开发。</span><br><span class="line">再往上层是数据服务层，这里面会对数据进行体系化，最终对外提供服务。</span><br><span class="line">最上层是业务应用层，这里会通过数据服务提供数据支撑。</span><br></pre></td></tr></table></figure><h3 id="某企业数据大脑"><a href="#某企业数据大脑" class="headerlink" title="某企业数据大脑"></a>某企业数据大脑</h3><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171141192.png" alt="image-20230517114128072"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这个是某企业的数据大脑总体设计，里面包含了数据中台。</span><br><span class="line">数据大脑主要是为了解决大数据系统建设中数据存储、连通、使用的共性问题，形成业务数据中台，包括数据资源的统一规划，数据整体建模和资产管理，数据标签化计算，形成不同行业的数据体系。</span><br><span class="line">将行业知识库和领域数据相结合，开发各类计算组件，构建统一数据加工平台，对数据进行加工整理支撑行业应用，形成相关领域行业的数据大脑。</span><br><span class="line"></span><br><span class="line">这里面的数据中台主要包含以下内容：</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171141182.png" alt="image-20230517114145986"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">到这为止，我们分析了多个企业的数据中台，虽然这些企业的数据中台架构没有完全一样的，但是总结下来我们会发现，他们里面都会有一些共同的核心内容。</span><br><span class="line">数据采集存储、数据加工计算，整合打通各个维度数据，最后对外提供数据服务。</span><br><span class="line">其实精简之后就是我在前面给大家总结的数据中台四字箴言，采存通用。</span><br><span class="line"></span><br><span class="line">希望通过我们前面的学习能够然大家对数据中台有一个整体的认识。</span><br></pre></td></tr></table></figure><h2 id="数据中台之数据加工总线"><a href="#数据中台之数据加工总线" class="headerlink" title="数据中台之数据加工总线"></a>数据中台之数据加工总线</h2><h3 id="目前大数据领域实时计算的现状"><a href="#目前大数据领域实时计算的现状" class="headerlink" title="目前大数据领域实时计算的现状"></a>目前大数据领域实时计算的现状</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">随着大数据行业的整体发展，企业对实时计算的需求越来越多，特别是在构建实时数仓的时候，需要接入很多实时数据源，并且数仓还是分层的，针对每一层的数据都需要进行实时计算，此时就需要开发很多实时计算程序，实时计算程序的复用性很低，针对每一种类型的数据都需要开发对应的实时计算程序，开发成本高，并且对程序员也不友好，需要专门的大数据开发工程师，所以我们希望在实时计算领域能够提供类似HiveSQL的功能，直接写SQL就能实现实时计算任务，不需要每次都写一堆的代码，提高工作效率，尽可能让会只会SQL的普通开发人员也能轻松的开发实时计算任务。</span><br><span class="line"></span><br><span class="line">为了解决这个痛点，于是，我们研发了数据加工总线平台，也可以称之为数据实时流转平台。</span><br></pre></td></tr></table></figure><h3 id="什么是数据加工总线"><a href="#什么是数据加工总线" class="headerlink" title="什么是数据加工总线"></a>什么是数据加工总线</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">为了使实时数据的处理能够更加高效、简单，所以我们研发了一站式实时数据开发平台。只需要在页面选择数据源、目的地以及对应的SQL计算逻辑，就可以轻松实现海量实时数据计算任务的开发。</span><br><span class="line"></span><br><span class="line">这个平台主要的功能就是支持SQL实现实时数据计算任务的开发。</span><br><span class="line"></span><br><span class="line">我们期望达到的目标，通过这套平台，可以实现用SQL解决80%以上的实时数据计算需求。</span><br></pre></td></tr></table></figure><h3 id="数据加工总线原型图总览"><a href="#数据加工总线原型图总览" class="headerlink" title="数据加工总线原型图总览"></a>数据加工总线原型图总览</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">由于数据加工总线涉及前端和后端，在企业中前端代码有专门的同事负责开发，我们大数据部门只需要负责后台功能开发即可，所以在课程中不涉及前端页面代码，在这里通过原型图来演示一下数据加工总线具体的使用流程，加深大家的理解。</span><br><span class="line">注意：原型图只能在这里给大家演示一下，不能发出去，希望大家理解。</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171152004.jpg" alt="图片描述"></p><h3 id="数据加工总线架构图V1-0"><a href="#数据加工总线架构图V1-0" class="headerlink" title="数据加工总线架构图V1.0"></a>数据加工总线架构图V1.0</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接下来看一下数据加工总线的后台架构图</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/ttyong/hexoBlog/raw/master/%E6%9E%97%E5%AD%90%E9%9B%A8%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/202305171154966.jpg" alt="图片描述"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">数据源和目的地都是Kafka，因为目前在大数据领域，实时数据一般都是用的Kafka。</span><br><span class="line">中间就是我们需要开发的核心计算引擎，基于SparkSQL封装的实时SQL计算引擎。</span><br><span class="line">为什么在这要选择使用SparkSQL？</span><br><span class="line">因为SparkSQL在我们公司已经广泛应用了很长时间了，并且Spark框架本身也迭代了很多版本了，比较稳定，整个生态圈也比较完善。所以前期在技术选型的时候优先考虑的是底层计算引擎的稳定性。</span><br><span class="line">还有就是秒级别的延时是可以满足业务需求的，所以当时SparkSQL+SparkStreaming是最好的方案。</span><br><span class="line">Flink当时版本还不是很稳定，FlinkSQL也是刚出现没多久，所以没有直接使用Flink。</span><br><span class="line">当时我们也考虑了，等第一个版本稳定了以后，后期再把FlinkSQL也增加进来，提供两套底层计算引擎，可以根据需求进行动态切换。</span><br><span class="line"></span><br><span class="line">针对这里面的数据字段和数据模型的概念做一下解释</span><br><span class="line">由于我们需要在SparkSQL中基于kafka的数据进行建表，kafka中的数据我们使用的是json格式的，json格式的数据只有字段名称，缺少字段类型信息，官方一点来说其实就是缺少元数据信息，所以需要针对kafka中的数据定义元数据，这样才能在SparkSQL中建表。</span><br><span class="line"></span><br><span class="line">注意：元数据的定义是在数据治理子系统中维护的。</span><br></pre></td></tr></table></figure><hr><blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
      
    
    </summary>
    
    
      <category term="大数据开发工程师" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/"/>
    
      <category term="大数据" scheme="http://tianyong.fun/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="直播平台三度关系推荐v2.0" scheme="http://tianyong.fun/tags/%E7%9B%B4%E6%92%AD%E5%B9%B3%E5%8F%B0%E4%B8%89%E5%BA%A6%E5%85%B3%E7%B3%BB%E6%8E%A8%E8%8D%90v2-0/"/>
    
  </entry>
  
</feed>
